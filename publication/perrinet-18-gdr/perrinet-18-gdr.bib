@inproceedings{Perrinet18gdr,
 abstract = {Recording eye movements is a technique that attracts an increasing number of scientists, but also in the general public. Indeed, this allows to quantitatively measure a number of useful dimensions of perception and behavior in general. However, most existing trackers rely on expensive or technically complex solutions. Here, we propose a simple framework to record eye movements using any camera, such as a webcam. As a proof of concept, the recorded image is processed in real-time to detect from a simple sub-set of eye movements : left, center, right or blink. The processing is based on two stages. First, we use a pre-trained computer vision algorithm to extract the image of the face. Second, we used a classical deep-learning architecture to learn to classify these sub-images. This network is a 3 layered convolutional neural network, for which we optimized performance as measured by the accuracy with cross-validation on a wide range of the network's hyper-parameters. Over a dataset of more than 1000 images, this network achieves an average accuracy of approximately 97%. We also provide with an integration with the psychopy library which shows that frames can be processed on a standard laptop at a rate of approximately 25Hz.},
 annote = { * poster presented @ [[https://gdrvision2018.sciencesconf.org/|GDR vision, Paris]].
* program : https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf
* poster : https://github.com/laurentperrinet/Perrinet18gdr/raw/master/Perrinet18gdr.pdf
* poster (code) : https://github.com/laurentperrinet/Perrinet18gdr
* source code for this framework: https://github.com/laurentperrinet/CatchTheEye
## * general presentation: LeCheapEyeTracker
## * code : https://github.com/laurentperrinet/LeCheapEyeTracker},
 author = {Perrinet, Laurent},
 bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Publications/Perrinet18gdr},
 booktitle = {GDR Vision, Paris, 2018},
 date-added = {2019-02-25 23:43:42 +0100},
 date-modified = {2019-02-25 23:44:59 +0100},
 keywords = {motion anticipation},
 projects = {pace-itn},
 title = {A low-cost, accessible eye tracking framework},
 url = {http://invibe.net/LaurentPerrinet/Publications/Perrinet18gdr},
 year = {2018}
}

