@inproceedings{Perrinet18gdr,
 abstract = {Recording eye movements is a technique that attracts an increasing number of scientists, but also in the general public. Indeed, this allows to quantitatively measure a number of useful dimensions of perception and behavior in general. However, most existing trackers rely on expensive or technically complex solutions. Here, we propose a simple framework to record eye movements using any camera, such as a webcam. As a proof of concept, the recorded image is processed in real-time to detect from a simple sub-set of eye movements : left, center, right or blink. The processing is based on two stages. First, we use a pre-trained computer vision algorithm to extract the image of the face. Second, we used a classical deep-learning architecture to learn to classify these sub-images. This network is a 3 layered convolutional neural network, for which we optimized performance as measured by the accuracy with cross-validation on a wide range of the network's hyper-parameters. Over a dataset of more than 1000 images, this network achieves an average accuracy of approximately 97 percent. We also provide with an integration with the psychopy library which shows that frames can be processed on a standard laptop at a rate of approximately 25 Hz.},
 author = {Perrinet, Laurent U},
 bdsk-url-1 = {https://github.com/laurentperrinet/Perrinet18gdr},
 booktitle = {GDR Vision, Paris, 2018},
 date-added = {2019-02-25 23:43:42 +0100},
 date-modified = {2019-09-01 16:38:50 +0300},
 keywords = {motion anticipation},
 pdf = {https://github.com/laurentperrinet/Perrinet18gdr/raw/master/Perrinet18gdr.pdf},
 projects = {pace-itn},
 title = {A low-cost, accessible eye tracking framework},
 url = {https://github.com/laurentperrinet/Perrinet18gdr},
 year = {2018}
}

