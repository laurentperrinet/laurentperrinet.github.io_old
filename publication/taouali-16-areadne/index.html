<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Laurent U Perrinet">

  
  
  
    
  
  <meta name="description" content="Natural scenes generally contain objects in motion. The local orientation of their contours and the direction of motion are two essential components of visual information which are processed in parallel in the early visual areas. Focusing on the primary visual cortex of the macaque monkey (V1), we challenged different models for the joint representation of orientation and direction within the neural activity. Precisely, we considered the response of V1 neurons to an oriented moving bar to investigate whether, and how, the information about the bar&#39;s orientation and direction could be encoded dynamically at the population activity level. For that purpose, we used a decoding approach based on a space-time receptive field model that encodes jointly orientation and direction. We based our decoding approach on the statistics of natural scenes by first determining optimal space-time receptive fields (RFs) that encode orientation and direction. For this, we first derived a set of dynamic filters from a database of natural images~[1] and following an unsupervised learning rule~[2]. More generally, this allows us to propose a dynamic generative model for the joint coding of orientation and direction. Then, using this model and a maximum likelihood paradigm, we infer the most likely representation for a given network activity~[3, 4]. We tested this model on surrogate data and on extracellular recordings in area emphV1 (67 cells) of awake macaque monkeys in response to oriented bars moving in $12$ different directions. Using a cross-validation method we could robustly decode both the orientation and the direction of the bar within the classical receptive field (cRF). Furthermore, this decoding approach shows different properties: First, information about the orientation of the bar is emerging ıt before entering the cRF if the trajectory of the bar is long enough. Second, when testing different orientations with the same direction, our approach unravels that we can decode the direction and the orientation independently. Moreover, we found that, similarly to orientation decoding, the decoding of direction is dynamic but weaker. Finally, our results demonstrate that the orientation and the direction of motion of an ambiguous moving bar can be progressively decoded in V1. This is a signature of a dynamic solution to the aperture problem in area V1, similarly to what was already found in area MT~[5]. $[1]$ J. Burge, W. Geisler. Optimal speed estimation in natural image movies predicts human performance. Nature Communications, 6, 7900. http://doi.org/10.1038/ncomms8900, 2015.  $[2]$ L. Perrinet. Role of homeostasis in learning sparse representations. ıt Neural Computation, 22(7):1812--36, 2010.  $[3]$ M. Jazayeri and J.A. Movshon. Optimal representation of sensory information by neural populations. ıt Nature Neuroscience, 9(5):690--696, 2006. $[4]$ W. Taouali, G. Benvenuti, P. Wallisch, F. Chavane, L. Perrinet. Testing the Odds of Inherent versus Observed Over-dispersion in Neural Spike Counts. ıt Journal of Neurophysiology, 2015. $[5]$ C. Pack, R. Born. Temporal dynamics of a neural solution to the aperture problem in visual area MT of macaque brain. ıt Nature, 409(6823), 1040--1042. 2001.">

  
  <link rel="alternate" hreflang="en-us" href="https://laurentperrinet.github.io/publication/taouali-16-areadne/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-140381649-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-140381649-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://laurentperrinet.github.io/publication/taouali-16-areadne/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@laurentperrinet">
  <meta property="twitter:creator" content="@laurentperrinet">
  
  <meta property="og:site_name" content="Novel visual computations">
  <meta property="og:url" content="https://laurentperrinet.github.io/publication/taouali-16-areadne/">
  <meta property="og:title" content="A dynamic model for decoding direction and orientation in macaque primary visual cortex | Novel visual computations">
  <meta property="og:description" content="Natural scenes generally contain objects in motion. The local orientation of their contours and the direction of motion are two essential components of visual information which are processed in parallel in the early visual areas. Focusing on the primary visual cortex of the macaque monkey (V1), we challenged different models for the joint representation of orientation and direction within the neural activity. Precisely, we considered the response of V1 neurons to an oriented moving bar to investigate whether, and how, the information about the bar&#39;s orientation and direction could be encoded dynamically at the population activity level. For that purpose, we used a decoding approach based on a space-time receptive field model that encodes jointly orientation and direction. We based our decoding approach on the statistics of natural scenes by first determining optimal space-time receptive fields (RFs) that encode orientation and direction. For this, we first derived a set of dynamic filters from a database of natural images~[1] and following an unsupervised learning rule~[2]. More generally, this allows us to propose a dynamic generative model for the joint coding of orientation and direction. Then, using this model and a maximum likelihood paradigm, we infer the most likely representation for a given network activity~[3, 4]. We tested this model on surrogate data and on extracellular recordings in area emphV1 (67 cells) of awake macaque monkeys in response to oriented bars moving in $12$ different directions. Using a cross-validation method we could robustly decode both the orientation and the direction of the bar within the classical receptive field (cRF). Furthermore, this decoding approach shows different properties: First, information about the orientation of the bar is emerging ıt before entering the cRF if the trajectory of the bar is long enough. Second, when testing different orientations with the same direction, our approach unravels that we can decode the direction and the orientation independently. Moreover, we found that, similarly to orientation decoding, the decoding of direction is dynamic but weaker. Finally, our results demonstrate that the orientation and the direction of motion of an ambiguous moving bar can be progressively decoded in V1. This is a signature of a dynamic solution to the aperture problem in area V1, similarly to what was already found in area MT~[5]. $[1]$ J. Burge, W. Geisler. Optimal speed estimation in natural image movies predicts human performance. Nature Communications, 6, 7900. http://doi.org/10.1038/ncomms8900, 2015.  $[2]$ L. Perrinet. Role of homeostasis in learning sparse representations. ıt Neural Computation, 22(7):1812--36, 2010.  $[3]$ M. Jazayeri and J.A. Movshon. Optimal representation of sensory information by neural populations. ıt Nature Neuroscience, 9(5):690--696, 2006. $[4]$ W. Taouali, G. Benvenuti, P. Wallisch, F. Chavane, L. Perrinet. Testing the Odds of Inherent versus Observed Over-dispersion in Neural Spike Counts. ıt Journal of Neurophysiology, 2015. $[5]$ C. Pack, R. Born. Temporal dynamics of a neural solution to the aperture problem in visual area MT of macaque brain. ıt Nature, 409(6823), 1040--1042. 2001."><meta property="og:image" content="https://laurentperrinet.github.io/img/hulk.png">
  <meta property="twitter:image" content="https://laurentperrinet.github.io/img/hulk.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-09-17T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-03-22T14:03:54&#43;01:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laurentperrinet.github.io/publication/taouali-16-areadne/"
  },
  "headline": "A dynamic model for decoding direction and orientation in macaque primary visual cortex",
  
  "datePublished": "2019-09-17T00:00:00Z",
  "dateModified": "2020-03-22T14:03:54+01:00",
  
  "author": {
    "@type": "Person",
    "name": "Wahiba Taouali"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Novel visual computations",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laurentperrinet.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "Natural scenes generally contain objects in motion. The local orientation of their contours and the direction of motion are two essential components of visual information which are processed in parallel in the early visual areas. Focusing on the primary visual cortex of the macaque monkey (V1), we challenged different models for the joint representation of orientation and direction within the neural activity. Precisely, we considered the response of V1 neurons to an oriented moving bar to investigate whether, and how, the information about the bar's orientation and direction could be encoded dynamically at the population activity level. For that purpose, we used a decoding approach based on a space-time receptive field model that encodes jointly orientation and direction. We based our decoding approach on the statistics of natural scenes by first determining optimal space-time receptive fields (RFs) that encode orientation and direction. For this, we first derived a set of dynamic filters from a database of natural images~[1] and following an unsupervised learning rule~[2]. More generally, this allows us to propose a dynamic generative model for the joint coding of orientation and direction. Then, using this model and a maximum likelihood paradigm, we infer the most likely representation for a given network activity~[3, 4]. We tested this model on surrogate data and on extracellular recordings in area emphV1 (67 cells) of awake macaque monkeys in response to oriented bars moving in $12$ different directions. Using a cross-validation method we could robustly decode both the orientation and the direction of the bar within the classical receptive field (cRF). Furthermore, this decoding approach shows different properties: First, information about the orientation of the bar is emerging ıt before entering the cRF if the trajectory of the bar is long enough. Second, when testing different orientations with the same direction, our approach unravels that we can decode the direction and the orientation independently. Moreover, we found that, similarly to orientation decoding, the decoding of direction is dynamic but weaker. Finally, our results demonstrate that the orientation and the direction of motion of an ambiguous moving bar can be progressively decoded in V1. This is a signature of a dynamic solution to the aperture problem in area V1, similarly to what was already found in area MT~[5]. $[1]$ J. Burge, W. Geisler. Optimal speed estimation in natural image movies predicts human performance. Nature Communications, 6, 7900. http://doi.org/10.1038/ncomms8900, 2015.  $[2]$ L. Perrinet. Role of homeostasis in learning sparse representations. ıt Neural Computation, 22(7):1812--36, 2010.  $[3]$ M. Jazayeri and J.A. Movshon. Optimal representation of sensory information by neural populations. ıt Nature Neuroscience, 9(5):690--696, 2006. $[4]$ W. Taouali, G. Benvenuti, P. Wallisch, F. Chavane, L. Perrinet. Testing the Odds of Inherent versus Observed Over-dispersion in Neural Spike Counts. ıt Journal of Neurophysiology, 2015. $[5]$ C. Pack, R. Born. Temporal dynamics of a neural solution to the aperture problem in visual area MT of macaque brain. ıt Nature, 409(6823), 1040--1042. 2001."
}
</script>

  

  


  


  





  <title>A dynamic model for decoding direction and orientation in macaque primary visual cortex | Novel visual computations</title>

</head>
<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  









<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Novel visual computations</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Novel visual computations</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Featured</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Events</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people"><span>People</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#grants"><span>Grants</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/sciblog/" target="_blank" rel="noopener"><span>BlogBook</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <div class="pub">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>A dynamic model for decoding direction and orientation in macaque primary visual cortex</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span >Wahiba Taouali</span>, <span >Giacomo Benvenuti</span>, <span >Frédéric Y Chavane</span>, <span >Laurent U Perrinet</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2016-01-01
  </span>
  

  

  

  
  
  

  
  

</div>

    








  




  



<div class="btn-links mb-3">
  
  








  



<a class="btn btn-outline-primary my-1 mr-1" href="/publication/taouali-16-areadne/taouali-16-areadne.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 js-cite-modal"
        data-filename="/publication/taouali-16-areadne/cite.bib">
  Cite
</button>













<a class="btn btn-outline-primary my-1 mr-1" href="https://doi.org/10.1167/15.12.484" target="_blank" rel="noopener">
  DOI
</a>



</div>


  
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">Natural scenes generally contain objects in motion. The local orientation of their contours and the direction of motion are two essential components of visual information which are processed in parallel in the early visual areas. Focusing on the primary visual cortex of the macaque monkey (V1), we challenged different models for the joint representation of orientation and direction within the neural activity. Precisely, we considered the response of V1 neurons to an oriented moving bar to investigate whether, and how, the information about the bar&rsquo;s orientation and direction could be encoded dynamically at the population activity level. For that purpose, we used a decoding approach based on a space-time receptive field model that encodes jointly orientation and direction. We based our decoding approach on the statistics of natural scenes by first determining optimal space-time receptive fields (RFs) that encode orientation and direction. For this, we first derived a set of dynamic filters from a database of natural images~[1] and following an unsupervised learning rule~[2]. More generally, this allows us to propose a dynamic generative model for the joint coding of orientation and direction. Then, using this model and a maximum likelihood paradigm, we infer the most likely representation for a given network activity~[3, 4]. We tested this model on surrogate data and on extracellular recordings in area emphV1 (67 cells) of awake macaque monkeys in response to oriented bars moving in $12$ different directions. Using a cross-validation method we could robustly decode both the orientation and the direction of the bar within the classical receptive field (cRF). Furthermore, this decoding approach shows different properties: First, information about the orientation of the bar is emerging ıt before entering the cRF if the trajectory of the bar is long enough. Second, when testing different orientations with the same direction, our approach unravels that we can decode the direction and the orientation independently. Moreover, we found that, similarly to orientation decoding, the decoding of direction is dynamic but weaker. Finally, our results demonstrate that the orientation and the direction of motion of an ambiguous moving bar can be progressively decoded in V1. This is a signature of a dynamic solution to the aperture problem in area V1, similarly to what was already found in area MT~[5]. $[1]$ J. Burge, W. Geisler. Optimal speed estimation in natural image movies predicts human performance. Nature Communications, 6, 7900. <a href="http://doi.org/10.1038/ncomms8900,">http://doi.org/10.1038/ncomms8900,</a> 2015.  $[2]$ L. Perrinet. Role of homeostasis in learning sparse representations. ıt Neural Computation, 22(7):1812&ndash;36, 2010.  $[3]$ M. Jazayeri and J.A. Movshon. Optimal representation of sensory information by neural populations. ıt Nature Neuroscience, 9(5):690&ndash;696, 2006. $[4]$ W. Taouali, G. Benvenuti, P. Wallisch, F. Chavane, L. Perrinet. Testing the Odds of Inherent versus Observed Over-dispersion in Neural Spike Counts. ıt Journal of Neurophysiology, 2015. $[5]$ C. Pack, R. Born. Temporal dynamics of a neural solution to the aperture problem in visual area MT of macaque brain. ıt Nature, 409(6823), 1040&ndash;1042. 2001.</p>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            
            
            <a href="/publication/#1">
              Conference paper
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9"><em>Proceedings of AREADNE</em></div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"></div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/coding-decoding/">coding decoding</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://laurentperrinet.github.io/publication/taouali-16-areadne/&amp;text=A%20dynamic%20model%20for%20decoding%20direction%20and%20orientation%20in%20macaque%20primary%20visual%20cortex" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://laurentperrinet.github.io/publication/taouali-16-areadne/&amp;t=A%20dynamic%20model%20for%20decoding%20direction%20and%20orientation%20in%20macaque%20primary%20visual%20cortex" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=A%20dynamic%20model%20for%20decoding%20direction%20and%20orientation%20in%20macaque%20primary%20visual%20cortex&amp;body=https://laurentperrinet.github.io/publication/taouali-16-areadne/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://laurentperrinet.github.io/publication/taouali-16-areadne/&amp;title=A%20dynamic%20model%20for%20decoding%20direction%20and%20orientation%20in%20macaque%20primary%20visual%20cortex" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=A%20dynamic%20model%20for%20decoding%20direction%20and%20orientation%20in%20macaque%20primary%20visual%20cortex%20https://laurentperrinet.github.io/publication/taouali-16-areadne/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://laurentperrinet.github.io/publication/taouali-16-areadne/&amp;title=A%20dynamic%20model%20for%20decoding%20direction%20and%20orientation%20in%20macaque%20primary%20visual%20cortex" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
    
    





  
    
    
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/wahiba-taouali/avatar_hu029f67fb37dda8ae792ac4a8ef7262e0_7582_270x270_fill_q90_lanczos_center.jpg" alt="Wahiba Taouali">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/author/wahiba-taouali/">Wahiba Taouali</a></h5>
        <h6 class="card-subtitle">PostDoc in Computational Neuroscience</h6>
        <p class="card-text">Motion Integration By V1 Population  (Post-Doc, 2013-03 / 2015-01).</p>
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.uk/citations?user=oHLjQTEAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/wahiba-taouali/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/taoualiw" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  


  
    
    





  


  
    
    





  
    
    
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/frederic-chavane/avatar_hu939e22bfda132e5dfe756f4281477277_68002_270x270_fill_lanczos_center_2.png" alt="Frédéric Chavane">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/author/frederic-chavane/">Frédéric Chavane</a></h5>
        
        
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://www.researchgate.net/profile/Frederic_Chavane" target="_blank" rel="noopener">
        <i class="ai ai-researchgate"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.uk/citations?user=LT0P6OwAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  


  
    
    





  
    
    
    
      
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/laurent-u-perrinet/avatar_hu34ad5b8db880542c60288aed1996fc62_245755_270x270_fill_q90_lanczos_center.jpeg" alt="Laurent U Perrinet">
      

      <div class="media-body">
        <h5 class="card-title"><a href="https://laurentperrinet.github.io/">Laurent U Perrinet</a></h5>
        <h6 class="card-subtitle">Researcher in Computational Neuroscience</h6>
        <p class="card-text">My research interests include Machine Learning and computational neuroscience applied to Vision.</p>
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/laurentperrinet" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.uk/citations?user=TVyUV38AAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="http://www.researcherid.com/rid/C-4900-2009" target="_blank" rel="noopener">
        <i class="ai ai-researcherid"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://www.zotero.org/groups/2485979/laurent_perrinet/library" target="_blank" rel="noopener">
        <i class="ai ai-zotero"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://publons.com/a/1206845/" target="_blank" rel="noopener">
        <i class="ai ai-publons"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="http://orcid.org/0000-0002-9536-010X" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://arxiv.org/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Perrinet%2C&#43;L&amp;terms-0-field=author&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first" target="_blank" rel="noopener">
        <i class="ai ai-arxiv"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://publons.com/a/1206845/" target="_blank" rel="noopener">
        <i class="ai ai-publons"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/laurentperrinet" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.instagram.com/laurentperrinet/" target="_blank" rel="noopener">
        <i class="fab fa-instagram"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/laurent-perrinet-1857b9/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  


  












  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/publication/taouali-15-vss/">A dynamic model for decoding direction and orientation in macaque primary visual cortex</a></li>
      
      <li><a href="/publication/perrinet-19-nccd/">A dynamic model for decoding direction and orientation in macaque primary visual cortex</a></li>
      
      <li><a href="/publication/taouali-15-icmns/">On overdispersion in neuronal evoked activity</a></li>
      
      <li><a href="/publication/taouali-16/">Testing the odds of inherent vs. observed overdispersion in neural spike counts</a></li>
      
      <li><a href="/publication/taouali-14-areadne/">A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</a></li>
      
    </ul>
  </div>
  





  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.66c553246b0f279a03be6e5597f72b52.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&rsquo;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared.
  </p>

  
  





  
  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">
      <img src="https://search.creativecommons.org/static/img/cc_icon.svg" alt="CC icon">
      <img src="https://search.creativecommons.org/static/img/cc-by_icon.svg" alt="CC by icon">
      
        <img src="https://search.creativecommons.org/static/img/cc-nc_icon.svg" alt="CC NC icon">
      
      
        <img src="https://search.creativecommons.org/static/img/cc-nd_icon.svg" alt="CC ND icon">
      
    </a>
  </p>




  <p class="powered-by">
    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
