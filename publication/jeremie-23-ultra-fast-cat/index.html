<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: January 19, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.6" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.4eb72b3c09083e6876124d44f28a6a86.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" disabled>
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" >
  

  
  



























  
  
  






  <meta name="author" content="Laurent U Perrinet" />





  

<meta name="description" content="Humans are able to robustly categorize images and can, for instance, detect the presence of an animal in a briefly flashed image in as little as 120 ms. Initially inspired by neuroscience, deep-learning algorithms literally bloomed up in the last decade such that the accuracy of machines is at present superior to humans for visual recognition tasks. However, these artificial networks are usually trained and evaluated on very specific tasks, for instance on the 1000 separate categories of IMAGENET. In that regard, biological visual systems are more flexible and efficient compared to artificial systems on generic ecological tasks. In order to deepen this comparison, we retrained the standard VGG Convolutional Neural Network (CNN) on two independent tasks which are ecologically relevant for humans: one task defined as detecting the presence of an animal and the other as detecting the presence of an artifact. We show that retraining the network achieves human-like performance level which is reported in psychophysical tasks. We also compare the accuracy of the detection on an image-by-image basis. This showed in particular that the two models perform better when combining their outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). These re-trained models could reproduce some unexpected behavioral observations from humans psychophysics such as the robustness to rotations (e.g. upside-down or slanted image) or to a grayscale transformation. Finally, we quantitatively tested the number of layers of the CNN which are necessary to reach such a performance, showing that a good accuracy for ultra-fast categorization could be reached with only a few layers, challenging the belief that image recognition would require a deep sequential analysis of visual objects. We expect to apply this framework to guide future model-based psychophysical experiments and biomimetic deep neuronal architectures designed for such tasks." />



<link rel="alternate" hreflang="en-us" href="https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/" />
<link rel="canonical" href="https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#bbdefb" />










  






<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/featured.jpg" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="Novel visual computations" />
<meta property="og:url" content="https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/" />
<meta property="og:title" content="Ultra-Fast Image Categorization in biology and in neural models | Novel visual computations" />
<meta property="og:description" content="Humans are able to robustly categorize images and can, for instance, detect the presence of an animal in a briefly flashed image in as little as 120 ms. Initially inspired by neuroscience, deep-learning algorithms literally bloomed up in the last decade such that the accuracy of machines is at present superior to humans for visual recognition tasks. However, these artificial networks are usually trained and evaluated on very specific tasks, for instance on the 1000 separate categories of IMAGENET. In that regard, biological visual systems are more flexible and efficient compared to artificial systems on generic ecological tasks. In order to deepen this comparison, we retrained the standard VGG Convolutional Neural Network (CNN) on two independent tasks which are ecologically relevant for humans: one task defined as detecting the presence of an animal and the other as detecting the presence of an artifact. We show that retraining the network achieves human-like performance level which is reported in psychophysical tasks. We also compare the accuracy of the detection on an image-by-image basis. This showed in particular that the two models perform better when combining their outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). These re-trained models could reproduce some unexpected behavioral observations from humans psychophysics such as the robustness to rotations (e.g. upside-down or slanted image) or to a grayscale transformation. Finally, we quantitatively tested the number of layers of the CNN which are necessary to reach such a performance, showing that a good accuracy for ultra-fast categorization could be reached with only a few layers, challenging the belief that image recognition would require a deep sequential analysis of visual objects. We expect to apply this framework to guide future model-based psychophysical experiments and biomimetic deep neuronal architectures designed for such tasks." /><meta property="og:image" content="https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/featured.jpg" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-03-21T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2022-05-11T09:32:04&#43;02:00">
  






    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/"
  },
  "headline": "Ultra-Fast Image Categorization in biology and in neural models",
  
  "image": [
    "https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/featured.jpg"
  ],
  
  "datePublished": "2023-03-21T00:00:00Z",
  "dateModified": "2022-05-11T09:32:04+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Jean-Nicolas Jérémie"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Novel visual computations",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Humans are able to robustly categorize images and can, for instance, detect the presence of an animal in a briefly flashed image in as little as 120 ms. Initially inspired by neuroscience, deep-learning algorithms literally bloomed up in the last decade such that the accuracy of machines is at present superior to humans for visual recognition tasks. However, these artificial networks are usually trained and evaluated on very specific tasks, for instance on the 1000 separate categories of IMAGENET. In that regard, biological visual systems are more flexible and efficient compared to artificial systems on generic ecological tasks. In order to deepen this comparison, we retrained the standard VGG Convolutional Neural Network (CNN) on two independent tasks which are ecologically relevant for humans: one task defined as detecting the presence of an animal and the other as detecting the presence of an artifact. We show that retraining the network achieves human-like performance level which is reported in psychophysical tasks. We also compare the accuracy of the detection on an image-by-image basis. This showed in particular that the two models perform better when combining their outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). These re-trained models could reproduce some unexpected behavioral observations from humans psychophysics such as the robustness to rotations (e.g. upside-down or slanted image) or to a grayscale transformation. Finally, we quantitatively tested the number of layers of the CNN which are necessary to reach such a performance, showing that a good accuracy for ultra-fast categorization could be reached with only a few layers, challenging the belief that image recognition would require a deep sequential analysis of visual objects. We expect to apply this framework to guide future model-based psychophysical experiments and biomimetic deep neuronal architectures designed for such tasks."
}
</script>

  

  




  
  
  

  
  

  


  
  <title>Ultra-Fast Image Categorization in biology and in neural models | Novel visual computations</title>

  
  
  
    <link rel="me" href="https://neuromatch.social/@laurentperrinet" />

  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper  dark " data-wc-page-id="1eb511e201ecf4b9ea9e71d38ffadb82" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.3c4b5f677f88bb5526061cb52d934de6.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Novel visual computations</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Novel visual computations</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#featured"><span>Latest</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Events</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#people"><span>People</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#talks"><span>Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#grants"><span>Grants</span></a>
          </li>

          
          

          

          
          
          
            
              
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/sciblog/" target="_blank" rel="noopener"><span>BlogBook</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    


  
    
    
  


<div class="pub">

  






















  
  



<div class="article-container pt-3">
  <h1>Ultra-Fast Image Categorization in biology and in neural models</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/author/jean-nicolas-jeremie/">Jean-Nicolas Jérémie</a></span>, <span >
      <a href="/author/laurent-u-perrinet/">Laurent U Perrinet</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March 2023
  </span>
  

  

  

  
  
  
  

  
  

</div>

  




<div class="btn-links mb-3">
  
  





  
  
    
  
<a class="btn btn-outline-primary btn-page-header" href="http://arxiv.org/abs/2205.03635" target="_blank" rel="noopener">
  Preprint
</a>




  





<a href="#" class="btn btn-outline-primary btn-page-header js-cite-modal"
        data-filename="/publication/jeremie-23-ultra-fast-cat/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header" href="https://doi.org/10.3390/vision7020029" target="_blank" rel="noopener">
  DOI
</a>



</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 600px; max-height: 400px;">
  <div style="position: relative">
    <img src="/publication/jeremie-23-ultra-fast-cat/featured_huab10630c6b830d85988701eae28ef374_131848_bfc696ecc9a546d2d2aa9287186aaa79.webp" width="600" height="400" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">Humans are able to robustly categorize images and can, for instance, detect the presence of an animal in a briefly flashed image in as little as 120 ms. Initially inspired by neuroscience, deep-learning algorithms literally bloomed up in the last decade such that the accuracy of machines is at present superior to humans for visual recognition tasks. However, these artificial networks are usually trained and evaluated on very specific tasks, for instance on the 1000 separate categories of IMAGENET. In that regard, biological visual systems are more flexible and efficient compared to artificial systems on generic ecological tasks. In order to deepen this comparison, we retrained the standard VGG Convolutional Neural Network (CNN) on two independent tasks which are ecologically relevant for humans: one task defined as detecting the presence of an animal and the other as detecting the presence of an artifact. We show that retraining the network achieves human-like performance level which is reported in psychophysical tasks. We also compare the accuracy of the detection on an image-by-image basis. This showed in particular that the two models perform better when combining their outputs. Indeed, animals (e.g. lions) tend to be less present in photographs containing artifacts (e.g. buildings). These re-trained models could reproduce some unexpected behavioral observations from humans psychophysics such as the robustness to rotations (e.g. upside-down or slanted image) or to a grayscale transformation. Finally, we quantitatively tested the number of layers of the CNN which are necessary to reach such a performance, showing that a good accuracy for ultra-fast categorization could be reached with only a few layers, challenging the belief that image recognition would require a deep sequential analysis of visual objects. We expect to apply this framework to guide future model-based psychophysical experiments and biomimetic deep neuronal architectures designed for such tasks.</p>
    

    
    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            <a href="/publication/#2">
              2
            </a>
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9"><em>Vision</em></div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style">










  





<video controls  >
  <source src="/publication/jeremie-23-ultra-fast-cat/Jeremie-etal-Vision_video-abstract.mp4" type="video/mp4">
</video>

<ul>
<li>read the paper <a href="https://www.mdpi.com/2411-5150/7/2/29" target="_blank" rel="noopener">online</a> or in <a href="https://www.mdpi.com/2411-5150/7/2/29/pdf" target="_blank" rel="noopener">PDF</a></li>
<li><a href="https://github.com/SpikeAI/2022-09_UltraFastCat" target="_blank" rel="noopener">full code</a> with extensive <a href="https://github.com/SpikeAI/2022-09_UltraFastCat/blob/main/Jeremie-etal-Vision_video-abstract.py" target="_blank" rel="noopener">Supplementary Material</a></li>
<li><a href="https://github.com/SpikeAI/2022-09_UltraFastCat/blob/main/Jeremie-etal-Vision_video-abstract.mp4" target="_blank" rel="noopener">Video Abstract</a> and code for  <a href="https://github.com/SpikeAI/2022-09_UltraFastCat/blob/main/Jeremie-etal-Vision_video-abstract.py" target="_blank" rel="noopener">Video Abstract</a></li>
<li>join the <a href="https://www.zotero.org/groups/4560566/ultrafastcat" target="_blank" rel="noopener">Zotero group</a> to add and discuss more items</li>
<li>this is a follow-up of: 











  


<div class="pub-list-item view-citation" style="margin-bottom: 1rem">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span class="article-metadata li-cite-author">
    

  <span >
      <a href="/author/jean-nicolas-jeremie/">Jean-Nicolas Jérémie</a></span>, <span >
      <a href="/author/laurent-u-perrinet/">Laurent U Perrinet</a></span>
  </span>
  (2021).
  <a href="/publication/jeremie-21-crs/">Ultra-fast categorization of images containing animals in vivo and in computo</a>.
  <em>Champalimaud Research Symposium (CRS21)</em>.
  
  <p>








  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/jeremie-21-crs/jeremie-21-crs.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/jeremie-21-crs/cite.bib">
  Cite
</a>














</p>

  
  
</div>


</li>
<li>see an extension perspective to visual search in: 











  


<div class="pub-list-item view-citation" style="margin-bottom: 1rem">
  <i class="far fa-file-alt pub-icon" aria-hidden="true"></i>

  
  

  <span class="article-metadata li-cite-author">
    

  <span >
      <a href="/author/jean-nicolas-jeremie/">Jean-Nicolas Jérémie</a></span>, <span >
      <a href="/author/emmanuel-dauce/">Emmanuel Daucé</a></span>, <span >
      <a href="/author/laurent-u-perrinet/">Laurent U Perrinet</a></span>
  </span>
  (2022).
  <a href="/publication/jeremie-22-areadne/">Ultra-rapid visual search in natural images using active deep learning</a>.
  <em>Proceedings of AREADNE</em>.
  
  <p>








  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/jeremie-22-areadne/jeremie-22-areadne.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/jeremie-22-areadne/cite.bib">
  Cite
</a>














  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://areadne.org/" target="_blank" rel="noopener">
    URL</a>

</p>

  
  
</div>


</li>
</ul>
</div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/classification/">classification</a>
  
  <a class="badge badge-light" href="/tag/deep-learning/">deep-learning</a>
  
  <a class="badge badge-light" href="/tag/efficient-coding/">efficient coding</a>
  
  <a class="badge badge-light" href="/tag/psychophysics/">psychophysics</a>
  
  <a class="badge badge-light" href="/tag/ultra-fast-categorization/">ultra-fast categorization</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Flaurentperrinet.github.io%2Fpublication%2Fjeremie-23-ultra-fast-cat%2F&amp;text=Ultra-Fast&#43;Image&#43;Categorization&#43;in&#43;biology&#43;and&#43;in&#43;neural&#43;models" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Flaurentperrinet.github.io%2Fpublication%2Fjeremie-23-ultra-fast-cat%2F&amp;t=Ultra-Fast&#43;Image&#43;Categorization&#43;in&#43;biology&#43;and&#43;in&#43;neural&#43;models" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=Ultra-Fast%20Image%20Categorization%20in%20biology%20and%20in%20neural%20models&amp;body=https%3A%2F%2Flaurentperrinet.github.io%2Fpublication%2Fjeremie-23-ultra-fast-cat%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Flaurentperrinet.github.io%2Fpublication%2Fjeremie-23-ultra-fast-cat%2F&amp;title=Ultra-Fast&#43;Image&#43;Categorization&#43;in&#43;biology&#43;and&#43;in&#43;neural&#43;models" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=Ultra-Fast&#43;Image&#43;Categorization&#43;in&#43;biology&#43;and&#43;in&#43;neural&#43;models%20https%3A%2F%2Flaurentperrinet.github.io%2Fpublication%2Fjeremie-23-ultra-fast-cat%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Flaurentperrinet.github.io%2Fpublication%2Fjeremie-23-ultra-fast-cat%2F&amp;title=Ultra-Fast&#43;Image&#43;Categorization&#43;in&#43;biology&#43;and&#43;in&#43;neural&#43;models" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="/author/jean-nicolas-jeremie/"><img class="avatar mr-3 avatar-circle" src="/author/jean-nicolas-jeremie/avatar_hua40b5f042c40f2b2bbad89397dde279b_69684_270x270_fill_q75_lanczos_center.jpg" alt="Jean-Nicolas Jérémie"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="/author/jean-nicolas-jeremie/">Jean-Nicolas Jérémie</a></h5>
      <h6 class="card-subtitle">Phd candidate in Computational Neuroscience</h6>
      <p class="card-text">During my PhD, I am focusing on ultra-fast processing in event-based neural networks.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/JNJER/" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/JnJerem" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/jeremie-jean-nicolas-91306a1a1/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
    



  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="/author/laurent-u-perrinet/"><img class="avatar mr-3 avatar-circle" src="/author/laurent-u-perrinet/avatar_hufdd75f582622d56af8f81b6f2821d19b_501026_270x270_fill_lanczos_center_3.png" alt="Laurent U Perrinet"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="/author/laurent-u-perrinet/">Laurent U Perrinet</a></h5>
      <h6 class="card-subtitle">Researcher in Computational Neuroscience</h6>
      <p class="card-text">My research interests include Machine Learning and computational neuroscience applied to Vision.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://neuromatch.social/@laurentperrinet" target="_blank" rel="noopener">
        <i class="fab fa-mastodon"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/0000-0002-9536-010X" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 <a rel="me" href="https://neuromatch.social/@laurentperrinet">Laurent U Perrinet</a>. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.62586ca65ca61821fe707eb9fa6268b7.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>




  
  <script async defer src="https://buttons.github.io/buttons.js"></script>

















</body>
</html>
