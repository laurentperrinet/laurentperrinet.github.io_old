<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>past-grant | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tag/past-grant/</link>
      <atom:link href="https://laurentperrinet.github.io/tag/past-grant/index.xml" rel="self" type="application/rss+xml" />
    <description>past-grant</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Mon, 15 Apr 2019 10:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/media/hulk.png</url>
      <title>past-grant</title>
      <link>https://laurentperrinet.github.io/tag/past-grant/</link>
    </image>
    
    <item>
      <title>SpikeAI: laureat du Défi Biomimétisme (2019)</title>
      <link>https://laurentperrinet.github.io/grant/spikeai/</link>
      <pubDate>Mon, 15 Apr 2019 10:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/spikeai/</guid>
      <description>&lt;h1 id=&#34;description&#34;&gt;Description&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Le projet SpikeAI est lauréat de l&#39;&lt;a href=&#34;http://www.cnrs.fr/mi/spip.php?article1452&amp;amp;lang=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;appel à projets 2019 &lt;em&gt;Biomimétisme&lt;/em&gt;&lt;/a&gt; :&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The SpikeAI project targets analog computing for artificial intelligence in the form of Spiking Neural Networks (SNNs). Computer vision systems widely rely on artificial intelligence and especially neural network based machine learning, which recently gained huge visibility. The training stage for deep convolutional neural networks is time-consuming and yields enormous energy consumption. In contrast, the human brain has the ability to perform visual tasks with unrivaled computational and energy efficiency. It is believed that one major factor of this efficiency is the fact that information is vastly represented by short pulses (spikes) at analog –not discrete– times. However, computer vision algorithms using such representation still lack in practice, and its high potential is largely underexploited. Inspired from biology, the project addresses the scientific question of developing a low-power, end-to-end analog sensing and processing architecture. This will be applied on the particular context of a field programmable analog array (FPAA) applied to a stereovision system dedicated to coastal surveillance using an aerial robot of 3D visual scenes, running on analog devices, without a central clock and to validate them in real-life situations. The ambitious long-term vision of the project is to develop the next generation AI paradigm that will at term compete with deep learning. We believe that neuromorphic computing, mainly studied in EU countries, will be a key technology in the next decade. It is therefore both a scientific and strategic challenge for France and EU to foster this technological breakthrough. &lt;em&gt;This call will help kickstart collaboration within this European consortium to help leverage the chance to successfully apply to future large-scale grant proposals (e.g. ANR, CHIST-ERA, ERC).&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get &lt;a href=&#34;https://spikeai.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;more information&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;outcomes&#34;&gt;outcomes&lt;/h2&gt;
&lt;p&gt;The main goal was mainly to build a network of actors and to answer to relevant calls in the field of biomimetic research. We have communicated through the diffusion of computational frameworks and actions which are gathered online @ &lt;a href=&#34;https://github.com/SpikeAI&#34;&gt;https://github.com/SpikeAI&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Summary of the actions taken:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We had a APROVIS3D FPP meeting April 23-24, 2019 in Lille with all partners. The call could support the travel of the 5 participants from outside Lille. During these two days, we had a first day to know each other better and a second day devoted to writing the grant proposal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With the help of this call, we could kickstart a collaboration within this European consortium which helped successfully achieve a large-scale grant proposal (CHIST-ERA : &lt;a href=&#34;https://laurentperrinet.github.io/grant/aprovis-3-d/&#34;&gt;https://laurentperrinet.github.io/grant/aprovis-3-d/&lt;/a&gt; ).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We organized a tutorial on deep learning during the GDR Vision, see &lt;a href=&#34;https://github.com/SpikeAI/2019-10-10_ML-tutorial&#34;&gt;https://github.com/SpikeAI/2019-10-10_ML-tutorial&lt;/a&gt; and &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/&#34;&gt;https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We could invite a major actor of the modeling of biomimetic computations, Ryad Benosman, to the GDR vision meeting. The call could support his travel and accommodation and was acknowledged in all communications (see &lt;a href=&#34;https://gdrvision2019.sciencesconf.org/resource/page/id/6)&#34;&gt;https://gdrvision2019.sciencesconf.org/resource/page/id/6)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ANR BalaV1 (2013/2016)</title>
      <link>https://laurentperrinet.github.io/grant/anr-bala-v1/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/anr-bala-v1/</guid>
      <description>&lt;h1 id=&#34;anr-balav1-balanced-states-in-area-v1-20132016&#34;&gt;ANR BalaV1: Balanced states in area V1 (2013/2016)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.agence-nationale-recherche.fr/Project-ANR-13-BSV4-0014&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Official website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In carnivores and primates the orientation selectivity (OS) of the cells in the primary visual cortex (V1) is organized in maps in which preferred orientations (POs) of the cells change gradually except near “pin- wheels”, around which all orientations are present. Over the last half-century the mechanism for OS has been hotly debated. However the theories that purport to explain OS have almost all considered cortical networks in which the neurons receive input preferentially from cells with similar PO. Such theories certainly capture the connectivity for neurons in orientation domains where neurons are surrounded by other cells with similar PO. However this does not necessarily hold near pinwheels: because of the discontinuous change in orientation preference at the pinwheel, neurons in this area are surrounded by cells of all preferred orientations. Thus if the probability of connection is solely dependent on anatomical distance, the inputs that these neurons receive should represent all orientations by roughly the same amount. Thus one may expect that the response of the cells near pinwheels should hardly vary with orientation, in contrast to experimental data. As a result, the common belief is that, at least near pinwheels, the connectivity depends also on the differences between preferred orientation. The situation near pinwheels in V1 of carnivores and primates is similar to that in the whole of V1 of rodents. In these species, neurons in V1 are OS but the network does not exhibit an orientation map and the surround of the cells represents all orientations roughly equally. In a recent theoretical paper (Hansel and van Vreeswijk 2012) we have demonstrated that in this situation, the response of the cells can still be orientation selective provided that the network operates in the balanced regime. Here we hypothesize that V1 with an orientation map operates in the balanced regime and therefore neurons can exhibit OS near pinwheels even in the absence of functional specific connectivity. The goal of this interdisciplinary project is to investigate whether the “balance hypothesis” holds for layer 2/3 in V1 of primate and carnivore and whether the functional organization observed in that layer can be accounted for without feature specific connectivity. We will combine modeling and experiments to investigate how the response of the neurons – the mean firing, the mean voltage, the inhibitory and excitatory conductances and importantly, the power spectrum of their fluctuations – vary with the location in the map, and also how a population of neurons – LFP, voltage-sensitive dye imaging or 2 photons – is affected by the various para- meters used to test the system. Whether V1 indeed operates in the balanced regime in more realistic conditions will be further investigated by determining how the local network responds to visual stimuli beyond the classical receptive field. We will investigate this issue in models of layer 2/3 representing multiple hyper- columns to characterize center-surround interactions and their dependence on the long-range connectivity. This will provide us with predictions for center-surround interactions for cells near pinwheels and in orientation domains. These predictions will be tested experimentally.&lt;/p&gt;
&lt;p&gt;The proposed project is new and ambitious. It aims at building a comprehensive and coherent understand- ing of the physiology of V1 layer 2/3 on several spatial scales from single cells to several hypercolumns and to account for this in mechanistic models. To accomplish these ambitious aims, we propose a combination of experimental and computational studies that take advantage of the unique strengths and the complementarity of expertise of 3 research teams. The Paris team has extensive experience in large-scale modeling of V1. The Toulouse and Marseille teams master both intra- and extracellular electrophysiology. In addition, the Marseille team is expert in microscopic and mesoscopic imaging techniques in V1.&lt;/p&gt;
&lt;p&gt;Acknowledgement&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;This work was supported by ANR project &amp;quot;BalaV1&amp;quot; N° ANR-13-BSV4-0014-02.  
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR CausaL (2018/2020)</title>
      <link>https://laurentperrinet.github.io/grant/anr-causal/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/anr-causal/</guid>
      <description>&lt;p&gt;With Andrea Brovelli (INT), Mateus Joffily (GATE)&amp;hellip;&lt;/p&gt;
&lt;p&gt;See &lt;a href=&#34;https://anr.fr/Project-ANR-18-CE28-0016&#34;&gt;https://anr.fr/Project-ANR-18-CE28-0016&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Humans have an extraordinary capacity to infer cause-effect relations. In particular, we excel in forming ​beliefs ​about the ​causal effect of actions​. Causal learning provides the basis for rational decision-making and allows people to engage in meaningful life and social interactions. Causal learning is a form of goal-directed learning, defined as the capacity to rapidly learn the consequence of actions and to select behaviours according to goals and motivational state. This ability is based on internal models of the consequence of our behaviors​ and relies on learning rules determined by the​ contingency between actions and outcomes​. At a first approximation, contingency Δ​P ​is operationalized as the difference between two conditional probabilities: i) P(O|A), the probability of outcome O given action A; ii) P(O|¬A), the probability of the outcome when the action is withheld. In everyday life, people perceive their actions as causing a given outcome if the contingency is positive, whereas they perceive them as preventing​ ​it​ ​if​ ​negative;​ ​when​ ​P(O|A)​ ​and​ ​P(O|¬A)​ ​are​ ​equal,​ ​people​ ​report​ ​no​ ​causal​ ​effect​​ ​. Despite the centrality of causal learning, a clear understanding of both the internal computations and neural substrates (the so-called ​cognitive architectures​) is currently missing. ​Our project will therefore address​ ​two​ ​key​ ​questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;What are the key ​internal representations of causal beliefs and what are the ​computational processes​​ ​that​ ​enable​ ​their​ ​formation​ ​during​ ​learning?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How ​​are ​​internal​ ​representations​ ​and ​​computational​​ processes​ ​​implemented​ ​​in ​​the ​​brain? CausaL​ ​​will​ ​address​ ​these​ ​two​ ​objectives​ ​through​ ​two​ ​dedicated​ ​research​ ​work​ ​packages​ ​(WPs).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Acknowledgement : This work was supported by ANR project ANR-18-AAPG–“CAUSAL, Cognitive Architectures of  Causal  Learning”.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ANR PredictEye (2018/2020)</title>
      <link>https://laurentperrinet.github.io/grant/anr-predicteye/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/anr-predicteye/</guid>
      <description>&lt;p&gt;The objectives of PREDICTEYE is to rigorously test and define the functional and neurophysiological grounds of probabilistic oculomotor internal models by investigating the multiple timescales at which the trajectory of a moving target is learned and represented in a probabilistic framework (Aim #1). Second, we will investigate the role of (pre)frontal oculomotor networks in building such probabilistic representations and their impact upon two of their downstream neural targets of the brainstem premotor centers (superior colliculus for saccades; NRTP for pursuit) (Aim #2). Our third objective is to model and simulate the dynamics of target motion prediction and eye movement performance. A key question is to unveil how probabilistic information about target timing and motion (i.e. direction and speed) is sampled over trial history by neuronal populations and integrated with Prior knowledge (i.e. sequence properties and rules of conditional probabilities) in order to coordinate saccades and pursuit and optimize their precisions (Aim #3).&lt;/p&gt;
&lt;p&gt;Acknowledgement&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;This work was supported by ANR project &amp;quot;PredictEye&amp;quot; ANR-XXXX.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR REM (2013/2016)</title>
      <link>https://laurentperrinet.github.io/grant/anr-rem/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/anr-rem/</guid>
      <description>

















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://static.tvtropes.org/pmwiki/pub/images/R.E.M..jpg&#34; &gt;


  &lt;img src=&#34;http://static.tvtropes.org/pmwiki/pub/images/R.E.M..jpg&#34; alt=&#34;We were open :-)&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Reinforcement learning theory provides a general conceptual framework to account for behavioral changes. Recently the idea that reinforcement may be used to explain learning in motor responses has emerged. In particular, there is a growing interest in studying the effects of reinforcement learning in arm movements trajectories (Dam, Kording, &amp;amp; Wei, 2013), pointing movements (Trommershauser, Landy, &amp;amp; Maloney, 2006), or eye movements (Madelain, Champrenaut, &amp;amp; Chauvin, 2007; Madelain &amp;amp; Krauzlis, 2003b; Madelain, Paeye, &amp;amp; Wallman, 2011; Sugrue, Corrado, &amp;amp; Newsome, 2004; Takikawa, Kawagoe, Itoh, Nakahara, &amp;amp; Hikosaka, 2002; Xu-Wilson, Zee, &amp;amp; Shadmehr, 2009). However, and despite these few seminal studies, much is still unknown about both the details of the effects of reward on motor control and the underlying mechanisms. &lt;strong&gt;This proposal aims at a better understanding of how skilled motor responses are learned focusing on voluntary eye movements.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Although learning is often regarded as a restricted period of time during which a behavior undergo some changes we view learning as a continuously ongoing process. In the case of motor control every instance of a behavior is followed by some consequences that will affect some dimensions of the future response. These changes will in return affect the functional relations with the environment and this feedback process continues through lifetime. Therefore we do not regard motor learning as a special phase that allows the emergence of a particular motor response but as a continuous adaptation to the changes within the organism that affect the functional relations with her environment. This distinction is important because the learning situations that are experimentally tested over a short period of time may then be viewed as a condensed version of motor learning in the real life: the same adaptive processes are responsible for the changes in the response in both situations.&lt;/p&gt;
&lt;p&gt;An important aspect of this fundamental research project is that the theoretical propositions addressed provide a new view on motor learning that departs from conventional wisdom. We expect to gain considerable knowledge on learning by constructing new experimental paradigms to collect behavioural data, implementing new learning models based on Bayesian theories and testing dynamical mathematical models of behavioural changes. &lt;strong&gt;Whichever way the results turn out, we anticipate that these studies will provide a better understanding of motor learning and provide a well-defined and solid framework for studying other forms of motor plasticity.&lt;/strong&gt; If eye movement learning follows the rules of other operant responses (i.e. responses reinforced by their consequences), this will constitute a minor revolution in the study of motor control, both at the behavioral and neural levels, with important implications for the understanding of plasticity in other motor systems.&lt;/p&gt;
&lt;p&gt;Acknowledgement&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;This work was supported by ANR project ANR-13-APPR-0008 &amp;quot;ANR R.E.M.&amp;quot;.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR SPEED (2013/2016)</title>
      <link>https://laurentperrinet.github.io/grant/anr-speed/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/anr-speed/</guid>
      <description>&lt;p&gt;Measuring speed and direction of moving objects is an essential computational step in order to move our eyes, hands or other body parts with respect to the environment. Whereas encoding and decoding of direction information is now largely understood in various neuronal systems, how the human brain accurately represents speed information remains largely unknown. Speed tuned neurons have been identified in several early cortical visual areas in monkeys. However, how such speed tuning emerges is not yet understood. A working hypothesis is that speed tuned neurons nonlinearly combine motion information extracted at different spatial and temporal scales, taking advantage of the statistical spatiotemporal properties of natural scenes. However, such pooling of information must be context dependent, varying with the spatial perceptual organization of the visual scenes. Furthermore, the population code underlying perceived speed is not elucidated either and therefore we are still far from understanding how speed information is decoded to drive and control motor responses or perceptual judgments.&lt;/p&gt;
&lt;p&gt;Recently, we have proposed that speed estimation is intrinsically a multi-scale, task-dependent problem (Simoncini et al., Nature Neuroscience 2012) and we have defined a new set of motion stimuli, constructed as random phase dynamical textures that mimic the statistics of natural scenes (Sanz-Leon et al., Journal of Neurophysiology 2012). This approach has proved to be fruitful to investigate nonlinear properties of motion integration.&lt;/p&gt;
&lt;p&gt;The current proposal brings together psychophysicists, oculomotor scientists and modelers to investigate speed processing in human. We aim at expanding this framework in order to understand how tracking eye movements and motion perception can take advantage of multiple scale processing for estimating target speed. We will design sets of high dimensional stimuli by extending our generative model. Using these natural-statistics stimuli, we will investigate how speed information is encoded by computing motion energy across different spatial and temporal filters. By analysing both perceptual and oculomotor responses we will probe the nonlinear mechanisms underlying the integration of the outputs of multiple spatiotemporal filters and implement these processes in a refined version of our model. Furthermore, we will test our working hypothesis that in natural scenes such nonlinear integration provides precise and reliable motion estimates, which leads to efficient motion-based behaviors. By comparing tracking responses with perception, we will also test a second critical hypothesis, that nonlinear speed computations are task-dependent. In particular, we will explore the extent to which the geometrical structures of visual scenes are decisive for perception beyond the motion energy computation used for early sensorimotor transformation. Finally we will investigate the role of contextual and extra-retinal, predictive information in building an efficient dynamic estimate of objects&#39; speed for perception and action.&lt;/p&gt;
&lt;p&gt;Acknowledgement&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;This work was supported by ANR project &amp;quot;ANR Speed&amp;quot; ANR-13-BSHS2-0006.    
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR TRAJECTORY (2016/2019)</title>
      <link>https://laurentperrinet.github.io/grant/anr-trajectory/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/anr-trajectory/</guid>
      <description>&lt;p&gt;Global motion processing is a major computational task of biological visual systems. When an object moves across the visual field, the sequence of visited positions is strongly correlated in space and time, forming a trajectory. These correlated images generate a sequence of local activation of the feed-forward stream. Local properties such as position, direction and orientation can be extracted at each time step by a feed-forward cascade of linear filters and static non-linearities. However such local, piecewise, analysis ignores the recent history of motion and faces several difficulties, such as systematic delays, ambiguous information processing (e.g., aperture and correspondence problems61) high sensitivity to noise and segmentation problems when several objects are present. Indeed, two main aspects of visual processing have been largely ignored by the dominant, classical feed-forward scheme. First, natural inputs are often ambiguous, dynamic and non-stationary as, e.g., objects moving along complex trajectories. To process them, the visual system must segment them from the scene, estimate their position and direction over time and predict their future location and velocity. Second, each of these processing steps, from the retina to the highest cortical areas, is implemented by an intricate interplay of feed-forward, feedback and horizontal interactions1. Thus, at each stage, a moving object will not only be processed locally, but also generate a lateral propagation of information. Despite decades of motion processing research, it is still unclear how the early visual system processes motion trajectories. We, among others, have proposed that anisotropic diffusion of motion information in retinotopic maps can contribute resolving many of these difficulties25 13. Under this perspective, motion integration, anticipation and prediction would be jointly achieved through the interactions between feed-forward, lateral and feedback propagations within a common spatial reference frame, the retinotopic maps.&lt;/p&gt;
&lt;p&gt;Addressing this question is particularly challenging, as it requires to probe these sequences of events at multiple scales (from individual cells to large networks) and multiple stages (retina, primary visual cortex (V1)). “TRAJECTORY” proposes such an integrated approach. Using state-of-the-art micro- and mesoscopic recording techniques combined with modeling approaches, we aim at dissecting, for the first time, the population responses at two key stages of visual motion encoding: the retina and V1. Preliminary experiments and previous computational studies demonstrate the feasibility of our work. We plan three coordinated physiology and modeling work-packages aimed to explore two crucial early visual stages in order to answer the following questions: How is a translating bar represented and encoded within a hierarchy of visual networks and for which condition does it elicit anticipatory responses? How is visual processing shaped by the recent history of motion along a more or less predictable trajectory? How much processing happens in V1 as opposed to simply reflecting transformations occurring already in the retina?&lt;/p&gt;
&lt;p&gt;The project is timely because partners master new tools such as multi-electrode arrays and voltage-sensitive dye imaging for investigating the dynamics of neuronal populations covering a large segment of the motion trajectory, both in retina and V1. Second, it is strategic: motion trajectories are a fundamental aspect of visual processing that is also a technological obstacle in computer vision and neuroprostheses design. Third, this project is unique by proposing to jointly investigate retinal and V1 levels within a single experimental and theoretical framework. Lastly, it is mature being grounded on (i) preliminary data paving the way of the three different aims and (ii) a history of strong interactions between the different groups that have decided to join their efforts.&lt;/p&gt;
&lt;h2 id=&#34;the-marseille-team&#34;&gt;The Marseille team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Frédéric Chavane (DR, CNRS, NEOPTO team) is working in the field of vision research for about 20 years with a special interest in the role of lateral interactions in the integration of sensory input in the primary visual cortex. His recent work suggest that lateral interactions mediated by horizontal intracortical connectivity participates actively in the input normalization that controls a wide range of function, from the contrast-response gain to the representation of illusory or real motion. His expertise range from microscopic (intracellular recordings) to mesoscopic (optical imaging, multi-electrode array) recording scales in the primary visual cortex of anesthetized and awake behaving animals.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Laurent Perrinet (CR, CNRS, NEOPTO team). His scientific interests focus on bridging computational understanding of neural dynamics and low-level sensory processing by focusing on motion perception. He is the author of papers in machine learning, computational neuroscience and behavioral psychology. One key concept is the use of statistical regularities from natural scenes as a main drive to integrate local neural information into a global understanding of the scene. In a recent paper that he coauthored (in Nature Neuroscience), he developed a method to use synthesized stimuli targeted to analyze physiological data in a system-identification approach.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ivo Vanzetta (CR, CNRS, NEOPTO team). His scientific interests focus on how to optimally use photonics-based imaging methods to investigate visual information processing in low-level visual areas, in the anesthetized and awake animal (rodent &amp;amp; primate). As can be seen from his bibliographic record, these methods include optical imaging of intrinsic signals and voltage sensitive dyes and, recently, 2 photon microscopy. Finally I. Vanzetta has an ongoing collaboration with L. Perrinet on the utilization of well-controlled, synthesized nature-like visual stimuli to probe the response characteristics of the primate&amp;rsquo;s visual system (Sanz-Leon &amp;amp; al. 2012).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;progress-meeting-anr-trajectory&#34;&gt;Progress meeting ANR TRAJECTORY&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Time    January 15th, 2018&lt;/li&gt;
&lt;li&gt;Location     INT&lt;/li&gt;
&lt;li&gt;General presentation of the grant, see &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-trajectory/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anr TRAJECTORY&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Overview of my current projects    &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html&#34;&gt;https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MotionClouds with trajectories    &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2018-01-16-testing-more-complex-trajectories.html&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2018-01-16-testing-more-complex-trajectories.html&lt;/a&gt; or &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;






  



  
  











&lt;figure id=&#34;figure-a-predictive-sequence-is-essential-in-resolving-the-coherence-problem--the-sequence-in-which-a-set-of-local-motion-is-shown-is-essential-for-the-detection-of-global-motion-we-replicate-here-the-experiments-by-scott-watamaniuk-and-colleagues-they-have-shown-behaviourally-that-a-dot-in-noise-is-much-more-detectable-when-it-follows-a-coherent-trajectory-up-to-an-order-of-magnitude-of-10-times-what-would-be-predicted-by-the-local-components-of-the-trajectory-in-this--movie-we-observe-white-noise-and-at-first-sight-no-information-is-detectable-in-fact-there-is-a-dot-moving-along-some-smooth-linear-trajectory-since-this-is-compatible-with-a-predictive-sequence-it-is-much-easier-to-see-the-dot-from-left-to-right-in-the-top-of-the-image-a-smooth-pursuit-helps-to-catch-it-this-simple-experiment-shows-that-even-if-local-motion-is-similar-in-both-movies-a-coherent-trajectory-is-more-easy-to-track-obviously-we-may-thus-conclude-that-the-whole-trajectory-is-more-that-its-individual-parts-and-that-the-independence-hypothesis-does-not-hold-if-we-want-to-account-for-the-predictive-information-in-input-sequences-such-as-seems-to-be-crucial-for-the-ap&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://laurentperrinet.github.io/grant/anr-trajectory/sequence_ABCD_huc740b9c3e27c30fe69cba33adb5a642d_17610017_2000x2000_fit_lanczos.gif&#34; data-caption=&#34;&amp;lt;em&amp;gt;A predictive sequence is essential in resolving the coherence problem.&amp;lt;/em&amp;gt;  The sequence in which a set of local motion is shown is essential for the detection of global motion. we replicate here the experiments by Scott Watamaniuk and colleagues. They have shown behaviourally that a dot in noise is much more detectable when it follows a coherent trajectory, up to an order of magnitude of 10 times what would be predicted by the local components of the trajectory. In this  movie we observe white noise and at first sight, no information is detectable. In fact, there is a dot moving along some smooth linear trajectory. Since this is compatible with a predictive sequence, it is much easier to see the dot (from left to right in the top of the image, a smooth pursuit helps to catch it). This simple experiment shows that, even if local motion is similar in both movies, a coherent trajectory is more easy to track. Obviously, we may thus conclude that the whole trajectory is more that its individual parts, and that the independence hypothesis does not hold if we want to account for the predictive information in input sequences such as seems to be crucial for the AP.&#34;&gt;


  &lt;img data-src=&#34;https://laurentperrinet.github.io/grant/anr-trajectory/sequence_ABCD_huc740b9c3e27c30fe69cba33adb5a642d_17610017_2000x2000_fit_lanczos.gif&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;400&#34; height=&#34;300&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;em&gt;A predictive sequence is essential in resolving the coherence problem.&lt;/em&gt;  The sequence in which a set of local motion is shown is essential for the detection of global motion. we replicate here the experiments by Scott Watamaniuk and colleagues. They have shown behaviourally that a dot in noise is much more detectable when it follows a coherent trajectory, up to an order of magnitude of 10 times what would be predicted by the local components of the trajectory. In this  movie we observe white noise and at first sight, no information is detectable. In fact, there is a dot moving along some smooth linear trajectory. Since this is compatible with a predictive sequence, it is much easier to see the dot (from left to right in the top of the image, a smooth pursuit helps to catch it). This simple experiment shows that, even if local motion is similar in both movies, a coherent trajectory is more easy to track. Obviously, we may thus conclude that the whole trajectory is more that its individual parts, and that the independence hypothesis does not hold if we want to account for the predictive information in input sequences such as seems to be crucial for the AP.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This work was supported by ANR project &amp;ldquo;TRAJECTORY&amp;rdquo; N° ANR-15-CE37-0011.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DOC2AMU (2016/2019)</title>
      <link>https://laurentperrinet.github.io/grant/doc-2-amu/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/doc-2-amu/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://doc2amu.univ-amu.fr/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOC2AMU&lt;/a&gt; is co-funded by the prestigious Marie Skłodowska-Curie COFUND action within the H2020 Research and Innovation programme of the European Union and by the Regional Council of Provence-Alpes-Côte d’Azur, with a contribution from A*MIDEX Foundation.&lt;/p&gt;
&lt;p&gt;Within this programme, the PhD fellows will sign a three-year work contract with one of the 12 Doctoral Schools of AMU. Numerous advantages&lt;/p&gt;
&lt;p&gt;These PhD fellowships are remunerated above that of a standard French PhD contract with a gross monthly salary of 2600 € and a gross monthly mobility allowance of 300 €, which after standard deductions will amount to a net salary of approximately 1625€/month (net amount may vary slightly). A 500€ travel allowance per year and per fellow is also provided for the fellows to travel between Marseille and their place of origin. Tailored training and personalised mentoring: Fellows will define and follow a Personal Career Development Plan at the beginning of their Doctoral thesis and will have access to a variety of training options and workshops. Financial support for international research training and conferences participations. A contribution to the research costs will be provided for the benefit of the fellow.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;This work was supported by the Doc2Amu project which received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 713750. Projet cofinancé par le Conseil Régional Provence-Alpes-Côte d’Azur. Projet cofinancé par le Conseil Régional Provence-Alpes-Côte d’Azur, la commission européenne et les Investissements d&amp;rsquo;Avenir.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BrainScaleS (2011/2014) </title>
      <link>https://laurentperrinet.github.io/grant/brain-scales/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/brain-scales/</guid>
      <description>&lt;p&gt;List of publications that were funded by European Union&amp;rsquo;s project Number FP7-269921, &amp;ldquo;&lt;a href=&#34;http://brainscales.kip.uni-heidelberg.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BrainScales&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;See also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;http://facets.kip.uni-heidelberg.de&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FACETS research project&lt;/a&gt; which
ended on 31 August 2010.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/grant/facets-itn/&#34;&gt;FACETS-ITN Marie-Curie&lt;/a&gt; initital
training network for graduate training continues until August 2013&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/grant/brain-scales/&#34;&gt;BrainScaleS project&lt;/a&gt; builds on
and extends the research done in FACETS. This 4 year project started
on January 1st, 2011.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>CODDE (2008/2012)</title>
      <link>https://laurentperrinet.github.io/grant/codde/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/codde/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;http://www.optimaldecisions.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CODDE&lt;/a&gt; network studies the links between sensory input, brain activity and motor output. It does this by combining behavioural techniques, brain imaging, movement recording and computational modelling.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FACETS (2006/2010)</title>
      <link>https://laurentperrinet.github.io/grant/facets/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/facets/</guid>
      <description>&lt;p&gt;List of publications that were funded by the
&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/&#34; class=&#34;http&#34;&gt;FACETS&lt;/a&gt;
project (more
&lt;a href=&#34;http://en.wikipedia.org/wiki/Facets_%28Science%29&#34; class=&#34;http&#34;&gt;info&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;also available on the FACET&amp;rsquo;s
&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/jss/Publications/author_Perrinet&#34; class=&#34;http&#34;&gt;website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;http://facets.kip.uni-heidelberg.de&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FACETS research project&lt;/a&gt; which
ended on 31 August 2010.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/grant/facets-itn/&#34;&gt;FACETS-ITN Marie-Curie&lt;/a&gt; initital
training network for graduate training continues until August 2013&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/grant/brain-scales/&#34;&gt;BrainScaleS project&lt;/a&gt; builds on
and extends the research done in FACETS. This 4 year project started
on January 1st, 2011.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>FACETS-ITN (2010/2013)</title>
      <link>https://laurentperrinet.github.io/grant/facets-itn/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/facets-itn/</guid>
      <description>&lt;h1 id=&#34;facets-itn-from-neuroscience-to-neuro-inspired-computing-20102013&#34;&gt;FACETS-ITN: From Neuroscience to neuro-inspired computing (2010/2013)&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://facets.kip.uni-heidelberg.de/images/e/e3/Public--ITN_PositionsPoster2.png&#34; title=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; alt=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; class=&#34;external_image&#34; style=&#34;width:25.0%&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; class=&#34;http&#34;&gt;FACETS ITN&lt;/a&gt;
project (EU funding, grant number 237955) is a &amp;lsquo;Marie-Curie Initial
Training Network&amp;rsquo; involves 15 groups at European Research Universities,
Research Centers and Industrial Partners in 6 countries. 22 Ph.D.
Positions are funded in the FACETS-ITN project in the following
scientific work areas: Neurobiology of Cells and Networks, Modelling of
Neural Systems, Neuromorphic Hardware, Neuro-Electronic Interfaces,
Computational Principles in Neural Architectures, Mechanisms of Learning
and Plasticity. &lt;span id=&#34;line-8&#34; class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;span
id=&#34;line-9&#34; class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;See also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;http://facets.kip.uni-heidelberg.de&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FACETS research project&lt;/a&gt; which
ended on 31 August 2010.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/grant/facets-itn/&#34;&gt;FACETS-ITN Marie-Curie&lt;/a&gt; initital
training network for graduate training continues until August 2013&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/grant/brain-scales/&#34;&gt;BrainScaleS project&lt;/a&gt; builds on
and extends the research done in FACETS. This 4 year project started
on January 1st, 2011.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>PACE-ITN (2015/2019)</title>
      <link>https://laurentperrinet.github.io/grant/pace-itn/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/pace-itn/</guid>
      <description>&lt;p&gt;The PACE ITN project involved over 50 researchers spread across 10 full and 5 associated partners, from academia and the private sector, established in 7 different European and Associated countries, the PACE network gathers a broad range of expertise from experimental psychology, cognitive neurosciences, brain imaging, technology and clinical sciences.&lt;/p&gt;
&lt;p&gt;The PACE Project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 642961&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
