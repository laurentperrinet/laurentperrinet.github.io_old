<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>matching pursuit | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tag/matching-pursuit/</link>
      <atom:link href="https://laurentperrinet.github.io/tag/matching-pursuit/index.xml" rel="self" type="application/rss+xml" />
    <description>matching pursuit</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Tue, 01 Jan 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/img/hulk.png</url>
      <title>matching pursuit</title>
      <link>https://laurentperrinet.github.io/tag/matching-pursuit/</link>
    </image>
    
    <item>
      <title>An adaptive homeostatic algorithm for the unsupervised learning of visual features</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-19-hulk/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-19-hulk/</guid>
      <description>&lt;h1 id=&#34;an-adaptive-algorithm-for-unsupervised-learning&#34;&gt;&amp;ldquo;An adaptive algorithm for unsupervised learning&amp;rdquo;&lt;/h1&gt;












  


&lt;video controls &gt;
  &lt;source src=&#34;https://laurentperrinet.github.io/sciblog/files/2019-09-11_Perrinet19.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;ul&gt;
&lt;li&gt;supplementary info : &lt;a href=&#34;https://spikeai.github.io/HULK/&#34;&gt;https://spikeai.github.io/HULK/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.mdpi.com/2411-5150/3/3/47&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.mdpi.com/2411-5150/3/3/47/htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.mdpi.com/2411-5150/3/3/47/pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for paper: &lt;a href=&#34;https://github.com/SpikeAI/HULK&#34;&gt;https://github.com/SpikeAI/HULK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for framework: &lt;a href=&#34;https://github.com/bicv/SparseHebbianLearning/&#34;&gt;https://github.com/bicv/SparseHebbianLearning/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for figures &lt;a href=&#34;https://github.com/SpikeAI/HULK/blob/master/Annex.ipynb&#34;&gt;https://github.com/SpikeAI/HULK/blob/master/Annex.ipynb&lt;/a&gt; (which is rendered @ &lt;a href=&#34;https://spikeai.github.io/HULK/&#34;&gt;https://spikeai.github.io/HULK/&lt;/a&gt; )&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2019-09-11_Perrinet19.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video abstract&lt;/a&gt; (and the 
&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2019-09-11_video-abstract-vision.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt; for generating it)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Role of homeostasis in learning sparse representations</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-10-shl/</link>
      <pubDate>Sat, 17 Jul 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-10-shl/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;perrinet-10-shl.png&#34; alt=&#34;header&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive Sparse Spike Coding : applications of Neuroscience to the compression of natural images</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-08-spie/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-08-spie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamical Neural Networks: modeling low-level vision at short latencies</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-07/</link>
      <pubDate>Sun, 18 Mar 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-07/</guid>
      <description>&lt;p&gt;Dynamical Neural Networks (DyNNs) are a class of models for networks of neurons where particular focus is put on the role of time in the emergence of functional computational properties. The definition and study of these models involves the cooperation of a large range of scientific fields from statistical physics, probabilistic modelling, neuroscience and psychology to control theory. It focuses on the mechanisms that may be relevant for studying cognition by hypothesizing that information is distributed in the activity of the neurons in the system and that the timing helps in maintaining this information to lastly form decisions or actions. The system responds at best to the constraints of the outside world and learning strategies tune this internal dynamics to achieve optimal performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in 
&lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Efficient representation of natural images using local cooperation</title>
      <link>https://laurentperrinet.github.io/publication/fischer-05/</link>
      <pubDate>Sat, 01 Jan 2005 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/fischer-05/</guid>
      <description>














&lt;figure id=&#34;figure-schematic-structure-of-the-primary-visual-cortex-implemented-in-the-present-study-simple-cortical-cells-are-modeled-through-log-gabor-functions-they-are-organized-in-pairs-in-quadrature-of-phase-dark-gray-circles-for-each-position-the-set-of-different-orientations-compose-a-pinwheel-large-light-gray-circles-the-retinotopic-organization-induces-that-adjacent-spatial-positions-are-arranged-in-adjacent-pinwheels-inhibition-interactions-occur-towards-the-closest-adjacent-positions-which-are-in-the-direc-tions-perpendicular-to-the-cell-preferred-orientation-and-toward-adjacent-orientations-light-red-connections-facilitation-occurs-to-wards-co-aligned-cells-up-to-a-larger-distance-dark-blue-connections-&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://laurentperrinet.github.io/publication/fischer-07/figure2.png&#34; data-caption=&#34;Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections).&#34;&gt;


  &lt;img src=&#34;https://laurentperrinet.github.io/publication/fischer-07/figure2.png&#34; alt=&#34;&#34; width=&#34;80%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections).
  &lt;/figcaption&gt;


&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Coding static natural images using spiking event times: do neurons cooperate?</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-03-ieee/</link>
      <pubDate>Sat, 18 Sep 2004 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-03-ieee/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;perrinet-03-ieee.png&#34; alt=&#34;header&#34;&gt;





  
  











&lt;figure id=&#34;figure-progressive-reconstruction-of-a-static-image-using-spikes-in-a-multi-scale-oriented-representation&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-03-ieee/v1_tiger_hue35305ea0fde0004c7038403208fa3b1_2047419_2000x2000_fit_lanczos.gif&#34; data-caption=&#34;Progressive reconstruction of a static image using spikes in a multi-scale oriented representation.&#34;&gt;


  &lt;img data-src=&#34;https://laurentperrinet.github.io/publication/perrinet-03-ieee/v1_tiger_hue35305ea0fde0004c7038403208fa3b1_2047419_2000x2000_fit_lanczos.gif&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;320&#34; height=&#34;240&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;em&gt;Progressive reconstruction of a static image using spikes in a multi-scale oriented representation.&lt;/em&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Feature detection using spikes : the greedy approach</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-04-tauc/</link>
      <pubDate>Sun, 18 Jul 2004 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-04-tauc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-02-sparse/</link>
      <pubDate>Thu, 18 Mar 2004 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-02-sparse/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
