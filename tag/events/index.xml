<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>events | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tag/events/</link>
      <atom:link href="https://laurentperrinet.github.io/tag/events/index.xml" rel="self" type="application/rss+xml" />
    <description>events</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Tue, 30 Jun 2020 09:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>events</title>
      <link>https://laurentperrinet.github.io/tag/events/</link>
    </image>
    
    <item>
      <title>PhD offer &#34;Ultra-fast vision using Spiking Neural Networks&#34;</title>
      <link>https://laurentperrinet.github.io/post/2020-06-30_phd-position/</link>
      <pubDate>Tue, 30 Jun 2020 09:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2020-06-30_phd-position/</guid>
      <description>&lt;p&gt;THE POSITION HAS BEEN FILLED.&lt;/p&gt;
&lt;p&gt;Dear colleagues,&lt;/p&gt;
&lt;p&gt;Applications are welcome for a fully funded doctoral position at &lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;INT&lt;/a&gt; in &lt;a href=&#34;https://en.wikipedia.org/wiki/Marseille&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Marseille&lt;/a&gt;, France. Your mission will be to build ultra-fast vision algorithms using event-based cameras and spiking neural networks. The project is funded by the &lt;a href=&#34;https://laurentperrinet.github.io/grant/aprovis-3-d/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;APROVIS3D&lt;/a&gt; grant (ANR-19-CHR3-0008-03) and will be coordinated by &lt;a href=&#34;https://laurentperrinet.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Laurent Perrinet&lt;/a&gt;. The work will be carried out in collaboration with a leading computer science institute at Universit√© C√¥te d‚ÄôAzur (Sophia Antipolis, France), the Laboratoire d&amp;rsquo;Informatique, Signaux et Syst√®mes de Sophia-Antipolis (I3S, UMR7271 - UNS CNRS), that will be part of the supervision team. We are seeking candidates with a strong background in machine learning, computer vision and computational neuroscience.&lt;/p&gt;
&lt;p&gt;To obtain further information, please visit &lt;a href=&#34;https://laurentperrinet.github.io/post/2020-06-30_phd-position&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/post/2020-06-30_phd-position&lt;/a&gt; or contact me @ &lt;a href=&#34;mailto:Laurent.Perrinet@univ-amu.fr&#34;&gt;Laurent.Perrinet@univ-amu.fr&lt;/a&gt;. To candidate, follow instructions on the dedicated &lt;a href=&#34;https://bit.ly/3igRji4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;server from the CNRS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The starting date is set to October 1st, 2020 and the appointment is for 36 month. Applications are welcome immediately.&lt;/p&gt;
&lt;p&gt;Thanks for distributing this announcement to potential candidates!&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;fr&#34; dir=&#34;ltr&#34;&gt;CD Doctorant &amp;quot;Vision ultra-rapide utilisant des R√©seaux de neurones impulsionnels&amp;quot; H/F (MARSEILLE) (MARSEILLE 05) &lt;a href=&#34;https://t.co/I5CXWxR3zi&#34;&gt;https://t.co/I5CXWxR3zi&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Emploi?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Emploi&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/OffreEmploi?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#OffreEmploi&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Recrutement?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Recrutement&lt;/a&gt;&lt;/p&gt;&amp;mdash; EmploiCNRS (@EmploiCNRS) &lt;a href=&#34;https://twitter.com/EmploiCNRS/status/1277872035700539392?ref_src=twsrc%5Etfw&#34;&gt;June 30, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;detailed-description-ultra-fast-vision-using-spiking-neural-networks&#34;&gt;Detailed description: &amp;ldquo;Ultra-fast vision using Spiking Neural Networks&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;Biological vision is surprisingly efficient. To take advantage of this efficiency, Deep learning and convolutional neural networks (CNNs) have recently produced great advances in artificial computer vision. However, these algorithms now face multiple challenges: learned architectures are often not interpretable, disproportionally energy greedy, and often lack the integration of contextual information that seems optimized in biological vision and human perception. Crucially, given an equal constraint on energy consumption, these algorithms are relatively slow compared to biological vision. It is believed that one major factor of this rapidity is the fact that visual information is represented by short pulses (spikes) at analog ‚Äì not discrete ‚Äì times (&lt;a href=&#34;#Paugam12&#34;&gt;Paugam and Bohte, 2012&lt;/a&gt;). However, most classical computer vision algorithms rely on such frame-based approaches. One solution to overcome their limitations is to use event-based representations, but these still lack in practice, and their high potential is largely underexploited. Inspired by biology, the project addresses the scientific question of developing a low-power sensing architecture for the processing of visual scenes, able to function on analog devices without a central clock and aimed at being validated in real-life situations. More specifically, the project will develop new paradigms for biologically inspired computer vision (&lt;a href=&#34;#Cristobal15&#34;&gt;Cristobal, Keil and Perrinet, 2015&lt;/a&gt;), from sensing to processing, in order to help machines such as Unmanned Autonomous Vehicles (UAV), autonomous vehicles, or robots gain high-level understanding from visual scenes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In this doctoral project, we propose to address major limitations of classical computer vision by implementing specific dynamical features of cortical circuits: &lt;em&gt;spiking neural networks&lt;/em&gt; (&lt;a href=&#34;#Perrinet04&#34;&gt;Perrinet, Thorpe and Samuelides, 2004&lt;/a&gt;; &lt;a href=&#34;#Lagorce16&#34;&gt;Lagorce et al., 2018&lt;/a&gt;), &lt;em&gt;lateral diffusion of neural information&lt;/em&gt; (&lt;a href=&#34;#Chavane2000&#34;&gt;Chavane et al., 2011&lt;/a&gt;; &lt;a href=&#34;#muller2018cortical&#34;&gt;Muller et al., 2018&lt;/a&gt;) and &lt;em&gt;dynamic neuronal association fields&lt;/em&gt; (&lt;a href=&#34;#Fr%c3%a9gnac2012&#34;&gt;Fr√©gnac et al., 2012&lt;/a&gt;; &lt;a href=&#34;#Fr%c3%a9gnac2016&#34;&gt;Fr√©gnac et al., 2016&lt;/a&gt;; &lt;a href=&#34;#gerard2016synaptic&#34;&gt;Gerard-Mercier et al., 2016&lt;/a&gt;)&lt;/strong&gt;. One starting point is to use event-based cameras &lt;a href=&#34;#Dupeyroux18&#34;&gt;(Dupeyroux et al., 2018)&lt;/a&gt; and to extend results of self-supervised learning that we have obtained on static, natural images (&lt;a href=&#34;#BoutinFranciosiniChavaneRuffierPerrinet20&#34;&gt;Boutin et al., 2020&lt;/a&gt;) showing in a recurrent cortical-like artificial CNN architecture the emergence of interactions which phenomenologically correspond to the &amp;ldquo;association field&amp;rdquo; described at the psychophysical (&lt;a href=&#34;#Field1993&#34;&gt;Field et al., 1993&lt;/a&gt;), spiking (&lt;a href=&#34;#Li2002&#34;&gt;Li and Gilbert, 2002&lt;/a&gt;) and synaptic (&lt;a href=&#34;#gerard2016synaptic&#34;&gt;Gerard-Mercier et al., 2016&lt;/a&gt;) levels. Indeed, the architecture of primary visual cortex (V1), the direct target of the feedforward visual flow, contains dense local recurrent connectivity with sparse long-range connections (&lt;a href=&#34;#Voges12&#34;&gt;Voges and Perrinet, 2012&lt;/a&gt;). Such connections add to the traditional convolutional kernels representing feedforward and local recurrent amplification a novel lateral interaction kernel within a single layer (across positions and channels). It is not well understood, but probably decisive for ultra-fast vision, how recurrent cortico-cortical loops add a level of distributed top-down complexity in the feed-forward stream of information which participates to the ultra-fast integration of sensory input and perceptual context (&lt;a href=&#34;#Keller2019&#34;&gt;Keller et al., 2019&lt;/a&gt;). Coupled with the dynamics of cortical circuits, this elaborate multiplexed architecture provides the conditions possible for defining ultra-fast vision algorithms.&lt;/p&gt;
&lt;h2 id=&#34;expected-profile-of-the-candidate&#34;&gt;Expected profile of the candidate&lt;/h2&gt;
&lt;p&gt;Candidates should have experience in the domain of computational neuroscience, physics, engineering or related, and a solid training in machine learning and computer vision.&lt;/p&gt;
&lt;p&gt;The candidate has to show good skills in computer science (programming skills, architecture understanding, git versioning, &amp;hellip;), and in image processing methods. Good command of programming tools (Python scripting) is required. Multidisciplinary background would be strongly appreciated and in particular an advanced knowledge in mathematics, for a deep understanding of signal processing methods, along with strong computational skills. The candidate needs to show a keen interest in neuroscience. It is a bonus if the candidate is curious about neuroscience and visual perception.&lt;/p&gt;
&lt;p&gt;The candidate has to fluently speak English to understand publications and to attend international conferences and workshops and pro-actively interact with partners in France, Switzerland, Spain and Greece. The preferred candidate will have the ability to work autonomously, and needs to be flexible to comply with the working method of the supervisors.&lt;/p&gt;
&lt;h2 id=&#34;research-context&#34;&gt;Research context&lt;/h2&gt;
&lt;p&gt;The thesis will be carried out in the team &amp;ldquo;NEuronal OPerations in visual TOpographic maps&amp;rdquo; (NeOpTo) within the &lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institut de Neurosciences de la Timone&lt;/a&gt; in &lt;a href=&#34;https://en.wikipedia.org/wiki/Marseille&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Marseille&lt;/a&gt;, a welcoming and lively town by the Mediterranean sea in the south of France. The research team is led by F. Chavane (DR2, CNRS) and currently hosts 4 permanent staff, 3 post-docs and 4 PhD students. The research themes of the team are focused on neuronal operations within visual cortical maps. Indeed, along the cortical hierarchy, low-level features such as the position and orientation of the visual stimulus (but also auditory tone, somatosensory touch, etc&amp;hellip;) but also higher-level features (such as faces, viewpoints of objects, etc&amp;hellip;) are represented topographically on the cortical surface.&lt;/p&gt;
&lt;p&gt;This work will be conducted in direct collaboration with &lt;a href=&#34;http://i3s.unice.fr/jmartinet/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jean Martinet&lt;/a&gt; who will co-supervise the thesis. We will develop these algorithms in collaboration with &lt;a href=&#34;https://scholar.google.fr/citations?user=_ZTFUooAAAAJ&amp;amp;hl=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ryad Benosman&lt;/a&gt; (Universit√© Pierre et Marie Curie) and &lt;a href=&#34;https://scholar.google.co.uk/citations?user=iIGoymcAAAAJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;St√©phane Viollet&lt;/a&gt; (√©quipe biorobotique, Institut des Sciences du Mouvement).&lt;/p&gt;
&lt;h2 id=&#34;fr-description-du-sujet-de-th√®se&#34;&gt;FR: Description du sujet de th√®se&lt;/h2&gt;
&lt;p&gt;La vision biologique est √©tonnamment efficace. Pour tirer parti de cette efficacit√©, l&amp;rsquo;apprentissage profond et les r√©seaux neuronaux convolutionnels (CNN) ont r√©cemment permis de r√©aliser de grandes avanc√©es en mati√®re de vision artificielle par ordinateur. Cependant, ces algorithmes sont aujourd&amp;rsquo;hui confront√©s √† de multiples d√©fis : les architectures apprises sont souvent peu interpr√©tables, sont d√©mesur√©ment gourmandes en √©nergie, n&amp;rsquo;int√®grent g√©n√©ralement pas les informations contextuelles qui semblent parfaitement adapt√©es √† la vision biologique et √† la perception humaine. Aussi ces algorithmes sont relativement lents -√† consommation √©nerg√©tique √©gale- par rapport √† la vision biologique. On pense qu&amp;rsquo;un facteur majeur de cette rapidit√© est le fait que l&amp;rsquo;information est repr√©sent√©e par de courtes impulsions √† des moments analogiques - et non discrets. Toutefois, les algorithmes de vision par ordinateur utilisant une telle repr√©sentation dans des r√©seaux de neurones impulsionnels font encore d√©faut dans la pratique, et son important potentiel est largement sous-exploit√©. Ce projet, qui est inspir√© de la biologie, aborde la question scientifique du d√©veloppement d&amp;rsquo;une architecture ultra-rapide de d√©tection et de traitement de sc√®nes visuelles, fonctionnant sur des appareils sans horloge centrale, et visant √† valider ce genre d&amp;rsquo;algorithmes √©v√©nementiels dans des situations r√©elles. Plus sp√©cifiquement, le projet d√©veloppera de nouveaux paradigmes pour une vision d&amp;rsquo;inspiration biologique, de la d√©tection au traitement, afin d&amp;rsquo;aider des machines telles que les robots a√©riens autonomes (UAV), les v√©hicules autonomes ou les robots √† acqu√©rir une compr√©hension de haut niveau des sc√®nes visuelles.&lt;/p&gt;
&lt;h2 id=&#34;fr-contexte-de-travail&#34;&gt;FR: Contexte de travail&lt;/h2&gt;
&lt;p&gt;La th√®se sera effectu√©e dans l&amp;rsquo;√©quipe &amp;ldquo;NEuronal OPerations in visual TOpographic maps&amp;rdquo; (NeOpTo) au sein de l&amp;rsquo;Institut de Neurosciences de la Timone (INT). L&amp;rsquo;√©quipe de recherche est dirig√©e par F. Chavane (DR2, CNRS) et accueille actuellement 4 personnels permanents, 3 post-doctorants et 4 doctorants. Les th√©matiques de recherche de l&amp;rsquo;√©quipe sont centr√©es sur les op√©rations neuronales au sein de cartes corticales visuelles. En effet, le long de la hi√©rarchie corticale, les caract√©ristiques de bas niveau telles que la position, l‚Äôorientation du stimulus visuel (mais aussi la tonalit√© auditive, le toucher somatosensoriel, etc&amp;hellip;) mais aussi les caract√©ristiques de niveau sup√©rieur (telles que les visages, les points de vue d‚Äôobjets, etc&amp;hellip;) sont repr√©sent√©es topographiquement sur la surface corticale.&lt;/p&gt;
&lt;p&gt;Cette th√®se sera men√©e en collaboration directe avec &lt;a href=&#34;http://i3s.unice.fr/jmartinet/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jean Martinet&lt;/a&gt; qui co-supervisera cette th√®se. Nous d√©velopperons ces algorithmes en collaboration avec &lt;a href=&#34;https://scholar.google.fr/citations?user=_ZTFUooAAAAJ&amp;amp;hl=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ryad Benosman&lt;/a&gt; (Universit√© Pierre et Marie Curie) et &lt;a href=&#34;https://scholar.google.co.uk/citations?user=iIGoymcAAAAJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;St√©phane Viollet&lt;/a&gt; (√©quipe biorobotique, Institut des Sciences du Mouvement).&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;BoutinFranciosiniChavaneRuffierPerrinet20&#34;&gt;Boutin, Victor, Angelo Franciosini, Fr√©d√©ric Chavane, Franck Ruffier, and Laurent U Perrinet. (2019). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system.&lt;/a&gt;&amp;rdquo; &lt;em&gt;arXiv&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Dupeyroux18&#34;&gt;Julien Dupeyroux, Victor Boutin, Julien R Serres, Laurent U Perrinet, St√©phane Viollet. (2018). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/dupeyroux-boutin-serres-perrinet-viollet-18/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;M2APix: a bio-inspired auto-adaptive visual sensor for robust ground height estimation.&lt;/a&gt;&amp;rdquo; &lt;em&gt;ISCAS&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Chavane2011&#34;&gt;Chavane, F., Sharon, D., Jancke, D., Marre, O., Fr√©gnac, Y. and Grinvald, A. (2011). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1016/S0928-4257%2800%2901096-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lateral spread of orientation selectivity in V1 is controlled by intracortical cooperativity.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Physiology Paris&lt;/em&gt; 94 (5-6): 333&amp;ndash;42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Cristobal15&#34;&gt;Gabriel Crist√≥bal, Laurent U Perrinet, Matthias S Keil (2015). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/cristobal-perrinet-keil-15-bicv/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Biologically Inspired Computer Vision.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Wiley&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Field1993&#34;&gt;Field, D.J., Hayes, A. and Hess, R.F. (1993). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1016/0042-6989%2893%2990156-Q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contour integration by the human visual system: Evidence for a local ‚Äúassociation field‚Äù.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Vision Research&lt;/em&gt; 33 (2), pp. 173-193.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;gerard2016synaptic&#34;&gt;Gerard-Mercier, Florian, Pedro V Carelli, Marc Pananceau, Xoana G Troncoso, and Yves Fr√©gnac. (2016). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://www.jneurosci.org/content/36/14/3925&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Synaptic Correlates of Low-Level Perception in V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Neuroscience&lt;/em&gt; 36 (14): 3925&amp;ndash;42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Keller2019&#34;&gt;Keller, A., Roth, M.M. and Scanziani, M. (2019). &lt;/a&gt; 2019. &amp;ldquo;&lt;a href=&#34;https://www.abstractsonline.com/pp8/#!/7883/presentation/65856&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The feedback receptive field of neurons in the mammalian primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;American Society for Neuroscience Abstracts&lt;/em&gt;, 403.13. Chicago.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Lagorce16&#34;&gt;Lagorce, X., Orchard, G., Galluppi, F., Shi, B. E., &amp;amp; Benosman, R. B.&lt;/a&gt; (2016). &amp;ldquo;&lt;a href=&#34;https://www.neuromorphic-vision.com/public/publications/1/publication.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HOTS: a hierarchy of event-based time-surfaces for pattern recognition.&lt;/a&gt;&amp;rdquo; &lt;em&gt;IEEE transactions on pattern analysis and machine intelligence&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Li2002&#34;&gt;Li W, Pi√´ch V, Gilbert CD&lt;/a&gt; (2006). &amp;ldquo;&lt;a href=&#34;http://www.paper.edu.cn/scholar/showpdf/MUz2UN2INTA0eQxeQh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contour saliency in primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Neuron&lt;/em&gt;, 50(6):951‚Äì962.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;muller2018cortical&#34;&gt;Muller, Lyle, Fr√©d√©ric Chavane, John Reynolds, and Terrence J Sejnowski. &lt;/a&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://papers.cnl.salk.edu/PDFs/Cortical%20travelling%20waves_%20mechanisms%20and%20computational%20principles.%202018-4515.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cortical Travelling Waves: Mechanisms and Computational Principles.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Nature Reviews Neuroscience&lt;/em&gt; 19 (5): 255.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Paugam12&#34;&gt;H√©l√®ne Paugam-Moisy, Sander M. Bohte. &lt;/a&gt; (2012). &amp;ldquo;Computing with Spiking Neuron Networks.&amp;rdquo; &lt;em&gt;Handbook of Natural Computing&lt;/em&gt;, Springer-Verlag, pp.335-376, 2012&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Perrinet04&#34;&gt;Laurent U Perrinet, Manuel Samuelides, Simon J Thorpe. &lt;/a&gt; (2004). &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-03-ieee/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Coding static natural images using spiking event times: do neurons cooperate?&amp;quot;&lt;/a&gt; &lt;em&gt;IEEE Transactions on Neural Networks&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Tang18&#34;&gt;Tang, Hanlin, Martin Schrimpf, William Lotter, Charlotte Moerman, Ana Paredes, Josue Ortega Caro, Walter Hardesty, David Cox, and Gabriel Kreiman. &lt;/a&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1073/pnas.1719397115&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recurrent computations for visual pattern completion.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt; 115 (35) 8835-8840.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Voges12&#34;&gt;Voges, Nicole, and Laurent U Perrinet.&lt;/a&gt; (2012). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Complex Dynamics in Recurrent Cortical Networks Based on Spatially Realistic Connectivities.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt; 6.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2020-09-11 : Feedforward and feedback processes in visual recognition (T Serre)</title>
      <link>https://laurentperrinet.github.io/post/2020-09-11_seminaire-thomas-serre/</link>
      <pubDate>Tue, 16 Jun 2020 06:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2020-09-11_seminaire-thomas-serre/</guid>
      <description>&lt;h1 id=&#34;2020-09-11--feedforward-and-feedback-processes-in-visual-recognition-by-thomas-serre&#34;&gt;2020-09-11 : &amp;ldquo;Feedforward and feedback processes in visual recognition&amp;rdquo; by Thomas Serre&lt;/h1&gt;
&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;http://serre-lab.clps.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Serre&lt;/a&gt; will present his recent work on &amp;ldquo;Feedforward and feedback processes in visual recognition&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching ‚Äì and sometimes even surpassing ‚Äì human accuracy on a variety of visual recognition tasks. In this talk, however, I will show that these neural networks and their recent extensions exhibit a limited ability to solve seemingly simple visual reasoning problems involving incremental grouping, similarity, and spatial relation judgments. Our group has developed a recurrent network model of classical and extra-classical receptive fields that is constrained by the anatomy and physiology of the visual cortex. The model was shown to account for diverse visual illusions providing computational evidence for a novel canonical circuit that is shared across visual modalities. I will show that this computational neuroscience model can be turned into a modern end-to-end trainable deep recurrent network architecture that addresses some of the shortcomings exhibited by state-of-the-art feedforward networks for solving complex visual reasoning tasks. This suggests that neuroscience may contribute powerful new ideas and approaches to computer science and artificial intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Dr. &lt;a href=&#34;http://serre-lab.clps.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Serre&lt;/a&gt; is an Associate Professor in Cognitive Linguistic &amp;amp; Psychological Sciences and an affiliate of the Carney Institute for Brain Science at Brown University. He received a Ph.D. in Neuroscience from MIT in 2006 and an MSc in EECS from T√©l√©com Bretagne (France) in 2000. His research seeks to understand the neural computations supporting visual perception and has been featured in the BBC series ‚ÄúVisions from the Future‚Äù and other news articles (The Economist, New Scientist, Scientific American, IEEE Computing in Science and Technology, Technology Review and Slashdot). Dr. Serre is the Faculty Director of the Center for Computation and Visualization and the Associate Director of the Initiative for Computation in Brain and Mind at Brown University. He also holds an International Chair in AI within the Artificial and Natural Intelligence Toulouse Institute (France). Dr. Serre has served as an area chair and a senior program committee member for top-tier machine learning and computer vision conferences including AAAI, CVPR, and NeurIPS. He is currently serving as a domain expert for IARPA‚Äôs Machine Intelligence from Cortical Networks (MICrONS) program and as a scientific advisor for Vium, Inc. He was the recipient of an NSF Early Career Award as well as DARPA‚Äôs Young Faculty Award and Director‚Äôs Award.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2020-03-13: Soutenance Victor Boutin</title>
      <link>https://laurentperrinet.github.io/post/2020-03-13_soutenance-victor-boutin/</link>
      <pubDate>Wed, 04 Mar 2020 09:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2020-03-13_soutenance-victor-boutin/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;fr&#34; dir=&#34;ltr&#34;&gt;Int√©ress√©s par le &amp;quot;Sparse deep predictive coding&amp;quot; / &amp;quot;codage hi√©rarchique, √©pars et pr√©dictif&amp;quot; ? Victor Boutin (Equipe NeOpTo) soutiendra sa th√®se de doctorat intitul√©e Vendredi 13 mars √† 14h  &lt;a href=&#34;https://t.co/BIrciyiRUf&#34;&gt;https://t.co/BIrciyiRUf&lt;/a&gt;&lt;br&gt;ü§ù &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt;  &lt;a href=&#34;https://twitter.com/CNRS?ref_src=twsrc%5Etfw&#34;&gt;@CNRS&lt;/a&gt; &lt;a href=&#34;https://twitter.com/regionpaca?ref_src=twsrc%5Etfw&#34;&gt;@regionpaca&lt;/a&gt; &lt;a href=&#34;https://twitter.com/CNRS_dr12?ref_src=twsrc%5Etfw&#34;&gt;@CNRS_dr12&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/INT?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#INT&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://twitter.com/FranckRUFFIER?ref_src=twsrc%5Etfw&#34;&gt;@FranckRUFFIER&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1235128290458951680?ref_src=twsrc%5Etfw&#34;&gt;March 4, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;Date : Vendredi 13 mars √† 14h&lt;/p&gt;
&lt;p&gt;Lieu:  salle Henri Gastaut, au rez de chauss√©e de l&amp;rsquo;INT  (how to &lt;a href=&#34;http://www.int.univ-amu.fr/contact&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;get there&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;La th√®se sera suivie d‚Äôun pot au R+4 de l‚Äô&lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institut de Neurosciences de la Timone&lt;/a&gt; (how to &lt;a href=&#34;http://www.int.univ-amu.fr/contact&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;get there&lt;/a&gt;)&lt;/p&gt;
&lt;h2 id=&#34;jury&#34;&gt;Jury&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.fr/citations?user=_ZTFUooAAAAJ&amp;amp;hl=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ryad Benosman&lt;/a&gt;, Universit√© Pierre et Marie Curie, Rapporteur&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.fr/citations?hl=fr&amp;amp;user=uR-7ex4AAAAJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simon Thorpe&lt;/a&gt;, CNRS, Rapporteur&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.i2m.univ-amu.fr/perso/sandrine.anthoine/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sandrine Anthoine&lt;/a&gt;, CNRS, Examinateur&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://neuro-psi.cnrs.fr/spip.php?article934&amp;amp;lang=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yves Fr√©gnac&lt;/a&gt;, CNRS, Examinateur&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sidkouider.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sid Kouider&lt;/a&gt;, CNRS, Examinateur&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://laurentperrinet.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Laurent Perrinet&lt;/a&gt;, CNRS, Directeur de th√®se&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ism.univ-amu.fr/ruffier/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Franck Ruffier&lt;/a&gt;, CNRS, Co-directeur de th√®se&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Mossadek_Talby&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mossadek Talby&lt;/a&gt;, AMU, Jury invit√©&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Building models to efficiently represent images is a central and difficult problem in the machine learning community. The neuroscientific study of the early visual cortical areas is a great source of inspiration to find economical and robust solutions. For instance, Sparse Coding (SC) is one of the most successful frameworks to model neural computation at the local scale in the visual cortex. It directly derives from the efficient coding hypothesis and could be thought of as a competitive mechanism that describes visual stimulus using the activity of a small fraction of neurons. At the structural scale of the ventral visual pathways, feedforward models of vision have accounted for neurophysiological evidence and provide the most successful frameworks for object recognition tasks. Nevertheless, these models do not leverage the high density of feedback and lateral interactions observed in the visual cortex. In particular, these connections are known to integrate contextual and attentional modulations to feedforward signals. The Predictive Coding (PC) theory has been proposed to model top-down and bottom-up interaction between cortical regions. The presented thesis introduces a model combining Sparse Coding and Predictive Coding in a hierarchical and convolutional architecture. Our model, called  Sparse Deep Predictive Coding (SDPC), was trained on several different databases including faces and natural images. We analyze the SPDC from a computational and a biological perspective. In terms of computation, the recurrent connectivity introduced by the PC framework allows the SDPC to converge to lower prediction errors with a higher convergence rate. In addition, we combine neuroscientific evidence with machine learning methods to analyze the impact of recurrent processing at both the neural organization and representational level. At the neural organization level, the feedback signal of the model accounted for a reorganization of the V1 association fields that promotes contour integration. At the representational level, the SDPC exhibited significant denoising ability which is highly correlated with the strength of the feedback from V2 to V1. These results from the SDPC model demonstrate that neuro-inspiration might be the right methodology to design more powerful and more robust computer vision algorithms.&lt;/p&gt;
&lt;h2 id=&#34;r√©sum√©&#34;&gt;R√©sum√©&lt;/h2&gt;
&lt;p&gt;La repr√©sentation concise et efficace de l&amp;rsquo;information est un probl√®me qui occupe une place centrale dans l&amp;rsquo;apprentissage machine. Le cerveau, et plus particuli√®rement le cortex visuel, ont depuis longtemps trouv√© des solutions performantes et robustes afin de r√©soudre un tel probl√®me. A l&amp;rsquo;√©chelle locale, le codage √©pars est l&amp;rsquo;un des m√©canismes les plus prometteurs pour mod√©liser le traitement de l&amp;rsquo;information au sein des populations de neurones dans le cortex visuel. Le codage √©pars introduit une comp√©tition entre les neurones afin de d√©crire un stimulus visuel en limitant le nombre de neurones actifs. A l&amp;rsquo;√©chelle structurelle, les mod√®les dits ascendants d√©crivent le cortex visuel comme une succession d&amp;rsquo;unit√©s de traitement dans lesquelles l&amp;rsquo;information se propage de la r√©tine vers les couches profondes du cortex. Ces mod√®les ont expliqu√© avec succ√®s un grand nombre de ph√©nom√®nes neuro-physiologiques et ont servi d&amp;rsquo;inspiration afin de construire des algorithmes de reconnaissance d&amp;rsquo;objets extr√™mement performants. N√©anmoins, les mod√®les ascendants n&amp;rsquo;expliquent pas le grand nombre de connections r√©currentes et descendantes que l&amp;rsquo;on trouve dans le cortex visuel. Ces connections sont connues pour moduler l&amp;rsquo;activit√© des neurones en incluant des details contextuels au flux d&amp;rsquo;information ascendant. La th√©orie du codage pr√©dictif a √©t√© sugg√©r√©e pour mod√©liser les connections ascendantes, r√©currentes, et descendantes que l&amp;rsquo;on retrouve entre les diff√©rentes r√©gions corticales. Cette th√®se propose de combiner codage √©pars et codage pr√©dictif au sein d&amp;rsquo;un mod√®le hi√©rarchique et convolutif. Nous avons entrain√© ce mod√®le sur diff√©rentes bases de donn√©es afin de l&amp;rsquo;analyser avec une perspective √† la fois computationnelle et biologique. D&amp;rsquo;un point de vue computationnel, nous d√©montrons que les connections descendantes, introduites par le codage pr√©dictif, permettent une convergence meilleure et plus rapide du mod√®le. De plus, nous analysons les effets des connections descendantes sur l&amp;rsquo;organisation des populations de neurones, ainsi que leurs cons√©quences sur la mani√®re dont notre algorithme se repr√©sente les images. Nous montrons que les connections descendantes r√©organisent les champs d&amp;rsquo;association de neurones dans V1 afin de permettre une meilleure int√©gration des contours. En outre, nous observons que ces connections permettent une meilleure reconstruction des images bruit√©es. Nos r√©sultats sugg√®rent que l&amp;rsquo;inspiration des neurosciences fournit un cadre prometteur afin de d√©velopper des algorithmes de vision artificielles plus performants et plus robustes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Postdoc position on Visual computations using Spatio-temporal Diffusion Kernels and Traveling Waves</title>
      <link>https://laurentperrinet.github.io/post/2019-10-28_postdoc-position/</link>
      <pubDate>Mon, 21 Oct 2019 09:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-28_postdoc-position/</guid>
      <description>&lt;p&gt;THE POSITION HAS BEEN FILLED.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Applications are welcome for a post-doctoral position at INT-Marseille, France exploring novel visual computations using spatio-temporal diffusion kernels and travelling waves. More info @ &lt;a href=&#34;https://t.co/f6tUR8XW6y&#34;&gt;https://t.co/f6tUR8XW6y&lt;/a&gt; &lt;a href=&#34;https://t.co/odzckjtloa&#34;&gt;pic.twitter.com/odzckjtloa&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1188940039293751297?ref_src=twsrc%5Etfw&#34;&gt;October 28, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;Dear colleagues,&lt;/p&gt;
&lt;p&gt;Applications are welcome for a post-doctoral position at &lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;INT&lt;/a&gt; in &lt;a href=&#34;https://en.wikipedia.org/wiki/Marseille&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Marseille&lt;/a&gt;, France. Your mission will be to explore novel visual computations using spatio-temporal diffusion kernels and traveling waves. The project is funded by the &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-horizontal-v1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ANR Horizontal V1&lt;/a&gt; grant (ANR-17-CE37-0006) from the French National Research Agency (ANR) and will be coordinated by &lt;a href=&#34;https://laurentperrinet.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Laurent Perrinet&lt;/a&gt;, in collaboration with &lt;a href=&#34;https://www.mullerlab.ca&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lyle Muller&lt;/a&gt; and &lt;a href=&#34;http://www.int.univ-amu.fr/spip.php?page=equipe&amp;amp;equipe=NeOpTo&amp;amp;lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fr√©d√©ric Chavane&lt;/a&gt; at INT and &lt;a href=&#34;http://neuro-psi.cnrs.fr/spip.php?article934&amp;amp;lang=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yves Fr√©gnac&lt;/a&gt; and Jan Antolik at UNIC-NeuroPSI, Gif. We are seeking candidates with a strong background in machine learning, computer vision and computational neuroscience.&lt;/p&gt;
&lt;p&gt;For more information, visit &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-28_postdoc-position&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/post/2019-10-28_postdoc-position&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The starting date is set to January 6th, 2020 but can be flexibly extended. To obtain further information or send applications (including a full CV, a letter of motivation, 2 reference names), please contact: &lt;a href=&#34;mailto:Laurent.Perrinet@univ-amu.fr&#34;&gt;Laurent.Perrinet@univ-amu.fr&lt;/a&gt;. The appointment is for 18 month. Applications are welcome immediately and until the end of year 2019.&lt;/p&gt;
&lt;p&gt;Thanks for distributing this announcement to potential candidates!&lt;/p&gt;
&lt;h1 id=&#34;detailed-description-visual-computations-using-spatio-temporal-diffusion-kernels-and-traveling-waves&#34;&gt;Detailed description: Visual computations using Spatio-temporal Diffusion Kernels and Traveling Waves&lt;/h1&gt;
&lt;p&gt;Biological vision is surprisingly efficient. To take advantage of this efficiency, Deep learning and convolutional neural networks (CNNs) have recently produced great advances in artificial computer vision. However, these algorithms now face multiple challenges: learned architectures are often not interpretable, disproportionally energy greedy, and often lack the integration of contextual information that seems optimized in biological vision and human perception. It is clear from recent advances in system and computational neuroscience that nonlinear, recurrent interactions in visual cortical networks are key to this efficiency¬†(&lt;a href=&#34;#Tang18&#34;&gt;Tang et al., 2018&lt;/a&gt;; &lt;a href=&#34;#Kietzmann19&#34;&gt;Kietzmann et al., 2019&lt;/a&gt;). We will use inspiration from neurophysiology and brain imaging to resolve this apparent gap between traditional CNNs and biological visual systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In this post-doctoral project, we propose to address these major limitations by focusing on specific dynamical features of cortical circuits: &lt;em&gt;lateral diffusion of sensory-evoked traveling waves&lt;/em&gt; (&lt;a href=&#34;#Chavane2000&#34;&gt;Chavane et al., 2011&lt;/a&gt;; &lt;a href=&#34;#muller2018cortical&#34;&gt;Muller et al., 2018&lt;/a&gt;) and &lt;em&gt;dynamic neuronal association fields&lt;/em&gt; (&lt;a href=&#34;#Fr%c3%a9gnac2012&#34;&gt;Fr√©gnac et al., 2012&lt;/a&gt;; &lt;a href=&#34;#Fr%c3%a9gnac2016&#34;&gt;Fr√©gnac et al., 2016&lt;/a&gt;; &lt;a href=&#34;#gerard2016synaptic&#34;&gt;Gerard-Mercier et al., 2016&lt;/a&gt;)&lt;/strong&gt;. Indeed, the architecture of primary visual cortex (V1), the direct target of the feedforward visual flow, contains dense local recurrent connectivity with sparse long-range connections (&lt;a href=&#34;#Voges12&#34;&gt;Voges and Perrinet, 2012&lt;/a&gt;). Such connections add to the traditional convolutional kernels representing feedforward and local recurrent amplification a novel lateral interaction kernel within a single layer (across positions and channels). Less studied, but probably decisive in active vision, recurrent cortico-cortical loops add a level of distributed top-down complexity which participates to the lateral integration of sensory input and perceptual context (&lt;a href=&#34;#Keller2019&#34;&gt;Keller et al., 2019&lt;/a&gt;). Coupled with the continuous time dynamics of cortical circuits, this elaborate multiplexed architecture provides the conditions possible for generating information diffusion through traveling waves. Inspired by recent work in neuroscience uncovering the ubiquity of these waves during visual processing, we aim to design a self-supervised CNN that will exploit these dynamics for new applications in computer vision.&lt;/p&gt;
&lt;p&gt;The proposed work will be organized as a collaboration between two labs (INT, Marseille and UNIC, Gif) along three tasks to be integrated in a unified model:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The starting point will be to extend results of self-supervised learning that we have obtained on static, natural images (&lt;a href=&#34;#BoutinFranciosiniChavaneRuffierPerrinet20&#34;&gt;Boutin et al., 2019&lt;/a&gt;) showing in a recurrent cortical-like artificial CNN architecture the emergence of interactions which phenomenologically correspond to the &amp;ldquo;association field&amp;rdquo; described at the psychophysical (&lt;a href=&#34;#Field1993&#34;&gt;Field et al., 1993&lt;/a&gt;), spiking (&lt;a href=&#34;#Li2002&#34;&gt;Li and Gilbert, 2002&lt;/a&gt;) and synaptic (&lt;a href=&#34;#gerard2016synaptic&#34;&gt;Gerard-Mercier et al., 2016&lt;/a&gt;) levels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The central aim will be to develop a dynamical version of this feedback/lateral kernel in the context of the &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-horizontal-v1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ANR Horizontal-V1&lt;/a&gt; project, linking the two labs and confronted to their recent electrophysiological data pointing to different classes of spatio-temporal diffusion and different degree of anisotropies during apparent and continuous motion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The implementation of this kernel inspired by CNN theory will be compared with a biologically realistic models of the early visual system (&lt;a href=&#34;#Antolik2019&#34;&gt;Antolik et al., 2019&lt;/a&gt;), and simulations of the lateral diffusion kernel will be developed in collaboration with &lt;a href=&#34;http://antolik.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jan Antolik&lt;/a&gt;, external collaborator to the ANR grant.  In parallel, using tools linking neural activity to VSD imaging¬†(&lt;a href=&#34;#muller2014stimulus&#34;&gt;Muller et al., 2014&lt;/a&gt;; &lt;a href=&#34;#Chemla2018&#34;&gt;Chemla et al., 2019&lt;/a&gt;), we will analyze at a more mesocopic level the role of observed traveling waves in forming efficient representations of the visual world.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;expected-profile-of-the-candidate&#34;&gt;Expected profile of the candidate&lt;/h2&gt;
&lt;p&gt;Candidates should have at least a PhD degree in the domain of computational neuroscience, physics, engineering or related, and a solid training in machine learning and computer vision.&lt;/p&gt;
&lt;p&gt;The candidate has to show good skills in computer science (programming skills, architecture understanding, git versioning, &amp;hellip;), and in image processing methods. Good command of programming tools (Python scripting) is required. Multidisciplinary background would be strongly appreciated and in particular an advanced knowledge in mathematics, for a deep understanding of signal processing methods, along with strong computational skills. The candidate needs to show a keen interest in neuroscience. It is a bonus if the candidate is curious about neuroscience and visual perception.&lt;/p&gt;
&lt;p&gt;The candidate has to fluently speak English to understand publications and to attend international conferences and workshops. The preferred candidate will have the ability to work autonomously, and needs to be flexible to comply with the working method of the supervisors.&lt;/p&gt;
&lt;h2 id=&#34;research-context&#34;&gt;Research context&lt;/h2&gt;
&lt;p&gt;This project is funded by the French National Research Agency (ANR) under the &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-horizontal-v1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ANR Horizontal V1&lt;/a&gt; grant (coordinator Y. Fr√©gnac) which aims at understanding the emergence of sensory predictions linking local shape attributes (orientation, contour) to global indices of movement (direction, speed, trajectory) at the earliest stage of cortical processing (primary visual cortex, i.e. V1). The cross-talk between physiological and theoretical approaches will be fostered by the close collaboration with the teams of Fr√©d√©ric Chavane at INT and Yves Fr√©gnac at UNIC. The theoretical work will be performed in close collaboration with &lt;a href=&#34;https://www.mullerlab.ca/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lyle Muller&lt;/a&gt; (Western U) and Jan Antolik (Prague). The project will be primarily hosted at the &lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institut de Neurosciences de la Timone&lt;/a&gt; in &lt;a href=&#34;https://en.wikipedia.org/wiki/Marseille&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Marseille&lt;/a&gt;, a lively town by the Mediterranean sea in the south of France, but the applicant will be asked also to show mobility to visit the other partner lab when needed.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Antolik2019&#34;&gt; Antolik, J, C Monier, Y Fr√©gnac, AP Davison. (2019). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/416156v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A comprehensive data-driven model of cat primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;BioRxiv&lt;/em&gt;, 416156.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;BoutinFranciosiniChavaneRuffierPerrinet20&#34;&gt; Boutin, Victor, Angelo Franciosini, Fr√©d√©ric Chavane, Franck Ruffier, and Laurent U Perrinet. (2019). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system.&lt;/a&gt;&amp;rdquo; &lt;em&gt;arXiv&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Chavane2000&#34;&gt; Chavane, F., C. Monier, V. Bringuier, P. Baudot, L. Borg-Graham, J. Lorenceau, and Y. Fr√©gnac. 2000. &lt;/a&gt; &amp;ldquo;The Visual Cortical Association Field: A Gestalt Concept or a Psychophysiological Entity?&amp;rdquo; &lt;em&gt;Frontiers in System Neuroscience&lt;/em&gt; 4(5): 1-26.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Chavane2011&#34;&gt; Chavane, F., Sharon, D., Jancke, D., Marre, O., Fr√©gnac, Y. and Grinvald, A.  (2011). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1016/S0928-4257%2800%2901096-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lateral spread of orientation selectivity in V1 is controlled by intracortical cooperativity.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Physiology Paris&lt;/em&gt; 94 (5-6): 333&amp;ndash;42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Chemla2018&#34;&gt; Chemla, Sandrine, Alexandre Reynaud, Matteo diVolo, Yann Zerlaut, Laurent Perrinet, Alain Destexhe, and Fr√©d√©ric Chavane. &lt;/a&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1523/JNEUROSCI.2792-18.2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Suppressive Waves Disambiguate the Representation of Long-Range Apparent Motion in Awake Monkey V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Neuroscience&lt;/em&gt; 39 (22) 4282-4298.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Field1993&#34;&gt; Field, D.J., Hayes, A. and Hess, R.F. (1993). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1016/0042-6989%2893%2990156-Q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contour integration by the human visual system: Evidence for a local ‚Äúassociation field‚Äù.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Vision Research&lt;/em&gt; 33 (2), pp. 173-193.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Fr√©gnac2012&#34;&gt; Fr√©gnac, Y. (2012)  &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://hal.archives-ouvertes.fr/hal-01685152/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reading out the synaptic echoes of low-level perception in V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;European Conference in Computer Vision&lt;/em&gt; 486-495. Springer, Berlin, Heidelberg.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Fr√©gnac2016&#34;&gt; Fr√©gnac, Y., Fournier, J., Gerard-Mercier, F., Monier, C., Carelli, P., , M., Troncoso, X. (2016).  &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://link-springer-com.insb.bib.cnrs.fr/content/pdf/10.1007%2F978-3-319-28802-4_4.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Visual Brain: Computing Through Multiscale Complexity.&lt;/a&gt;&amp;rdquo; In &lt;em&gt;Micro-, Meso- and Macro-Dynamics of the Brain&lt;/em&gt; pp 43-57.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;gerard2016synaptic&#34;&gt; Gerard-Mercier, Florian, Pedro V Carelli, Marc Pananceau, Xoana G Troncoso, and Yves Fr√©gnac. (2016). &lt;/a&gt; &amp;ldquo;&lt;a href=&#34;https://www.jneurosci.org/content/36/14/3925&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Synaptic Correlates of Low-Level Perception in V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Neuroscience&lt;/em&gt; 36 (14): 3925&amp;ndash;42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Keller2019&#34;&gt;Keller, A., Roth, M.M. and Scanziani, M. (2019).  &lt;/a&gt; 2019. &amp;ldquo;&lt;a href=&#34;https://www.abstractsonline.com/pp8/#!/7883/presentation/65856&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The feedback receptive field of neurons in the mammalian primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;American Society for Neuroscience Abstracts&lt;/em&gt;,  403.13. Chicago.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Kietzmann19&#34;&gt;Kietzmann, Tim C., Courtney J. Spoerer, Lynn K. A. S√∂rensen, Radoslaw M. Cichy, Olaf Hauk, and Nikolaus Kriegeskorte. &lt;/a&gt; (2019). &amp;ldquo;&lt;a href=&#34;https://doi.org/10/gf9j2t&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recurrence Is Required to Capture the Representational Dynamics of the Human Visual System.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;, October, 201905544.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Li2002&#34;&gt;Li W, Pi√´ch V, Gilbert CD&lt;/a&gt;  (2006). &amp;ldquo;&lt;a href=&#34;http://www.paper.edu.cn/scholar/showpdf/MUz2UN2INTA0eQxeQh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contour saliency in primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Neuron&lt;/em&gt;, 50(6):951‚Äì962.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;muller2014stimulus&#34;&gt;Muller, Lyle, Alexandre Reynaud, Fr√©d√©ric Chavane, and Alain Destexhe. &lt;/a&gt; (2014). &amp;ldquo;&lt;a href=&#34;http://www.int.univ-amu.fr/IMG/pdf/Muller_Nature_Communications2014.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Stimulus-Evoked Population Response in Visual Cortex of Awake Monkey Is a Propagating Wave.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Nature Communications&lt;/em&gt; 5: 3675.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;muller2018cortical&#34;&gt; Muller, Lyle, Fr√©d√©ric Chavane, John Reynolds, and Terrence J Sejnowski. &lt;/a&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://papers.cnl.salk.edu/PDFs/Cortical%20travelling%20waves_%20mechanisms%20and%20computational%20principles.%202018-4515.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cortical Travelling Waves: Mechanisms and Computational Principles.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Nature Reviews Neuroscience&lt;/em&gt; 19 (5): 255.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Tang18&#34;&gt;Tang, Hanlin, Martin Schrimpf, William Lotter, Charlotte Moerman, Ana Paredes, Josue Ortega Caro, Walter Hardesty, David Cox, and Gabriel Kreiman. &lt;/a&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1073/pnas.1719397115&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recurrent computations for visual pattern completion.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt; 115 (35) 8835-8840.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;Voges12&#34;&gt; Voges, Nicole, and Laurent U Perrinet.&lt;/a&gt; (2012). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Complex Dynamics in Recurrent Cortical Networks Based on Spatially Realistic Connectivities.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt; 6.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-10-10: GDR vision 2019</title>
      <link>https://laurentperrinet.github.io/post/2019-10-10_gdrvision/</link>
      <pubDate>Thu, 10 Oct 2019 12:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-10_gdrvision/</guid>
      <description>&lt;p&gt;Avec Anna Montagnini, Manuel Vidal et Fran√ßoise Vitu, nous organisons cette ann√©e le GDR Vision √† Marseille les journ√©es du 10 et 11 octobre.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plus d&amp;rsquo;infos sur &lt;a href=&#34;https://gdrvision2019.sciencesconf.org/&#34;&gt;https://gdrvision2019.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;nous aurons un atelier m√©thodologique le jeudi matin sur les apports possibles du Deep Learning pour les sciences de la vision: &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Utiliser l&amp;rsquo;apprentissage profond en vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;la session sp√©ciale du jeudi est sponsoris√©e par la &lt;a href=&#34;https://laurentperrinet.github.io/project/spikeai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;projet SpikeAI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R√©unions pass√©es:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lille: &lt;a href=&#34;https://gdrvision2017.sciencesconf.org/&#34;&gt;https://gdrvision2017.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paris: &lt;a href=&#34;https://gdrvision2018.sciencesconf.org/&#34;&gt;https://gdrvision2018.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-10-10: Atelier Utiliser l&#39;apprentissage profond en vision</title>
      <link>https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/</link>
      <pubDate>Thu, 10 Oct 2019 09:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/</guid>
      <description>&lt;p&gt;Date : jeudi 10 octobre de 9h30 √† 12h30&lt;/p&gt;
&lt;p&gt;Intervenants : Laurent Perrinet et Chlo√© Pasturel&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://gdrvision2019.sciencesconf.org/resource/page/id/2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;programme&lt;/a&gt;: Nous proposons dans cet atelier pratique de pr√©senter les nouveaux enjeux apport√©s par l&amp;rsquo;apprentissage profond et plus g√©n√©ralement par l&amp;rsquo;apprentissage machine. L&amp;rsquo;objectif est de montrer sous forme de simples exercises pratiques comment ces nouveaux outils permettent 1) de cat√©goriser des images 2) d&amp;rsquo;apprendre un tel mod√®les 3) de g√©n√©rer de nouvelles images √† partir d&amp;rsquo;une base existante.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SpikeAI/2019-10-10_ML-tutorial&#34;&gt;https://github.com/SpikeAI/2019-10-10_ML-tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Atelier concoct√© en collaboration avec &lt;a href=&#34;https://github.com/chloepasturel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chlo√© Pasturel&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cet atelier fait partie du &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-10_gdrvision/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GDR vision 2019&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-10-07: Le temps des sens</title>
      <link>https://laurentperrinet.github.io/post/2019-10-07_neurostories/</link>
      <pubDate>Mon, 07 Oct 2019 18:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-07_neurostories/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Cette pr√©sentation lors des &lt;a href=&#34;http://neuroschool-stories.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroStories&lt;/a&gt; vise √† aborder la notion de temps dans le cerveau.&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/jJKTdlChefc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;Chaque ann√©e, NeuroSchool nous raconte des histoires sur un th√®me √† la fois philosophique et scientifique. L‚Äôobjectif est de faire conna√Ætre, d‚Äôune mani√®re inventive, les recherches de pointe men√©es √† Marseille et ailleurs, dans le domaine des neurosciences. Le format inventif associe des NeuroStories et des causeries scientifiques.&amp;rdquo; &lt;a href=&#34;http://neuroschool-stories.com/&#34;&gt;http://neuroschool-stories.com/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Le texte de cette pr√©sentation est repris dans &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-temps/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Conversation&lt;/a&gt; (&lt;a href=&#34;https://theconversation.com/temps-et-cerveau-comment-notre-perception-nous-fait-voyager-dans-le-temps-127567&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;lien direct&lt;/a&gt;) ainsi que dans &lt;a href=&#34;https://www.science-et-vie.com/paroles-d-experts/temps-et-cerveau-comment-notre-perception-nous-fait-voyager-dans-le-temps-53387&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Science &amp;amp; Vie&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neurostories: d&amp;rsquo;autres figures anim√©es du flash-lag effect&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-05-20: Symposium on Active Inference at NeuroFrance 2019</title>
      <link>https://laurentperrinet.github.io/post/2019-05-23-neurofrance/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-05-23-neurofrance/</guid>
      <description>&lt;h2 id=&#34;active-inference-bridging-theoretical-and-experimental-neurosciences--inference-active-un-pont-entre-neurosciences-th√©oriques-et-exp√©rimentales&#34;&gt;Active Inference: Bridging theoretical and experimental neurosciences. / Inference Active: Un pont entre neurosciences th√©oriques et exp√©rimentales.&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.neurosciences.asso.fr/V2/colloques/SN19/index_en.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://neuro-marseille.org/wp-content/uploads/2018/07/capture-decran-2018-07-06-a-190423.png&#34; alt=&#34;Site NeuroFrance&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SYMPOSIUM S17&lt;/li&gt;
&lt;li&gt;When: 23.05.2019 11:00-13:00h&lt;/li&gt;
&lt;li&gt;When: Endoume 1+2&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;s171httpswwwprofessionalabstractscomnf2019iplannerpresentation1397-active-inference-and-brain-computer-interfaces--inf√©rence-active-et-interfaces-cerveau-machine&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1397&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S17.1&lt;/a&gt; 	Active inference and Brain-Computer Interfaces / Inf√©rence active et interfaces cerveau-machine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Mattout J. (Lyon, France), Mladenovic J. (Lyon, France), Frey J. (Bordeaux, France)3, Joffily M. (Lyon, France), Maby E. (Lyon, France), Lotte F. (Lyon, France)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Brain-Computer Interfaces (BCIs) devices bypass natural pathways to connect the brain with a machine, directly. They may rely on invasive or non-invasive measures of brain activity and applications cover a large domain, mostly but not restricted to clinical ones. A major objective is to restore communication and autonomy in heavily motor impaired patients.
However, no BCI has made its way to a routinely used clinical application yet. One lead for improvement is to endow the machine with learning abilities so that it can optimize its decisions and adapt to changes in the user signals over time1. Several approaches have been proposed but a generic framework is still lacking to foster the development of efficient adaptive BCIs2.
Initially proposed to model perception, learning and action by the brain, the Active Inference (AI) framework offers great promises in that aim3. It rests on an explicit generative model of the environment. In BCI, from the machine&amp;rsquo;s point of view, brain signals play the role of sensory inputs on which the machine&amp;rsquo;s perception of mental states will be based. Furthermore, the machine builds up decisions and trades between different actions such as: go on observing, deciding to decide, correcting its previous action or moving on.
In this talk, I will present an instantiation of AI in the context of the EEG-based P300-speller BCI for communication, showing it can flexibly combine complementary adaptive features pertaining to both perception and action, and yield significant improvements as shown on realistic simulations. We will discuss perspectives to further extend the current model and performance as well as the challenges ahead to implement this framework online.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Mattout, J. Brain-Computer Interfaces: A Neuroscience Paradigm of Social Interaction? A Matter of Perspective. Frontiers in Human Neuroscience 6, (2012).&lt;/li&gt;
&lt;li&gt;Mladenovic, J., Mattout, J. &amp;amp; Lotte, F. A Generic Framework for Adaptive EEG-Based BCI Training and Operation. in Brain-computer interfaces handbook: technological and theoretical advances (eds. Nam, C. S., Nijholt, A. &amp;amp; Lotte, F.) Chapter 31 (Taylor &amp;amp; Francis, CRC Press, 2018).&lt;/li&gt;
&lt;li&gt;Friston, K., Mattout, J. &amp;amp; Kilner, J. Action understanding and active inference. Biological Cybernetics 104, 137-160 (2011).&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;s172httpswwwprofessionalabstractscomnf2019iplannerpresentation1398-comparing-active-inference-and-reinforcement-learning-models-of-a-go-nogo-task-and-their-relationships-to-striatal-dopamine-2-receptors-assessed-using-pet--comparaison-des-mod√®les-dinf√©rence-active-et-dapprentissage-par-renforcement-dans-une-t√¢che-go--nogo--relation-avec-les-r√©cepteurs-dopaminergiques-d2-striataux-√©valu√©s-par-tep&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1398&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S17.2&lt;/a&gt; 	Comparing active inference and reinforcement learning models of a Go NoGo task and their relationships to striatal dopamine 2 receptors assessed using PET / Comparaison des mod√®les d&amp;rsquo;inf√©rence active et d&amp;rsquo;apprentissage par renforcement dans une t√¢che Go / NoGo : relation avec les r√©cepteurs dopaminergiques D2 striataux √©valu√©s par TEP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;R. Adams (London)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1398&#34;&gt;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1398&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Adaptive behaviour includes the ability to choose actions that result in advantageous outcomes. It is key to survival and a fundamental function of nervous systems. Active inference (AI) and reinforcement learning (RL) are two influential models of how the brain might achieve this. A key AI parameter is the precision of beliefs about policies. Precision controls the stochasticity of action selection - similar to decision temperature in RL - and is thought to be encoded by striatal dopamine. 75 healthy subjects performed a &amp;lsquo;go/no-go&amp;rsquo; task, and we measured striatal dopamine 2/3 receptor (D2/3R) availability in a subset of 25 using [11C]-(+)-PHNO positron emission tomography. In behavioural model comparison, RL performed best across the whole group but AI performed best in accurate subjects. D2/3R availability in the limbic striatum correlated with AI policy precision and also with RL irreducible decision &amp;lsquo;noise&amp;rsquo;. Limbic striatal D2/3R availability also correlated with AI Pavlovian prior beliefs - i.e. the respective probabilities of making or withholding actions in rewarding or loss-avoiding contexts - and the RL learning rate. These findings are consistent with the notion that occupancy of inhibitory striatal D2/3Rs controls the variability of action selection.&lt;/p&gt;
&lt;h3 id=&#34;s173httpswwwprofessionalabstractscomnf2019iplannerpresentation1399-principles-and-psychophysics-of-active-inference-in-anticipating-a-dynamic-switching-probabilistic-bias--principes-et-psychophysique-de-linf√©rence-active-dans-lestimation-dun-biais-dynamique-et-volatile-de-probabilit√©&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1399&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S17.3&lt;/a&gt; 	Principles and psychophysics of active inference in anticipating a dynamic, switching probabilistic bias / Principes et psychophysique de l&amp;rsquo;inf√©rence active dans l¬¥estimation d&amp;rsquo;un biais dynamique et volatile de probabilit√©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;L. Perrinet (Marseille)&lt;/li&gt;
&lt;li&gt;see more info on this &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-05-23-neurofrance/&#34;&gt;talk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;s174httpswwwprofessionalabstractscomnf2019iplannerpresentation1400-is-laziness-contagious-a-computational-approach-to-attitude-alignment--la-fain√©antise-est-elle-contagieuse-une-approche-computationnelle-de-lalignement-des-attitudes&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S17.4&lt;/a&gt; 	Is laziness contagious? A computational approach to attitude alignment / La fain√©antise est-elle contagieuse? Une approche computationnelle de l¬¥alignement des attitudes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;J. Daunizeau (Paris)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What do people learn from observing others¬¥ attitudes, such as prudence, impatience or laziness? Rather than viewing these attitudes as examples of subjective and biologically entrenched personality traits, we assume that they derive from uncertain (and mostly implicit) beliefs about how to best weigh risks, delays and efforts in ensuing cost-benefit trade-offs. In this view, it is adaptive to update one¬¥s belief after having observed others¬¥ attitude, which provides valuable information regarding how to best behave in related difficult decision contexts. This is the starting point of our bayesian model of attitude alignment, which we derive in the light of recent neuroimaging findings. First, we disclose a few non-trivial predictions from this model. Second, we validate these predictions experimentally by profiling people¬¥s prudence, impatience and laziness both before and after guessing a series of cost-benefit arbitrages performed by calibrated artificial agents (which are impersonating human individuals). Third, we extend these findings and assess attitude alignment in autistic individuals. Finally, we discuss the relevance and implications of this work, with a particular emphasis on the assessment of biases of social cognition.&lt;/p&gt;
&lt;h3 id=&#34;s175httpswwwprofessionalabstractscomnf2019iplannerpresentation223-generative-bayesian-modeling-for-causal-inference-between-neural-activity-and-behavior-in-drosophila-larva&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/223&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S17.5&lt;/a&gt; 	Generative Bayesian modeling for causal inference between neural activity and behavior in Drosophila larva&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;C. Barre (Paris) (TBC)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A fundamental property of the central nervous system is its ability to select appropriate behavioral patterns or sequences of behavioral patterns in response to sensory cues, but what are the biological mechanisms underlying decision making? The Drosophila larva is an ideal animal model for reverse-engineering the neural processes underlying behavior. The full connectome of the larva brain has been imaged at the individual-synapse level using electron microscopy.
The host of genetic techniques available for Drosophila allows us to optogenetically manipulate over 1,500 of its roughly 12,000 neurons individually in freely behaving larvae.
This enables us to establish causal relationships between neural activity, and behavior at the fundamental level of individual neurons and neural connections.
We have access to video record of the individual behavior of ~3,000,000 larvae. We have identified 6 stereotypical behavioral patterns using a combination of supervised and unsupervised machine learning. The behavioral identified for the larva: crawl, turn, stop, crawl backward, hunch (retract the head), and roll (lateral slide). Each realization of a behavioral pattern is characterized by a different duration, amplitude, and velocity.
Here we present a generative model that extracts the behavior of wildtype larvae using Bayesian inference, and interprets behavioral changes following neuron activation or inactivation from large-scale experimental screens. Fig. shows the average behavior of 10,000 larvae over time in a screen where a single neuron is activated at t=30s. A clear change in behavior is seen following activation is seen which is well captured by the model, illustrating its accuracy.
The generative model enables us to robustly detect behavioral modifications as significant deviations of the patterns in the larvae&amp;rsquo;s sequence of activities from their equilibrium behavior.&lt;/p&gt;
&lt;h3 id=&#34;neurofrance-marseille-capitale-des-neurosciences&#34;&gt;NeuroFrance: Marseille, capitale des neurosciences&lt;/h3&gt;
&lt;p&gt;Du  22 au 24 mai 2019 au Palais des congr√®s de Marseille (Parc Chanot), pr√®s de 1300 chercheurs, cliniciens et √©tudiants venus du monde entier partageront leurs travaux lors de NeuroFrance 2019, colloque international organis√© par la Soci√©t√© des Neurosciences.Au total, 8 conf√©rences pl√©ni√®res, 42 symposiums, 6 sessions sp√©cialis√©es, 525 communications affich√©es, ainsi qu‚Äôune exposition avec 42 entreprises et soci√©t√©s de biotechnologies, feront de ce colloque un moment exceptionnel pour mettre en lumi√®re les avanc√©es majeures scientifiques et technologiques sur le fonctionnement du cerveau. Vous pourrez aussi d√©couvrir le &amp;ldquo;Neurovillage&amp;rdquo; qui permettra de vous immerger au c≈ìur des innovations neuroscientifiques marseillaises, ainsi que  l‚Äôexposition  ¬´ L‚ÄôArt en t√™te ¬ª, compos√©e de cinq ≈ìuvres originales cr√©√©es par des artistes et des scientifiques. Plusieurs √©v√©nements seront √©galement propos√©s autour du colloque pour le grand public comme pour les chercheurs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-11-09 : Retinal computations</title>
      <link>https://laurentperrinet.github.io/post/2018-11-09_seminaire-escobar/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2018-11-09_seminaire-escobar/</guid>
      <description>&lt;h1 id=&#34;2018-11-09--retinal-computations-by-maria-jos√©-escobar-chile&#34;&gt;2018-11-09 : &amp;ldquo;Retinal computations&amp;rdquo; by Maria Jos√© Escobar (Chile)&lt;/h1&gt;
&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;http://profesores.elo.utfsm.cl/~mjescobar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mar√≠a Jos√© Escobar, Ph.D.&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Retinal computations&amp;rdquo; : The retina is part of the nervous system and consists in well-organized layers of different cell types and functions. Those cells have been vastly studied in various animal models, and also the circuits conveying to different functional categories. All these different types of either physiological properties or computation equivalents revealed the retina as not a single light to electricity encoder but a pre-processing layer, which is in charge to extract relevant visual signals from the environment that are critical for animal survival. During this seminar, we describe some of the computations performed by the retina, and how this knowledge can be applied to solve engineering problems, such as image processing and robot controllers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.int.univ-amu.fr/IMG/200x130xsiteon0.png,q1331299836.pagespeed.ic.IKYGzK4Zu8.png&#34; alt=&#34;Sponsored by&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-04-05 : *Probabilities and Optimal Inference to understand the Brain* Workshop</title>
      <link>https://laurentperrinet.github.io/post/2018-04-05_optimal-inference-brain-workshop/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2018-04-05_optimal-inference-brain-workshop/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;IMG_20180406_164630.jpg&#34; alt=&#34;participants&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;probabilities-and-optimal-inference-to-understand-the-brain&#34;&gt;Probabilities and Optimal Inference to understand the Brain&lt;/h1&gt;
&lt;h2 id=&#34;a-2-day-workshop-at-the-institute-of-neurosciences-timone-in-marseille&#34;&gt;a 2-day workshop at the Institute of Neurosciences Timone in Marseille&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;affiche&#34;&gt;&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Date&lt;/dt&gt;
&lt;dd&gt;April 5-6th 2018&lt;/dd&gt;
&lt;dt&gt;Location&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href=&#34;http://www.int.univ-amu.fr/contact&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institute of Neurosciences Timone in Marseille in the south of
France&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Main site&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href=&#34;https://opt-infer-brain.sciencesconf.org/&#34;&gt;https://opt-infer-brain.sciencesconf.org/&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Full program&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href=&#34;https://opt-infer-brain.sciencesconf.org/program/details&#34;&gt;https://opt-infer-brain.sciencesconf.org/program/details&lt;/a&gt;.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Organizing committee&lt;/dt&gt;
&lt;dd&gt;Paul Apicella, Frederic Danion, Nicole Malfait, Anna Montagnini and
Laurent Perrinet&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;&lt;img src=&#34;http://www.int.univ-amu.fr/IMG/200x130xsiteon0.png,q1331299836.pagespeed.ic.IKYGzK4Zu8.png&#34; alt=&#34;Sponsored by&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-03-26 : PhD Program: course in Computational Neuroscience</title>
      <link>https://laurentperrinet.github.io/post/2018-03-26-cours-neuro-comp-fep/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2018-03-26-cours-neuro-comp-fep/</guid>
      <description>&lt;h1 id=&#34;phd-program-course-in-computational-neuroscience&#34;&gt;PhD Program: course in Computational Neuroscience&lt;/h1&gt;
&lt;p&gt;Context&lt;/p&gt;
&lt;p&gt;Computational neuroscience is an expending field that is proving to be essential in neurosciences. The aim of this course will be to provide a common solid background in computational neurosciences. The course will comprise historical recall of the field and a description of the different modelling approaches that are currently developed, including details about their specificities, limits and advantages.&lt;/p&gt;
&lt;p&gt;Objective&lt;/p&gt;
&lt;p&gt;The course aims at introducing students with the major tools that will be necessary during their thesis to model or analyze their neuroscientific results. While it will start by a short, generic introduction, we will then explore different systems at different scales. On the first day, we will study the different possible regimes in which a single neuron can behave, while progressively introducing the theory of dynamical systems to understand these more globally. Then, during the second day, we will introduce methods to analyze neuroscientific data in general, such as Bayesian methods and information theory. This will be implemented by simple practical examples.&lt;/p&gt;
&lt;p&gt;Language of intervention&lt;/p&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;p&gt;Number of hours&lt;/p&gt;
&lt;p&gt;~20 hours (session 1=7 + session 2=7 + session 3=4)&lt;/p&gt;
&lt;p&gt;Max participants&lt;/p&gt;
&lt;p&gt;15 for the practical sessions (afternoon Day 2 and Day 3), unlimited for theoretical courses&lt;/p&gt;
&lt;p&gt;Public priority&lt;/p&gt;
&lt;p&gt;PhD students&lt;/p&gt;
&lt;p&gt;Public concerned&lt;/p&gt;
&lt;p&gt;PhD students, interested M2 students and postdocs&lt;/p&gt;
&lt;p&gt;Location&lt;/p&gt;
&lt;p&gt;Institut des Neurosciences de la Timone (INT)&lt;/p&gt;
&lt;p&gt;Keywords&lt;/p&gt;
&lt;p&gt;neuronal modelling, neural circuit modelling, information theory, decoding and encoding&lt;/p&gt;
&lt;p&gt;Targets&lt;/p&gt;
&lt;p&gt;Understanding how computational modelling can be used to formulate and solve neuroscience problems at different spatial and temporal scales; learning the formal notions of information, encoding and decoding and experimenting their use on toy datasets&lt;/p&gt;
&lt;p&gt;Program&lt;/p&gt;
&lt;p&gt;&lt;em&gt;First session:&lt;/em&gt; Introduction to modeling single neurons (morning); An introduction to neural masses: modeling assemblies of neurons up to capturing collective oscillations and resting state dynamics in a mean-field model - presentation of the Virtual Brain software (afternoon) - &lt;em&gt;Second session:&lt;/em&gt; An overview on &amp;ldquo;What is encoding?&amp;rdquo; &amp;ldquo;What is decoding?&amp;quot;: formalization of the notion of information in neural activity; shared and transferred information; integration, segregation and complexity (morning). Bayesian probabilities, the Free-energy principle and Active Inference, with practical demonstrations in python (afternoon). &lt;em&gt;Third session:&lt;/em&gt; the problem of information estimation in practice. Practical exercices in Matlab: estimating entropy and stimulus decodability from spike trains; comparing coding hypotheses (morning).&lt;/p&gt;
&lt;p&gt;Pre-required&lt;/p&gt;
&lt;p&gt;Basic knowledge of statistics and probability and calculus (differential equations,&amp;hellip;) is useful, but steps will be explained and complex math avoided as much as possible. Practical exercises are in python and/or MATLAB, so basic knowledge of these environments is a plus.&lt;/p&gt;
&lt;h2 id=&#34;program&#34;&gt;program&lt;/h2&gt;
&lt;h3 id=&#34;day-1--2018-03-26--an-introduction-to-computational-neuroscience&#34;&gt;day 1 : 2018-03-26 : an introduction to Computational Neuroscience&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;09:30-12:30 = &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2015-12-08_cours_neurocomp/2017-03-06_LaurentPezard.pdf&#34; title=&#34;Introduction to modeling single neurons&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to modeling single neurons&lt;/a&gt; (LaP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14:00-17:00 = An introduction to neural masses: modeling assemblies of neurons up to capturing resting state dynamics in a mean-field model - presentation of the Virtual Brain software (DaB)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-2--2018-03-27--information-theory--bayesian-models&#34;&gt;day 2 : 2018-03-27 : Information theory / bayesian models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;09:15-10:30 = An overview on &amp;ldquo;What is encoding?&amp;rdquo; &amp;ldquo;What is decoding?&amp;quot;: formalization of the notion of information in neural activity (DaB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;11:00-12:15 = (&amp;hellip;continued after the coffee break: ) Live information! From sharing information to transferring information (and a glimpse into the zoo of higher-order friends) (DaB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14:00-17:10 = &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2018-03-26_cours-NeuroComp_FEP.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Probabilities, the Free-energy principle and Active Inference&lt;/a&gt; (LuP).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-3--2018-03-28--practical-course-on-information-theory&#34;&gt;day 3 : 2018-03-28 : Practical course on Information theory&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;09:30-12:30 = Practical course on Information theory (DaB)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;more-material-related-to-the-course&#34;&gt;More material related to the course&lt;/h2&gt;
&lt;h3 id=&#34;day-1---morning--the-single-neuron&#34;&gt;day 1 - morning : the single neuron&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;site du livre de Gerstner et al &amp;ldquo;Neuronal Dynamics&amp;rdquo;: &lt;a href=&#34;http://neuronaldynamics.epfl.ch/&#34;&gt;http://neuronaldynamics.epfl.ch/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A (longer) introduction to the Hodgkin-Huxley model in three steps by Dr Stefano Luccioli&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez1.pdf&#34;&gt;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez1.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez2.pdf&#34;&gt;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez2.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez3.pdf&#34;&gt;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez3.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An interactive course with Wulfram Gerstner &lt;a href=&#34;https://www.edx.org/course/neuronal-dynamics-computational-epflx-bio465-1x&#34;&gt;https://www.edx.org/course/neuronal-dynamics-computational-epflx-bio465-1x&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;His book ONLINE &lt;a href=&#34;http://cn.epfl.ch/~gerstner/NeuronalDynamics-MOOC1.html&#34;&gt;http://cn.epfl.ch/~gerstner/NeuronalDynamics-MOOC1.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-1---afternoon--neural-mass-models&#34;&gt;day 1 - afternoon : neural mass models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Another interactive course @ Washington University &lt;a href=&#34;https://www.coursera.org/course/compneuro&#34;&gt;https://www.coursera.org/course/compneuro&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collection of didactic material for the EU FP7 ITN Neural Engineering Transformative Technology &lt;a href=&#34;http://www.neural-engineering.eu/training/index.html&#34;&gt;http://www.neural-engineering.eu/training/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Didactic material from Lab in Computational Neuroscience &lt;a href=&#34;http://neuro.fi.isc.cnr.it/index.php?page=didactic-material&#34;&gt;http://neuro.fi.isc.cnr.it/index.php?page=didactic-material&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A open source simulator of a whole brain which runs on your laptop, &amp;ldquo;The Virtual Brain&amp;rdquo;: &lt;a href=&#34;http://thevirtualbrain.org&#34;&gt;http://thevirtualbrain.org&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-2---morning--information-theory&#34;&gt;day 2 - morning : information theory&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The best book on information theory and decoding, freely available directly from the author: &lt;a href=&#34;http://www.inference.phy.cam.ac.uk/itprnn/book.html&#34;&gt;http://www.inference.phy.cam.ac.uk/itprnn/book.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a gentle introduction to bayesian methods : &lt;a href=&#34;https://homepages.inf.ed.ac.uk/pseries/Peg_files/Chapter9_SotiropoulosSeries.pdf&#34;&gt;https://homepages.inf.ed.ac.uk/pseries/Peg_files/Chapter9_SotiropoulosSeries.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-2---afternoon--bayesian-models&#34;&gt;day 2 - afternoon : bayesian models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;an interesting read : &lt;a href=&#34;http://cognitrn.psych.indiana.edu/busey/q551/PDFs/PredictivCodingRaoBallard.pdf&#34;&gt;http://cognitrn.psych.indiana.edu/busey/q551/PDFs/PredictivCodingRaoBallard.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a tutorial on free-energy : some exercises : &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S0022249615000759&#34;&gt;http://www.sciencedirect.com/science/article/pii/S0022249615000759&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;solutions to the tutorial : &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contacts&#34;&gt;contacts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LaP: Laurent Pezard &amp;laquo;&lt;a href=&#34;mailto:Laurent.Pezard@univ-amu.fr&#34;&gt;Laurent.Pezard@univ-amu.fr&lt;/a&gt;&amp;raquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DaB: Demian Battaglia &amp;laquo;&lt;a href=&#34;mailto:demian.battaglia@univ-amu.fr&#34;&gt;demian.battaglia@univ-amu.fr&lt;/a&gt;&amp;raquo;, INS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LuP: Laurent Udo Perrinet &amp;laquo;&lt;a href=&#34;mailto:laurent.perrinet@univ-amu.fr&#34;&gt;laurent.perrinet@univ-amu.fr&lt;/a&gt;&amp;raquo;, INT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PhD program: Nicole Malfait &amp;laquo;&lt;a href=&#34;mailto:Nicole.Malfait@univ-amu.fr&#34;&gt;Nicole.Malfait@univ-amu.fr&lt;/a&gt;&amp;raquo;, Anna Montagnini &amp;laquo;&lt;a href=&#34;mailto:anna.montagnini@univ-amu.fr&#34;&gt;anna.montagnini@univ-amu.fr&lt;/a&gt;&amp;raquo;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://www.int.univ-amu.fr/IMG/200x130xsiteon0.png,q1331299836.pagespeed.ic.IKYGzK4Zu8.png&#34; alt=&#34;Sponsored by&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2016-10-26 : EUVIP BICV</title>
      <link>https://laurentperrinet.github.io/post/2016-10-26_euvip-bicv/</link>
      <pubDate>Wed, 26 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2016-10-26_euvip-bicv/</guid>
      <description>&lt;h1 id=&#34;2016-10-26--euvip-special-session-on-biologically-inspired-computer-vision&#34;&gt;2016-10-26 : EUVIP Special Session on &lt;em&gt;Biologically Inspired Computer Vision&lt;/em&gt;&lt;/h1&gt;
&lt;h2 id=&#34;description-of-the-session&#34;&gt;description of the session&lt;/h2&gt;
&lt;p&gt;Recent advances in imaging technologies have yielded scientific data at
unprecedented detail and volume, leading to the need of a shift of
paradigm in image processing and computer vision. Beyond the usual
classical von Neumann architecture, one strategy that is emerging in
order to process and interpret this amount of data follows from the
architecture of biological organisms and shows for instance
computational paradigms implementing asynchronous communication with a
high degree of local connectivity in sensors or brain tissues. This
session aims at bringing together researchers from different fields of
Biologically Inspired Computer Vision to present latest results in the
field, from fundamental to more specialized topics, including visual
analysis based on a computational level, hardware implementation, and
the design of new more advanced vision sensors. It is expected to
provide a comprehensive overview in the computer area of biologically
motivated vision. On the one hand, biological organisms can provide a
source of inspiration for new computationally efficient and robust
vision models and on the other hand machine vision approaches can
provide new insights for understanding biological visual systems. This
session covers a wide range of topics from fundamental to more
specialized topics, including visual analysis based on a computational
level, hardware implementation, and the design of new more advanced
vision sensors. In particular, we expect to provide an overview of a few
representative applications and current state of the art of the research
in this area.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;URL
&lt;a href=&#34;http://www-l2ti.univ-paris13.fr/euvip2016/index.php/86-euvip2016/129-tentative-technical-program-in-detail&#34;&gt;http://www-l2ti.univ-paris13.fr/euvip2016/index.php/86-euvip2016/129-tentative-technical-program-in-detail&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;date
October 26th, 2016&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Location
Ecole Centrale Marseille&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Address
&lt;a href=&#34;https://www.centrale-marseille.fr/fr/acces-0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;38 rue Fr√©d√©ric Joliot-Curie 13013 Marseille,
France&lt;/a&gt; Phone : +33
(0)4 91 05 45 45&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Programme&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;13.50  &lt;a href=&#34;http://ieeexplore.ieee.org/document/7764586/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Visual System Inspired Algorithm For Contours, Corner And T Junction Detection&lt;/a&gt;, Antoni Buades, &lt;em&gt;Rafael Grompone Von Gioi&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;13.50  &lt;a href=&#34;https://laurentperrinet.github.io/talk/2016-10-26-perrinet-16-euvip/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Biologically-inspired characterization of sparseness in natural images&lt;/a&gt;, &lt;em&gt;Laurent Perrinet&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14.10 &lt;a href=&#34;http://david.alleysson.free.fr/Publications/JIST0224reprint.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Color filter array imitating the random nature of color arrangement in the human cone mosaic&lt;/a&gt;, Prakhar Amba, &lt;em&gt;David Alleysson&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14.30 &lt;a href=&#34;http://ieeexplore.ieee.org/document/7764601/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Illuminant-Independent Analysis Of Reflectance As Sensed By Humans, And Its Applicability To Computer Vision&lt;/a&gt;, Alban Flachot, Phelma, J.Kevin O&amp;rsquo;Regan, &lt;em&gt;Edoardo Provenzi&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14.50 &lt;a href=&#34;https://laurentperrinet.github.io/talk/2016-10-26-fillatre-barlaud-perrinet-16-euvip/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor&lt;/a&gt;, Lionel Fillatre, Michel Barlaud, &lt;em&gt;Laurent Perrinet&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2010-06-22 : CodeJamNr4</title>
      <link>https://laurentperrinet.github.io/post/2010-06-22_codejam-nr4/</link>
      <pubDate>Tue, 22 Jun 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2010-06-22_codejam-nr4/</guid>
      <description>&lt;h1 id=&#34;facets-code-jam-workshop-4&#34;&gt;FACETS Code Jam Workshop #4&lt;/h1&gt;
&lt;p&gt;We held a CodeJam 22nd-24th June 2010, in Marseille.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://neuralensemble.org/media/images/codejam4_group_photo.jpg&#34; alt=&#34;Participants&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the
&lt;a href=&#34;http://neuralensemble.org/meetings/CodeJam4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of the FACETS CodeJam workshops is to catalyze open-source, collaborative software development in computational and systems neuroscience and neuroinformatics, by bringing together researchers, students and engineers to share ideas, present their work, and write code together. The general format of the workshops is to dedicate the mornings to invited and contributed talks, leaving the afternoons free for discussions and code sprints. &lt;BR&gt;
For the 4th FACETS CodeJam, the main theme of the meeting will be workflows: what are the best practices for combining different tools (simulators, analysis tools, visualization tools, databases etc.) to ensure the efficient and reproducible flow of data and information from experiment conception to publication and archiving? &lt;BR&gt;
(&amp;hellip;) &lt;BR&gt;
The meeting organizers gratefully acknowledge the support of the European Union through the FACETS Project (grant no. IST-2005-15879), and the International Neuroinformatics Co-ordinating Facility (INCF). We also wish to express our great appreciation to the DyVA team at the Institut de Neurosciences Cognitives de la M√©diterran√©e for providing us with a great location and much assistance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuralensemble.org/meetings/CodeJam4.html&#34;&gt;http://neuralensemble.org/meetings/CodeJam4.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuralensemble.org/meetings/CJ4_Program_v2.pdf&#34;&gt;http://neuralensemble.org/meetings/CJ4_Program_v2.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://facets.kip.uni-heidelberg.de/internal/jss/AttendMeeting?mI=73&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FACETS code jam #4&lt;/a&gt;{.https}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;Affiche&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2010-05-27 : Neurocomp08</title>
      <link>https://laurentperrinet.github.io/post/2008-10-08_neurocomp/</link>
      <pubDate>Thu, 27 May 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2008-10-08_neurocomp/</guid>
      <description>&lt;h1 id=&#34;2008-10-08--deuxi√®me-conf√©rence-fran√ßaise-de-neurosciences-computationnelles-neurocomp08&#34;&gt;2008-10-08 : Deuxi√®me conf√©rence fran√ßaise de Neurosciences Computationnelles, &amp;ldquo;Neurocomp08&amp;rdquo;&lt;/h1&gt;
&lt;p&gt;La deuxi√®me conf√©rence fran√ßaise de Neurosciences Computationnelles, &amp;ldquo;Neurocomp08&amp;rdquo;, s&amp;rsquo;est d√©roul√©e √† la Facult√© de M√©decine de Marseille du 8 au 11 octobre 2008. Cette conf√©rence, organis√©e par le groupe de travail Neurocomp, a permis de r√©unir les principaux acteurs fran√ßais du domaine (francophones ou non). Le champ des Neurosciences Computationnelles porte sur l&amp;rsquo;√©tude des m√©canismes de calcul qui sont √† l&amp;rsquo;origine de nos capacit√©s cognitives. Cette approche n√©cessite l&amp;rsquo;int√©gration constructive de nombreux domaines disciplinaires, du neurone au comportement, des sciences du vivant √† la mod√©lisation num√©rique. Avec ce colloque, nous avons offert un lieu d&amp;rsquo;√©changes afin de favoriser des collaborations interdisciplinaires entre des √©quipes relevant des neurosciences, des sciences de l&amp;rsquo;information, de la physique statistique, de la robotique. Cette √©dition a √©galement √©t√© l&amp;rsquo;occasion d&amp;rsquo;ouvrir le cadre √† de nouveaux domaines (mod√®les pour l&amp;rsquo;imagerie, interfaces cerveau-machine,&amp;hellip;) notamment gr√¢ce √† des ateliers th√©matiques (une nouveaut√© dans cette √©dition). Certains des principaux enjeux du domaine ont √©t√© pr√©sent√©s par quatre conf√©renciers invit√©s : Ad Aertsen (Freiburg, Allemagne), Gustavo Deco (Barcelone, Espagne), Gregor Sch√∂ner (Bochum, Allemagne), Andrew B. Schwartz (Pittsburgh, USA). Des interventions orale plus courtes et plus sp√©cifiques √©taient √©galement au programme, sur la base d&amp;rsquo;une s√©lection du comit√© de lecture. Une cinquantaine de posters ont √©galement √©t√© pr√©sent√©s au cours de ces journ√©es. Le premier jour √©tait consacr√© aux mod√®les de la cellule neurale, aux mod√®les des traitements visuels et corticaux, ainsi qu&amp;rsquo;aux mod√®les de r√©seaux de neurones bio-mim√©tiques. La seconde journ√©e √©tait consacr√©e aux interfaces cerveau-machine, √† la dynamique des grands ensembles de neurones, √† la plasticit√© fonctionnelle et aux interfaces neurales. Enfin, la journ√©e de samedi √©tait consacr√©e √† des ateliers th√©matiques, l&amp;rsquo;un sur les interfaces cerveau-machine, l&amp;rsquo;autre sur la vision computationnnelle. Cette conf√©rence a connu un beau succ√®s de par l&amp;rsquo;affluence (200 personnes environ) et la qualit√© des interventions. Ce succ√®s tient √©galement au fort soutien financier et organisationnel qu&amp;rsquo;elle a obtenu de ses partenaires. Les organisateurs remercient le CNRS, la Soci√©t√© des neurosciences, le conseil r√©gional de la r√©gion Provence Alpes C√¥te d&amp;rsquo;Azur, le conseil g√©n√©ral des Bouches de Rh√¥ne, la mairie de Marseille, l&amp;rsquo;universit√© de Provence, l&amp;rsquo;IFR &amp;ldquo;Sciences du cerveau et de la cognition&amp;rdquo;, l&amp;rsquo;INRIA, ainsi que la facult√© de m√©decine de Marseille et l&amp;rsquo;universit√© de la M√©diterran√©e qui ont h√©berg√© la conf√©rence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Les actes de la conf√©rence regroupant les 68 contributions sont disponibles sur le &lt;a href=&#34;http://hal.archives-ouvertes.fr/NEUROCOMP08&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;serveur HAL d√©di√©&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;Affiche&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computational Neuroscience: From Representations to Behavior</title>
      <link>https://laurentperrinet.github.io/post/2010-05-27_neurocomp-marseille-workshop/</link>
      <pubDate>Wed, 08 Oct 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/post/2010-05-27_neurocomp-marseille-workshop/</guid>
      <description>&lt;h1 id=&#34;computational-neuroscience-from-representations-to-behavior&#34;&gt;Computational Neuroscience: From Representations to Behavior&lt;/h1&gt;
&lt;h2 id=&#34;second-neurocomp-marseille-workshop&#34;&gt;Second NeuroComp Marseille Workshop&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Date: 27-28 May 2010&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Location: Amphith√©√¢tre Charve at the Saint-Charles&#39; University campus&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M√©tro :
Line 1 et 2 (St Charles), a 5 minute walk from the railway station.
&lt;a href=&#34;http://maps.google.com/maps/ms?ie=UTF8&amp;amp;hl=fr&amp;amp;t=h&amp;amp;msa=0&amp;amp;msid=104552809318940980121.0004855ba608957ac9d29&amp;amp;ll=43.297245,5.369546&amp;amp;spn=0.011978,0.027874&amp;amp;z=16&#34; class=&#34;http&#34;&gt;&lt;/li&gt;
&lt;li&gt;Map (Amphith√©√¢tre Charve, University Main Entrance, etc.)&lt;/a&gt;
&lt;a href=&#34;http://85.31.207.119/SITERTM_WEB/PagesFlash/pdf/PlanReseau.pdf&#34; class=&#34;http&#34;&gt;&lt;/li&gt;
&lt;li&gt;Metro, Bus and Tramway&lt;/a&gt;
&lt;a href=&#34;http://www.navettemarseilleaeroport.com/indexA.php&#34; class=&#34;http&#34;&gt;&lt;/li&gt;
&lt;li&gt;Getting to Marseille from Airport&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Computational Neuroscience emerges now as a major breakthrough in
exploring cognitive functions. It brings together theoretical tools that
elucidate fundamental mechanisms responsible for experimentally observed
behaviour in the applied neurosciences. This is the second Computational
Neuroscience Workshop organized by the &amp;ldquo;NeuroComp Marseille&amp;rdquo; network.&lt;/p&gt;
&lt;p&gt;It will focus on latest advances on the understanding of how information
may be represented in neural activity (1st day) and on computational
models of learning, decision-making and motor control (2nd day). The
workshop will bring together leading researchers in these areas of
theoretical neuroscience. The meeting will consist of invited speakers
with sufficient time to discuss and share ideas and data. All
conferences were in English.&lt;/p&gt;
&lt;h2 id=&#34;program&#34;&gt;Program&lt;/h2&gt;
&lt;p&gt;27 May 2010 &lt;strong&gt;Neural representations for sensory information &amp;amp; the
structure-function relation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;9h00-9h30&lt;/p&gt;
&lt;p&gt;Reception and coffee&lt;/p&gt;
&lt;p&gt;9h30-10h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://laurentperrinet.github.io/&#34; class=&#34;http&#34;&gt;Laurent Perrinet&lt;/a&gt;&lt;/em&gt;
Institut de Neurosciences Cognitives de la M√©diterran√©e, CNRS and
Universit√© de la M√©diterran√©e - Marseille
&lt;strong&gt;¬´Presentation of the Workshop and Topic¬ª&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;10h00-11h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.ceremade.dauphine.fr/~peyre/&#34; class=&#34;http&#34;&gt;Gabriel Peyr√©&lt;/a&gt;&lt;/em&gt;
CNRS and Universit√© Paris-Dauphine
&lt;a href=&#34;http://www.ceremade.dauphine.fr/~peyre/talks/2010-05-20-neurosciences-marseilles.pdf&#34; class=&#34;http&#34;&gt;&lt;strong&gt;¬´Sparse Geometric Processing of Natural Images¬ª&lt;/strong&gt;&lt;/a&gt;
In this talk, I will review recent works on the sparse representations
of natural images. I will in particular focus on both the application of
these emerging models to image processing problems, and their potential
implication for the modeling of visual processing.
Natural images exhibit a wide range of geometric regularities, such as
curvilinear edges and oscillating textures. Adaptive image
representations select bases from a dictionary of orthogonal or
redundant frames that are parameterized by the geometry of the image. If
the geometry is well estimated, the image is sparsely represented by
only a few atoms in this dictionary.
On an ingeniering level, these methods can be used to enhance the
resolution of super-resolution inverse problems, and can also be used to
perform texture synthesis. On a biological level, these mathematical
representations share similarities with low level grouping processes
that operate in areas V1 and V2 of the visual brain. We believe both
processing and biological application of geometrical methods work hand
in hand to design and analyze new cortical imaging methods.&lt;/p&gt;
&lt;p&gt;11h00-12h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.crea.polytechnique.fr/JeanPetitot/home.html&#34; class=&#34;http&#34;&gt;Jean Petitot&lt;/a&gt;&lt;/em&gt;
Centre d&amp;rsquo;Analyse et de Math√©matique Sociales, Ecole des Hautes Etudes en
Sciences Sociales - Paris &lt;strong&gt;¬´Neurogeometry of visual perception¬ª&lt;/strong&gt;
In relation with experimental data, we propose a geometric model of the
functional architecture of the primary visual cortex (V1) explaining
contour integration. The aim is to better understand the type of
geometry algorithms implemented by this functional architecture. The
contact structure of the 1-jet space of the curves in the plane, with
its generalization to the roto-translation group, symplectifications,
and sub-Riemannian geometry, are all neurophysiologically realized by
long-range horizontal connections. Virtual structures, such as illusory
contours of the Kanizsa type, can then be explained by this model.&lt;/p&gt;
&lt;p&gt;12h00&lt;/p&gt;
&lt;p&gt;Lunch&lt;/p&gt;
&lt;p&gt;14h00-14h45&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://homepages.inf.ed.ac.uk/pseries/&#34; class=&#34;http&#34;&gt;Peggy Series&lt;/a&gt;&lt;/em&gt;
Institute for Adaptive and Neural Computation, Edinburgh
&lt;strong&gt;¬´Bayesian Priors in Perception and Decision Making¬ª&lt;/strong&gt;
We&amp;rsquo;ll present two recent projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first project (with M. Chalk and A. R. Seitz) is an experimental
investigation of the influence of expectations on the perception of
simple stimuli. Using a simple task involving estimation and detection
of motion random dots displays, we examined whether expectations can be
developed quickly and implicitly and how they affect perception. We find
that expectations lead to attractive biases such that stimuli appear as
being more similar to the expected one than they really are, as well as
visual hallucinations in the absence of a stimulus. We discuss our
findings in terms of Bayesian Inference.&lt;/li&gt;
&lt;li&gt;In the second project (with A. Kalra and Q. Huys), we explore the
concepts of optimism and pessimism in decision making. Optimism is
usually assessed using questionnaires, such as the LOT-R. Here, using a
very simple behavioral task, we show that optimism can be described in
terms of a prior on expected future rewards. We examine the correlation
between the shape of this prior for individual subjects and their scores
on questionnaires, as well as with other measures of personality traits.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;14h45-15h45&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.informatik.uni-ulm.de/ni/staff/HNeumann/&#34; class=&#34;http&#34;&gt;Heiko Neumann&lt;/a&gt;&lt;/em&gt; (in
collaboration with Florian Raudies)
Inst. of Neural Information Processing, Ulm University Germany
&lt;strong&gt;¬´Cortical mechanisms of transparent motion perception ‚Äì a neural
model¬ª&lt;/strong&gt;
Transparent motion is perceived when multiple motions different in
directions and/or speeds are presented in the same part of visual space.
In perceptual experiments the conditions have been studied under which
motion transparency occurs. An upper limit in the number of perceived
transparent layers has been investigated psychophysically. Attentional
signals can improve the perception of a single motion amongst several
motions. While criteria for the occurrence of transparent motion have
been identified only few potential neural mechanisms have been discussed
so far to explain the conditions and mechanisms for segregating multiple
motions.
A neurodynamical model is presented which builds upon a previously
developed neural architecture emphasizing the role of feedforward
cascade processing and feedback from higher to earlier stages for
selective feature enhancement and tuning. Results of computational
experiments are consistent with findings from physiology and
psychophysics. Finally, the model is demonstrated to cope with realistic
data from computer vision benchmark databases.
Work supported by European Union (project SEARISE), BMBF, and CELEST&lt;/p&gt;
&lt;p&gt;15h45-15h00&lt;/p&gt;
&lt;p&gt;Coffee break&lt;/p&gt;
&lt;p&gt;16h00-17h00&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CANCELED&lt;/strong&gt;
&lt;em&gt;&lt;a href=&#34;http://pauli.uni-muenster.de/tp/index.php?id=9&amp;amp;L=1&#34; class=&#34;http&#34;&gt;Rudolf Friedrich&lt;/a&gt;&lt;/em&gt;
Institute f√ºr Theoretische Physik Westf√§lische Wilhelms Universit√§t
M√ºnster
&lt;strong&gt;¬´Windows to Complexity: Disentangling Trends and Fluctuations in
Complex Systems¬ª&lt;/strong&gt;
In the present talk, we discuss how to perform an analysis of
experimental data of complex systems by disentangling the effects of
dynamical noise (fluctuations) and deterministic dynamics (trends). We
report on results obtained for various complex systems like turbulent
fields, the motion of dissipative solitons in nonequilibrium systems,
traffic flows, and biological data like human tremor data and brain
signals. Special emphasis is put on methods to predict the occurrence of
qualitative changes in systems far from equilibrium.
[1] R. Friedrich, J. Peinke, M. Reza Rahimi Tabar: Importance of
Fluctuations: Complexity in the View of stochastic Processes (in:
Springer Encyclopedia on Complexity and System Science, (2009))&lt;/p&gt;
&lt;p&gt;17h00-17h45&lt;/p&gt;
&lt;p&gt;General Discussion&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;line-39&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;28 May 2010 &lt;strong&gt;Computational models of learning and decision making&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;9h30-10h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://brovelli.free.fr/&#34; class=&#34;http&#34;&gt;Andrea Brovelli&lt;/a&gt;&lt;/em&gt;
Institut de Neurosciences Cognitives de la M√©diterran√©e, CNRS and
Universit√© de la M√©diterran√©e - Marseille
&lt;strong&gt;¬´An introduction to Motor Learning, Decision-Making and Motor
Control¬ª&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;10h00-11h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://emmanuel.dauce.free.fr&#34; class=&#34;http&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/em&gt;
Mouvement &amp;amp; Perception, UMR 6152, Facult√© des sciences du sport
&lt;strong&gt;¬´Adapting the noise to the problem : a Policy-gradient approach of
receptive fields formation¬ª&lt;/strong&gt;
In machine learning, Kernel methods are give a consistent framework for
applying the perceptron algorithm to non-linear problems. In
reinforcement learning, the analog of the perceptron delta-rule is
called the &amp;ldquo;policy-gradient&amp;rdquo; approch proposed by Williams in 1992 in the
framework of stochastic neural networks. Despite its generality and
straighforward applicability to continuous command problems, quite few
developments of the method have been proposed since. Here we present an
account of the use of a kernel transformation of the perception space
for learning a motor command, in the case of eye orientation and
multi-joint arm control. We show that such transformation allows the
system to learn non-linear transformation, like the log-like resolution
of a foveated retina, or the transformation from a cartesian perception
space to a log-polar command, by shaping appropriate receptive fields
from the perception to the command space. We also present a method for
using multivariate correlated noise for learning high-DOF control
problems, and propose some interpretations on the putative role of
correlated noise for learning in biological systems.&lt;/p&gt;
&lt;p&gt;11h00-12h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.eng.cam.ac.uk/~ml468/&#34; class=&#34;http&#34;&gt;M√°t√© Lengyel&lt;/a&gt;&lt;/em&gt;
Computational &amp;amp; Biological Learning Lab, Department of Engineering,
University of Cambridge
&lt;strong&gt;¬´Why remember? Episodic versus semantic memories for optimal decision
making¬ª&lt;/strong&gt;
Memories are only useful inasmuch as they allow us to act adaptively in
the world. Previous studies on the use of memories for decision making
have almost exclusively focussed on implicit rather than declarative
memories, and even when they did address declarative memories they dealt
only with semantic but not episodic memories. In fact, from a purely
computational point of view, it seems wasteful to have memories that are
episodic in nature: why should it be better to act on the basis of the
recollection of single happenings (episodic memory), rather than the
seemingly normative use of accumulated statistics from multiple events
(semantic memory)? Using the framework of reinforcement learning, and
Markov decision processes in particular, we analyze in depth the
performance of episodic versus semantic memory-based control in a
sequential decision task under risk and uncertainty in a class of simple
environments. We show that episodic control should be useful in a range
of cases characterized by complexity and inferential noise, and most
particularly at the very early stages of learning, long before
habitization (the use of implicit memories) has set in. We interpret
data on the transfer of control from the hippocampus to the striatum in
the light of this hypothesis.&lt;/p&gt;
&lt;p&gt;12h00-14h00&lt;/p&gt;
&lt;p&gt;Lunch&lt;/p&gt;
&lt;p&gt;14h00-15h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://www.cs.bris.ac.uk/~rafal/&#34; class=&#34;http&#34;&gt;Rafal Bogacz&lt;/a&gt;&lt;/em&gt;
Department of Computer Science, University of Bristol
&lt;strong&gt;¬´Optimal decision making and reinforcement learning in the
cortico-basal-ganglia circuit¬ª&lt;/strong&gt;
During this talk I will present a computational model describing
decision making process in the cortico-basal ganglia circuit. The model
assumes that this circuit performs statistically optimal test that
maximizes speed of decisions for any required accuracy. In the model,
this circuit computes probabilities that considered alternatives are
correct, according to Bayes‚Äô theorem. This talk will show that the
equation of Bayes‚Äô theorem can be mapped onto the functional anatomy of
a circuit involving the cortex, basal ganglia and thalamus. This theory
provides many precise and counterintuitive experimental predictions,
ranging from neurophysiology to behaviour. Some of these predictions
have been already validated in existing data and others are a subject of
ongoing experiments. During the talk I will also discuss the
relationships between the above model and current theories of
reinforcement learning in the cortico-basal-ganglia circuit.&lt;/p&gt;
&lt;p&gt;15h00-15h30&lt;/p&gt;
&lt;p&gt;Coffee break&lt;/p&gt;
&lt;p&gt;15h30-16h30&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://e.guigon.free.fr/&#34; class=&#34;http&#34;&gt;Emmanuel Guigon&lt;/a&gt;&lt;/em&gt;
Institut des Syst√®mes Intelligents et de Robotique, UPMC - CNRS / UMR
7222
&lt;strong&gt;¬´Optimal feedback control as a principle for adaptive control of
posture and movement¬ª&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;16h30-17h15&lt;/p&gt;
&lt;p&gt;General Discussion&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;line-54&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;line-57&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;sponsored-by&#34;&gt;Sponsored by&lt;/h2&gt;
&lt;p&gt;&lt;span id=&#34;line-59&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.incm.cnrs-mrs.fr/&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://www.incm.cnrs-mrs.fr/images/logo-INCM.png&#34; title=&#34;http://www.incm.cnrs-mrs.fr/&#34; class=&#34;external_image&#34; style=&#34;width:15.0%&#34; alt=&#34;http://www.incm.cnrs-mrs.fr/&#34; /&gt;&lt;/a&gt;
&lt;span id=&#34;line-60&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;a href=&#34;http://www.ism.univmed.fr/&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://www.ism.univmed.fr/IMG/logoISM2.gif&#34; title=&#34;http://www.ism.univmed.fr/&#34; class=&#34;external_image&#34; style=&#34;width:10.0%&#34; alt=&#34;http://www.ism.univmed.fr/&#34; /&gt;&lt;/a&gt;
&lt;span id=&#34;line-61&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;a href=&#34;http://sites.univ-provence.fr/ifrscc/&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://sites.univ-provence.fr/ifrscc/plugins/kitcnrs/images/logoifr.jpg&#34; title=&#34;http://sites.univ-provence.fr/ifrscc/&#34; class=&#34;external_image&#34; style=&#34;width:5.0%&#34; alt=&#34;http://sites.univ-provence.fr/ifrscc/&#34; /&gt;&lt;/a&gt;
&lt;span id=&#34;line-62&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;a href=&#34;http://www.univmed.fr/&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://www.univmed.fr/App_Themes/Default/images/hp/logo_d.gif&#34; title=&#34;http://www.univmed.fr/&#34; class=&#34;external_image&#34; style=&#34;width:8.0%&#34; alt=&#34;http://www.univmed.fr/&#34; /&gt;&lt;/a&gt;
&lt;span id=&#34;line-63&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;a href=&#34;http://www.univ-provence.fr/&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://www.univ-provence.fr/Local/up/fr/bandeau/logo_up.gif&#34; title=&#34;http://www.univ-provence.fr/&#34; class=&#34;external_image&#34; style=&#34;width:5.0%&#34; alt=&#34;http://www.univ-provence.fr/&#34; /&gt;&lt;/a&gt;
&lt;span id=&#34;line-64&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;a href=&#34;http://www.univ-provence.fr/gsite/index.php?project=pole3c&#34; class=&#34;http&#34;&gt;Pole 3c&lt;/a&gt;
&lt;span id=&#34;line-66&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;span
id=&#34;line-68&#34; class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;span id=&#34;line-69&#34;
class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;Affiche&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
