<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>homeostasis | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tag/homeostasis/</link>
      <atom:link href="https://laurentperrinet.github.io/tag/homeostasis/index.xml" rel="self" type="application/rss+xml" />
    <description>homeostasis</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Thu, 15 Jun 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_512x512_fill_lanczos_center_3.png</url>
      <title>homeostasis</title>
      <link>https://laurentperrinet.github.io/tag/homeostasis/</link>
    </image>
    
    <item>
      <title>A Robust Event-Driven Approach to Always-on Object Recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-23/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-23/</guid>
      <description>

















&lt;figure  id=&#34;figure-the-hots-architecture&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/hots.png&#34; alt=&#34;The HOTS architecture.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The HOTS architecture.
    &lt;/figcaption&gt;&lt;/figure&gt;



















&lt;figure  id=&#34;figure-preformance-of-the-algorithm-on-the-dvsgesture-dataset-for-this-gesture-recognition-task-the-online-hots-accuracy-remains-close-to-the-chance-level-for-about-100-events-more-evidence-needs-to-be-accumulated-and-then-the-accuracy-increases-monotonically-outperforming-the-previous-method-after-about-10000-events-at-an-average-of-93-of-the-number-of-events-in-the-sample&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/gesture_online.png&#34; alt=&#34;Preformance of the algorithm on the DVSgesture dataset. For this gesture recognition task, the online HOTS accuracy remains close to the chance level for about 100 events. More evidence needs to be accumulated, and then the accuracy increases monotonically, outperforming the previous method after about 10.000 events (at an average of 9.3% of the number of events in the sample).&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;90%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Preformance of the algorithm on the DVSgesture dataset. For this gesture recognition task, the online HOTS accuracy remains close to the chance level for about 100 events. More evidence needs to be accumulated, and then the accuracy increases monotonically, outperforming the previous method after about 10.000 events (at an average of 9.3% of the number of events in the sample).
    &lt;/figcaption&gt;&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Learning heterogeneous delays of spiking neurons for motion detection</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-fens/</link>
      <pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-fens/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to efficiently make use of time in neural computations? ‚è±Ô∏è&lt;br&gt;With &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; we developed a model of spiking neuron including, in addition to synaptic weights, synaptic delays. &lt;a href=&#34;https://t.co/eztnd5CUMn&#34;&gt;https://t.co/eztnd5CUMn&lt;/a&gt;&lt;br&gt;Come see this work on Tuesday morning at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; poster n¬∞ 547 ü™©&lt;/p&gt;&amp;mdash; @antoine_grimaldi@neuromatch.social (@A_Grismaldi) &lt;a href=&#34;https://twitter.com/A_Grismaldi/status/1546471536571342849?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Camille Besnainou&lt;/span&gt;, &lt;span &gt;
      Hugo Ladret&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Decoding spiking motifs using neurons with heterogeneous delays</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-areadne/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-areadne/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to efficiently make use of time in neural computations? ‚è±Ô∏è&lt;br&gt;With &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; we developed a model of spiking neuron including, in addition to synaptic weights, synaptic delays. &lt;a href=&#34;https://t.co/eztnd5CUMn&#34;&gt;https://t.co/eztnd5CUMn&lt;/a&gt;&lt;br&gt;Come see this work on Tuesday morning at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; poster n¬∞ 547 ü™©&lt;/p&gt;&amp;mdash; @antoine_grimaldi@neuromatch.social (@A_Grismaldi) &lt;a href=&#34;https://twitter.com/A_Grismaldi/status/1546471536571342849?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Camille Besnainou&lt;/span&gt;, &lt;span &gt;
      Hugo Ladret&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Learning heterogeneous delays of Spiking Neurons for motion detection</title>
      <link>https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;During the &lt;a href=&#34;https://twitter.com/hashtag/CVPR2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CVPR2022&lt;/a&gt;-&lt;a href=&#34;https://twitter.com/hashtag/NeuroVision?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NeuroVision&lt;/a&gt; workshop about ¬´¬†What can computer vision learn from visual neuroscience?¬†¬ª, &lt;a href=&#34;https://twitter.com/A_Grismaldi?ref_src=twsrc%5Etfw&#34;&gt;@A_Grismaldi&lt;/a&gt; will talk today about ¬´¬†Learning hetero-synaptic delays of Spiking Neurons for motion detection¬†¬ª shows how to learn spike motifs !&lt;a href=&#34;https://t.co/95HGSGUOUy&#34;&gt;https://t.co/95HGSGUOUy&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1538417555911720963?ref_src=twsrc%5Etfw&#34;&gt;June 19, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Camille Besnainou&lt;/span&gt;, &lt;span &gt;
      Hugo Ladret&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>From event-based computations to a bio-plausible Spiking Neural Network</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-crs/</link>
      <pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-crs/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/aIt5OAleMR8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;this proceedings paper follows up the poster presented at CBMI : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/&#34;&gt;A homeostatic gain control mechanism to improve event-driven object recognition&lt;/a&gt;.
  &lt;em&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal.archives-ouvertes.fr/hal-03336554&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/grimaldi-21-cbmi.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-21-cbmi/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;











  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=KxX4pZKexCo&amp;amp;t=3335s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Video
&lt;/a&gt;



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/CBMI50038.2021.9461901&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;read the follow-up paper : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2023).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34;&gt;A Robust Event-Driven Approach to Always-on Object Recognition&lt;/a&gt;.
  &lt;em&gt;In revision&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/grimaldi-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-23/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.36227/techrxiv.18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A homeostatic gain control mechanism to improve event-driven object recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;to be presented at the &lt;a href=&#34;https://cbmi2021.univ-lille.fr/call-for-contributions#callforpapersspecialbioinspired&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bio-inspired circuits, systems and algorithms for multimedia&lt;/a&gt; special session of the &lt;a href=&#34;https://cbmi2021.univ-lille.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/a&gt; conference that you can &lt;a href=&#34;https://www.youtube.com/watch?v=KxX4pZKexCo&amp;amp;t=3335s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;watch on Youtube&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;this proceedings paper follows up he poster presented in : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/&#34;&gt;A robust bio-inspired approach to event-driven object recognition&lt;/a&gt;.
  &lt;em&gt;Computational and Systems Neuroscience (Cosyne) 2021&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/grimaldi-21-cosyne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-21-cosyne/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;this proceedings paper was followed by the poster presented at CRS : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-crs/&#34;&gt;From event-based computations to a bio-plausible Spiking Neural Network&lt;/a&gt;.
  &lt;em&gt;Champalimaud Research Symposium (CRS21)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-crs/grimaldi-21-crs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-21-crs/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;











  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=aIt5OAleMR8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Video
&lt;/a&gt;




&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;read the follow-up paper : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2023).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34;&gt;A Robust Event-Driven Approach to Always-on Object Recognition&lt;/a&gt;.
  &lt;em&gt;In revision&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/grimaldi-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-23/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.36227/techrxiv.18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;Antoine Grimaldi and Laurent Perrinet received funding from the European Union ERA-NET CHIST-ERA 2018 research and innovation program under grant agreement No ANR-19-CHR3-0008-03.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A robust bio-inspired approach to event-driven object recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Tomorrow Antoine Grimaldi will present our joint work on &amp;quot;A robust bio-inspired approach to event-driven object recognition&amp;quot; at &lt;a href=&#34;https://twitter.com/hashtag/cosyne2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#cosyne2021&lt;/a&gt; check-out the poster now &lt;a href=&#34;https://t.co/DUNQPcv1mx&#34;&gt;https://t.co/DUNQPcv1mx&lt;/a&gt; or meet him tomorrow during the poster session ! &lt;a href=&#34;https://t.co/wKTJPZbR6B&#34;&gt;pic.twitter.com/wKTJPZbR6B&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1364962423120265218?ref_src=twsrc%5Etfw&#34;&gt;February 25, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;



















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_74547e5c5bfc250f1c766a5b12fd761b.webp 400w,
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_a12dc585f10bdf8434fd3c54162119d8.webp 760w,
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_74547e5c5bfc250f1c766a5b12fd761b.webp&#34;
               width=&#34;100%&#34;
               height=&#34;555&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;see the poster online on the &lt;a href=&#34;https://app.hopin.com/events/cosyne-2021/expo/377631&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hopin platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;see a follow-up in: 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/&#34;&gt;A homeostatic gain control mechanism to improve event-driven object recognition&lt;/a&gt;.
  &lt;em&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal.archives-ouvertes.fr/hal-03336554&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/grimaldi-21-cbmi.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-21-cbmi/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;











  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=KxX4pZKexCo&amp;amp;t=3335s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Video
&lt;/a&gt;



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/CBMI50038.2021.9461901&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;read also the follow-up paper : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Antoine Grimaldi&lt;/span&gt;, &lt;span &gt;
      Victor Boutin&lt;/span&gt;, &lt;span &gt;
      Sio-Hoi Ieng&lt;/span&gt;, &lt;span &gt;
      Ryad Benosman&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2023).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34;&gt;A Robust Event-Driven Approach to Always-on Object Recognition&lt;/a&gt;.
  &lt;em&gt;In revision&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/grimaldi-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-23/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.36227/techrxiv.18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;Antoine Grimaldi and Laurent Perrinet received funding from the European Union ERA-NET CHIST-ERA 2018 research and innovation program under grant agreement No ANR-19-CHR3-0008-03.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>An adaptive homeostatic algorithm for the unsupervised learning of visual features</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-19-hulk/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-19-hulk/</guid>
      <description>&lt;h1 id=&#34;an-adaptive-algorithm-for-unsupervised-learning&#34;&gt;&amp;ldquo;An adaptive algorithm for unsupervised learning&amp;rdquo;&lt;/h1&gt;











  





&lt;video controls  &gt;
  &lt;source src=&#34;https://laurentperrinet.github.io/sciblog/files/2019-09-11_Perrinet19.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;

&lt;ul&gt;
&lt;li&gt;supplementary info : &lt;a href=&#34;https://spikeai.github.io/HULK/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://spikeai.github.io/HULK/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mdpi.com/2411-5150/3/3/47&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mdpi.com/2411-5150/3/3/47/htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mdpi.com/2411-5150/3/3/47/pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for paper: &lt;a href=&#34;https://github.com/SpikeAI/HULK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SpikeAI/HULK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for framework: &lt;a href=&#34;https://github.com/bicv/SparseHebbianLearning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/bicv/SparseHebbianLearning/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for figures &lt;a href=&#34;https://github.com/SpikeAI/HULK/blob/master/Annex.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SpikeAI/HULK/blob/master/Annex.ipynb&lt;/a&gt; (which is rendered @ &lt;a href=&#34;https://spikeai.github.io/HULK/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://spikeai.github.io/HULK/&lt;/a&gt; )&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2019-09-11_Perrinet19.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video abstract&lt;/a&gt; (and the &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2019-09-11_video-abstract-vision.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt; for generating it)&lt;/li&gt;
&lt;li&gt;previous publication : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/&#34;&gt;Role of homeostasis in learning sparse representations&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/0706.3177&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/perrinet-10-shl.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-10-shl/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/bicv/SparseHebbianLearning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco.2010.05-08-795&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;






$$f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}$$
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Role of homeostasis in learning sparse representations</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-10-shl/</link>
      <pubDate>Sat, 17 Jul 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-10-shl/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;header&#34; srcset=&#34;
               /publication/perrinet-10-shl/perrinet-10-shl_hu777e1b4c36a985ac18eef85e9ebdc601_40055_d7acdbd6e958712a51334f3917e12c3a.webp 400w,
               /publication/perrinet-10-shl/perrinet-10-shl_hu777e1b4c36a985ac18eef85e9ebdc601_40055_d578515dc2a53c83d87da6a118d6908e.webp 760w,
               /publication/perrinet-10-shl/perrinet-10-shl_hu777e1b4c36a985ac18eef85e9ebdc601_40055_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/perrinet-10-shl_hu777e1b4c36a985ac18eef85e9ebdc601_40055_d7acdbd6e958712a51334f3917e12c3a.webp&#34;
               width=&#34;657&#34;
               height=&#34;215&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;related publication : 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2019).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-hulk/&#34;&gt;An adaptive homeostatic algorithm for the unsupervised learning of visual features&lt;/a&gt;.
  &lt;em&gt;Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-hulk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-hulk/perrinet-19-hulk.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-19-hulk/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/SpikeAI/HULK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision3030047&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;header&#34;
           src=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/ssc.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
