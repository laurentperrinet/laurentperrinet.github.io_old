<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>neuromorphic hardware | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tag/neuromorphic-hardware/</link>
      <atom:link href="https://laurentperrinet.github.io/tag/neuromorphic-hardware/index.xml" rel="self" type="application/rss+xml" />
    <description>neuromorphic hardware</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Fri, 06 Oct 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_512x512_fill_lanczos_center_3.png</url>
      <title>neuromorphic hardware</title>
      <link>https://laurentperrinet.github.io/tag/neuromorphic-hardware/</link>
    </image>
    
    <item>
      <title>Time-to-Contact Map by Joint Estimation of Up-to-Scale Inverse Depth and Global Motion using a Single Event Camera</title>
      <link>https://laurentperrinet.github.io/publication/nunes-23-iccv/</link>
      <pubDate>Fri, 06 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/nunes-23-iccv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Robust Event-Driven Approach to Always-on Object Recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-23/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-23/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning heterogeneous delays in a layer of spiking neurons for fast motion detection</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-23-bc/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-23-bc/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;a follow-up of  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stakes of Neuromorphic Foveation: a promising future for embedded event cameras</title>
      <link>https://laurentperrinet.github.io/publication/gruel-23-bc/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/gruel-23-bc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning heterogeneous delays of spiking neurons for motion detection</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-icip/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-icip/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up as journal paper: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23-bc/&#34;&gt;Learning heterogeneous delays in a layer of spiking neurons for fast motion detection&lt;/a&gt;.
   &lt;em&gt;Biological Cybernetics&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23-bc/grimaldi-23-bc.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-23-bc/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;presented at &lt;a href=&#34;https://2022.ieeeicip.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICIP 2022&lt;/a&gt; 16-19 October 2022 in Bordeaux, France&lt;/li&gt;
&lt;li&gt;paper &lt;a href=&#34;https://cmsworkshops.com/ICIP2022/papers/accepted_papers.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3241&lt;/a&gt; (note that the title of the paper was slightly changed)&lt;/li&gt;
&lt;li&gt;time of presentation:&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 20:30 - 20:45 China Standard Time (UTC +8)&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 14:30 - 14:45 Central European Time (UTC +2)&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 12:30 - 12:45 UTC&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 08:30 - 08:45 Eastern Time (UTC -4)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;session-neuromorphic-and-perception-based-image-acquisition-and-analysis&#34;&gt;Session &amp;ldquo;Neuromorphic and perception-based image acquisition and analysis&amp;rdquo;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cmsworkshops.com/ICIP2022/view_session.php?SessionID=1009&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TQ-L.A Special session on Tueasday, October 18 from 14:00 to 16:00&lt;/a&gt;
&lt;a href=&#34;https://cmsworkshops.com/ICIP2022/view_session.php?SessionID=1009&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;program.png&#34; srcset=&#34;
               /publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_f8a7cb42bd03234f7da5bec1c350d0bc.webp 400w,
               /publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_89309a4e4d488ee921a24367811bf50c.webp 760w,
               /publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_f8a7cb42bd03234f7da5bec1c350d0bc.webp&#34;
               width=&#34;760&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organized by Dr. Marc Antonini, Dr. Panagiotis Tsakalides, and Dr. Effrosyni Doutsi:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;During the last decade much attention has been paid to understanding the human brain properties and functions in order to mimic the computational mechanisms of this highly intelligent processing ‚Äúmachine‚Äù that seems to be able to address several technological challenges that the scientific community is currently facing. Digital sobriety is quite important among these challenges as it concerns the reduction of the energy footprint caused by the use and transmission of the digital information. According to recent studies, almost 80% of global data flows is due to online videos stored in big data centers ready to be accessed on demand at any time by several users all over the world. As a result, scientists are urged to find energy-saving solutions to capture, process, understand, compress and stream this great volume of visual information in an environmental responsible and greener manner.
&lt;em&gt;Brain-inspired or neuro-inspired or spike-based or event-based computing are all terms used to describe the emerging technological trend motivated by the brain capability to dynamically capture and to spatio-temporally process and transform the great volume of the 3D visual information into a very compact spike train that is fed forward to the visual cortex of the brain passing through a very dense neural network. This is an energy efficient process, a fact that triggered the attention of the signal processing community trying to design more sober video services.&lt;/em&gt;
Indeed, every step of the brain processing pipeline provides inspiration towards novel disruptive implementations of image and video processing components: (i) visual sensors responsible for capturing and projecting the visual information into a neuromorphic chip, (ii) image understanding utilizing spiking neural networks to better approximate the dense interconnected network of neurons along the visual pathway, (iii) image processing and compression motivated by the exceptional compactness of the spike trains, capable of providing an ultra-high-definition perception of the visual world. In addition, the last decade has witnessed the progress of neuromorphic algorithms and hardware, which has already reached performance and manufacturing levels that is beyond the state- of-the-art.
The objective of this special session is to highlight the importance of neuromorphic computing in image and video processing. We are interested in bringing together scientists working on different spike-based computational models, from sensing to understanding, who will share their knowledge and discuss about the advantages and the limitations of this type of systems. The aim is to progress towards an end-to-end and robust technology where the hardware and software will both follow the same neuro-inspired principles, addressing important challenges of the current conventional systems. Last but not least, this special session would be a great opportunity to build a strong international consortium between different teams to attract European and international funding to further study and promote neuromorphic computing for different signal processing open challenges.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Learning heterogeneous delays of spiking neurons for motion detection</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-fens/</link>
      <pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-fens/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to efficiently make use of time in neural computations? ‚è±Ô∏è&lt;br&gt;With &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; we developed a model of spiking neuron including, in addition to synaptic weights, synaptic delays. &lt;a href=&#34;https://t.co/eztnd5CUMn&#34;&gt;https://t.co/eztnd5CUMn&lt;/a&gt;&lt;br&gt;Come see this work on Tuesday morning at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; poster n¬∞ 547 ü™©&lt;/p&gt;&amp;mdash; @antoine_grimaldi@neuromatch.social (@A_Grismaldi) &lt;a href=&#34;https://twitter.com/A_Grismaldi/status/1546471536571342849?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ultra-rapid visual search in natural images using active deep learning</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-22-fens/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-22-fens/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;üëâüèº Jean-Nicolas J√©r√©mie &lt;a href=&#34;https://twitter.com/JnJerem?ref_src=twsrc%5Etfw&#34;&gt;@JnJerem&lt;/a&gt; &lt;br&gt;üìçPoster session at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; &lt;br&gt;üéØ Ultra-rapid visual search in natural images using active deep learning.&lt;a href=&#34;https://twitter.com/hashtag/FENSAmbassador?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENSAmbassador&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SocNeuro_Tweets?ref_src=twsrc%5Etfw&#34;&gt;@SocNeuro_Tweets&lt;/a&gt; &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; 1/2 &lt;a href=&#34;https://t.co/ldGJMCQb4c&#34;&gt;pic.twitter.com/ldGJMCQb4c&lt;/a&gt;&lt;/p&gt;&amp;mdash; M√©lina Cordeau (@CordeauMelina) &lt;a href=&#34;https://twitter.com/CordeauMelina/status/1546389505917206531?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;This work extends to natural scenes a previous work on visual search on a simplified task formulated in  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/pierre-albiges/&#34;&gt;Pierre Albig√®s&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
  &lt;em&gt;Journal of Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;follows  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
  &lt;em&gt;Proceedings of AREADNE&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/jeremie-22-areadne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/jeremie-22-areadne/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://areadne.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;It is based on a first work on transfer learning and its application to a natural task : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/&#34;&gt;Ultra-Fast Image Categorization in biology and in neural models&lt;/a&gt;.
   &lt;em&gt;Vision&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://arxiv.org/abs/2205.03635&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-23-ultra-fast-cat/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision7020029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;in particular, we found retinotopic mapping to be adapted to that extension : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/&#34;&gt;Retinotopic mapping improves the reliability of image classification&lt;/a&gt;.
   &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/2022-06-19-neuro-vision-retinotopic.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/talk/2022-06-19-neuro-vision-retinotopic/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Decoding spiking motifs using neurons with heterogeneous delays</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-areadne/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-areadne/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to efficiently make use of time in neural computations? ‚è±Ô∏è&lt;br&gt;With &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; we developed a model of spiking neuron including, in addition to synaptic weights, synaptic delays. &lt;a href=&#34;https://t.co/eztnd5CUMn&#34;&gt;https://t.co/eztnd5CUMn&lt;/a&gt;&lt;br&gt;Come see this work on Tuesday morning at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; poster n¬∞ 547 ü™©&lt;/p&gt;&amp;mdash; @antoine_grimaldi@neuromatch.social (@A_Grismaldi) &lt;a href=&#34;https://twitter.com/A_Grismaldi/status/1546471536571342849?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ultra-rapid visual search in natural images using active deep learning</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-22-areadne/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-22-areadne/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This work extends to natural scenes a previous work on visual search on a simplified task formulated in  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/pierre-albiges/&#34;&gt;Pierre Albig√®s&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
  &lt;em&gt;Journal of Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;It is based on a first work on transfer learning and its application to a natural task : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/&#34;&gt;Ultra-Fast Image Categorization in biology and in neural models&lt;/a&gt;.
   &lt;em&gt;Vision&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://arxiv.org/abs/2205.03635&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-23-ultra-fast-cat/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision7020029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;in particular, we found retinotopic mapping to be adapted to that extension : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/&#34;&gt;Retinotopic mapping improves the reliability of image classification&lt;/a&gt;.
   &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/2022-06-19-neuro-vision-retinotopic.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/talk/2022-06-19-neuro-vision-retinotopic/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-fens/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
  &lt;em&gt;Proceedings of the FENS Forum 2022&lt;/em&gt;.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-fens/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/jeremie-22-fens/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Learning heterogeneous delays of Spiking Neurons for motion detection</title>
      <link>https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;During the &lt;a href=&#34;https://twitter.com/hashtag/CVPR2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CVPR2022&lt;/a&gt;-&lt;a href=&#34;https://twitter.com/hashtag/NeuroVision?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NeuroVision&lt;/a&gt; workshop about ¬´¬†What can computer vision learn from visual neuroscience?¬†¬ª, &lt;a href=&#34;https://twitter.com/A_Grismaldi?ref_src=twsrc%5Etfw&#34;&gt;@A_Grismaldi&lt;/a&gt; will talk today about ¬´¬†Learning hetero-synaptic delays of Spiking Neurons for motion detection¬†¬ª shows how to learn spike motifs !&lt;a href=&#34;https://t.co/95HGSGUOUy&#34;&gt;https://t.co/95HGSGUOUy&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1538417555911720963?ref_src=twsrc%5Etfw&#34;&gt;June 19, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out 









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contributions of neuroscience to the detection and localization of objects in visual inputs</title>
      <link>https://laurentperrinet.github.io/talk/2022-06-14-mir-symposium/</link>
      <pubDate>Tue, 14 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2022-06-14-mir-symposium/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;for visual search see: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/pierre-albiges/&#34;&gt;Pierre Albig√®s&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2020).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
   &lt;em&gt;Journal of Vision&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
     
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Code
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for retinotopy, see: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas J√©r√©mie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/&#34;&gt;Retinotopic mapping improves the reliability of image classification&lt;/a&gt;.
   &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/2022-06-19-neuro-vision-retinotopic.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/talk/2022-06-19-neuro-vision-retinotopic/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for event-based computations, see: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/&#34;&gt;Learning heterogeneous delays of Spiking Neurons for motion detection&lt;/a&gt;.
   &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/2022-06-19-neuro-vision-heterogeneous.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/talk/2022-06-19-neuro-vision-heterogeneous/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for event-based motion detection, see: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
   &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Polychrony detection using heterogeneous delays</title>
      <link>https://laurentperrinet.github.io/talk/2022-05-19-centuri-day/</link>
      <pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2022-05-19-centuri-day/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Follow this future presentations 









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/&#34;&gt;Learning heterogeneous delays of Spiking Neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-heterogeneous/2022-06-19-neuro-vision-heterogeneous.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/talk/2022-06-19-neuro-vision-heterogeneous/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Glad to meet the &lt;a href=&#34;https://twitter.com/centuri_ls?ref_src=twsrc%5Etfw&#34;&gt;@centuri_ls&lt;/a&gt; crowd at the &lt;a href=&#34;https://twitter.com/hashtag/CENTURIday?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CENTURIday&lt;/a&gt; ! With &lt;a href=&#34;https://twitter.com/A_Grismaldi?ref_src=twsrc%5Etfw&#34;&gt;@A_Grismaldi&lt;/a&gt; &lt;a href=&#34;https://t.co/r4633Vzg4F&#34;&gt;https://t.co/r4633Vzg4F&lt;/a&gt; &lt;a href=&#34;https://t.co/GbOGKhB6zA&#34;&gt;https://t.co/GbOGKhB6zA&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1527604282043813888?ref_src=twsrc%5Etfw&#34;&gt;May 20, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;followed-up as a poster: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-areadne/&#34;&gt;Decoding spiking motifs using neurons with heterogeneous delays&lt;/a&gt;.
   &lt;em&gt;Proceedings of AREADNE&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-areadne/grimaldi-22-areadne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-22-areadne/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/slides/2022-07-01_grimaldi-22-areadne/&#34; target=&#34;_blank&#34;&gt;
     Slides
   &lt;/a&gt;
   
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://areadne.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for event-based motion detection, see: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
   &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>From event-based computations to a bio-plausible Spiking Neural Network</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-crs/</link>
      <pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-crs/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/aIt5OAleMR8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;this proceedings paper follows up the poster presented at CBMI : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2021).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/&#34;&gt;A homeostatic gain control mechanism to improve event-driven object recognition&lt;/a&gt;.
   &lt;em&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal.archives-ouvertes.fr/hal-03336554&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/grimaldi-21-cbmi.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-21-cbmi/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=KxX4pZKexCo&amp;amp;t=3335s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Video
 &lt;/a&gt;
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/CBMI50038.2021.9461901&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;read the follow-up paper : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34;&gt;A Robust Event-Driven Approach to Always-on Object Recognition&lt;/a&gt;.
   &lt;em&gt;TechRxiv preprint&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/grimaldi-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-23/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.36227/techrxiv.18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A homeostatic gain control mechanism to improve event-driven object recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;to be presented at the &lt;a href=&#34;https://cbmi2021.univ-lille.fr/call-for-contributions#callforpapersspecialbioinspired&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bio-inspired circuits, systems and algorithms for multimedia&lt;/a&gt; special session of the &lt;a href=&#34;https://cbmi2021.univ-lille.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/a&gt; conference that you can &lt;a href=&#34;https://www.youtube.com/watch?v=KxX4pZKexCo&amp;amp;t=3335s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;watch on Youtube&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;this proceedings paper follows up he poster presented in : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2021).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/&#34;&gt;A robust bio-inspired approach to event-driven object recognition&lt;/a&gt;.
   &lt;em&gt;Computational and Systems Neuroscience (Cosyne) 2021&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/grimaldi-21-cosyne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-21-cosyne/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;this proceedings paper was followed by the poster presented at CRS : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2021).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-crs/&#34;&gt;From event-based computations to a bio-plausible Spiking Neural Network&lt;/a&gt;.
   &lt;em&gt;Champalimaud Research Symposium (CRS21)&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-crs/grimaldi-21-crs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-21-crs/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=aIt5OAleMR8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Video
 &lt;/a&gt;
 
 
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;read the follow-up paper : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34;&gt;A Robust Event-Driven Approach to Always-on Object Recognition&lt;/a&gt;.
   &lt;em&gt;TechRxiv preprint&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/grimaldi-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-23/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.36227/techrxiv.18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;Antoine Grimaldi and Laurent Perrinet received funding from the European Union ERA-NET CHIST-ERA 2018 research and innovation program under grant agreement No ANR-19-CHR3-0008-03.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A robust bio-inspired approach to event-driven object recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Tomorrow Antoine Grimaldi will present our joint work on &amp;quot;A robust bio-inspired approach to event-driven object recognition&amp;quot; at &lt;a href=&#34;https://twitter.com/hashtag/cosyne2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#cosyne2021&lt;/a&gt; check-out the poster now &lt;a href=&#34;https://t.co/DUNQPcv1mx&#34;&gt;https://t.co/DUNQPcv1mx&lt;/a&gt; or meet him tomorrow during the poster session ! &lt;a href=&#34;https://t.co/wKTJPZbR6B&#34;&gt;pic.twitter.com/wKTJPZbR6B&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1364962423120265218?ref_src=twsrc%5Etfw&#34;&gt;February 25, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_74547e5c5bfc250f1c766a5b12fd761b.webp 400w,
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_a12dc585f10bdf8434fd3c54162119d8.webp 760w,
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_74547e5c5bfc250f1c766a5b12fd761b.webp&#34;
               width=&#34;100%&#34;
               height=&#34;555&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;see the poster online on the &lt;a href=&#34;https://app.hopin.com/events/cosyne-2021/expo/377631&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hopin platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;see a follow-up in: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2021).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/&#34;&gt;A homeostatic gain control mechanism to improve event-driven object recognition&lt;/a&gt;.
   &lt;em&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal.archives-ouvertes.fr/hal-03336554&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/grimaldi-21-cbmi.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-21-cbmi/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=KxX4pZKexCo&amp;amp;t=3335s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Video
 &lt;/a&gt;
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/CBMI50038.2021.9461901&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;read also the follow-up paper : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/&#34;&gt;A Robust Event-Driven Approach to Always-on Object Recognition&lt;/a&gt;.
   &lt;em&gt;TechRxiv preprint&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-23/grimaldi-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-23/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.36227/techrxiv.18003077&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;Antoine Grimaldi and Laurent Perrinet received funding from the European Union ERA-NET CHIST-ERA 2018 research and innovation program under grant agreement No ANR-19-CHR3-0008-03.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
