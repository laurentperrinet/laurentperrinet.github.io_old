[{"authors":null,"categories":null,"content":"Laurent Perrinet is a computational neuroscientist specialized in large scale neural network models of low-level vision, perception and action, currently at the \u0026ldquo;Institut de Neurosciences de la Timone\u0026rdquo; (France), a joint research unit (CNRS / Aix-Marseille Universit√©). He co-authored more than 40 articles in computational neuroscience and computer vision. He graduated from the aeronautics engineering school SUPAERO, in Toulouse (France) with a signal processing and applied mathematics degree. He received a PhD in Cognitive Science in 2003 on the mathematical analysis of temporal spike coding of images by using a multi-scale and adaptive representation of natural scenes. His research program is focusing in bridging the complex dynamics of realistic, large-scale models of spiking neurons with functional models of low-level vision. In particular, as part of the FACETS and BrainScaleS consortia, he has developed experimental protocols in collaboration with neurophysiologists to characterize the response of population of neurons. Recently, he extended models of visual processing in the framework of predictive processing in collaboration with the team of Karl Friston at the University College of London. This method aims at characterizing the processing of dynamical flow of information as an active inference process. His current challenge within the NeOpTo team is to translate, or compile in computer terminology, this mathematical formalism with the event-based nature of neural information with the aim of pushing forward the frontiers of Artificial Intelligence systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://laurentperrinet.github.io/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"Laurent Perrinet is a computational neuroscientist specialized in large scale neural network models of low-level vision, perception and action, currently at the \u0026ldquo;Institut de Neurosciences de la Timone\u0026rdquo; (France), a joint research unit (CNRS / Aix-Marseille Universit√©). He co-authored more than 40 articles in computational neuroscience and computer vision. He graduated from the aeronautics engineering school SUPAERO, in Toulouse (France) with a signal processing and applied mathematics degree. He received a PhD in Cognitive Science in 2003 on the mathematical analysis of temporal spike coding of images by using a multi-scale and adaptive representation of natural scenes.","tags":null,"title":"Laurent Perrinet","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536444000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536444000,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://laurentperrinet.github.io/tutorial/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":["Laurent Perrinet"],"categories":null,"content":"","date":1546297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546297200,"objectID":"7e8b205e3560a20ac80afe0bc337d670","permalink":"https://laurentperrinet.github.io/talk/2019-04-18_jnlf/","publishdate":"2019-01-01T00:00:00+01:00","relpermalink":"/talk/2019-04-18_jnlf/","section":"talk","summary":"Les illusions visuelles sont des cr√©ations d'artistes, de scientifiques et plus r√©cemment, gr√¢ce aux r√©seaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent dans les airs ou des serpents se mettent √† tourner. Au-del√† de leur ind√©niable cot√© ludique, ces illusions nous apprennent beaucoup sur le fonctionnement du cerveau, notamment quand celles-ci se transforment en hallucinations visuelles, d√©passant ainsi les limites des capacit√©s de notre perception. En tant que chercheur en Neurosciences √† l'Institut de Neurosciences de la Timone √† Marseille, je vous d√©voilerai des aspects du fonctionnement du cerveau qui sont souvent m√©connus. En particulier, nous verrons pourquoi un magicien peut tromper nos sens ou comment des objets peuvent voyager dans le temps. Surtout nous essaierons de comprendre le fonctionnement de notre perception visuelle sur les bases d'une th√©orie de la vision non pas comme une simple cam√©ra qui enregistre des images mais comme un processus actif en relation avec le monde qui nous entoure. ","tags":[],"title":"Des illusions aux hallucinations visuelles: une porte sur la perception","type":"talk"},{"authors":["C√©sar R. Ravello","Laurent U. Perrinet","Mar√≠a-Jos√© Escobar","Adri√°n G. Palacios"],"categories":null,"content":" D√®s la r√©tine, le syst√®me visuel pr√©f√®re des images naturelles Dans la r√©tine, au premier √©tage du traitement de l\u0026rsquo;image visuelle, on peut obtenir des repr√©sentations extr√™mement fines. Une collaboration entre des chercheurs fran√ßais et chiliens a permis de mettre en √©vidence que, dans la r√©tine de rongeurs, une repr√©sentation de la vitesse de l\u0026rsquo;image visuelle est pr√©cis√©ment cod√©e. Dans cette collaboration pluridisciplinaire, l\u0026rsquo;utilisation d\u0026rsquo;un mod√®le du fonctionnement de la r√©tine a permis de g√©n√©rer un nouveau type de stimuli visuels qui a r√©v√©l√© des r√©sultats exp√©rimentaux surprenants.\nTravail collaboratif et multi-disciplinaire entre @cesarravello @laurentperrinet Mar√≠a Jos√© Escobar et @APalacio_s librement disponible sur @SciReports - merci √† l\u0026#39;@AgenceRecherche pour l\u0026#39;aide financi√®re et √† @CNRS @CNRS_dr12 + @univamu pour l\u0026#39;#InstitutDeNeurosciencesDeLaTimone https://t.co/YixRfpCrT3\n\u0026mdash; laurentperrinet (@laurentperrinet) February 3, 2019  La r√©tine est la premi√®re √©tape du traitement visuel, aux capacit√©s √©tonnantes. √Ä la diff√©rence d\u0026rsquo;un simple capteur comme ceux qu‚Äôon trouve dans les appareils photographiques num√©riques, ce mince tissu neuronal est un syst√®me complexe et encore largement m√©connu. Une meilleure connaissance de cette structure est essentielle pour la construction de capteurs du futur efficaces et √©conomes -par exemple ceux qui √©quiperont les futures voitures autonomes- mais aussi pour mieux comprendre des pathologies comme la D√©ficience Maculaire Li√©e √† l\u0026rsquo;Age (DMLA). Une des facettes m√©connues de la r√©tine est sa capacit√© √† d√©tecter des mouvements et cet article permet de mieux comprendre une partie des m√©canismes en jeu.\nNew study on speed selectivity in the #retina showing that a majority of neurons prefer natural-like stimuli. Collaborative and multi-disciplinary work with @cesarravello @laurentperrinet Mar√≠a Jos√© Escobar and @APalacio_s available with @SciReports at https://t.co/Vb7GoRxjoT\n\u0026mdash; Adrian Palacios (@APalacio_s) February 3, 2019  Retinal cell preference for natural-like stimuli. Very elegant work by @APalacio_s et al. #retina #neuroscience #decoding https://t.co/3xNWaZd5x6\n\u0026mdash; Andres Canales-Johnson (@canalesjohnson) February 4, 2019  Conciliant mod√©lisation et neurophysiologie, cette √©tude a permis de faire des pr√©dictions sur le traitement de l\u0026rsquo;information r√©tinienne et en particulier de g√©n√©rer des textures synth√©tiques qui sont optimales pour ces mod√®les (voir film). Les enregistrements effectu√©s sur la r√©tine de rongeurs diurnes Octodon degus ont ensuite permis de mesurer la s√©lectivit√© √† la vitesse mais aussi de valider une nouvelle fois ces mod√®les en reconstruisant l\u0026rsquo;image d\u0026rsquo;entr√©e √† partir de l\u0026rsquo;activit√© neurale.\nLe r√©sultat le plus inattendu est la diff√©rence de s√©lectivit√© de certaines classes de neurones r√©tiniens par rapport √† la complexit√© du stimulus pr√©sent√©. En effet, la repr√©sentation de la vitesse est relativement peu pr√©cise si on utilise des r√©seaux de lignes (\u0026ldquo;Grating\u0026rdquo;), comme cela est d\u0026rsquo;habitude r√©alis√© dans la plupart des exp√©riences neurophysiologiques. Au contraire, elle devient plus pr√©cise si on utilise comme signaux visuels des textures artificielles ressemblant √† des nuages en mouvement (\u0026ldquo;MC Narrow\u0026rdquo;). En particulier, plus cette texture est complexe, plus la repr√©sentation est pr√©cise (\u0026ldquo;MC Broad\u0026rdquo;).\n#R√©sultatScientifique üîç| D√®s la #r√©tine, le syst√®me #visuel pr√©f√®re des images naturelles\n‚ñ∂Ô∏è https://t.co/BBY2IpGum6\nüìï @SciReports | https://t.co/5mULuWTp3N\nü§ù @CNRS @CNRS_dr12 @univamu #InstitutDeNeurosciencesDeLaTimone #LaurentPerrinet pic.twitter.com/34R1URHUic\n\u0026mdash; Biologie au CNRS (@INSB_CNRS) February 1, 2019  Speed-Selectivity in Retinal Ganglion Cells is Sharpened by Broad Spatial Frequency, Naturalistic Stimuli. Beautiful article in Scientific Reports on an original animal model, the diurnal rodent Octodon degus. https://t.co/BdzyzEVYnX (open access) pic.twitter.com/1UaoMYTFd2\n\u0026mdash; St√©phane Deny (@StephaneDeny) January 30, 2019  Ces textures complexes sont plus proches des images naturellement observ√©es et ces r√©sultats montrent donc que d√®s la r√©tine, le syst√®me visuel est particuli√®rement adapt√© √† des stimulations naturelles. Ce r√©sultat devrait pouvoir s\u0026rsquo;√©tendre √† des textures encore plus complexes et encore plus proches d\u0026rsquo;images naturelles, mais aussi pouvoir se g√©n√©raliser √† d\u0026rsquo;autres aires visuelles plus complexes, comme le cortex visuel primaire, et √† d\u0026rsquo;autres esp√®ces.\n Pour une cellule repr√©sentative, on montre ici la r√©ponse au cours du temps sous forme d\u0026rsquo;impulsions pour diff√©rentes pr√©sentations (Trial) ainsi que la moyenne de cette r√©ponse (Firing rate). Les diff√©rentes colonnes repr√©sentent diff√©rentes vitesses des stimulations sur la r√©tine. Les diff√©rentes lignes sont diff√©rentes stimulations. En bleu, une stimulation classique sous forme de r√©seaux de lignes (¬´ Grating ¬ª). En vert et Orange, la r√©ponse √† une texture progressivement plus complexe (de ¬´ Mc Narrow ¬ª √† ¬´ MC Broad ¬ª). Si les r√©ponses aux diff√©rents stimulations sont en moyenne similaires, elles sont variables d‚Äôessai en essai et une analyse statistique a permis de montrer que dans la majorit√© des cellules, les r√©ponses sont d\u0026rsquo;autant plus pr√©cises que la stimulation est complexe. ¬© Cesar Ravello     Cette vid√©o montre les trois classes de stimulations utilis√©es dans cette √©tude. En plus des r√©seaux sinuso√Ødaux (‚ÄúGrating‚Äù) qui sont classiquement utilis√©s en neurosciences, cette √©tude a utilis√© des textures al√©atoires (Motion Clouds (MC)) qui sont inspir√©es de mod√®les du traitement visuel. Ils permettent en particulier de manipuler des param√®tres visuels critiques comme la vari√©t√© de fr√©quences spatiales qui sont superpos√©es: soit unique (‚ÄúGrating‚Äù), fine (‚ÄúMC Narrow‚Äù), soit plus large (‚ÄúMC Broad‚Äù). Ces vid√©os ont √©t√© directement projet√©es sur des r√©tines pos√©es sur des grilles d‚Äô√©lectrodes qui permettent de mesurer l‚Äôactivit√© neurale (voir figure). ¬© Laurent Perrinet / Cesar Ravello\n","date":1546297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546297200,"objectID":"99be955cfcda8bbb82ec76c8226d705d","permalink":"https://laurentperrinet.github.io/publication/ravello-19/","publishdate":"2019-01-01T00:00:00+01:00","relpermalink":"/publication/ravello-19/","section":"publication","summary":"D√®s la r√©tine, le syst√®me visuel pr√©f√®re des images naturelles Dans la r√©tine, au premier √©tage du traitement de l\u0026rsquo;image visuelle, on peut obtenir des repr√©sentations extr√™mement fines. Une collaboration entre des chercheurs fran√ßais et chiliens a permis de mettre en √©vidence que, dans la r√©tine de rongeurs, une repr√©sentation de la vitesse de l\u0026rsquo;image visuelle est pr√©cis√©ment cod√©e. Dans cette collaboration pluridisciplinaire, l\u0026rsquo;utilisation d\u0026rsquo;un mod√®le du fonctionnement de la r√©tine a permis de g√©n√©rer un nouveau type de stimuli visuels qui a r√©v√©l√© des r√©sultats exp√©rimentaux surprenants.","tags":null,"title":"Speed-Selectivity in Retinal Ganglion Cells is Sharpened by Broad Spatial Frequency, Naturalistic Stimuli","type":"publication"},{"authors":["Jean-Bernard Damasse","Laurent U. Perrinet","Laurent Madelain","Anna Montagnini"],"categories":null,"content":"","date":1538344800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538344800,"objectID":"26b8a2fc0cacfa12844d3cc81e66a163","permalink":"https://laurentperrinet.github.io/publication/damasse-18/","publishdate":"2018-10-01T00:00:00+02:00","relpermalink":"/publication/damasse-18/","section":"publication","summary":"","tags":null,"title":"Reinforcement effects in anticipatory smooth eye movements","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536444000,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://laurentperrinet.github.io/tutorial/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Sandrine Chemla","Alexandre Reynaud","Matteo diVolo","Yann Zerlaut","Laurent Perrinet","Alain Destexhe","Fr√©d√©ric Chavane"],"categories":null,"content":"","date":1532037600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532037600,"objectID":"50431c6ccc7fa47ac1abb9954dad676c","permalink":"https://laurentperrinet.github.io/publication/chemla-18/","publishdate":"2018-07-20T00:00:00+02:00","relpermalink":"/publication/chemla-18/","section":"publication","summary":"The ``apparent motion'' illusion is evoked when stationary stimuli are successively flashed in spatially separated positions. It depends on the precise spatial and temporal separations of the stimuli. For large spatiotemporal separation, the long-range apparent motion (lrAM), it remains unclear how the visual system computes unambiguous motion signals. Here we investigated whether intracortical interactions within retinotopic maps could shape a global motion representation at the level of V1 population in response to a lrAM. In fixating monkeys, voltage-sensitive dye imaging revealed the emergence of a spatio-temporal representation of the motion trajectory at the scale of V1 population activity, shaped by systematic backward suppressive waves. We show that these waves are the expected emergent property of a recurrent gain control fed by the horizontal intra-cortical network. Such non-linearities explain away ambiguous correspondence problems of the stimulus along the motion path, preformating V1 population response for an optimal read-out by downstream areas.","tags":null,"title":"Suppressive waves disambiguate the representation of long-range apparent motion in awake monkey V1","type":"publication"},{"authors":["Mina A. Khoei","Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":" Visual illusions: their origin lies in prediction  Flash-Lag Effect. When a visual stimulus moves along a continuous trajectory, it may be seen ahead of its veridical position with respect to an unpredictable event such as a punctuate flash. This illusion tells us something important about the visual system: contrary to classical computers, neural activity travels at a relatively slow speed. It is largely accepted that the resulting delays cause this perceived spatial lag of the flash. Still, after several decades of debates, there is no consensus regarding the underlying mechanisms.   Researchers from the Timone Institute of Neurosciences bring a new theoretical hypothesis on a visual illusion discovered at the beginning of the 20th century. This illusion remained misunderstood while it poses fundamental questions about how our brains represent events in space and time. This study published on January 26, 2017 in the journal PLOS Computational Biology, shows that the solution lies in the predictive mechanisms intrinsic to the neural processing of information.\nNew Research: The Flash-Lag Effect as a Motion-Based Predictive Shift https://t.co/K3KWPO8l4a Khoei et al. #vision #motion #neuralnetworks pic.twitter.com/RElm4Qqo58\n\u0026mdash; PLOS Comp Biol (@PLOSCompBiol) February 8, 2017  Visual illusions are still popular: in a quasi-magical way, they can make objects appear where they are not expected\u0026hellip; They are also excellent opportunities to question the constraints of our perceptual system. Many illusions are based on motion, such as the flash-lag effect. Observe a luminous dot that moves along a rectilinear trajectory. If a second light dot is flashed very briefly just above the first, the moving point will always be perceived in front of the flash while they are vertically aligned.\nProcessing visual information takes time and even if these delays are remarkably short, they are not negligible and the nervous system must compensate them. For an object that moves predictably, the neural network can infer its most probable position taking into account this processing time. For the flash, however, this prediction can not be established because its appearance is unpredictable. Thus, while the two targets are aligned on the retina at the time of the flash, the position of the moving object is anticipated by the brain to compensate for the processing time: it is this differentiated treatment that causes the flash-lag effect.\nThe researchers show that this hypothesis also makes it possible to explain the cases where this illusion does not work: for example if the flash appears at the end of the moving dot\u0026rsquo;s trajectory or if the target reverses its path in an unexpected way. In this work, the major innovation is to use the accuracy of information in the dynamics of the model. Thus, the corrected position of the moving target is calculated by combining the sensory flux with the internal representation of the trajectory, both of which exist in the form of probability distributions. To manipulate the trajectory is to change the precision and therefore the relative weight of these two information when they are optimally combined in order to know where an object is at the present time. The researchers propose to call parodiction (from the ancient Greek paron, the present) this new theory that joins Bayesian inference with taking into account neuronal delays.\nDespite the simplicity of this solution, parodiction has elements that may seem counter-intuitive. Indeed, in this model, the physical world is considered \u0026ldquo;hidden\u0026rdquo;, that is to say, it can only be guessed by our sensations and our experience. The role of visual perception is then to deliver to our central nervous system the most likely information despite the different sources of noise, ambiguity and time delays. According to the authors of this publication, the visual treatment would consist in a \u0026ldquo;simulation\u0026rdquo; of the visual world projected at the present time, even before the visual information can actually modulate, confirm or cancel this simulation. This hypothesis, which seems to belong to \u0026ldquo;science fiction\u0026rdquo;, is being tested with more detailed and biologically plausible hierarchical neural network models that should allow us to better understand the mysteries underlying our perception. Visual illusions have still the power to amaze us!\nNew from Khoei et al. The Flash-Lag Effect as a #Motion-Based Predictive Shift https://t.co/K3KWPO8l4a #neuralnetworks pic.twitter.com/iWsd9nK5qp\n\u0026mdash; PLOS Comp Biol (@PLOSCompBiol) February 8, 2017  ","date":1485385200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1485385200,"objectID":"bfd147642e8504d567d1d4628f16966a","permalink":"https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/","publishdate":"2017-01-26T00:00:00+01:00","relpermalink":"/publication/khoei-masson-perrinet-17/","section":"publication","summary":"Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object‚Äôs motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects‚Äô position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.","tags":null,"title":"The flash-lag effect as a motion-based predictive shift","type":"publication"},{"authors":["Cesar U Ravello","Maria-Jose U Escobar","Adrian G Palacios","Laurent U Perrinet"],"categories":null,"content":"","date":1477954800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477954800,"objectID":"0a50e0e556c2bbe845d4b751e803c9a5","permalink":"https://laurentperrinet.github.io/publication/ravello-16-droplets/","publishdate":"2016-11-01T00:00:00+01:00","relpermalink":"/publication/ravello-16-droplets/","section":"publication","summary":"","tags":["Image texture ; Neuroscience ; Computer vision ; Retina"],"title":"Differential response of the retinal neural code with respect to the sparseness of natural images","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1475272800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475272800,"objectID":"7086ec2f451d080124c1424ed13c5705","permalink":"https://laurentperrinet.github.io/publication/perrinet-16-euvip/","publishdate":"2016-10-01T00:00:00+02:00","relpermalink":"/publication/perrinet-16-euvip/","section":"publication","summary":"Natural images follow statistics inherited by the structure of our physical (visual) environment. In particular, a prominent facet of this structure is that images can be described by a relatively sparse number of features. We designed a sparse coding algorithm biologically-inspired by the architecture of the primary visual cortex. We show here that coefficients of this representation exhibit a power-law distribution. For each image, the exponent of this distribution characterizes sparseness and varies from image to image. To investigate the role of this sparseness, we designed a new class of random textured stimuli with a controlled sparseness value inspired by measurements of natural images. Then, we provide with a method to synthesize random textures images with a given sparseness statistics that match that of some class of natural images and provide perspectives for their use in neurophysiology.","tags":null,"title":"Biologically-inspired characterization of sparseness in natural images","type":"publication"},{"authors":["Jean-Bernard Damasse","Laurent Perrinet","Jeremie Jozefowiez","Laurent Madelain","Anna Montagnini"],"categories":null,"content":"","date":1472680800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472680800,"objectID":"9f06218457c3203f5ecd260bf3b11009","permalink":"https://laurentperrinet.github.io/publication/damasse-16-vss/","publishdate":"2016-09-01T00:00:00+02:00","relpermalink":"/publication/damasse-16-vss/","section":"publication","summary":"","tags":null,"title":"Operant reinforcement versus reward expectancy: effects on anticipatory eye movements","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"63e1fd879d909485461334c861ad9b77","permalink":"https://laurentperrinet.github.io/project/tout-public/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/tout-public/","section":"project","summary":"Listes d'actions destin√©es √† la culture scientifique et au public en g√©n√©ral.","tags":["EtienneRey"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://laurentperrinet.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Laurent Perrinet"],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461103200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515798000,"objectID":"37ad3cc6a237e5d6596ca28d3dfc9868","permalink":"https://laurentperrinet.github.io/post/etiennerey/","publishdate":"2016-04-20T00:00:00+02:00","relpermalink":"/post/etiennerey/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["Wahiba Taouali","Giacomo Benvenuti","Fr√©d√©ric Chavane","Laurent Perrinet"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"ae433a6885751e176896111ed33940e6","permalink":"https://laurentperrinet.github.io/publication/taouali-15-vss/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/taouali-15-vss/","section":"publication","summary":"Natural scenes generally contain objects in motion. The local orientation of their contours and the direction of motion are two essential components of visual information which are processed in parallel in the early visual areas.Focusing on the primary visual cortex of the macaque monkey (V1), we challenged different models for the joint representation of orientation and direction within the neural activity. Precisely, we considered the response of V1 neurons to an oriented moving bar to investigate whether, and how, the information about the bar's orientation and direction could be encoded dynamically at the population activity level.For that purpose, we used a decoding approach based on a space-time receptive field model that encodes jointly orientation and direction. We based our decoding approach on the statistics of natural scenes by first determining optimal space-time receptive fields (RFs) that encode orientation and direction. For this, we first derived a set of dynamic filters from a database of natural images~[1] and following an unsupervised learning rule~[2].More generally, this allows us to propose a dynamic generative model for the joint coding of orientation and direction. Then, using this model and a maximum likelihood paradigm, we infer the most likely representation for a given network activity~[3, 4]. We tested this model on surrogate data and on extracellular recordings in area emphV1 (67 cells) of awake macaque monkeys in response to oriented bars moving in $12$ different directions. Using a cross-validation method we could robustly decode both the orientation and the direction of the bar within the classical receptive field (cRF).Furthermore, this decoding approach shows different properties: First, information about the orientation of the bar is emerging ƒ±t before entering the cRF if the trajectory of the bar is long enough. Second, when testing different orientations with the same direction, our approach unravels that we can decode the direction and the orientation independently. Moreover, we found that, similarly to  orientation decoding, the decoding of direction is dynamic but weaker. Finally, our results demonstrate that the orientation and the direction of motion of an ambiguous moving bar can be progressively decoded in V1. This is a signature of a dynamic solution to the aperture problem in area V1, similarly to what was already found in area MT~[5].$[1]$ J. Burge, W. Geisler. Optimal speed estimation in natural image movies predicts human performance. Nature Communications, 6, 7900. http://doi.org/10.1038/ncomms8900, 2015. $[2]$ L. Perrinet. Role of homeostasis in learning sparse representations. ƒ±t Neural Computation, 22(7):1812--36, 2010. $[3]$ M. Jazayeri and J.A. Movshon. Optimal representation of sensory information by neural populations. ƒ±t Nature Neuroscience, 9(5):690--696, 2006.$[4]$ W. Taouali, G. Benvenuti, P. Wallisch, F. Chavane, L. Perrinet. Testing the Odds of Inherent versus Observed Over-dispersion in Neural Spike Counts. ƒ±t Journal of Neurophysiology, 2015.$[5]$ C. Pack, R. Born. Temporal dynamics of a neural solution to the aperture problem in visual area MT of macaque brain. ƒ±t Nature, 409(6823), 1040--1042. 2001. ","tags":null,"title":"A dynamic model for decoding direction and orientation in macaque primary visual cortex","type":"publication"},{"authors":["Jonathan Vacher","Andrew Isaac Meso","Laurent U Perrinet","Gabriel Peyr√©"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"0cc2b9c7c446eae0899fbb1ae3f80308","permalink":"https://laurentperrinet.github.io/publication/vacher-16/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/vacher-16/","section":"publication","summary":"A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a gen-erative model intended to probe visual motion perception. It is first derived in a set of axiomatic steps constrained by biological plausibility. We then extend previous con-tributions by detailing three equivalent formulations of the Gaussian dynamic texture model. First, the composite dynamic textures are constructed by the random aggrega-tion of warped patterns, which can be viewed as 3D Gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real time, on-the-fly, texture synthesis using time-discretized auto-regressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log-likelihood of the probability density. The log-likelihoods are finally essential for the construction of a Bayesian inference framework. We use the model to probe speed perception in humans psychophysically using zoom-like changes in stimulus spatial frequency content. The likelihood is contained within the genera-tive model and we chose a slow speed prior consistent with previous literature. We then validated the fitting process of the model using synthesized data. The human data replicates previous findings that relative perceived speed is positively biased by spatial frequency increments. The effect cannot be fully accounted for by previous models, but the current prior acting on the spatio-temporal likelihoods has proved necessary in accounting for the perceptual bias.","tags":["Motion perception","Psychophysics","Bayesian Modelling","Dynamic textures","Stochastic Par-tial Differential Equations","Computer Science - Computer Vision and Pattern Recognition","Quantitative Biology - Neurons and Cognition","üîçNo DOI found"],"title":"Bayesian Modeling of Motion Perception using Dynamical Stochastic Textures","type":"publication"},{"authors":["Laurent U. Perrinet","Rick A. Adams","Karl Friston"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"875e8c9a6676162c4f4f5816896d2780","permalink":"https://laurentperrinet.github.io/publication/perrinet-16-networks/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-16-networks/","section":"publication","summary":"We consider the problem of sensorimotor delays in the optimal control of movement under un-certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop andtheir implications for active inference. Active inference uses a generalisation of Kalman filter-ing to provide Bayes optimal estimates of hidden states and action in generalised coordinatesof motion. Representing hidden states in generalised coordinates provides a simple means ofcompensating for both sensory and oculomotor delays. This compensation is illustrated us-ing neuronal simulations of oculomotor following responses with and without compensation.We then consider an extension of the generative model that produces ocular followingto simulate smooth pursuit eye movements --- in which the system believes both the target andits centre of gaze are attracted by a (fictive) point moving in the visual field. Finally, thegenerative model is equipped with a hierarchical structure, so that it can register and rememberunseen (occluded) trajectories and emit anticipatory responses. These simulations speak to astraightforward and neurobiologically plausible solution to the generic problem of integratinginformation from different sources with different temporal delays and the particular difficultiesencountered when a system --- like the oculomotor system --- tries to control its environmentwith delayed signals.","tags":null,"title":"Compensation of oculomotor delays in the visual system's network.","type":"publication"},{"authors":["Anna Montagnini","Jean-Bernard Damasse","Laurent U. Perrinet","Guillaume Masson"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"ccd74a7dd78c79db61db6426d44a90ad","permalink":"https://laurentperrinet.github.io/publication/montagnini-16-ecvp/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/montagnini-16-ecvp/","section":"publication","summary":"","tags":null,"title":"Effects of motion predictability on anticipatory and visually-guided eye movements: a common prior for sensory processing and motor control?","type":"publication"},{"authors":["Jean-Bernard Damasse","Anna Montagnini","Laurent U. Perrinet"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"bba457f04c75675e91f3d893a33785fc","permalink":"https://laurentperrinet.github.io/publication/damasse-16-ecvp/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/damasse-16-ecvp/","section":"publication","summary":"","tags":null,"title":"Modeling the effect of dynamic contingencies on anticipatory eye movements","type":"publication"},{"authors":["Jens Kremkow","Laurent U. Perrinet","Cyril Monier","Jose-Manuel Alonso","Ad Aertsen","Yves Fr√©gnac","Guillaume S. Masson"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"dbce997abfca067b735b3a9e77df0091","permalink":"https://laurentperrinet.github.io/publication/kremkow-16/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/kremkow-16/","section":"publication","summary":"Neurons in the primary visual cortex are known for responding vigorously but with high variability to classical stimuli such as drifting bars or gratings. By contrast, natural scenes are encoded more efficiently by sparse and temporal precise spiking responses. We used a conductance-based model of the visual system in higher mammals to investigate how two specific features of the thalamo-cortical pathway, namely push-pull receptive field organization and synaptic depression, can contribute to this contextual reshaping of V1 responses. By comparing cortical dynamics evoked respectively by natural vs. artificial stimuli in a comprehensive parametric space analysis, we demonstrate that the reliability and sparseness of the spiking responses during natural vision is not a mere consequence of the increased bandwidth in the sensory input spectrum. Rather, it results from the combined impacts of synaptic depression and push-pull inhibition, the later acting for natural scenes as a form of ``effective'' feed-forward inhibition as demonstrated in other sensory systems. Thus, the combination of feedforward-like inhibition with fast thalamo-cortical synaptic depression by simple cells receiving a direct structured input from thalamus composes a generic computational mechanism for generating a sparse and reliable encoding of natural sensory events.","tags":["Visual Cortex","area V1","Excitation/inhibition","natural visual stimuli","push-pull receptive field","RetinaClouds","Sensory coding","üîçNo DOI found"],"title":"Push-Pull Receptive Field Organization and Synaptic Depression: Mechanisms for Reliably Encoding Naturalistic Stimuli in V1","type":"publication"},{"authors":["Wahiba Taouali","Giacomo Benvenuti","Pascal Wallisch","Fr√©d√©ric Chavane","Laurent U Perrinet"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"bd64c4a35030fe282cdf6f718bb8cac8","permalink":"https://laurentperrinet.github.io/publication/taouali-16/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/taouali-16/","section":"publication","summary":"The repeated presentation of an identical visual stimulus in the receptive field of a neuron may evoke different spiking patterns at each trial. Probabilistic methods are essential to understand the functional role of this variance within the neural activity. In that case, a Poisson process is the most common model of trial-to-trial variability. For a Poisson process, the variance of the spike count is constrained to be equal to the mean, irrespective of the duration of measurements. Numerous studies have shown that this relationship does not generally hold. Specifically, a majority of electrophysiological recordings show an \"overdispersion\" effect: responses that exhibit more intertrial variability than expected from a Poisson process alone. A model that is particularly well suited to quantify overdispersion is the Negative-Binomial distribution model. This model is well-studied and widely used but has only recently been applied to neuroscience. In this article, we address three main issues. First, we describe how the Negative-Binomial distribution provides a model apt to account for overdispersed spike counts. Second, we quantify the significance of this model for any neurophysiological data by proposing a statistical test, which quantifies the odds that overdispersion could be due to the limited number of repetitions (trials). We apply this test to three neurophysiological data sets along the visual pathway. Finally, we compare the performance of this model to the Poisson model on a population decoding task. We show that the decoding accuracy is improved when accounting for overdispersion, especially under the hypothesis of tuned overdispersion.","tags":["anr-trax","decoding","Decoding","negative-binomial distribution","Negative-binomial distribution","overdispersion","Overdispersion","spike counts","Spike counts","Tuning function","tuning function.","spikes","taouali15"],"title":"Testing the odds of inherent vs. observed overdispersion in neural spike counts.","type":"publication"},{"authors":["Kiana Mansour Pour","Laurent U. Perrinet","Guillaume S. Masson","Anna Montagnini"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"122ce2e7c14ef823da56ee097c7a9236","permalink":"https://laurentperrinet.github.io/publication/mansour-16-ecvp/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/mansour-16-ecvp/","section":"publication","summary":"","tags":null,"title":"Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit","type":"publication"},{"authors":["Kiana Mansour Pour","Laurent U. Perrinet","Guillaume S. Masson","Anna Montagnini"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"2d06995d916b105e915cc3a717ceed3f","permalink":"https://laurentperrinet.github.io/publication/mansour-16-gdr/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/mansour-16-gdr/","section":"publication","summary":"","tags":null,"title":"Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit","type":"publication"},{"authors":["Kiana Mansour Pour","Laurent U. Perrinet","Guillaume S. Masson","Anna Montagnini"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"91036ffd42e7f31a24efd73660a365c6","permalink":"https://laurentperrinet.github.io/publication/mansour-16-sfn/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/mansour-16-sfn/","section":"publication","summary":"","tags":null,"title":"Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit","type":"publication"},{"authors":["Gabriel Crist√≥bal","Laurent Perrinet","Matthias S. Keil"],"categories":null,"content":" Biologically Inspired Computer Vision As state-of-the-art imaging technologies becomes more and more advanced, yielding scientific data at unprecedented detail and volume, the need to process and interpret all the data has made image processing and computer vision also increasingly important. Sources of data that have to be routinely dealt with today applications include video transmission, wireless communication, automatic fingerprint processing, massive databanks, non-weary and accurate automatic airport screening, robust night vision to name a few. Multidisciplinary inputs from other disciplines such as computational neuroscience, cognitive science, mathematics, physics and biology will have a fundamental impact in the progress of imaging and vision sciences. One of the advantages of the study of biological organisms is to devise very diÔ¨Äerent type of computational paradigms beyond the usual von Neumann e.g. by implementing a neural network with a high degree of local connectivity.\n  This is a comprehensive and rigorous reference in the area of biologically motivated vision sensors. The study of biologically visual systems can be considered as a two way avenue. On the one hand, biological organisms can provide a source of inspiration for new computational efficient and robust vision models and on the other hand machine vision approaches can provide new insights for understanding biological visual systems. Along the different chapters, this book covers a wide range of topics from fundamental to more specialized topics, including visual analysis based on a computational level, hardware implementation, and the design of new more advanced vision sensors. The last two sections of the book provide an overview of a few representative applications and current state of the art of the research in this area. This makes it a valuable book for graduate, Master, PhD students and also researchers in the field.\nThis book contains 17 chapters that have been organized in four different parts: * Fundamentals * Sensing * Modeling * Applications\nSee the Table of contents.\n  ","date":1446332400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446332400,"objectID":"1279272fa85e2d8ded3ce02fcb3913c8","permalink":"https://laurentperrinet.github.io/publication/cristobal-perrinet-keil-15-bicv/","publishdate":"2015-11-01T00:00:00+01:00","relpermalink":"/publication/cristobal-perrinet-keil-15-bicv/","section":"publication","summary":"Biologically Inspired Computer Vision As state-of-the-art imaging technologies becomes more and more advanced, yielding scientific data at unprecedented detail and volume, the need to process and interpret all the data has made image processing and computer vision also increasingly important. Sources of data that have to be routinely dealt with today applications include video transmission, wireless communication, automatic fingerprint processing, massive databanks, non-weary and accurate automatic airport screening, robust night vision to name a few.","tags":null,"title":"Biologically Inspired Computer Vision","type":"publication"},{"authors":["Gabriel Crist√≥bal","Laurent Perrinet","Matthias S. Keil"],"categories":null,"content":"","date":1446332400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446332400,"objectID":"b50e63f4dc0332662df9a7de8634d9df","permalink":"https://laurentperrinet.github.io/publication/cristobal-perrinet-keil-15-bicv-chap-1/","publishdate":"2015-11-01T00:00:00+01:00","relpermalink":"/publication/cristobal-perrinet-keil-15-bicv-chap-1/","section":"publication","summary":"","tags":null,"title":"Introduction","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1446332400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446332400,"objectID":"2b1f4daf1a63e8432cafb7feac19fceb","permalink":"https://laurentperrinet.github.io/publication/perrinet-15-bicv/","publishdate":"2015-11-01T00:00:00+01:00","relpermalink":"/publication/perrinet-15-bicv/","section":"publication","summary":"","tags":["bicv-sparse"],"title":"Sparse Models for Computer Vision","type":"publication"},{"authors":["Anna Montagnini","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1446332400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446332400,"objectID":"61cb6f383891ef5679c5cfe487534495","permalink":"https://laurentperrinet.github.io/publication/montagnini-15-bicv/","publishdate":"2015-11-01T00:00:00+01:00","relpermalink":"/publication/montagnini-15-bicv/","section":"publication","summary":"","tags":["bicv-motion"],"title":"Visual motion processing and human tracking behavior","type":"publication"},{"authors":["Wahiba Taouali","Giacomo Benvenuti","Pascal Wallisch","Fr√©d√©ric Chavane","Laurent U. Perrinet"],"categories":null,"content":"","date":1443650400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1443650400,"objectID":"36e783e9f9cc992820eaba651dec3ade","permalink":"https://laurentperrinet.github.io/publication/taouali-15/","publishdate":"2015-10-01T00:00:00+02:00","relpermalink":"/publication/taouali-15/","section":"publication","summary":"The repeated presentation of an identical visual stimulus in the receptive field of a neuron may evoke different spiking patterns at each trial. Probabilistic methods are essential to understand its functional role within the neural activity. In that case, a Poisson process is the most common model of trial-to-trial variability. However, the variance of the spike count is constrained to be equal to the mean, irrespective of measurement's duration. Numerous studies have shown that this relationship does not generally hold. Specifically, a majority of electrophysiological recordings show an ``em overdispersion'' effect: Responses that exhibit more inter-trial variability than expected from a Poisson process alone. A model that is particularly well suited to quantify overdispersion is the Negative-Binomial distribution model. This model is largely applied and studied but has only recently been applied to neuroscience. In this paper, we address three main issues. First, we describe how the Negative-Binomial distribution provides a model apt to account for overdispersed spike counts. Second, we quantify the significance of this model for any neurophysiological data by proposing a statistical test, which quantifies the odds that overdispersion could be due to the limited number of repetitions (trials). We apply this test to three neurophysiological tests along the visual pathway. Finally, we compare the performance of this model to the Poisson model on a population decoding task. This shows that more knowledge about the form of dispersion tuning is necessary to have a significant gain, uncovering a possible feature of the neural spiking code.","tags":["decoding","spikes","taouali14"],"title":"Testing the Odds of Inherent versus Observed Over-dispersion in Neural Spike Counts","type":"publication"},{"authors":["Laurent U. Perrinet","James A. Bednar"],"categories":null,"content":"","date":1438380000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438380000,"objectID":"7c132b903380a9f883be7d43306c0643","permalink":"https://laurentperrinet.github.io/publication/perrinet-15-eusipco/","publishdate":"2015-08-01T00:00:00+02:00","relpermalink":"/publication/perrinet-15-eusipco/","section":"publication","summary":"Oriented edges in images of natural scenes tend to be aligned in co-linear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (the \"good continuation law\" of Gestalt psychology). The visual system appears to take advantage of this prior knowledge about natural images, with human contour detection and grouping performance well predicted by such an \"association field\" between edge elements. Geisler et al (2001) have estimated this prior information available to the visual system by extracting contours from a database of natural images, and showed that these statistics could predict behavioral data from humans in a line completion task. In this paper, we show that an association field of this type can be used for the sparse representation of natural images.","tags":["association","bicv-sparse","coding","connections","field","lateral","natural","scene","sparse","sparselets","statistics"],"title":"Sparse Coding Of Natural Images Using A Prior On Edge Co-Occurences","type":"publication"},{"authors":["Jonathan Vacher","Andrew Isaac Meso","Laurent Perrinet","Gabriel Peyre"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"c2804cac3cc2125f9fd4a939c4a99c36","permalink":"https://laurentperrinet.github.io/publication/vacher-15-icms/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/vacher-15-icms/","section":"publication","summary":"","tags":null,"title":"A Mathematical Account of Dynamic Texture Synthesis for Probing Visual Perception","type":"publication"},{"authors":["Anna Montagnini","Jean-Bernard Damasse","Laurent U. Perrinet","Laurent Madelain"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"8e34cf520a701244575b6a6bfe81c459","permalink":"https://laurentperrinet.github.io/publication/montagnini-15-sfn/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/montagnini-15-sfn/","section":"publication","summary":"","tags":["bayesian models"],"title":"Anticipating a moving target: role of vision and reinforcement","type":"publication"},{"authors":["Jean-Bernard Damasse","Laurent Madelain","Laurent Perrinet","Anna Montagnini"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"4a954e30c0af2a4d0f3381f267fd2a82","permalink":"https://laurentperrinet.github.io/publication/damasse-15-vss/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/damasse-15-vss/","section":"publication","summary":"When an object is moving in the visual field, we are able to accurately track it with a combination of saccades and smooth eye movements. These movements allow us to align and stabilize the object on the fovea, thus enabling visual analysis with high acuity. Importantly, when predictive information is available about the target motion, anticipatory smooth pursuit eye movements (aSPEM) are efficiently generated before target appearance, which reduce the typical sensorimotor delay between target motion onset and foveation.By manipulating the probability for target motion direction we were able to bias the direction and mean velocity of aSPEM (baseline condition). This suggests that probabilistic information may be used to inform the internal representation of motion prediction for the initiation of anticipatory movements. To further understand the nature of this process, we investigate the effects of reinforcement on aSPEM with two distinct experiments. First, it has been previously shown that several properties of eye movements can be modulated by reinforcement paradigms based on monetary reward (Madelain et al. 2011). We adapted and extended this framework to prediction-based aSPEM, by associating a monetary reward to a criterion-matching anticipatory velocity, in the gap before the target onset. Second, it has also been reported that accurate perception per se can play the role of an efficient ecological reinforcer for visually guided saccades (Montagnini \u0026 Chelazzi, 2005). With a gaze-contingent procedure, we manipulated the discriminability of a perceptual target (appearing during the pursuit trial and followed by a discrimination task) The difficulty level of this task has been matched depending on the velocity of aSPEM. This experiment taps on the very reason to produce anticipatory tracking movement, that is to grant a quicker high-acuity vision of the moving target. We compare predictive anticipatory eye movements across these conditions.","tags":null,"title":"Anticipatory smooth eye movements and reinforcement","type":"publication"},{"authors":["Jonathan Vacher","Andrew Isaac Meso","Laurent U Perrinet","Gabriel Peyr√©"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"5271085a92f2cbb7f8091cd3cfe0ded3","permalink":"https://laurentperrinet.github.io/publication/vacher-15-nips/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/vacher-15-nips/","section":"publication","summary":"","tags":null,"title":"Biologically Inspired Dynamic Textures for Probing Motion Perception","type":"publication"},{"authors":["Laurent U. Perrinet","James A. Bednar"],"categories":null,"content":"Retinal cell preference for natural-like stimuli. Very elegant work by @APalacio_s et al. #retina #neuroscience #decoding https://t.co/3xNWaZd5x6\n\u0026mdash; Andres Canales-Johnson (@canalesjohnson) February 4, 2019   Edge co-occurrences (A) An example image with the list of extracted edges overlaid. Each edge is represented by a red line segment which represents its position (center of segment), orientation, and scale (length of segment). We controlled the quality of the reconstruction from the edge information such that the residual energy was less than 5%. (B) The relationship between a reference edge A and another edge B can be quantified in terms of the difference between their orientations $\\theta$, ratio of scale $\\sigma$, distance $d$ between their centers, and difference of azimuth (angular location) $\\phi$. Additionally, we define $\\psi=\\phi - \\theta/2$, which is symmetric with respect to the choice of the reference edge; in particular, $\\psi=0$ for co-circular edges. % (see text). As in~\\citet{Geisler01}, edges outside a central circular mask are discarded in the computation of the statistics to avoid artifacts. (Image credit: Andrew Shiva, Creative Commons Attribution-Share Alike 3.0 Unported license). This is used to compute the chevron map in Figure~2.   ÂãïÁâ©„ÅãÂê¶„Åã„ÅÆË¶ãÂàÜ„ÅëÊñπ„ÄÇhttp://t.co/TTY8MwZGoO„ÄÄÂºïÁî®„Åï„Çå„Å¶„Çã„Åë„Å©„ÄÅThorpe (1996)„ÅÆ150ms„ÅßÂå∫Âà•„Åï„Çå„Å¶„Çã„Å£„Å¶Ë©±(„Å™„Å§„Åã„Åó„ÅÑ)„Å®Èñ¢‰øÇ„ÅÇ„Çä„Åù„ÅÜ„ÄÇ\n\u0026mdash; Makito Oku (@okumakito) June 22, 2015   The probability distribution function $p(\\psi, \\theta)$ represents the distribution of the different geometrical arrangements of edges\u0026rsquo; angles, which we call a chevron map. We show here the histogram for non-animal natural images, illustrating the preference for co-linear edge configurations. For each chevron configuration, deeper and deeper red circles indicate configurations that are more and more likely with respect to a uniform prior, with an average maximum of about $3$ times more likely, and deeper and deeper blue circles indicate configurations less likely than a flat prior (with a minimum of about $0.8$ times as likely). Conveniently, this chevron map shows in one graph that non-animal natural images have on average a preference for co-linear and parallel edges, (the horizontal middle axis) and orthogonal angles (the top and bottom rows),along with a slight preference for co-circular configurations (for $\\psi=0$ and $\\psi=\\pm \\frac \\pi 2$, just above and below the central row). We compare chevron maps in different image categories in Figure~3.   Edge co-occurrences can account for rapid categorization of natural versus animal imageshttp://t.co/NY9HapBx2S pic.twitter.com/rKQ8I5i6Ty\n\u0026mdash; Francis Villatoro (@emulenews) June 22, 2015   As for Figure 2, we show the probability of edge configurations as chevron maps for two databases (man-made, animal). Here, we show the ratio of histogram counts relative to that of the non-animal natural image dataset. Deeper and deeper red circles indicate configurations that are more and more likely (and blue respectively less likely) with respect to the histogram computed for non-animal images. In the left plot, the animal images exhibit relatively more circular continuations and converging angles (red chevrons in the central vertical axis) relative to non-animal natural images, at the expense of co-linear, parallel, and orthogonal configurations (blue circles along the middle horizontal axis). The man-made images have strikingly more co-linear features (central circle), which reflects the prevalence of long, straight lines in the cage images in that dataset. We use this representation to categorize images from these different categories in Figure~4.    Classification results. To quantify the difference in low-level feature statistics across categories (see Figure~3, we used a standard Support Vector Machine (SVM) classifier to measure how each representation affected the classifier\u0026rsquo;s reliability for identifying the image category. For each individual image, we constructed a vector of features as either (FO) the histogram of first-order statistics as the histogram of edges\u0026rsquo; orientations, (CM) the chevron map subset of the second-order statistics, (i.e., the two-dimensional histogram of relative orientation and azimuth; see Figure 2 ), or (SO) the full, four-dimensional histogram of second-order statistics (i.e., all parameters of the edge co-occurrences). We gathered these vectors for each different class of images and report here the results of the SVM classifier using an F1 score (50\\% represents chance level). While it was expected that differences would be clear between non-animal natural images versus laboratory (man-made) images, results are still quite high for classifying animal images versus non-animal natural images, and are in the range reported by~\\citet{Serre07} (F1 score of 80\\% for human observers and 82\\% for their model), even using the CM features alone. We further extend this results to the psychophysical results of Serre et al. (2007) in Figure 5.    To see whether the patterns of errors made by humans are consistent with our model, we studied the second-order statistics of the 50 non-animal images that human subjects in Serre et al. (2007) most commonly falsely reported as having an animal. We call this set of images the false-alarm image dataset. (Left) This chevron map plot shows the ratio between the second-order statistics of the false-alarm images and the full non-animal natural image dataset, computed as in Figure 3 (left). Just as for the images that actually do contain animals (Figure~\\ref{fig:chevrons2}, left), the images falsely reported as having animals have more co-circular and converging (red chevrons) and fewer collinear and orthogonal configurations (blue chevrons). (Right) To quantify this similarity, we computed the Kullback-Leibler distance between the histogram of each of these images from the false-alarm image dataset, and the average histogram of each class. The difference between these two distances gives a quantitative measure of how close each image is to the average histograms for each class. Consistent with the idea that humans are using edge co-occurences to do rapid image categorization, the 50 non-animal images that were worst classified are biased toward the animal histogram ($d\u0026rsquo; = 1.04$), while the 550 best classified non-animal images are closer to the non-animal histogram.   ","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"6c5d7302877e74ebd56153473901a0df","permalink":"https://laurentperrinet.github.io/publication/perrinet-bednar-15/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-bednar-15/","section":"publication","summary":"Retinal cell preference for natural-like stimuli. Very elegant work by @APalacio_s et al. #retina #neuroscience #decoding https://t.co/3xNWaZd5x6\n\u0026mdash; Andres Canales-Johnson (@canalesjohnson) February 4, 2019   Edge co-occurrences (A) An example image with the list of extracted edges overlaid. Each edge is represented by a red line segment which represents its position (center of segment), orientation, and scale (length of segment). We controlled the quality of the reconstruction from the edge information such that the residual energy was less than 5%.","tags":["assofield"],"title":"Edge co-occurrences can account for rapid categorization of natural versus animal images","type":"publication"},{"authors":["Caroline Landelle Fr√©deric Danion","Anna Montagnini","Laurent U. Perrinet","Laurent Madelain"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"fbfe473d9830ee0090419be17949c1ad","permalink":"https://laurentperrinet.github.io/publication/danion-15-sfn/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/danion-15-sfn/","section":"publication","summary":"","tags":["bayesian models"],"title":"Eye tracking a self-moved target with complex hand-target dynamics","type":"publication"},{"authors":["Wahiba Taouali","Giacomo Benvenuti","Pascal Wallisch","Fr√©d√©ric Chavane","Laurent Perrinet"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"2da4f922f8f79c6abb06801a3cd00d33","permalink":"https://laurentperrinet.github.io/publication/taouali-15-icmns/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/taouali-15-icmns/","section":"publication","summary":"The repeated presentation of an identical visual stimulus in the receptive field of a neuron may evoke different spiking patterns at each trial. Probabilistic methods are essential to understand its functional role within the neural activity. In that case, a Poisson process is the most common model of trial-to-trial variability. However, the variance of the spike count is constrained to be equal to the mean, irrespective of measurement's duration. Numerous studies have shown that this relationship does not generally hold. Specifically, a majority of electrophysiological recordings show an ``em overdispersion'' effect: Responses that exhibit more inter-trial variability than expected from a Poisson process alone. A model that is particularly well suited to quantify overdispersion is the Negative-Binomial distribution model. This model is largely applied and studied but has only recently been applied to neuroscience. In this paper, we address three main issues. First, we describe how the Negative-Binomial distribution provides a model apt to account for overdispersed spike counts. Second, we quantify the significance of this model for any neurophysiological data by proposing a statistical test, which quantifies the odds that overdispersion could be due to the limited number of repetitions (trials). We apply this test to three neurophysiological tests along the visual pathway. Finally, we compare the performance of this model to the Poisson model on a population decoding task. This shows that more knowledge about the form of dispersion tuning is necessary to have a significant gain, uncovering a possible feature of the neural spiking code.","tags":null,"title":"On overdispersion in neuronal evoked activity","type":"publication"},{"authors":["C. Ravello","F. Olivares","R. Herzog","L. Perrinet","M.J. Escobar","A.G. Palacios"],"categories":null,"content":"","date":1420066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420066800,"objectID":"1d2b4cb8d6d9bc223d51c325dd0e8909","permalink":"https://laurentperrinet.github.io/publication/ravello-15/","publishdate":"2015-01-01T00:00:00+01:00","relpermalink":"/publication/ravello-15/","section":"publication","summary":"","tags":null,"title":"Spatiotemporal tuning of retinal ganglion cells dependent on the context of signal presentation","type":"publication"},{"authors":["Laurent U. Perrinet","Rick A. Adams","Karl J. Friston"],"categories":null,"content":"","date":1417388400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417388400,"objectID":"da20b43c63c3d8b3822f4c1abb68c266","permalink":"https://laurentperrinet.github.io/publication/perrinet-adams-friston-14/","publishdate":"2014-12-01T00:00:00+01:00","relpermalink":"/publication/perrinet-adams-friston-14/","section":"publication","summary":"This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalised coordinates of motion. Representing hidden states in generalised coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the generative model to simulate smooth pursuit eye movements---in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system---like the oculomotor system---tries to control its environment with delayed signals.","tags":["active-inference","bayesian","bicv-sparse","delays","eye","eye-movements","free-energy","freemove","generalized-coordinates","generalized-filtering","oculomotor","perception","smooth-pursuit","tracking-eye-movements","variational-filtering"],"title":"Active inference, eye movements and oculomotor delays","type":"publication"},{"authors":["Andrew I. Meso","Claudio Simoncini","Laurent Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1406844000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406844000,"objectID":"ae53f3d7541e45df40358b9436f2a144","permalink":"https://laurentperrinet.github.io/publication/meso-14-vss/","publishdate":"2014-08-01T00:00:00+02:00","relpermalink":"/publication/meso-14-vss/","section":"publication","summary":"Estimating object speed in visual scenes is a critical part of perception. While various aspects of speed computation including discrimination thresholds, neural mechanisms and spatial integration mechanisms have been studied, there remain areas to elucidate. One is the integration of information across spatio-temporal frequency channels to compute speed. We probe this integration with a 2-AFC psychophysical task in which moving random phase noise stimuli are used with experimenter defined frequency parameters and bandwidths to target specific neural populations. They are presented for 300ms in a large square aperture with smooth eye movements recorded while speed discrimination judgements are made over two intervals. There is no instruction to observers to pursue the stimuli and no pre trial saccade to induce a classic ocular following response. After a latency, eye movements follow the stimulated direction presumably to facilitate the speed judgement. Within each of the two intervals, we randomly vary a range of spatial frequency and speed parameters respectively such that stimuli at the centre of the ranges are identical. The aim is to characterise the speed response of the eye movements recorded in a context which creates an ocular motor √¢‚Ç¨Àúaction√¢‚Ç¨‚Ñ¢ during a perceptual task instead of artificially separating the two. Within the speed varied intervals, averaged eye movements are systematically modulated in strength by stimulus speed. Within the spatial frequency intervals, higher frequencies perceived as faster in discrimination responses interestingly show no corresponding strengthening of eye responses particularly at higher contrasts where they may be weaker. Thus for a pair of stimuli matched for contrast and perceived speed, this early eye response appears to be driven by a contrast dependent low level motion energy like computation. We characterise an underlying spatial frequency response which is shifted towards lower frequencies, unlike the perceptual responses and is probably separate from perception.","tags":["anr-speed","speed-tuning"],"title":"Beyond simply faster and slower: exploring paradoxes in speed perception","type":"publication"},{"authors":["Laurent U. Perrinet","James A. Bednar"],"categories":null,"content":"","date":1406844000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406844000,"objectID":"b32e5513d77529f7cccf22f1b6663ff0","permalink":"https://laurentperrinet.github.io/publication/perrinet-bednar-14-vss/","publishdate":"2014-08-01T00:00:00+02:00","relpermalink":"/publication/perrinet-bednar-14-vss/","section":"publication","summary":"Analysis and interpretation of a visual scene to extract its category, such as whether it contains an animal, is typically assumed to involve higher-level associative brain areas. Previous proposals have been based on a series of processing steps organized in a multi-level hierarchy that would progressively analyze the scene at increasing levels of abstraction, from contour extraction to low-level object recognition and finally to object categorization (Serre, PNAS 2007). We explore here an alternative hypothesis that the statistics of edge co-occurences are sufficient to perform a rough yet robust (translation, scale, and rotation invariant) scene categorization. The method is based on a realistic model of image analysis in the primary visual cortex that extends previous work from Geisler et al. (Vis. Res. 2001). Using a scale-space analysis coupled with a sparse coding algorithm, we achieved detailed and robust extraction of edges in different sets of natural images. This edge-based representation allows for a simple characterization of the ``association field'' of edges by computing the statistics of co-occurrences. We show that the geometry of angles made between edges is sufficient to distinguish between different sets of natural images taken in a variety of environments (natural, man-made, or containing an animal). Specifically, a simple classifier, working solely on the basis of this geometry, gives performance similar to that of hierarchical models and of humans in rapid-categorization tasks. Such results call attention to the importance of the relative geometry of local image patches in visual computation, with implications for designing efficient image analysis systems. Most importantly, they challenge assumptions about the flow of computations in the visual system and emphasize the relative importance in this process of associative connections, and in particular of intra-areal lateral connections.","tags":["assofield"],"title":"Edge co-occurrences are sufficient to categorize natural versus animal images","type":"publication"},{"authors":["Mina A. Khoei","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1406844000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406844000,"objectID":"8bfc879d951c9f5f391701db53807991","permalink":"https://laurentperrinet.github.io/publication/khoei-14-vss/","publishdate":"2014-08-01T00:00:00+02:00","relpermalink":"/publication/khoei-14-vss/","section":"publication","summary":"The flash lag effect (FLE) is a well known visual illusion that reveals the perceptual difference in position coding of moving and stationary flashed objects. It has been reproduced experimentally in retina and V1 along with some relevant evidences about motion based position coding in areas MT and MT+. Numerous hypotheses for mechanisms underlying FLE such as motion extrapolation, latency difference, position persistence, temporal averaging and postdiction have been under debate for last two decades. Here, we have challenged our previous motion-based prediction model to understand FLE, consistently with the motion extrapolation account proposed by Nijhawan. Our hypothesis is based on predictability of motion trajectory and importance of motion signal in manipulation of receptive field shape for moving objects. Using a probabilistic framework, we have implemented motion-based prediction (MBP) and simulated three different demonstrations of FLE including standard, flash initiated and flash terminated cycles. This method allowed us to compare the shape of the characteristic receptive fields for moving and stationary flashed dots in the case of rightward and leftward motions. As control model, we have eliminated velocity signal from motion estimation and simulated position-based (PX) model of FLE. Results of MBP model suggest that above a minimal time for duration of flash, the development of predictive component for the moving object is sufficient to shift in the direction of motion and to produce flash lag effect. MBP model reproduces experimental data of FLE and its dependence to the contrast of flash. Against what has been argued as shortage of motion extrapolation account, in our results spatial lead of moving object is also evident in flash initiated cycle. Our model, without being restricted to one special visual area, provides a generic account for FLE by emphasize on different manipulation of stationary objects and trajectory motion by the sensory system.","tags":["khoei14fle"],"title":"Motion-based prediction model for flash lag effect","type":"publication"},{"authors":["Claudio Simoncini","Anna Montagnini","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1406844000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406844000,"objectID":"8437d9dae0e9884eb37137c1c8d7de85","permalink":"https://laurentperrinet.github.io/publication/simoncini-14-vss/","publishdate":"2014-08-01T00:00:00+02:00","relpermalink":"/publication/simoncini-14-vss/","section":"publication","summary":"Under natural viewing conditions, large eye movements are interspace by small eye movements (microsaccade). Recent works have shown that these two kinds of eye movements are generate by the same oculomotor mechanisms (Goffart et al., 2012) and are driven from the same visual information (Simoncini et al., VSS 2012 abstract). These results seem to demonstrate that microsaccade and saccade represent a continuum of the same ocular movement. However, if the role played in vision perception by large saccades is clearly identified, the role of the microsaccade is not clearly defined. In order to investigate the role of microsaccade, we measured pattern discrimination performance using an ABX match-to-sample task during the presentation of 1/f natural statistics texture where we varied the spatial frequency contents. We compared perceptual performance with eye movements recorded during the task. We found that the rate of microsaccadic movements changed as a function of the subjects task strategy. In particular, in the trials where the perception of the difference between the stimuli was simple (low spatial frequency) the subjects used the information provided by all the stimuli to do the task and the microsaccadic rate for all the stimuli (ABX) was the same. However, when the perception of the difference between the stimuli was harder (for instance for high spatial frequency), the subjects rather used the information provided by the last two stimuli only and the microsaccadic rate for the image BX increased respect at the image A. These results demonstrate that microsaccadic eye movements also play a role during the analysis of the visual scene and that such experiments can help decipher their participation to perception of the scene. Goffart L., Hafed Z.M., Krauzlis R.J. 2012. Visual fixation as equilibrium: evidence from superior colliculus inactivation. (31) 10627-10636.","tags":["microsaccades"],"title":"The characteristics of microsaccadic eye movements varied with the change of strategy in a match-to-sample task.","type":"publication"},{"authors":["Wahiba Taouali","Laurent Perrinet"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"cf663492ba0ff12f7ba5e1ed3ec38e6c","permalink":"https://laurentperrinet.github.io/publication/taouali-14-areadne/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/taouali-14-areadne/","section":"publication","summary":"","tags":null,"title":"A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise","type":"publication"},{"authors":["Wahiba Taouali","Laurent Perrinet"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"2a49f426812d6c6cd3d14fae11873ba2","permalink":"https://laurentperrinet.github.io/publication/taouali-14-neurocomp/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/taouali-14-neurocomp/","section":"publication","summary":"","tags":null,"title":"A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise","type":"publication"},{"authors":["Jonathan Vacher","Andrew Isaac Meso","Laurent Perrinet","Gabriel Peyre"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"be668460d100a02c9706494ffc120932","permalink":"https://laurentperrinet.github.io/publication/vacher-14-ihp/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/vacher-14-ihp/","section":"publication","summary":"This work extends the MotionClouds dynamic texture model testing aspects of its parametrization with an application in psychophysics. ","tags":null,"title":"Dynamic Textures For Probing Motion Perception","type":"publication"},{"authors":["P Philipp Rudiger","Jean-Luc Stevens","Bharath Chandra Talluri","Laurent U. Perrinet","James A. Bednar"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"18975c86f97ed0d13e7ebe1d90b5b0ec","permalink":"https://laurentperrinet.github.io/publication/rudiger-14-cosyne/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/rudiger-14-cosyne/","section":"publication","summary":"","tags":null,"title":"Relationship between natural image statistics and lateral connectivity in the primary visual cortex","type":"publication"},{"authors":["Bernhard A. Kaplan","Mina A. Khoei","Anders Lansner","Laurent U. Perrinet"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"87ac758310b5becccd093c1e8955bd91","permalink":"https://laurentperrinet.github.io/publication/kaplan-khoei-14/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/kaplan-khoei-14/","section":"publication","summary":"","tags":["bayesian","khoei14fle","models"],"title":"Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network","type":"publication"},{"authors":["Mina A. Khoei","Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":"","date":1383260400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383260400,"objectID":"1de874f4c0bd9dcade9bc4bf5626442f","permalink":"https://laurentperrinet.github.io/publication/khoei-13-jpp/","publishdate":"2013-11-01T00:00:00+01:00","relpermalink":"/publication/khoei-13-jpp/","section":"publication","summary":"","tags":["khoei13jpp","motion-extrapolation","neural_representation"],"title":"Motion-based prediction explains the role of tracking in motion extrapolation","type":"publication"},{"authors":["Laurent U. Perrinet","Rick A. Adams","Karl Friston"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"00d7f86918f76c4162fa1e0a49f2499c","permalink":"https://laurentperrinet.github.io/publication/perrinet-13-cns/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-13-cns/","section":"publication","summary":"We consider the problem of sensorimotor delays in the optimal control of movement under un-certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop andtheir implications for active inference. Active inference uses a generalisation of Kalman filter-ing to provide Bayes optimal estimates of hidden states and action in generalised coordinatesof motion. Representing hidden states in generalised coordinates provides a simple means ofcompensating for both sensory and oculomotor delays. This compensation is illustrated us-ing neuronal simulations of oculomotor following responses with and without compensation.We then consider an extension of the generative model that produces ocular followingto simulate smooth pursuit eye movements --- in which the system believes both the target andits centre of gaze are attracted by a (fictive) point moving in the visual field. Finally, the gen-erative model is equipped with a hierarchical structure, so that it can register and rememberunseen (occluded) trajectories and emit anticipatory responses. These simulations speak to astraightforward and neurobiologically plausible solution to the generic problem of integratinginformation from different sources with different temporal delays and the particular difficultiesencountered when a system --- like the oculomotor system --- tries to control its environmentwith delayed signals.","tags":null,"title":"Active inference, eye movements and oculomotor delays.","type":"publication"},{"authors":["Laurent U. Perrinet","Rick A. Adams","Karl Friston"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"47e3f7af224cf7e12e3529e3ea4ca19c","permalink":"https://laurentperrinet.github.io/publication/perrinet-13-jffos/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-13-jffos/","section":"publication","summary":"We consider the problem of sensorimotor delays in the optimal control of movement under un-certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop andtheir implications for active inference. Active inference uses a generalisation of Kalman filter-ing to provide Bayes optimal estimates of hidden states and action in generalised coordinatesof motion. Representing hidden states in generalised coordinates provides a simple means ofcompensating for both sensory and oculomotor delays. This compensation is illustrated us-ing neuronal simulations of oculomotor following responses with and without compensation.We then consider an extension of the generative model that produces ocular followingto simulate smooth pursuit eye movements --- in which the system believes both the target andits centre of gaze are attracted by a (fictive) point moving in the visual field. Finally, the gen-erative model is equipped with a hierarchical structure, so that it can register and rememberunseen (occluded) trajectories and emit anticipatory responses. These simulations speak to astraightforward and neurobiologically plausible solution to the generic problem of integratinginformation from different sources with different temporal delays and the particular difficultiesencountered when a system --- like the oculomotor system --- tries to control its environmentwith delayed signals.","tags":null,"title":"Active inference, eye movements and oculomotor delays.","type":"publication"},{"authors":["Rodrigo Nava","J. Victor Marcos","Boris Escalante-Ram√≠rez","Gabriel Crist√≥bal","Laurent U. Perrinet","Ra√∫l S. J. Est√©par"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"f231603f8147d552da5b7f3ece074388","permalink":"https://laurentperrinet.github.io/publication/nava-13/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/nava-13/","section":"publication","summary":"In recent years, with the advent of High-resolution Computed Tomography (HRCT), there has been an increased interest for diagnosing Chronic Obstructive Pulmonary Disease (COPD), which is commonly presented as emphysema. Since low-attenuation areas in HRCT images describe different emphysema patterns, the discrimination problem should focus on the characterization of both local intensities and global spatial variations. We propose a novel texture-based classification framework using complex Gabor filters and local binary patterns. We also analyzed a set of global and local texture descriptors to characterize emphysema morphology. The results have shown the effectiveness of our proposal and that the combination of descriptors provides robust features that lead to an improvement in the classification rate.","tags":["sparse_coding","texture","translational-science"],"title":"Advances in Texture Analysis for Emphysema Classification","type":"publication"},{"authors":["Bernhard A. Kaplan","Anders Lansner","Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"69cb1f17a99fb25bc6a452138ff47478","permalink":"https://laurentperrinet.github.io/publication/kaplan-13/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/kaplan-13/","section":"publication","summary":"Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may implement predictive coding and what function their connectivity may have. We present a network model of conductance-based integrate-and-fire neurons inspired by the architecture of retinotopic cortical areas that assumes predictive coding is implemented through network connectivity, namely in the connection delays and in selectiveness for the tuning properties of source and target cells. We show that the applied connection pattern leads to motion-based prediction in an experiment tracking a moving dot. In contrast to our proposed model, a network with random or isotropic connectivity fails to predict the path when the moving dot disappears. Furthermore, we show that a simple linear decoding approach is sufficient to transform neuronal spiking activity into a probabilistic estimate for reading out the target trajectory. ","tags":["motion detection","motion extrapolation","probabilistic representation","predictive coding","network of spiking neurons","large-scale neuromorphic systems"],"title":"Anisotropic connectivity implements motion-based prediction in a spiking neural network","type":"publication"},{"authors":["Andrew Meso","Claudio Simoncini","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"dcdcbae8385a42c124806425d5c22a3f","permalink":"https://laurentperrinet.github.io/publication/meso-13-vss/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/meso-13-vss/","section":"publication","summary":"Humans are able to interact successfully with moving objects in our dynamic world and the visual system effi ciently performs the motion computation that makes this possible. Object speed and direction are estimated following the integration of information across cortical motion sensitive channels. Speed estimation along this system is not fully understood, particularly the mapping function between the actual speed of viewed objects and that perceived by observers, a question we address in this work. It has been demonstrated that perceived speed is profoundly influenced by object contrast, spatial frequency, stimulus complexity and frequency bandwidth. In a 2 interval forced choice speed discrimination task, we present a random phase textured motion stimulus to probe small shifts in perceived speed measured using fi xed stimulus sets as reference scales while mean spatial frequency and bandwidths serve as the dependent variable in a probe. The presentations are short (200ms). Using a scale of narrowband stimuli (0.2 octaves), we measured a shift in perceived speed; higher frequencies are seen as faster moving than lower ones. On the scale of broader bandwidth (1 octave), this difference across frequency was reduced and perceived speed seems to converge on a slower representation. From these results we estimated this mapping between perceived and veridical stimulus speeds. In direct comparisons, the relative speed is faster for high frequencies and increases in bandwidth make stimuli appear slower. During this early computation, when presented with a random phase stimulus it appears that the visual systems makes assumptions about expected speeds based on the richness of the frequency content and the veridical speed is not explicitly computed. In this first 200ms, the perceptual system perhaps underestimates some speeds in an optimal response for initially stabilizing the scene. Acknowledgement: CNRS \u0026 Brainscales FP7","tags":["motion"],"title":"How and why do image frequency properties influence perceived speed?","type":"publication"},{"authors":["Claudio Simoncini","Laurent U. Perrinet","Anna Montagnini","Guillaume S. Masson"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"488ccebd1c69fe4332b2eefdc6be296e","permalink":"https://laurentperrinet.github.io/publication/simoncini-13-vss/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/simoncini-13-vss/","section":"publication","summary":"The visual system does not process information instantaneously, but rather integrates over time. Integration occurs both for stationary objects and moving objects, with very similar time constants (Burr, 1981). We measured, as a function of exposure duration, speed discrimination and ocular following performance for rich textured motion stimuli of varying spatial frequency bandwidth. Psychometric sensitivity and Oculometric sensitivity for these patterns increased with exposure duration. However the best stimuli for ocular following (namely those with a large bandwidth for spatial frequency) was well integrated up to about 150 - 200 msec, while the best stimuli for speed discrimination (small bandwidth) was well integrated up to about 300 msec. Interestingly, discriminability of ocular tracking eye movements follow a non-monotonic time course, due to the contribution of motor noise. These results suggest that although perception and action relies work in synergy, they may be described by two different integrating mechanisms: A low level, fast one guiding the ocular movement to enable one to catch stimuli in the visual fi eld quickly; and a slower one being able to measure the speed difference between two objects translating in the visual fi eld. Burr, D.C. (1981). Temporal summation of moving images by the human visual system. Proceedings of Royal Society, B211, 321 - 339","tags":["eye","motion","movements","perception","psychophysics"],"title":"Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.","type":"publication"},{"authors":["Mina A. Khoei","Giacomo Benvenuti","Fr√©d√©ric Chavane","Laurent U. Perrinet"],"categories":null,"content":"","date":1356994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356994800,"objectID":"efbcb3b5e4f45306df2de57ee15ac36d","permalink":"https://laurentperrinet.github.io/publication/khoei-13-cns/","publishdate":"2013-01-01T00:00:00+01:00","relpermalink":"/publication/khoei-13-cns/","section":"publication","summary":"","tags":["bayesian","khoei14fle","models"],"title":"Motion-based prediction and development of the response to an 'on the way' stimulus","type":"publication"},{"authors":["Rick A. Adams","Laurent U. Perrinet","Karl Friston"],"categories":null,"content":"","date":1349042400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349042400,"objectID":"17347db40bbc868085f66a637a026e7b","permalink":"https://laurentperrinet.github.io/publication/adams-12/","publishdate":"2012-10-01T00:00:00+02:00","relpermalink":"/publication/adams-12/","section":"publication","summary":"This paper introduces a model of oculomotor control during the smooth pursuit of occluded visual targets. This model is based upon active inference, in which subjects try to minimise their (proprioceptive) prediction error based upon posterior beliefs about the hidden causes of their (exteroceptive) sensory input. Our model appeals to a single principle -- the minimisation of variational free energy -- to provide Bayes optimal solutions to the smooth pursuit problem. However, it tries to accommodate the cardinal features of smooth pursuit of partially occluded targets that have been observed empirically in normal subjects and schizophrenia. Specifically, we account for the ability of normal subjects to anticipate periodic target trajectories and emit pre-emptive smooth pursuit eye movements -- prior to the emergence of a target from behind an occluder. Furthermore, we show that a single deficit in the postsynaptic gain of prediction error units (encoding the precision of posterior beliefs) can account for several features of smooth pursuit in schizophrenia: namely, a reduction in motor gain and anticipatory eye movements during visual occlusion, a paradoxical improvement in tracking unpredicted deviations from target trajectories and a failure to recognise and exploit regularities in the periodic motion of visual targets. This model will form the basis of subsequent (dynamic causal) models of empirical eye tracking measurements, which we hope to validate, using psychopharmacology and studies of schizophrenia.","tags":["occlusion","schizophrenia","spem"],"title":"Smooth Pursuit and Visual Occlusion: Active Inference and Oculomotor Control in Schizophrenia","type":"publication"},{"authors":["Paula S. Leon","Ivo Vanzetta","Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":"","date":1330556400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330556400,"objectID":"9cfdc9231eeaf93544fd87541f7b0eba","permalink":"https://laurentperrinet.github.io/publication/sanz-12/","publishdate":"2012-03-01T00:00:00+01:00","relpermalink":"/publication/sanz-12/","section":"publication","summary":"Choosing an appropriate set of stimuli is essential to characterize the response of a sensory system to a particular functional dimension, such as the eye movement following the motion of a visual scene. Here, we describe a framework to generate random texture movies with controlled information content, i.e., Motion Clouds. These stimuli are defined using a generative model that is based on controlled experimental parametrization. We show that Motion Clouds correspond to dense mixing of localized moving gratings with random positions. Their global envelope is similar to natural-like stimulation with an approximate full-field translation corresponding to a retinal slip. We describe the construction of these stimuli mathematically and propose an open-source Python-based implementation. Examples of the use of this framework are shown. We also propose extensions to other modalities such as color vision, touch, and audition.","tags":["sanz12jnp"],"title":"Motion Clouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception","type":"publication"},{"authors":["Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":"","date":1330556400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330556400,"objectID":"4623e59bf94b6cdc78f759c6f3d99658","permalink":"https://laurentperrinet.github.io/publication/masson-12/","publishdate":"2012-03-01T00:00:00+01:00","relpermalink":"/publication/masson-12/","section":"publication","summary":"Short-latency ocular following are reflexive, tracking eye movements that are observed in human and non-human primates in response to a sudden and brief translation of the image. Initial, open-loop part of the eye acceleration reflects many of the properties attributed to low-level motion processing. We review a very large set of behavioral data demonstrating several key properties of motion detection and integration stages and their dynamics. We propose that these properties can be modeled as a behavioral receptive field exhibiting linear and nonlinear mechanisms responsible for context-dependent spatial integration and gain control. Functional models similar to that used for describing neuronal properties of receptive fields can then be applied successfully.","tags":["behavioral_receptive_field","eye_movements","motion_estimation","primate","tracking"],"title":"The behavioral receptive field underlying motion integration for primate tracking eye movements","type":"publication"},{"authors":["Laurent U. Perrinet","Rick A. Adams","Karl Friston"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"9108fe20d3d5a1d3d5dc6c774a66d030","permalink":"https://laurentperrinet.github.io/publication/perrinet-12-areadne/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-12-areadne/","section":"publication","summary":"We consider the problem of sensorimotor delays in the optimal control of movement under un-certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop andtheir implications for active inference. Active inference uses a generalisation of Kalman filter-ing to provide Bayes optimal estimates of hidden states and action in generalised coordinatesof motion. Representing hidden states in generalised coordinates provides a simple means ofcompensating for both sensory and oculomotor delays. This compensation is illustrated us-ing neuronal simulations of oculomotor following responses with and without compensation.We then consider an extension of the generative model that produces ocular followingto simulate smooth pursuit eye movements --- in which the system believes both the target andits centre of gaze are attracted by a (fictive) point moving in the visual field. Finally, the gen-erative model is equipped with a hierarchical structure, so that it can register and rememberunseen (occluded) trajectories and emit anticipatory responses. These simulations speak to astraightforward and neurobiologically plausible solution to the generic problem of integratinginformation from different sources with different temporal delays and the particular difficultiesencountered when a system --- like the oculomotor system --- tries to control its environmentwith delayed signals.This work was supported from the European Community's Seventh Framework Program FP7/2007-2013 under grant agreement number 214728-2, \"CODDE\".","tags":null,"title":"Active inference, smooth pursuit and oculomotor delays.","type":"publication"},{"authors":["Nicole Voges","Laurent U. Perrinet"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"11b59f2a8ee40366aa15a0c1a0c0ee74","permalink":"https://laurentperrinet.github.io/publication/voges-12/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/voges-12/","section":"publication","summary":"Most studies on the dynamics of recurrent cortical networks are either based on purely random wiring or neighborhood couplings. Neuronal cortical connectivity, however, shows a complex spatial pattern composed of local and remote patchy connections. We ask to what extent such geometric traits influence the  '' idle'' dynamics of two-dimensional (2d) cortical network models composed of conductance-based integrate-and-fire (iaf) neurons. In contrast to the typical 1 mm2 used in most studies, we employ an enlarged spatial set-up of 25 mm2 to provide for long-range connections. Our models range from purely random to distance-dependent connectivities including patchy projections, i.e., spatially clustered synapses. Analyzing the characteristic measures for synchronicity and regularity in neuronal spiking, we explore and compare the phase spaces and activity patterns of our simulation results. Depending on the input parameters, different dynamical states appear, similar to the known synchronous regular  '' SR'' or asynchronous irregular  '' AI'' firing in random networks. Our structured networks, however, exhibit shifted and sharper transitions, as well as more complex activity patterns. Distance-dependent connectivity structures induce a spatio-temporal spread of activity, e.g., propagating waves, that random networks cannot account for. Spatially and temporally restricted activity injections reveal that a high amount of local coupling induces rather unstable AI dynamics. We find that the amount of local versus long-range connections is an important parameter, whereas the structurally advantageous wiring cost optimization of patchy networks has little bearing on the phase space.","tags":["dynamical_model","lateral_connections","patch-based","recurrent_neural_networks"],"title":"Complex dynamics in recurrent cortical networks based on spatially realistic connectivities","type":"publication"},{"authors":["Claudio Simoncini","Laurent U. Perrinet","Anna Montagnini","Pascal Mamassian","Guillaume S. Masson"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"9781fb51459379d278f099d11bb9bd31","permalink":"https://laurentperrinet.github.io/publication/simoncini-12-coding/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/simoncini-12-coding/","section":"publication","summary":"To measure speed and direction of moving objects, the cortical motion system pools information across different spatiotemporal channels. One yet unsolved question is to understand how the brain pools this information and whether this pooling is generic or adaptive at the behavioral contexts. Here, we investigate in humans this integration process for two different tasks: psychophysical speed discrimination and ocular following eye movements, which are a probe of early motion detection and integration (Masson \u0026 Perrinet, 2011). For both tasks, we used short presentations of ``moving textures'' stimuli (Schrater et al., 2000) in which the width of the spatial frequency distribution (Bsf) was varied. We found that larger Bsf elicited stronger initial eye velocity during the open-loop part of tracking responses. Moreover, richer stimuli resulted in more accurate and reliable motor responses. By contrast, larger Bsf had a detrimental effect upon speed discrimination performance: speed discrimination thresholds linearly decreased when the width of spatial frequency distribution increased. These opposite results can be explained by a different decoding strategy where speed information is under the control of different gain setting mechanisms. We tested this model by measuring contrast response functions of both ocular following and speed discrimination for each Bsf. We found that varying spatial frequency distribution had opposite effect upon contrast gain control. Increasing Bsf lowered half-saturation contrast for ocular following but increased it for perception. Our results supports the view that speed-based perception and tracking eye movements are under the control of different early decoding mechanism.ReferencesMasson, G.S. \u0026 Perrinet, L.U. The behavioural receptive field underlying motion integration for primate tracking eye movements. Neurosci. BioBehav. Review 36, 1-25 (2011).Schrater, P.R., Knill, D.C. \u0026 Simoncelli, E.P. Mechanism of visual motion detection. Nat. Neurosci. 3, 64-68 (2000).","tags":["eye movements","motion perception","psychophysics"],"title":"Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.","type":"publication"},{"authors":["Claudio Simoncini","Anna Montagnini","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"efe92d24d9f32dc735f83ebfb549a481","permalink":"https://laurentperrinet.github.io/publication/simoncini-12-vss/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/simoncini-12-vss/","section":"publication","summary":"Under natural viewing conditions, small movements of the eyes prevent the maintenance of a steady direction of gaze. It is unclear how the spatiotemporal content of the fixated scene has an impact on the properties of miniatures, fixational eye movements. We have investigated the characteristics of fixational eye movements recorded while human subjects are instructed to fixate natural statistics random textures (Motion Clouds) in which we manipulated the spatial frequency content. We used long presentations (5 sec) of Motion Clouds stimuli (Schrater et al. 2000) of varying spatial frequency bandwidths (Bsf) around different central spatial frequency (Sf0). We found that central spatial frequency has an effect upon microsaccadic eye movements. In particular, smaller saccadic amplitudes were associated with high spatial frequencies, and larger saccades with low spatial frequencies. Broadening the spatial frequency bandwidth also changed the distribution of microsaccade amplitudes. A lower spatial frequencies, larger Bsf resulted in a large reduction of microsaccades amplitude while fixation behavior for high spatial frequencies texture was not affected. Relationship between microsaccade rate and intersaccadic timing was also dependent upon Bsf. These results suggest that the spatial frequency content of the fixated images have a strong impact upon fixation instability.","tags":["eye movements","motion perception","psychophysics"],"title":"Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.","type":"publication"},{"authors":["Claudio Simoncini","Laurent U. Perrinet","Anna Montagnini","Pascal Mamassian","Guillaume S. Masson"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"5f0fa9e3eaa10f282d732e1eff204ce1","permalink":"https://laurentperrinet.github.io/publication/simoncini-12/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/simoncini-12/","section":"publication","summary":"Moving objects generate motion information at different scales, which are processed in the visual system with a bank of spatiotemporal frequency channels. It is not known how the brain pools this information to reconstruct object speed and whether this pooling is generic or adaptive; that is, dependent on the behavioral task. We used rich textured motion stimuli of varying bandwidths to decipher how the human visual motion system computes object speed in different behavioral contexts. We found that, although a simple visuomotor behavior such as short-latency ocular following responses takes advantage of the full distribution of motion signals, perceptual speed discrimination is impaired for stimuli with large bandwidths. Such opposite dependencies can be explained by an adaptive gain control mechanism in which the divisive normalization pool is adjusted to meet the different constraints of perception and action.","tags":null,"title":"More is not always better: dissociation between perception and action explained by adaptive gain control","type":"publication"},{"authors":["Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"9ae1d748edd216b5ada59bd55ce9b503","permalink":"https://laurentperrinet.github.io/publication/masson-12-areadne/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/masson-12-areadne/","section":"publication","summary":"In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to psychophysics and behavior. We demonstrate that this solution is the result of  two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independently of their texture. Second, we observe that incoherent features are explained away while coherent information diffuses progressively to the global scale. Most previous models included ad-hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features. Here, we have proved that motion-based predictive coding, as it is  implemented in this functional model, is sufficient to solve the aperture problem. This simpler solution may give insights in the role of prediction underlying a large class of sensory computations.","tags":["aperture problem","probabilistic representation","predictive coding","emergence"],"title":"Motion-based prediction is sufficient to solve the aperture problem","type":"publication"},{"authors":["Laurent Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"b1a5f2187cfabe1c229fc75c6b18bbd0","permalink":"https://laurentperrinet.github.io/publication/perrinet-12-pred/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-12-pred/","section":"publication","summary":"In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to psychophysics and behavior. We demonstrate that this solution is the result of  two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independently of their texture. Second, we observe that incoherent features are explained away while coherent information diffuses progressively to the global scale. Most previous models included ad-hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features. Here, we have proved that motion-based predictive coding, as it is  implemented in this functional model, is sufficient to solve the aperture problem. This simpler solution may give insights in the role of prediction underlying a large class of sensory computations.","tags":["aperture problem","probabilistic representation","predictive coding","emergence"],"title":"Motion-based prediction is sufficient to solve the aperture problem","type":"publication"},{"authors":["Karl Friston","Rick A. Adams","Laurent Perrinet","Michael Breakspear"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"4b757a5fa945f21e226cfddda93c96e9","permalink":"https://laurentperrinet.github.io/publication/friston-12/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/friston-12/","section":"publication","summary":"","tags":["free_energy","saccades"],"title":"Perceptions as Hypotheses: Saccades as Experiments","type":"publication"},{"authors":["Mina A. Khoei","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"4f13ffb3c1ee0ba853c14874b30997ac","permalink":"https://laurentperrinet.github.io/publication/khoei-12-sfn/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/khoei-12-sfn/","section":"publication","summary":"","tags":["bayesian models"],"title":"Role of motion-based prediction in motion extrapolation","type":"publication"},{"authors":["Claudio Simoncini","Anna Montagnini","Laurent U. Perrinet","Pascal Mamassian","Guillaume S. Masson"],"categories":null,"content":"","date":1314828000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314828000,"objectID":"b68c97284ad5d3a17de1db36b4ddcacf","permalink":"https://laurentperrinet.github.io/publication/simoncini-2011-pattern/","publishdate":"2011-09-01T00:00:00+02:00","relpermalink":"/publication/simoncini-2011-pattern/","section":"publication","summary":"In order to analyze the characteristics of a rich dynamic visual environment, the visual system must integrate information collected at different scales through different spatiotemporal frequency channels. Still, it remains unclear how reliable representations of motion direction or speed are elaborated when presented with large bandwidth motion stimuli or natural statistics. Last year, we have shown that broadening the spatiotemporal frequency content of a textured pattern moving at constant speed leads to different results on a reflexive tracking task and a speed discrimination task. Larger bandwidth stimuli increase response amplitude and sensitivity of ocular following, consistently with a maximum-likelihood (ML) model of motion decoding. In contrast, larger bandwidth stimuli impair speed discrimination performance, suggesting that the perceptual system cannot take advantage of such additional, redundant information. Instead of ML, a gain control decoding mechanism can explain the drop in performance, suggesting that action and perception rely on different decoding mechanisms. To further investigate such task-dependant pooling of motion information, we measured pattern discrimination performance using these textured stimuli. Two noise patterns were presented sequentially for 250 ms on a CRT monitor (1280 √ó 1024 @ 100 Hz) and covered 47$,^‚àò$ of visual angle with identical properties (mean SF, bandwidth SF, speed) except for a randomized phase spectrum. A test pattern was then presented and subjects were asked to match it with one or the other reference stimulus (ABX task). At small bandwidth and optimal mean spatial frequency (0.3 cpd), subjects were able to discriminate the two patterns with high accuracy. Performance dropped to chance level as spatial frequency bandwidth increased. Increasing the mean spatial frequency decreased the overall performance. Again, these results suggest that perceptual performance is deteriorated in presence of larger information.","tags":["motion_clouds"],"title":"Pattern discrimination for moving random textures: Richer stimuli are more difficult to recognize","type":"publication"},{"authors":["Amarender Bogadhi","Anna Montagnini","Pascal Mamassian","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1301608800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1301608800,"objectID":"9f582a70800dd6acf11cfbbb452809a7","permalink":"https://laurentperrinet.github.io/publication/bogadhi-11/","publishdate":"2011-04-01T00:00:00+02:00","relpermalink":"/publication/bogadhi-11/","section":"publication","summary":"Accuracy in estimating an object's global motion over time is not only affected by the noise in visual motion information but also by the spatial limitation of the local motion analyzers (aperture problem). Perceptual and oculomotor data demonstrate that during the initial stages of the motion information processing, 1D motion cues related to the object's edges have a dominating influence over the estimate of the object's global motion. However, during the later stages, 2D motion cues related to terminators (edge-endings) progressively take over, leading to a final correct estimate of the object's global motion. Here, we propose a recursive extension to the Bayesian framework for motion processing (Weiss, Simoncelli, \u0026 Adelson, 2002) cascaded with a model oculomotor plant to describe the dynamic integration of 1D and 2D motion information in the context of smooth pursuit eye movements. In the recurrent Bayesian framework, the prior defined in the velocity space is combined with the two independent measurement likelihood functions, representing edge-related and terminator-related information, respectively to obtain the posterior. The prior is updated with the posterior at the end of each iteration step. The maximum-a posteriori (MAP) of the posterior distribution at every time step is fed into the oculomotor plant to produce eye velocity responses that are compared to the human smooth pursuit data. The recurrent model was tuned with the variance of pursuit responses to either \"pure\" 1D or \"pure\" 2D motion. The oculomotor plant was tuned with an independent set of oculomotor data, including the effects of line length (i.e. stimulus energy) and directional anisotropies in the smooth pursuit responses. The model not only provides an accurate qualitative account of dynamic motion integration but also a quantitative account that is close to the smooth pursuit response across several conditions (three contrasts and three speeds) for two human subjects.","tags":["bayesian","kaplan13","khoei13jpp","perrinet12pred"],"title":"Pursuing motion illusions: a realistic oculomotor framework for Bayesian inference","type":"publication"},{"authors":["Guillaume S. Masson","Laurent U. Perrinet"],"categories":null,"content":"","date":1298934000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1298934000,"objectID":"1947c85245778d5a36407043b1e52030","permalink":"https://laurentperrinet.github.io/publication/masson-11/","publishdate":"2011-03-01T00:00:00+01:00","relpermalink":"/publication/masson-11/","section":"publication","summary":"Short-latency ocular following are reflexive, tracking eye movements that are observed in human and non-human primates in response to a sudden and brief translation of the image. Initial, open-loop part of the eye acceleration reflects many of the properties attributed to low-level motion processing. We review a very large set of behavioral data demonstrating several key properties of motion detection and integration stages and their dynamics. We propose that these properties can be modeled as a behavioral receptive field exhibiting linear and nonlinear mechanisms responsible for context-dependent spatial integration and gain control. Functional models similar to that used for describing neuronal properties of receptive fields can then be applied successfully.","tags":["behavioral_receptive_field","eye_movements","motion_estimation","primate","tracking"],"title":"The behavioral receptive field underlying motion integration for primate tracking eye movements","type":"publication"},{"authors":["J. Fleuriet","S. Hugues","L. Perrinet","L. Goffart"],"categories":null,"content":"","date":1296514800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1296514800,"objectID":"e2f9027a08b80eb0e1dd8d394ca94c9b","permalink":"https://laurentperrinet.github.io/publication/fleuriet-11/","publishdate":"2011-02-01T00:00:00+01:00","relpermalink":"/publication/fleuriet-11/","section":"publication","summary":"When generating a saccade toward a moving target, the target displacement that occurs during the period spanning from its detection to the saccade end must be taken into account to accurately foveate the target and to initiate its pursuit. Previous studies have shown that these saccades are characterized by a lower peak velocity and a prolonged deceleration phase. In some cases, a second peak eye velocity appears during the deceleration phase, presumably reflecting the late influence of a mechanism that compensates for the target displacement occurring before saccade end. The goal of this work was to further determine in the head restrained monkey the dynamics of this putative compensatory mechanism. A step-ramp paradigm, where the target motion was orthogonal to a target step occurring along the primary axes, was used to estimate from the generated saccades: a component induced by the target step and another one induced by the target motion. Resulting oblique saccades were compared with saccades to a static target with matched horizontal and vertical amplitudes. This study permitted to estimate the time taken for visual motion-related signals to update the programming and execution of saccades. The amplitude of the motion-related component was slightly hypometric with an undershoot that increased with target speed. Moreover, it matched with the eccentricity that the target had 40-60 ms before saccade end. The lack of significant difference in the delay between the onsets of the horizontal and vertical components between saccades directed toward a static target and those aimed at a moving target questions the late influence of the compensatory mechanism. The results are discussed within the framework of the \"dual drive\" and \"remapping\" hypotheses.","tags":["eye-movements","eye_velocity","motion","motion-estimation","moving_target","saccades","target_speed"],"title":"Saccadic foveation of a moving visual target in the rhesus monkey","type":"publication"},{"authors":["Laurent Perrinet","David Fitzpatrick","James A. Bednar"],"categories":null,"content":"","date":1293836400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293836400,"objectID":"7b940d9dc657b1dcfc5e9e186df69091","permalink":"https://laurentperrinet.github.io/publication/perrinet-11-sfn/","publishdate":"2011-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-11-sfn/","section":"publication","summary":"Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an \"association field\" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments. W.H. Bosking and Y. Zhang and B. Schofield and D. Fitzpatrick (1997) Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex Journal of Neuroscience 17:2112-27. E.M. Callaway and L.C. Katz (1990) Emergence and refinement of clustered horizontal connections in cat striate cortex. Journal of Neuroscience 10:1134--53. Y. Choe and R. Miikkulainen (2004) Contour integration and segmentation with self-organized lateral connections Biological Cybernetics 90:75-88. D.J. Field, A. Hayes, and R.F. Hess (1993) Contour integration by the human visual system: Evidence for a local \"association field\", Vision Research 33:173--93. W.S. Geisler, J.S. Perry, B.J. Super, and D.P. Gallogly (2001) Edge co-occurrence in natural images predicts contour grouping performance. Vision Research 41:711-24.","tags":["sanz12jnp"],"title":"Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1","type":"publication"},{"authors":["Nicole Voges","Laurent Perrinet"],"categories":null,"content":"","date":1288566000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1288566000,"objectID":"36a8d7f1692e4d8dce69e4063e290e49","permalink":"https://laurentperrinet.github.io/publication/voges-10-a/","publishdate":"2010-11-01T00:00:00+01:00","relpermalink":"/publication/voges-10-a/","section":"publication","summary":"We study cortical network dynamics for a spatially embedded network model. It represents, in terms of spatial scale, a large piece of cortex allowing for long-range connections, resulting in a rather sparse connectivity. The spatial embedding also permits us to include distance-dependent conduction delays. We use two different types of conductance-based I\u0026F neurons as excitatory and inhibitory units, as well as specific connection probabilities. In order to remain computationally tractable, we reduce neuron density, modelling part of the missing internal input via external poissonian spike trains. Compared to previous studies, we observe significant changes in the dynamical phase space: Altered activity patterns require another regularity measures than the coefficient of variation. Hence, we compare three different regularity measure on the basis of artificial inter-spike-interval distributions. We identify two types of mixed states, where different phases coexist in certain regions of the phase space. More notably, our boundary between high and low activity states depends predominantly on the relation between excitatory and inhibitory synaptic strength instead of the input rate.","tags":["area-v1","association_field","assofield","perrinet11sfn"],"title":"Phase space analysis of networks based on biologically realistic parameters.","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1277935200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277935200,"objectID":"93f60419c723dc647421eded04272c00","permalink":"https://laurentperrinet.github.io/publication/perrinet-10-shl/","publishdate":"2010-07-01T00:00:00+02:00","relpermalink":"/publication/perrinet-10-shl/","section":"publication","summary":"Neurons in the input layer of primary visual cortex in primates develop edge-like receptive fields. One approach to understanding the emergence of this response is to state that neural activity has to efficiently represent sensory data with respect to the statistics of natural scenes. Furthermore, it is believed that such an efficient coding is achieved using a competition across neurons so as to generate a sparse representation, that is, where a relatively small number of neurons are simultaneously active. Indeed, different models of sparse coding coupled with Hebbian learning and homeostasis have been proposed that successfully match the observed emergent response. However, the specific role of homeostasis in learning such sparse representations is still largely unknown. By quantitatively assessing the efficiency of the neural representation during learning, we derive a cooperative homeostasis mechanism which optimally tunes the competition between neurons within the sparse coding algorithm. We apply this homeostasis while learning small patches taken from natural images and compare its efficiency with state-of-the-art algorithms. Results show that while different sparse coding algorithms give similar coding results, the homeostasis provides an optimal balance for the representation of natural images within the population of neurons. Competition in sparse coding is optimized when it is fair: By contributing to optimize statistical competition across neurons, homeostasis is crucial in providing a more efficient solution to the emergence of independent components.","tags":["adaptive","assofield","cell","coding","competition-optimized","cooperative","fields","hebbian","homeostasis","images","khoei13jpp","learning","matching","natural","neural","of","overcomplete_dictionaries","perrinet10shl","perrinet11sfn","perrinet12pred","population","pursuit","receptive","sanz12jnp","simple","sparse","sparse_coding","sparse_hebbian_learning","sparse_spike_coding","statistics","unsupervised"],"title":"Role of homeostasis in learning sparse representations","type":"publication"},{"authors":["Jens Kremkow","Laurent U. Perrinet","Guillaume S. Masson","Ad Aertsen"],"categories":null,"content":"","date":1275343200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1275343200,"objectID":"2590699cb285c082e8a08c05d6fc292b","permalink":"https://laurentperrinet.github.io/publication/kremkow-10-jcns/","publishdate":"2010-06-01T00:00:00+02:00","relpermalink":"/publication/kremkow-10-jcns/","section":"publication","summary":"Neurons in the neocortex receive a large number of excitatory and inhibitory synaptic inputs. Excitation and inhibition dynamically balance each other, with inhibition lagging excitation by only few milliseconds. To characterize the functional consequences of such correlated excitation and inhibition, we studied models in which this correlation structure is induced by feedforward inhibition (FFI). Simple circuits show that an effective FFI changes the integrative behavior of neurons such that only synchronous inputs can elicit spikes, causing the responses to be sparse and precise. Further, effective FFI increases the selectivity for propagation of synchrony through a feedforward network, thereby increasing the stability to background activity. Last, we show that recurrent random networks with effective inhibition are more likely to exhibit dynamical network activity states as have been observed in vivo. Thus, when a feedforward signal path is embedded in such recurrent network, the stabilizing effect of effective inhibition creates an suitable substrate for signal propagation. In conclusion, correlated excitation and inhibition support the notion that synchronous spiking may be important for cortical processing.","tags":["coding","conductances","correlated","integration","propagation","signal","sparse","synaptic"],"title":"Functional consequences of correlated excitatory and inhibitory conductances in cortical networks","type":"publication"},{"authors":["Jens Kremkow","Laurent U. Perrinet","Guillaume S. Masson","Ad Aertsen"],"categories":null,"content":"","date":1275343200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1275343200,"objectID":"3490b9e12c46d67c3fb58485d2415bf5","permalink":"https://laurentperrinet.github.io/publication/kremkow-10/","publishdate":"2010-06-01T00:00:00+02:00","relpermalink":"/publication/kremkow-10/","section":"publication","summary":"Neurons in the neocortex receive a large number of excitatory and inhibitory synaptic inputs. Excitation and inhibition dynamically balance each other, with inhibition lagging excitation by only few milliseconds. To characterize the functional consequences of such correlated excitation and inhibition, we studied models in which this correlation structure is induced by feedforward inhibition (FFI). Simple circuits show that an effective FFI changes the integrative behavior of neurons such that only synchronous inputs can elicit spikes, causing the responses to be sparse and precise. Further, effective FFI increases the selectivity for propagation of synchrony through a feedforward network, thereby increasing the stability to background activity. Last, we show that recurrent random networks with effective inhibition are more likely to exhibit dynamical network activity states as have been observed in vivo. Thus, when a feedforward signal path is embedded in such recurrent network, the stabilizing effect of effective inhibition creates an suitable substrate for signal propagation. In conclusion, correlated excitation and inhibition support the notion that synchronous spiking may be important for cortical processing.","tags":["feed-forward_inhibition","inhibition","network_dynamics"],"title":"Functional consequences of correlated excitatory and inhibitory conductances in cortical networks","type":"publication"},{"authors":["Amarender Bogadhi","Anna Montagnini","Pascal Mamassian","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1262300400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262300400,"objectID":"ee628b17e38527b78a891e55524304f8","permalink":"https://laurentperrinet.github.io/publication/bogadhi-10-vss/","publishdate":"2010-01-01T00:00:00+01:00","relpermalink":"/publication/bogadhi-10-vss/","section":"publication","summary":"","tags":["bayesian"],"title":"A recurrent Bayesian model of dynamic motion integration for smooth pursuit","type":"publication"},{"authors":["Emmanuel Dauc√©","Laurent U. Perrinet"],"categories":null,"content":"","date":1262300400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262300400,"objectID":"bfd3f7e2cf62354c33d072a05e6eb5bc","permalink":"https://laurentperrinet.github.io/publication/dauce-10/","publishdate":"2010-01-01T00:00:00+01:00","relpermalink":"/publication/dauce-10/","section":"publication","summary":"Despite the long and fruitful history of neuroscience, a global, multi-level description of cardinal brain functions is still far from reach. Using analytical or numerical approaches, emphComputational Neuroscience aims at the emergence of such common principles by using concepts from Dynamical Systems and Information Theory. The aim of this Special Issue of the Journal of Physiology (Paris) is to reflect the latest advances in this field which has been presented during the NeuroComp08 conference that took place in October 2008 in Marseille (France). By highlighting a selection of works presented at the conference, we wish to illustrate the intrinsic diversity of this field of research but also the need of an unification effort that is becoming more and more necessary to understand the brain in its full complexity, from multiple levels of description to a multi-level understanding.","tags":null,"title":"Computational Neuroscience, from Multiple Levels to Multi-level","type":"publication"},{"authors":["Claudio Simoncini","Laurent U. Perrinet","Anna Montagnini","Pascal Mamassian","Guillaume S. Masson"],"categories":null,"content":"","date":1262300400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262300400,"objectID":"4209f18f080e6a1faf5e9653c9b66752","permalink":"https://laurentperrinet.github.io/publication/simoncini-10-vss/","publishdate":"2010-01-01T00:00:00+01:00","relpermalink":"/publication/simoncini-10-vss/","section":"publication","summary":"","tags":["motion-clouds","sanz12jnp"],"title":"Different pooling of motion information for perceptual speed discrimination and behavioral speed estimation","type":"publication"},{"authors":["Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1262300400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262300400,"objectID":"b7edc2252253d5c7852e9bad57b381f1","permalink":"https://laurentperrinet.github.io/publication/perrinet-10-areadne/","publishdate":"2010-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-10-areadne/","section":"publication","summary":"","tags":["bayesian","center-surround","eye","following","integration","interactions","model","motion","movements","ocular","perception","response","tracking","visual"],"title":"Dynamical emergence of a neural solution for motion integration","type":"publication"},{"authors":["Nicole Voges","Laurent U. Perrinet"],"categories":null,"content":"","date":1262300400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262300400,"objectID":"7d31054e93fa240cd1174bb52db1c750","permalink":"https://laurentperrinet.github.io/publication/voges-10-neurocomp/","publishdate":"2010-01-01T00:00:00+01:00","relpermalink":"/publication/voges-10-neurocomp/","section":"publication","summary":"We study cortical network dynamics for a more realistic network model. It represents, in terms of spatial scale, a large piece of cortex allowing for long-range connections, resulting in a rather sparse connectivity. We use two different types of conductance-based I\u0026F neurons as excitatory and in- hibitory units, as well as specific connection probabilities. In order to re- main computationally tractable, we reduce neuron density, modelling part of the missing internal input via external poissonian spike trains. Compared to previous studies, we observe significant changes in the dynamical phase space: Altered activity patterns require another regularity measure than the coefficient of variation. We identify two types of mixed states, where differ- ent phases coexist in certain regions of the phase space. More notably, our boundary between high and low activity states depends predominantly on the relation between excitatory and inhibitory synaptic strength instead of the input rate. Key words:Artificial neural networks, Data analysis, Simulation, Spiking neurons. This work is supported by EC IP project FP6-015879 (FACETS).","tags":["lateral_connections"],"title":"Phase space analysis of networks based on biologically realistic parameters","type":"publication"},{"authors":["Laurent Perrinet"],"categories":null,"content":"","date":1262300400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262300400,"objectID":"84890dad39fa2bbe18058579a212dc8d","permalink":"https://laurentperrinet.github.io/publication/perrinet-10-tauc/","publishdate":"2010-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-10-tauc/","section":"publication","summary":"Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.","tags":["bayesian","center-surround","divisive_normalization","motion-perception","motion-segmentation","motion_2d","navier-stokes","neural_masses","neuronal_representation","ocular_following_response","particle-filter","pde","probabilistic_framework"],"title":"Probabilistic models of the low-level visual system: the role of prediction in detecting motion","type":"publication"},{"authors":["Laurent U. Perrinet","Nicole Voges","Jens Kremkow","Guillaume S. Masson"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"0af404da37a4044072479d12631dc57a","permalink":"https://laurentperrinet.github.io/publication/perrinet-09-cosyne/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-09-cosyne/","section":"publication","summary":"Short presentation of a large moving pattern elicits an Ocular Following Response (OFR) that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction between competing motions. Similar mechanisms have been demonstrated in V1 cortical activity in response to center-surround gratings patterns measured with real-time optical imaging in awake monkeys. More recent experiments of OFR have used disk gratings and bipartite stimuli which are optimized to study the dynamics of center-surround integration. We quantified two main characteristics of the global spatial integration of motion from an intermediate map of possible local translation velocities: (i) a finite optimal stimulus size for driving OFR, surrounded by an antagonistic modulation and (ii) a direction selective suppressive effect of the surround on the contrast gain control of the central stimuli [Barthelemy06,Barthelemy07]. In fact, the machinery behind the visual perception of motion and the subsequent sensorimotor transformation is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may understand this response as an ideal observer in a probabilistic framework by using Bayesian theory [Weiss02] and we extended in the dynamical domain the ideal observer model to simulate the spatial integration of the different local motion cues within a probabilistic representation. We proved that this model is successfully adapted to model the OFR for the different experiments [Perrinet07neurocomp], that is for different levels of noise with full field gratings, with disks of various sizes and also for the effect of a flickering surround. However, another emphad hoc inhibitory mechanism has to be added in this model to account for suppressive effects of the surround. We explore here an hypothesis where this could be understood as the effect of a recurrent prediction of information in the velocity map. In fact, in previous models, the integration step assumes independence of the local information while natural scenes are very predictable: Due to the rigidity and inertia of physical objects in visual space, neighboring local spatiotemporal information is redundant and one may introduce this empha priori knowledge of the statistics of the input in the ideal observer model. We implement this in a realistic model of a layer representing velocities in a map of cortical columns, where predictions are implemented by lateral interactions within the cortical area. First, raw velocities are estimated locally from images and are propagated to this area in a feed-forward manner. Using this velocity map, we progressively learn the dependance of local velocities in a second layer of the model. This algorithm is cyclic since the prediction is using the local velocities which are themselves using both the feed-forward input and the prediction: We control the convergence of this process by measuring results for different learning rate. Results show that this simple model is sufficient to disambiguate characteristic patterns such as the Barber-Pole illusion. Due to the recursive network which is modulating the velocity map, it also explains that the representation may exhibit some memory, such as when an object suddenly disappears or when presenting a dot followed by a line (line-motion illusion). Finally, we applied this model that was tuned over a set of natural scenes to gratings of increasing sizes. We observed first that the feed-forward response as tuned to neurophysiological data gave lower responses at higher eccentricities, and that this effect was greater for higher grating frequencies. Then, we observed that depending on the size of the disk and on its spatial frequency, the recurrent network of lateral interactions Lastly, we explore how a surrounding velocity non congruous with the central excitation information shunts the ocular response and how it is topographically represented in the cortical activity.","tags":["bayesian","center-surround","eye","following","integration","interactions","model","motion","movements","ocular","perception","response","tracking","visual"],"title":"Decoding center-surround interactions in population of neurons for the ocular following response","type":"publication"},{"authors":["Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"3fe743b2b905bc4bf779f691ed8ff97d","permalink":"https://laurentperrinet.github.io/publication/perrinet-09/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-09/","section":"publication","summary":"","tags":["bayesian","center-surround","eye","following","integration","interactions","model","motion","movements","ocular","perception","response","tracking","visual"],"title":"Decoding the population dynamics underlying ocular following response using a probabilistic framework","type":"publication"},{"authors":["Nicole Voges","Laurent U. Perrinet"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"8527e135d8e8743af128baea9dcdd297","permalink":"https://laurentperrinet.github.io/publication/voges-09-cosyne/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/voges-09-cosyne/","section":"publication","summary":"Most studies of cor tical network dynamics are either based on purely random wiring or neighborhood cou- plings, e.g., [Kumar, Schrader, Aer tsen, Rotter, 2008, Neural Computation 20, 1--43]. Neuronal connections in the cor tex, however, show a complex spatial pattern composed of local and long-range connections, the latter featuring a so-called patchy projection pattern, i.e., spatially clustered synapses [Binzegger, Douglas, Martin, 2007, J. Neurosci. 27(45), 12242--12254]. The idea of our project is to provide and to analyze probabilistic network models that more adequately represent horizontal connectivity in the cor tex. In par- ticular, we investigate the effect of specific projection patterns on the dynamical state space of cor tical networks. Assuming an enlarged spatial scale we employ a distance dependent connectivity that reflects the geometr y of dendrites and axons. We simulate the network dynamics using a neuronal network simula- tor NEST/PyNN. Our models are composed of conductance based integrate-and-fire neurons, representing fast spiking inhibitor y and regular spiking excitator y cells. In order to compare the dynamical state spaces of previous studies with our network models we consider the following connectivity assumptions: purely random or purely local couplings, a combination of local and distant synapses, and connectivity structures with patchy projections. Similar to previous studies, we also find different dynamical states depending on the input parameters: the external input rate and the numerical relation between excitator y and inhibitor y synaptic weights. These states, e.g., synchronous regular (SR) or asynchronous irregular (AI) firing, are characterized by measures like the mean firing rate, the correlation coefficient, the coefficient of variation and so for th. On top of identified biologically realistic background states (AI), stimuli are applied in order to analyze their stability. Comparing the results of our different network models we find that the param- eter space necessar y to describe all possible dynamical states of a network is much more concentrated if local couplings are involved. The transition between different states is shifted (with respect to both in- put parameters) and shar pened in dependence of the relative amount of local couplings. Local couplings strongly enhance the mean firing rate, and lead to smaller values of the correlation coefficient. In terms of emergence of synchronous states, however, networks with local versus non-local or patchy versus random remote connections exhibit a higher probability of synchronized spiking. Concerning stability, preliminar y results indicate that again networks with local or patchy connections show a higher probability of changing from the AI to the SR state. We conclude that the combination of local and remote projections bears impor- tant consequences on the activity of network: The apparent differences we found for distinct connectivity assumptions in the dynamical state spaces suggest that network dynamics strongly depend on the con- nectivity structure. This effect might be even stronger with respect to the spatio-temporal spread of signal propagation. This work is suppor ted by EC IP project FP6-015879 (FACETS).","tags":["lateral-connections"],"title":"Dynamical state spaces of cortical networks representing various horizontal connectivities","type":"publication"},{"authors":["Nicole Voges","Laurent U. Perrinet"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"df78c8b991931379aaa22a1a44f9b3f8","permalink":"https://laurentperrinet.github.io/publication/voges-09-gns/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/voges-09-gns/","section":"publication","summary":"Most studies of cortical network dynamics are either based on purely random wiring or neighborhood couplings [1], focussing on a rather local scale. Neuronal connections in the cortex, however, show a more complex spatial pattern composed of local and long-range patchy connections [2,3] as shown in the figure: It represents a tracer injection (gray areas) in the GM of a flattened cortex (top view): Black dots indicate neuron positions, blue lines their patchy axonal ramifications, and red lines represent the local connections. Moreover, to include distant synapses, one has to enlarge the spatial scale from the typically assumed 1mm to 5mm side length. As it is our aim to analyze more realistic network models of the cortex we assume a distance dependent connectivity that reflects the geometry of dendritesand axons [3]. Here, we ask to what extent the assumption of specific geometric traits influences the resulting dynamical behavior of these networks. Analyzing various characteristic measures that describe spiking neurons (e.g., coefficient of variation, correlation coefficient), we compare the dynamical state spaces of different connectivity types: purely random or purely local couplings, a combination of local and distant synapses, and connectivity structures with patchy projections. On top of biologically realistic background states, a stimulus is applied in order to analyze their stabilities. As previous studies [1], we also find different dynamical states depending on the external input rate and the numerical relation between excitatory and inhibitory synaptic weights. Preliminary results indicate, however, that transitions between these states are much sharper in case of local or patchy couplings. This work is supported by EU Grant 15879 (FACETS). Thanks to Stefan Rotter who supervised the PhD project [3] this work is based on. Network dynamics are simulated with NEST/PyNN [4]. [1] A. Kumar, S. Schrader, A. Aertsen and S. Rotter, Neural Computation 20, 2008, 1-43. [2] T. Binzegger, R.J. Douglas and K.A.C. Martin, J. of Neurosci., 27(45), 2007, 12242-12254. [3] Voges N, Fakultaet fuer Biologie, Albert-Ludwigs-Universitaet Freiburg, 2007. [4] NEST. M.O. Gewaltig and M. Diesmann, Scholarpedia 2(4):1430.","tags":["lateral-connections"],"title":"Dynamics of cortical networks including long-range patchy connections","type":"publication"},{"authors":["Jens Kremkow","Laurent U. Perrinet","Guillaume S. Masson","Ad Aertsen"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"f13bb4ecdf7a4aba73051b0bd5ddefc1","permalink":"https://laurentperrinet.github.io/publication/kremkow-09-gns/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/kremkow-09-gns/","section":"publication","summary":"Neurons receive a large number of excitatory and inhibitory synaptic inputs whose temporal interplay determines their spiking behavior. On average, excitation (Gexc) and inhibition (Ginh) balance each other, such that spikes are elicited by fluctuations [1]. In addition, it has been shown in vivo that Gexc and Ginh are correlated, with Ginh lagging Gexc only by few milliseconds (6ms), creating a small temporal integration window [2,3]. This correlation structure could be induced by feed-forward inhibition (FFI), which has been shown to be present at many sites in the central nervous system. To characterize the functional consequences of the FFI, we first modeled a simple circuit using spiking neurons with conductance based synapses and studied the effect on the single neuron integration. We then coupled many of such circuits to construct a feed-forward network (synfire chain [4,5]) and investigated the effect of FFI on signal propagation along such feed-forward network. We found that the small temporal integration window, induced by the FFI, changes the integrative properties of the neuron. Only transient stimuli could produce a response when the FFI was active whereas without FFI the neuron responded to both steady and transient stimuli. Due to the increase in selectivity to transient inputs, the conditions of signal propagation through the feed-forward network changed as well. Whereas synchronous inputs could reliable propagate, high asynchronous input rates, which are known to induce synfire activity [6], failed to do so. In summary, the FFI increased the stability of the synfire chain. Supported by DFG SFB 780, EU-15879-FACETS, BMBF 01GQ0420 to BCCN Freiburg [1] Kumar A., Schrader S., Aertsen A. and Rotter S. (2008). The high-conductance state of cortical networks. Neural Computation, 20(1):1--43. [2] Okun M. and Lampl I. (2008). Instantaneous correlation of excitation and inhibition during ongoing and sensory- evoked activities. Nat Neurosci, 11(5):535--7. [3] Baudot P., Levy M., Marre O., Monier C. and Fr√©gnac (2008). submitted. [4] Abeles M. (1991). Corticonics: Neural circuits of the cerebral cortex. Cambridge, UK [5] Diesmann M., Gewaltig M-O and Aertsen A. (1999). Stable propagation of synchronous spiking in cortical neural networks. Nature, 402(6761):529--33. [6] Kumar A., Rotter S. and Aertsen A. (2008), Conditions for propagating synchronous spiking and asynchronous firing rates in a cortical network model. J Neurosci 28 (20), 5268--80. Preliminary Program","tags":["feed-forward_inhibition","large_scale_networks"],"title":"Functional consequences of correlated excitation and inhibition on single neuron integration and signal propagation through synfire chains","type":"publication"},{"authors":["Laurent U. Perrinet","Alexandre Reynaud","Fr√©d√©ric Chavane","Guillaume S. Masson"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"6dbb076b213757c360836710b2fb0876","permalink":"https://laurentperrinet.github.io/publication/perrinet-09-vss/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-09-vss/","section":"publication","summary":"Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction between competing motions. Similar mechanisms have been demonstrated in V1 cortical activity in response to center-surround gratings patterns measured with real-time optical imaging in awake monkeys (see poster of Reynaud et al., VSS09). Based on a previously developed Bayesian framework, we have developed an optimal statistical decoder of such an observed cortical population activity as recorded by optical imaging. This model aims at characterizing the statistical dependence between early neuronal activity and ocular responses and its performance was analyzed by comparing this neuronal read-out and the actual motor responses on a trial-by-trial basis. First, we show that relative performance of the behavioral contrast response function is similar to the best estimate obtained from the neural activity. In particular, we show that the latency of ocular response increases with low contrast conditions as well as with noisier instances of the behavioral task as decoded by the model. Then, we investigate the temporal dynamics of both neuronal and motor responses and show how motion information as represented by the model is integrated in space to improve population decoding over time. Lastly, we explore how a surrounding velocity non congruous with the central excitation information shunts the ocular response and how it is topographically represented in the cortical activity. Acknowledgment: European integrated project FACETS IST-15879.","tags":["motion"],"title":"Inferring monkey ocular following responses from V1 population dynamics using a probabilistic model of motion integration","type":"publication"},{"authors":["Pierre Yger","Daniel Bruderle","Jochen Eppler","Jens Kremkow","Dejan Pecevski","Laurent U. Perrinet","Michael Schmuker","Eilif Muller","Andrew P. Davison"],"categories":null,"content":"","date":1230764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230764400,"objectID":"f279066143657644f8c363ec4f1840c3","permalink":"https://laurentperrinet.github.io/publication/yger-09-gns/","publishdate":"2009-01-01T00:00:00+01:00","relpermalink":"/publication/yger-09-gns/","section":"publication","summary":"NeuralEnsemble (http://neuralensemble.org) is a multilateral effort to coordinate and organise neuroscience software development efforts based around the Python programming language into a larger, meta-simulator software system. To this end, NeuralEnsemble hosts services for source code management and bug tracking (Subversion/Trac) for a number of open-source neuroscience tools, organizes an annual workshop devoted to collaborative software development in neuroscience, and manages a google-group discussion forum. Here, we present two NeuralEnsemble hosted projects: PyNN (http://neuralensemble.org/PyNN) is a package for simulator-independent specification of neuronal network models. You can write the code for a model once, using the PyNN API, and then run it without modification on any simulator that PyNN supports. Currently NEURON, NEST, PCSIM and a VLSI hardware implementation are fully supported. NeuroTools (http://neuralensemble.org/NeuroTools) is a set of tools to manage, store and analyse computational neuroscience simulations. It has been designed around PyNN, but can also be used for data from other simulation environments or even electrophysiological measurements. We will illustrate how the use of PyNN and NeuroTools ease the developmental process of models in computational neuroscience, enhancing collaboration between different groups and increasing the confidence in correctness of results. NeuralEnsemble efforts are supported by the European FACETS project (EU-IST-2005-15879)","tags":["neuralensemble","neurotools","pynn"],"title":"NeuralEnsemble: Towards a meta-environment for network modeling and data analysis","type":"publication"},{"authors":["Nicole Voges","Laurent U. Perrinet"],"categories":null,"content":"","date":1222812000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1222812000,"objectID":"797aa357e385bf8b9c03774629cfd63c","permalink":"https://laurentperrinet.github.io/publication/voges-08-neurocomp/","publishdate":"2008-10-01T00:00:00+02:00","relpermalink":"/publication/voges-08-neurocomp/","section":"publication","summary":"","tags":["lateral-connections"],"title":"Analyzing cortical network dynamics with respect to different connectivity assumptions","type":"publication"},{"authors":["Jens Kremkow","Laurent U. Perrinet","Ad M. Aertsen","Guillaume S. Masson"],"categories":null,"content":"","date":1222812000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1222812000,"objectID":"f5ed50bef60fa3752d01e7c5a3eadd58","permalink":"https://laurentperrinet.github.io/publication/kremkow-08-neurocomp/","publishdate":"2008-10-01T00:00:00+02:00","relpermalink":"/publication/kremkow-08-neurocomp/","section":"publication","summary":"","tags":["feed-forward_inhibition","large_scale_networks"],"title":"Functional properties of feed-forward inhibition","type":"publication"},{"authors":["Laurent U. Perrinet","Emmanuel Dauc√©"],"categories":null,"content":"","date":1222812000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1222812000,"objectID":"a2334942315328755450565dd2a7e5e7","permalink":"https://laurentperrinet.github.io/publication/perrinet-08-b/","publishdate":"2008-10-01T00:00:00+02:00","relpermalink":"/publication/perrinet-08-b/","section":"publication","summary":"","tags":["computational-neuroscience"],"title":"Proceedings of the second french conference on Computational Neuroscience, Marseille","type":"publication"},{"authors":["Fr√©d√©ric V. Barth√©lemy","Laurent U. Perrinet","Eric Castet","Guillaume S. Masson"],"categories":null,"content":"","date":1201820400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1201820400,"objectID":"e5db51eca2f6a5302024daadc857d517","permalink":"https://laurentperrinet.github.io/publication/barthelemy-08-a/","publishdate":"2008-02-01T00:00:00+01:00","relpermalink":"/publication/barthelemy-08-a/","section":"publication","summary":"Integrating information is essential to measure the physical 2D motion of a surface from both ambiguous local 1D motion of its elongated edges and non-ambiguous 2D motion of its features such as corners or texture elements. The dynamics of this motion integration shows a complex time course as read from tracking eye movements: first, local 1D motion signals are extracted and pooled to initiate ocular responses, then 2D motion signals are integrated to adjust the tracking direction until it matches the surface motion direction. The nature of these 1D and 2D motion computations are still unclear. One hypothesis is that their different dynamics may be explained from different contrast sensitivities. To test this, we measured contrast-response functions of early, 1D-driven and late, 2D-driven components of ocular following responses to different motion stimuli: gratings, plaids and barberpoles. We found that contrast dynamics of 1D-driven responses are nearly identical across the different stimuli. On the contrary, late 2D-driven components with either plaids or barberpoles have similar latencies but different contrast dynamics. Temporal dynamics of both 1D- and 2D-driven responses demonstrates that the different contrast gains are set very early during the response time course. Running a Bayesian model of motion integration, we show that a large family of contrast-response functions can be predicted from the probability distributions of 1D and 2D motion signals for each stimulus and by the shape of the prior distribution. However, the pure delay (i.e. largely independent upon contrast) observed between 1D- and 2D-motion supports the fact that 1D and 2D probability distributions are computed independently. This two-pathway Bayesian model supports the idea that 1D and 2D mechanisms represent edges and features motion in parallel.","tags":["bayesian","khoei13jpp","model","motion-clouds","motion-integration","ocular_following_response","ofr","perrinet12pred","response_latency","sanz12jnp"],"title":"Dynamics of distributed 1D and 2D motion representations for short-latency ocular following.","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"9462f242e261f60e9b9dc531e2ee68a0","permalink":"https://laurentperrinet.github.io/publication/perrinet-08-spie/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-08-spie/","section":"publication","summary":"If modern computers are sometimes superior to cognition in some specialized tasks such as playing chess or browsing a large database, they can't beat the efficiency of biological vision for such simple tasks as recognizing a relative or following an object in a complex background. We present in this paper our attempt at outlining the dynamical, parallel and event-based representation for vision in the architecture of the central nervous system. We will illustrate this by showing that in a signal matching framework, a L/LN (linear/non-linear) cascade may efficiently transform a sensory signal into a neural spiking signal and we apply this framework to a model retina. However, this code gets redundant when using an over-complete basis as is necessary for modeling the primary visual cortex: we therefore optimize the efficiency cost by increasing the sparseness of the code. This is implemented by propagating and canceling redundant information using lateral interactions. We compare the efficiency of this representation in terms of compression as the reconstruction quality as a function of the coding length. This will correspond to a modification of the Matching Pursuit algorithm where the ArgMax function is optimized for competition, or Competition Optimized Matching Pursuit (COMP). We will particularly focus on bridging neuroscience and image processing and on the advantages of such an interdisciplinary approach.","tags":["assofield","coding","competition","computation","correlation-based","decorrelation","inhibition","matching","neural","optimized","population","pursuit","sparse","spike","spike-event"],"title":"Adaptive Sparse Spike Coding : applications of Neuroscience to the compression of natural images","type":"publication"},{"authors":["Jens Kremkow","Laurent U. Perrinet","Pierre Baudot","Manu Levy","Olivier Marre","Cyril Monier","Yves Fr√©gnac","Guillaume S. Masson","Ad Aertsen"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"6f891adfcd8747291a84855cd02d486e","permalink":"https://laurentperrinet.github.io/publication/kremkow-08-sfn/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/kremkow-08-sfn/","section":"publication","summary":"In the primary visual cortex (V1), single cell responses to simple visual stimuli (gratings) are usually dense but with a high trial-by-trial variability. In contrast, when exposed to full field natural scenes, the firing patterns of these neurons are sparse but highly reproducible over trials (Marre et al., 2005; Fr√©gnac et al., 2006). It is still not understood how these two classes of stimuli can elicit these two distinct firing behaviours. A common model for simple-cell computation in layer 4 is the ``push-pull'' circuitry (Troyer et al. 1998). It accounts for the observed anti-phase behaviour between excitatory and inhibitory conductances in response to a drifting grating (Anderson et al., 2000; Monier et al., 2008), creating a wide temporal integration window during which excitation is integrated without the shunting or opponent effect of inhibition and allowed to elicit multiple spikes. This is in contrast to recent results from intracellular recordings in vivo during presentation of natural scenes (Baudot et al., submitted). Here the excitatory and inhibitory conductances were highly correlated, with inhibition lagging excitation only by few milliseconds (ÃÉ6 ms). This small lag creates a narrow temporal integration window such that only synchronized excitatory inputs can elicit a spike, similar to parallel observations in other cortical sensory areas (Wehr and Zador, 2003; Okun and Lampl, 2008). To investigate the cellular and network mechanisms underlying these two different correlation structures, we constructed a realistic model of the V1 network using spiking neurons with conductance based synapses. We calibrated our model to fit the irregular ongoing activity pattern as well as in vivo conductance measurements during drifting grating stimulation and then extracted predicted responses to natural scenes seen through eye-movements. Our simulations reproduced the above described experimental observation, together with anti-phase behaviour between excitation and inhibition during gratings and phase lagged activation during natural scenes. In conclusion, the same cortical network that shows dense and variable responses to gratings exhibits sparse and precise spiking to natural scenes. Work is under way to show to which extent this feature is specific for the feedforward vs recurrent nature of the modelled circuit.","tags":["feed-forward_inhibition","large_scale_networks"],"title":"Control of the temporal interplay between excitation and inhibition by the statistics of visual input: a V1 network modelling study","type":"publication"},{"authors":["Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"70ebc9151fa803247875baa3c1aa43c0","permalink":"https://laurentperrinet.github.io/publication/perrinet-08-areadne/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-08-areadne/","section":"publication","summary":"The machinery behind the visual perception of motion and the subsequent sensorimotor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may understand this response as an ideal observer in a probabilistic framework by using Bayesian theor·ªπWeiss02 which we previously proved to be successfully adapted to model the OFR for different levels of noise with full field gratings or with disk of various sizes and the effect of a flickering surroundÃÉPerrinet07neurocomp. More recent experiments of OFR have used disk gratings and bipartite stimuli which are optimized to study the dynamics of center-surround integration. We quantified two main characteristics of the global spatial integration of motion from an intermediate map of possible local translation velocities: (i) a finite optimal stimulus size for driving OFR, surrounded by an antagonistic modulation and (ii) a direction selective suppressive effect of the surround on the contrast gain control of the central stimuli~ÃÉBarthelemy06,Barthelemy07. Herein, we extended in the dynamical domain the ideal observer model to simulate the spatial integration of the different local motion cues within a probabilistic representation. We present analytical results which show that the hypothesis of independence of local measures can describe the initial segment of spatial integration of motion signal. Within this framework, we successfully accounted for the dynamical contrast gain control mechanisms observed in the behavioral data for center-surround stimuli. However, another inhibitory mechanism had to be added to account for suppressive effects of the surround. We explore here an hypothesis where this could be understood as the effect of a recurrent integration of information in the velocity map. F. Barthelemy, L. U. Perrinet, E. Castet, and G. S. Masson. Dynamics of distributed 1D and 2D motion representations for short-latency ocular following. Vision Research, 48(4):501--22, feb 2007. doi: 10.1016/j.visres.2007.10.020. F. V. Barthelemy, I. Vanzetta, and G. S. Masson. Behavioral receptive field for ocular following in humans: Dynamics of spatial summation and center-surround interactions. Journal of Neurophysiology, (95):3712--26, Mar 2006. doi: 10.1152/jn.00112.2006. L. U. Perrinet and G. S. Masson. Modeling spatial integration in the ocular following response using a probabilistic framework. Journal of Physiology (Paris), 2007. doi: 10.1016/j.jphysparis.2007.10.011. Y. Weiss, E. P. Simoncelli, and E. H. Adelson. Motion illusions as optimal percepts. Nature Neuroscience, 5(6):598--604, Jun 2002. doi: 10.1038/nn858. This work was supported by EC IP project FP6-015879, ''FACETS''.","tags":["bayesian","center-surround","divisive","eye","following","integration","interactions","model","motion","movements","normalization","ocular","perception","response","tracking","visual"],"title":"Decoding the population dynamics underlying ocular following response using a probabilistic framework","type":"publication"},{"authors":["Nicole Voges","Jens Kremkow","Laurent U. Perrinet"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"2cdfa8cd9d92479d394886ccd2ae840b","permalink":"https://laurentperrinet.github.io/publication/voges-08/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/voges-08/","section":"publication","summary":"","tags":["lateral-connections"],"title":"Dynamics of cortical networks based on patchy connectivity patterns","type":"publication"},{"authors":["Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"da8e2c2fd857c3f2e4a112b5a9db39fb","permalink":"https://laurentperrinet.github.io/publication/perrinet-08-a/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-08-a/","section":"publication","summary":"","tags":["bayesian","center-surround","eye","following","integration","interactions","model","motion","movements","ocular","perception","response","tracking","visual"],"title":"Modeling spatial integration in the ocular following response to center-surround stimulation using a probabilistic framework","type":"publication"},{"authors":["Andrew P. Davison","Daniel Bruderle","Jochen Eppler","Jens Kremkow","Eilif Muller","Dejan Pecevski","Laurent U. Perrinet","Pierre Yger"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"bd50966740ee38a62e92883c865e7b17","permalink":"https://laurentperrinet.github.io/publication/davison-08/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/davison-08/","section":"publication","summary":"Computational neuroscience has produced a diversity of software for simulations of networks of spiking neurons, with both negative and positive consequences. On the one hand, each simulator uses its own programming or configuration language, leading to considerable difficulty in porting models from one simulator to another. This impedes communication between investigators and makes it harder to reproduce and build on the work of others. On the other hand, simulation results can be cross-checked between different simulators, giving greater confidence in their correctness, and each simulator has different optimizations, so the most appropriate simulator can be chosen for a given modelling task. A common programming interface to multiple simulators would reduce or eliminate the problems of simulator diversity while retaining the benefits. PyNN is such an interface, making it possible to write a simulation script once, using the Python programming language, and run it without modification on any supported simulator (currently NEURON, NEST, PCSIM, Brian and the Heidelberg VLSI neuromorphic hardware). PyNN increases the productivity of neuronal network modelling by providing high-level abstraction, by promoting code sharing and reuse, and by providing a foundation for simulator-agnostic analysis, visualization and data-management tools. PyNN increases the reliability of modelling studies by making it much easier to check results on multiple simulators. PyNN is open-source software and is available from http://neuralensemble.org/PyNN.","tags":["computational-neuroscience","kaplan13","pynn"],"title":"PyNN: A Common Interface for Neuronal Network Simulators","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1199142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199142000,"objectID":"52f8c754a5aa992a2649244b91e12c2d","permalink":"https://laurentperrinet.github.io/publication/perrinet-08/","publishdate":"2008-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-08/","section":"publication","summary":"","tags":["adaptive","bayesian","coding","framework","modeling","neuronal","probabilistic","representation","sparse","spike"],"title":"What adaptive code for efficient spiking representations? A model for the formation of receptive fields of simple cells","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1172703600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1172703600,"objectID":"d68be22e260f48e64153239a5d523d2e","permalink":"https://laurentperrinet.github.io/publication/perrinet-07/","publishdate":"2007-03-01T00:00:00+01:00","relpermalink":"/publication/perrinet-07/","section":"publication","summary":"The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in ocular following response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may understand this response as an ideal observer in a probabilistic framework by using Bayesian theory [Weiss, Y., Simoncelli, E.P., Adelson, E.H., 2002. Motion illusions as optimal percepts. Nature Neuroscience, 5(6), 598-604, doi:10.1038/nn858] which we previously proved to be successfully adapted to model the OFR for different levels of noise with full field gratings. More recent experiments of OFR have used disk gratings and bipartite stimuli which are optimized to study the dynamics of center-surround integration. We quantified two main characteristics of the spatial integration of motion: (i) a finite optimal stimulus size for driving OFR, surrounded by an antagonistic modulation and (ii) a direction selective suppressive effect of the surround on the contrast gain control of the central stimuli [Barth√©lemy, F.V., Vanzetta, I., Masson, G.S., 2006. Behavioral receptive field for ocular following in humans: dynamics of spatial summation and center-surround interactions. Journal of Neurophysiology, (95), 3712-3726, doi:10.1152/jn.00112.2006]. Herein, we extended the ideal observer model to simulate the spatial integration of the different local motion cues within a probabilistic representation. We present analytical results which show that the hypothesis of independence of local measures can describe the spatial integration of the motion signal. Within this framework, we successfully accounted for the contrast gain control mechanisms observed in the behavioral data for center-surround stimuli. However, another inhibitory mechanism had to be added to account for suppressive effects of the surround.","tags":["bayesian","bayesian-model","center-surround","center-surround-interactions","coding","computation","dictionaries","distributed","efficient","interactions","inverse","khoei13jpp","learning","linear","matching","model","motion","motion-clouds","motion-integration","movements","neuronal","ocular-following-response","ofr","over-complete","perception","perrinet12pred","probabilistic","pursuit","representation","sanz12jnp","sparse","spike","spike-event","tracking","tracking-eye-movements","vision","visual","visual-perception"],"title":"Dynamical Neural Networks: modeling low-level vision at short latencies","type":"publication"},{"authors":["B. Cessac","E. Dauc√©","L. Perrinet","M. Samuelides"],"categories":null,"content":"","date":1172703600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1172703600,"objectID":"a0724d654fb2979e097e35470b7361ee","permalink":"https://laurentperrinet.github.io/publication/cessac-07-a/","publishdate":"2007-03-01T00:00:00+01:00","relpermalink":"/publication/cessac-07-a/","section":"publication","summary":"","tags":null,"title":"Introduction","type":"publication"},{"authors":["Bruno Cessac","Emmanuel Dauc√©","Laurent U. Perrinet","Manuel Samuelides"],"categories":null,"content":"","date":1172703600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1172703600,"objectID":"988efe32fe93ebd9b5c58007fdb306e1","permalink":"https://laurentperrinet.github.io/publication/cessac-07/","publishdate":"2007-03-01T00:00:00+01:00","relpermalink":"/publication/cessac-07/","section":"publication","summary":"","tags":["computational-neuroscience"],"title":"Topics in Dynamical Neural Networks: From Large Scale Neural Networks to Motor Control and Vision","type":"publication"},{"authors":["Anna Montagnini","Pascal Mamassian","Laurent Perrinet","Eric Castet","Guillaume S. Masson"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"53413d7ee2ebadfd6a679995d5787936","permalink":"https://laurentperrinet.github.io/publication/montagnini-06-neurocomp/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/montagnini-06-neurocomp/","section":"publication","summary":"The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor data demonstrate that motion processing of extended ob jects is initially dominated by the local 1D motion cues orthogonal to the ob ject's edges, whereas 2D information takes pro- gressively over and leads to the final correct represen- tation of global motion. A Bayesian framework ac- counting for the sensory noise and general expectancies for ob ject velocities has proven successful in explaining several experimental findings concerning early motion processing [1, 2, 3]. However, a complete functional model, encompassing the dynamical evolution of ob- ject motion perception is still lacking. Here we outline several experimental observations concerning human smooth pursuit of moving ob jects and more particu- larly the time course of its initiation phase. In addi- tion, we propose a recursive extension of the Bayesian model, motivated and constrained by our oculomotor data, to describe the dynamical integration of 1D and 2D motion information.","tags":["aperture","bayesian","evolution","eye","inference","model","motion","movement","object","problem","pursuit","recursive","smooth","temporal"],"title":"Bayesian modeling of dynamic motion integration","type":"publication"},{"authors":["Anna Montagnini","Pascal Mamassian","Laurent U. Perrinet","Eric Castet","Guillaume S. Masson"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"9202f899972ade188baee0686389a3e4","permalink":"https://laurentperrinet.github.io/publication/montagnini-07/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/montagnini-07/","section":"publication","summary":"The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor data demonstrate that motion processing of extended ob jects is initially dominated by the local 1D motion cues orthogonal to the ob ject's edges, whereas 2D information takes pro- gressively over and leads to the final correct represen- tation of global motion. A Bayesian framework ac- counting for the sensory noise and general expectancies for ob ject velocities has proven successful in explaining several experimental findings concerning early motion processing [1, 2, 3]. However, a complete functional model, encompassing the dynamical evolution of ob- ject motion perception is still lacking. Here we outline several experimental observations concerning human smooth pursuit of moving ob jects and more particu- larly the time course of its initiation phase. In addi- tion, we propose a recursive extension of the Bayesian model, motivated and constrained by our oculomotor data, to describe the dynamical integration of 1D and 2D motion information.","tags":["bayesian","kaplan13","khoei13jpp","perrinet12pred"],"title":"Bayesian modeling of dynamic motion integration","type":"publication"},{"authors":["Anna Montagnini","Pascal Mamassian","Laurent U. Perrinet","Eric Castet","Guillaume S. Masson"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"2e0b6df605f6630767de8592454967cf","permalink":"https://laurentperrinet.github.io/publication/montagnini-07-a/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/montagnini-07-a/","section":"publication","summary":"When the visual information about an object's motion differs at the local level, the visuomotor system needs to integrate information across time to solve this ambiguity and converge to the final motion solution. For an oblique line moving horizontally, edge-related motion cues differ from terminator-related information, the latter being coherent with the line's global motion. We have previously shown that ocular tracking of this kind of stimuli is transiently biased toward the edge-orthogonal direction, before converging to the global motion direction. Here, we model the dynamic convergence to the global-motion solution as a recursive update of inferential knowledge in the velocity space. We assume that motion estimation is based on a prior distribution and two independent likelihood functions representing edge-related and terminator-related information. Importantly, the shape of the Bayesian functions is constrained by smooth-pursuit eye-movement data. Model predictions about the dynamic convergence to the correct motion solution are compared to human smooth-pursuit recordings when varying different stimulus parameters (speed, contrast).","tags":["motion"],"title":"Dynamic inference for motion tracking","type":"publication"},{"authors":["Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"a9548d6acdf8e0a39c6e20b0a6ccf240","permalink":"https://laurentperrinet.github.io/publication/perrinet-07-neurocomp/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-07-neurocomp/","section":"publication","summary":"The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may understand this response as an ideal observer in a probabilis- tic framework by using Bayesian theory (Weiss et al., 2002) which we previously proved to be successfully adapted to model the OFR for different levels of noise with full field gratings (Perrinet et al., 2005). More recent experiments of OFR have used disk gratings and bipartite stimuli which are optimized to study the dy- namics of center-surround integration. We quantified two main characteristics of the spatial integration of motion : (i) a finite optimal stimulus size for driving OFR, surrounded by an antagonistic modulation and (ii) a direction selective sup- pressive effect of the surround on the contrast gain control of the central stim- uli (Barth√©lemy et al., 2006). Herein, we extended the ideal observer model to simulate the spatial integration of the different local motion cues within a proba- bilistic representation. We present analytical results which show that the hypoth- esis of independence of local measures can describe the integration of the spatial motion signal. Within this framework, we successfully accounted for the con- trast gain control mechanisms observed in the behavioral data for center-surround stimuli. However, another inhibitory mechanism had to be added to account for suppressive effects of the surround.","tags":["bayesian","center-surround","eye","following","integration","interactions","model","motion","movements","ocular","perception","re-","sponse","tracking","visual"],"title":"Modeling spatial integration in the ocular following response using a probabilistic framework","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"c7c7a3a0103eb1b3ec0df07cfb696159","permalink":"https://laurentperrinet.github.io/publication/perrinet-07-mipm/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-07-mipm/","section":"publication","summary":"I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm inspired by statistical inference, Matching Pursuit and Hebbian learning. This algorithm allows to learn efficient \"edge-like\" receptive fields similarly to Independent Components Analysis. The correlation-based inhibition has been shown to be a necessary condition for the fomation of this type of receptive fields and shows the putative functional role of lateral propagation of information in cortical layers. I'll first present state-of-the-art neural algorithms for this task, the results of a detailed analysis of this Sparse Hebbian Learning algorithm and finally draw a comparison with similar strategies.","tags":["unsupervised_learning"],"title":"Neural Codes for Adaptive Sparse Representations of Natural Images","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"e02c19bb1e02aeed72895e7d6e442286","permalink":"https://laurentperrinet.github.io/publication/perrinet-07-cns/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-07-cns/","section":"publication","summary":"We describe the theoretical formulation of a learning algorithm in a model of the primary visual cortex (V1) and present results of the efficiency of this algorithm by comparing it to the SparseNet algorithm [1]. As the SparseNet algorithm, it is based on a model of signal synthesis as a Linear Generative Model but differs in the efficiency criteria for the representation. This learning algorithm is in fact based on an efficiency criteria based on the Occam razor: for a similar quality, the shortest representation should be privileged. This inverse problem is NP-complete and we propose here a greedy solution which is based on the architecture and nature of neural computations [2]). It proposes that the supra-threshold neural activity progressively removes redundancies in the representation based on a correlation-based inhibition and provides a dynamical implementation close to the concept of neural assemblies from Hebb [3]). We present here results of simulation of this network with small natural images (available at http://www.incm.cnrs-mrs.fr/LaurentPerrinet/SparseHebbianLearning) and compare it to the Sparsenet solution. Extending it to realistic images and to the NEST simulator http://www.nest-initiative.org/, we show that this learning algorithm based on the properties of neural computations produces adaptive and efficient representations in V1. 1. Olshausen B, Field DJ: Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Res 1997, 37:3311-3325. 2. Perrinet L: Feature detection using spikes: the greedy approach. J Physiol Paris 2004, 98(4--6):530-539. 3. Hebb DO: The organization of behavior. Wiley, New York; 1949.","tags":["area-v1"],"title":"On efficient sparse spike coding schemes for learning natural scenes in the primary visual cortex","type":"publication"},{"authors":["Andrew Davison","Pierre Yger","Jens Kremkow","Laurent U. Perrinet","Eilif Muller"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"28067d09bdd855577ac84bab8489cd78","permalink":"https://laurentperrinet.github.io/publication/davison-07-cns/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/davison-07-cns/","section":"publication","summary":"Trends in programming language development and adoption point to Python as the high-level systems integration language of choice. Python leverages a vast developer-base external to the neuroscience community, and promises leaps in simulation complexity and maintainability to any neural simulator that adopts it. PyNN http://neuralensemble.org/PyNN strives to provide a uniform application programming interface (API) across neural simulators. Presently NEURON and NEST are supported, and support for other simulators and neuromorphic VLSI hardware is under development. With PyNN it is possible to write a simulation script once and run it without modification on any supported simulator. It is also possible to write a script that uses capabilities specific to a single simulator. While this sacrifices simulator-independence, it adds flexibility, and can be a useful step in porting models between simulators. The design goals of PyNN include allowing access to low-level details of a simulation where necessary, while providing the capability to model at a high level of abstraction, with concomitant gains in development speed and simulation maintainability. Another of our aims with PyNN is to increase the productivity of neuroscience modeling, by making it faster to develop models de novo, by promoting code sharing and reuse across simulator communities, and by making it much easier to debug, test and validate simulations by running them on more than one simulator. Modelers would then become free to devote more software development effort to innovation, building on the simulator core with new tools such as network topology databases, stimulus programming, analysis and visualization tools, and simulation accounting. The resulting, community-developed 'meta-simulator' system would then represent a powerful tool for overcoming the so-called complexity bottleneck that is presently a major roadblock for neural modeling.","tags":["pynn"],"title":"PyNN: towards a universal neural simulator API in Python","type":"publication"},{"authors":["Sylvain Fischer","Filip ≈†roubek","Laurent Perrinet","Rafael Redondo","Gabriel Crist√≥bal"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"ad34d34463f51bb7a10c3ed814e22946","permalink":"https://laurentperrinet.github.io/publication/fischer-07-cv/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/fischer-07-cv/","section":"publication","summary":"Meanwhile biorthogonal wavelets got a very popular image processing tool, alternative multiresolution transforms have been proposed for solving some of their drawbacks, namely the poor selectivity in orientation and the lack of translation in- variance due to the aliasing between subbands. These transforms are generally overcomplete and consequently offer huge degrees of freedom in their design. At the same time their optimization get a challenging task. We proposed here a log-Gabor wavelet transform gathering the excellent mathematical properties of the Gabor functions with a carefully construction to maintain the properties of the filters and to permit exact reconstruction. Two major improvements are proposed: first the highest frequency bands are covered by narrowly localized oriented filters. And second, all the frequency bands including the highest and lowest frequencies are uniformly covered so as exact reconstruction is achieved using the same filters in both the direct and the inverse transforms (which means that the transform is self-invertible). The transform is optimized not only mathematically but it also follows as much as possible the knowledge on the receptive field of the simple cells of the Primary Visual Cortex (V1) of primates and on the statistics of natural images. Compared to the state of the art, the log-Gabor wavelets show excellent behavior in their ability to segregate the image information (e.g. the contrast edges) from incoherent Gaussian noise by hard thresholding and to code the image features through a reduced set of coefficients with large magnitude. Such characteristics make the transform a promising tool for general image processing tasks.","tags":["assofield","denoising","filters","high-pass","image","log-gabor","motion-clouds","oriented","perrinet11sfn","sanz12jnp","system","transforms","visual","wavelet","wavelets"],"title":"Self-Invertible 2D Log-Gabor Wavelets","type":"publication"},{"authors":["Sylvain Fischer","Rafael Redondo","Laurent Perrinet","Gabriel Crist√≥bal"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"417b4362d9153ab18454a4ab8dd41a0c","permalink":"https://laurentperrinet.github.io/publication/fischer-07/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/fischer-07/","section":"publication","summary":"","tags":["assofield","log-gabor","log_gabor","motion-clouds","perrinet11sfn","sanz12jnp"],"title":"Sparse Approximation of Images Inspired from the Functional Architecture of the Primary Visual Areas","type":"publication"},{"authors":["Jens Kremkow","Laurent Perrinet","Arvind Kumar","Ad Aertsen","Guillaume Masson"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"3bd786fb0d499b5283b9f6891e6c48df","permalink":"https://laurentperrinet.github.io/publication/kremkow-07-cns/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/kremkow-07-cns/","section":"publication","summary":"Sensory input enters the cortex via the thalamocortical (TC) projection, where it elicits large postsynaptic potentials in layer 4 neurons [1]. Interestingly, the TC connections account for only ÃÉ15% of synapses onto these neurons. It has been therefore controversially discussed how thalamic input can drive the cortex. Strong TC synapses have been one suggestion to ensure the strength of the TC projection (\"strong-synapse model\"). Another possibility is that the excitation from single thalamic fibers are weak but get amplified by recurrent excitatory feedback in layer 4 (\"amplifier model\"). Bruno and Sakmann [2] recently provided new evidence that individual TC synapses in vivo are weak and only produce small excitatory postsynaptic potentials. However, they suggested that thalamic input can activate the cortex due to the synchronous firing and that cortical amplification is not required. This would support the \"synchrony model\" proposed by correlation analysis [3]. Here, we studied the effect of correlation in the TC input, with weak synapses, to the responses of a layered cortical network model. The connectivity of the layered network was taken from Binzegger et al. 2004 [4]. The network was simulated using NEST [5] with the Python interface PyNN [6] to enable interoperability with different simulators. The sensory input to layer 4 was modelled by a simple retino-geniculate model of the transformation of light into spike trains [7], which was implemented by leaky integrate-and-fire model neurons. We found that introducing correlation into TC inputs enhanced the likelihood to produce responses in layer 4 and improved the activity propagation across layers. In addition, we compared the response of the cortical network to different noise conditions and obtained contrast response functions which were in accordance with neurophysiological observations. This Work is supported by the 6th RFP of the EU (grant no. 15879-FACETS) and by the BMBF grant 01GQ0420 to the BCCN Freiburg. 1. Chung S, Ferster D: Strength and orientation tuning of the thalamic input to simple cells revealed by electrically evoked cortical suppression. Neuron 1998, 20:1177-1189. 2. Bruno M, Sakmann B: Cortex is driven by weak but synchronously active thalamocortical synpases. Science 2006, 312:1622-1627. 3. Alonso JM, Usrey WM, Reid RC: Precisely correlated firing in cells of the lateral geniculate nucleus. Nature 1996, 383:815-819. 4. Binzegger T, Douglas RJ, Martin KAC: A quantitative map of the circuit of the cat primary visual cortex. J Neurosci 2004, 24:8441-8453. 5. NEST http://www.nest-initiative.org 6. PyNN http://pynn.gforge.inria.fr 7. Gazeres N, Borg-Graham LJ, Fr√©gnac Y: A phenomenological model of visually evoked spike trains in cat geniculate nonlagged X-cells. Vis Neurosci 1998, 15:1157-1174.","tags":["cortex"],"title":"Synchrony in thalamic inputs enhances propagation of activity through cortical layers","type":"publication"},{"authors":["Anna Montagnini","Pascal Mamassian","Laurent U. Perrinet","Guillaume S. Masson"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"4d8ab5deb2e13721270514248d5beea7","permalink":"https://laurentperrinet.github.io/publication/montagnini-07-b/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/montagnini-07-b/","section":"publication","summary":"Perceptual and oculomotor data demonstrate that, when the visual information about an object's motion differs on the local (edge-related) and global levels, the local 1D motion cues dominate initially, whereas 2D information takes progressively over and leads to the final correct representation of global motion. Previous models have explained the initial errors (deviations from the global motion) in terms of best perceptual guess in the Bayesian sense. These models accounted for the intrinsic sensory noise of the image and general expectancies for object velocities. Here we propose a recursive extension of the Bayesian model, with the purpose of encompassing the whole dynamical evolution of motion processing, from the 1D cues to the correct global motion. Our model is motivated and constrained by smooth pursuit oculomotor data. Eye movements were recorded in 3 participants using the scleral search coil technique. Participants were asked to track either a single line (vertical or oblique) or a Gaussian blob moving horizontally. In our model, oculomotor data obtained with non ambiguous stimuli (e.g. with coherent local and global information, such as a Gaussian blob or a vertical line moving horizontally) are combined to constrain the initial likelihood and prior functions for the general, ambiguous case (e.g. a tilted line moving horizontally). The prior knowledge is then recursively updated by using the previous posterior probability as the current prior. The idea is that the recursive injection of posterior distribution boosts the spread of information about the object's shape, favoring the integration of 1D and 2D cues. In addition, a simple model of the sensory-oculomotor loop is taken into account, including transmission delays and the evolution of the retinal motion during pursuit. Preliminary results show substantial agreement between the model prediction and the oculomotor data.","tags":["bayesian"],"title":"Visual tracking of ambiguous moving objects: A recursive Bayesian model","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"6c266edfd0bb17e3549b6ce62756f687","permalink":"https://laurentperrinet.github.io/publication/perrinet-06-cns/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-06-cns/","section":"publication","summary":"We describe the theoretical formulation of a learning algorithm in a model of the primary visual cortex (V1) and present results of the efficiency of this algorithm by comparing it to the SparseNet algorithm (Olshausen, 1996). As the SparseNet algorithm, it is based on a model of signal synthesis as a Linear Generative Model but differs in the efficiency criteria for the representation. This learning algorithm is in fact based on an efficiency criteria based on the Occam razor: for a similar quality, the shortest representation should be privilegied. This inverse problem is NP-complete and we propose here a greedy solution which is based on the architecture and nature of neural computations (Perrinet, 2006). We present here results of a simulation of this network of small natural images (available at http://www.incm.cnrs-mrs.fr/perrinet/dynn/SparseHebbianLearning ) and compare it to the SparseNet solution. We show that this solution based on neural computations produces an adaptive algorithm for efficient representations in V1.","tags":["unsupervised_learning"],"title":"An efficiency razor for model selection and adaptation in the primary visual cortex","type":"publication"},{"authors":["Adrien Wohrer","Guillaume S. Masson","Laurent U. Perrinet","Pierre Kornprobst","Thierry Vieville"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"eaeb3213e228b72d987e02191a28d896","permalink":"https://laurentperrinet.github.io/publication/wohrer-06/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/wohrer-06/","section":"publication","summary":"","tags":["retina"],"title":"Contrast sensitivity adaptation in a virtual spiking retina and its adequation with mammalians retinas","type":"publication"},{"authors":["Laurent U. Perrinet","Jens Kremkow"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"49ef7e009235b9bdc08560fc2baf3d19","permalink":"https://laurentperrinet.github.io/publication/perrinet-06-ciotat/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-06-ciotat/","section":"publication","summary":"","tags":["gain_control"],"title":"Dynamical contrast gain control mechanisms in a layer 2/3 model of the primary visual cortex","type":"publication"},{"authors":["Laurent U. Perrinet","Jens Kremkow"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"cc3cf7fb2087f8e4e0f9a22608f06ce3","permalink":"https://laurentperrinet.github.io/publication/perrinet-06-fab/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-06-fab/","section":"publication","summary":"Computations in a cortical column are characterized by the dynamical, event-based nature of neuronal signals and are structured by the layered and parallel structure of cortical areas. But they are also characterized by their efficiency in terms of rapidity and robustness. We propose and study here a model of information integration in the primary visual cortex (V1) thanks to the parallel and interconnected network of similar cortical columns. In particular, we focus on the dynamics of contrast gain control mechanisms as a function of the distribution of information relevance in a small population of cortical columns. This cortical area is modeled as a collection of similar cortical columns which receive input and are linked according to a specific connectivity pattern which is relevant to this area. These columns are simulated using the sc Nest simulator Morrison04 using conductance-based Integrate-and-Fire neurons and consist vertically in 3 different layers. The architecture was inspired by neuro-physiological observations on the influence of neighboring activities on pyramidal cells activity and correlates with the lateral flow of information observed in the primary visual cortex, notably in optical imaging experiments Jancke04, and is similar in its final implementation to local micro-circuitry of the cortical column presented by Grossberg05. % They show prototypical spontaneous dynamical behavior to different levels of noise which are relevant to the generic modeling of biological cortical columns Kremkow05. In the future, the connectivity will be derived from an algorithm that was used for modeling the transient spiking response of a layer of neurons to a flashed image and which was based on the Matching Pursuit algorithm Perrinet04. % The visual input is first transmitted from the Lateral Geniculate Nucleus (LGN) using the model of Gazeres98. It transforms the image flow into a stream of spikes with contrast gain control mechanisms specific to the retina and the LGN. This spiking activity converges to the pyramidal cells of layer 2/3 thanks to the specification of receptive fields in layer 4 providing a preference for oriented local contrasts in the spatio-temporal visual flow. In particular, we use in these experiments visual input organized in a center-surround spatial pattern which was optimized in size to maximize the response of a column in the center and to the modulation of this response by the surround (bipartite stimulus). This class of stimuli provide different levels of input activation and of visual ambiguity in the visual space which were present in the spatio-temporal correlations in the input spike flow optimized to the resolution of cortical columns in the visual space. It thus provides a method to reveal the dynamics of information integration and particularly of contrast gain control which are characteristic to the function of V1.","tags":["gain_control"],"title":"Dynamical contrast gain control mechanisms in a layer 2/3 model of the primary visual cortex","type":"publication"},{"authors":["Laurent U. Perrinet","Jens Kremkow","Fr√©d√©ric V. Barth√©lemy","Guillaume S. Masson","Fr√©d√©ric Chavane"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"fed23a448e1ceae6d28530c9793cbb59","permalink":"https://laurentperrinet.github.io/publication/perrinet-06-fens/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-06-fens/","section":"publication","summary":"","tags":["motion"],"title":"Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework","type":"publication"},{"authors":["Laurent U. Perrinet","Fr√©d√©ric V. Barth√©lemy","Guillaume S. Masson"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"4bcd11caab6d06c3eebc10ad68208f6d","permalink":"https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-06-neurocomp/","section":"publication","summary":"The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor data demonstrate that motion processing of extended ob jects is initially dominated by the local 1D motion cues orthogonal to the ob ject's edges, whereas 2D information takes pro- gressively over and leads to the final correct represen- tation of global motion. A Bayesian framework ac- counting for the sensory noise and general expectancies for ob ject velocities has proven successful in explaining several experimental findings concerning early motion processing [1, 2, 3]. However, a complete functional model, encompassing the dynamical evolution of ob- ject motion perception is still lacking. Here we outline several experimental observations concerning human smooth pursuit of moving ob jects and more particu- larly the time course of its initiation phase. In addi- tion, we propose a recursive extension of the Bayesian model, motivated and constrained by our oculomotor data, to describe the dynamical integration of 1D and 2D motion information.","tags":["aperture","bayesian","evolution","eye","inference","model","motion","movement","object","problem","pursuit","recursive","smooth","temporal"],"title":"Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework","type":"publication"},{"authors":["Rafael Redondo","Sylvain Fischer","Laurent U. Perrinet","Gabriel Crist√≥bal"],"categories":null,"content":"","date":1122847200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1122847200,"objectID":"d8f4f222ced21e4f5119f22711160535","permalink":"https://laurentperrinet.github.io/publication/redondo-05/","publishdate":"2005-08-01T00:00:00+02:00","relpermalink":"/publication/redondo-05/","section":"publication","summary":"We present a biologically plausible model of simple cortical cells as 1) a linear transform representing edges and 2) a non-linear iterative stage of inhibition and facilitation between neighboring coefficients. The linear transform is a complex log-Gabor wavelet transform which is overcomplete (i.e. there are more coefficients than pixels in the image) and has exact reconstruction. The inhibition consists in diminishing down the coefficients which are not at a local-maxima along the direction normal to the edge filter orientation, whereas the facilitation enhances the collinear and co-aligned local-maximum coefficients. At each iteration and after the inhibition and facilitation stages, the reconstructed error is subtracted in the transform domain for keeping an exact reconstruction. Such process concentrates the signal energy on a few coefficients situated along the edges of the objects, yielding a sparse representation. The rationale for such procedure is: (1) th e overcompleteness offers flexibility for activity reassignment; (2) images can be coded by sparse Gabor coefficients located on object edges; (3) image contours produce aligned and collinear local-maxima in the transform domain; (4) the inhibition/facilitation processes are able to extract the contours. The sparse Gabor coefficients are mostly connected each other and located along object contours. Such layout makes chain coding suitable for compression purposes. Specially adapted to Gabor wavelets features, our chain coding represents every chain by its end-points (head and tail) and the elementary movements necessary to walk along the chain from head to tail. Moreover it predicts the module and phase of each Gabor coefficient according to the previous chain coefficient. As a result, redundancy of the transform domain is further reduced. Used for compression, the scheme limits particularly the high-frequency artifacts. The model performs also efficiently in tasks the Human Visual System is supposed to deal with, as for instance edge extraction and image denoising.","tags":["log-gabor"],"title":"Modeling of simple cells through a sparse overcomplete gabor wavelet representation based on local inhibition and facilitation","type":"publication"},{"authors":["Sylvain Fischer","Rafael Redondo","Laurent Perrinet","Gabriel Crist√≥bal"],"categories":null,"content":"","date":1117576800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1117576800,"objectID":"9c1e343bed181e9a2364a439e968a9ec","permalink":"https://laurentperrinet.github.io/publication/fischer-05-a/","publishdate":"2005-06-01T00:00:00+02:00","relpermalink":"/publication/fischer-05-a/","section":"publication","summary":"Efficient sparse coding of overcomplete transforms remains still anopen problem. Different methods have been proposed in theliterature, but most of them are limited by a heavy computationalcost and by difficulties to find the optimal solutions. We proposehere an algorithm suitable for Gabor wavelets and based onbiological models. It is composed by local operations betweenneighboring transform coefficients and achieves a sparserepresentation with a relatively low computational cost. Used with achain coder, this sparse Gabor wavelet transform is suitable forimage compression but is also of interest also for otherapplications, in particular for edge and contour extraction andimage denoising.","tags":["area-v1","log-gabor","receptive_field","sparse_coding"],"title":"Sparse Gabor wavelets by local operations","type":"publication"},{"authors":["Laurent U. Perrinet","Fr√©d√©ric V. Barth√©lemy","Eric Castet","Guillaume S. Masson"],"categories":null,"content":"","date":1104534000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104534000,"objectID":"7074c21e8e21d730f2b0e246352f73ff","permalink":"https://laurentperrinet.github.io/publication/perrinet-05-a/","publishdate":"2005-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-05-a/","section":"publication","summary":"The integration of information is essential to measure the exact 2D motion of a surface from both local ambiguous 1D motion produced by elongated edges and local non-ambiguous 2D motion from features such as corners, end-points or texture elements. The dynamics of this motion integration shows a complex time course which can be read from tracking eye movements: local 1D motion signals are extracted first and then pooled to initiate the ocular responses before that 2D motion signals are taken into account to refine the tracking direction until it matches the surface motion direction. The nature of these 1D and 2D motion computations is still unclear. Previously, we have shown that the late, 2D-driven response components to either plaids or barber-poles have very similar latencies over a large range of contrast, suggesting a shared mechanism. However, they showed different contrast response functions with these different motion stimuli, suggesting different motion processing. We designed a two-pathways Bayesian model of motion integration and showed that this family of contrast response functions can be predicted from the probability distributions of 1D and 2D motion signals for each type of stimulus. Indeed, this formulation may explain contrast response functions that could not be explained by a simple bayesian model (Weiss et al., 2002 em Nature Neuroscience bf 5 , 598--604) and gives a quantitative argument to study how local information with different relative ambiguities values may be pooled to provide an integrated response of the system. Finally, we formulate how different spatial information may be pooled and we draw the analogy of this method with methods using the partial derivative equations. This simple model correctly explains some non-linear interactions between neighboring neurons selective to motion direction which are observed in short-latency ocular following and neuro-physiological data.","tags":["bayesian","models"],"title":"Dynamics of motion representation in short-latency ocular following: A two-pathways Bayesian model","type":"publication"},{"authors":["Laurent Perrinet"],"categories":null,"content":"","date":1104534000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104534000,"objectID":"badedf0ad438e8142475d55b696d1afa","permalink":"https://laurentperrinet.github.io/publication/perrinet-05/","publishdate":"2005-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-05/","section":"publication","summary":"","tags":["integrate_and_fire"],"title":"Efficient Source Detection Using Integrate-and-Fire Neurons","type":"publication"},{"authors":["Sylvain Fischer","Rafael Redondo","Laurent U. Perrinet","Gabriel Crist√≥bal"],"categories":null,"content":"","date":1104534000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104534000,"objectID":"b2177ba9dc3caceb3228de1684b1d6c2","permalink":"https://laurentperrinet.github.io/publication/fischer-05/","publishdate":"2005-01-01T00:00:00+01:00","relpermalink":"/publication/fischer-05/","section":"publication","summary":"Low-level perceptual computations may be understood in terms of efficient codes (Simoncelli and Olshausen, 2001, Annual Review of Neuroscience 24 1193-216). Following this argument, we explore models of representation for natural static images as a way to understand the processing of information in the primary visual cortex. This representation is here based on a generative linear model of the synthesis of images using an over-complete multi-resolution dictionary of edges. This transform is implemented using log-Gabor filters and permits an exact reconstruction of any image. However, this linear representation is redundant and since to any image may correspond different representations, we explore more efficient representations of the image. The problem is stated as an ill-posed inverse problem and we compare first different known strategies by computing the efficiency of the solutions given by Matching Pursuit (Perrinet, 2004, IEEE Trans. Neural Networks 15 1164-75) and sparse edge coding (Fischer, in press, Trans. Image Processing) with classical representation methods such as JPEG. This comparison allows us to provide a synthesized approach using a probabilistic representation which would progressively construct the neural representation by using lateral cooperations. We propose an algorithm which dynamically diffuses information to correlated filters so as to yield a progressively disambiguated representation. This approach takes advantage of the computational properties of spiking neurons such as Integrate-and-Fire neurons and provides an efficient yet simple model for the representation of natural images. This representation is directly linked with the edge content of natural images and we show applications of this method to edge extraction, denoising and compression. We also show that this dynamical approach fits with neuro-physiological observations and may explain the non-linear interactions between neighboring neurons which may be observed in the cortex.","tags":["matching-pursuit"],"title":"Efficient representation of natural images using local cooperation","type":"publication"},{"authors":["Laurent U. Perrinet","Manuel Samuelides","Simon J. Thorpe"],"categories":null,"content":"","date":1093989600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1093989600,"objectID":"5f929153186f73eefabac8dcbffa7732","permalink":"https://laurentperrinet.github.io/publication/perrinet-04-a/","publishdate":"2004-09-01T00:00:00+02:00","relpermalink":"/publication/perrinet-04-a/","section":"publication","summary":"To understand possible strategies of temporal spike coding in the central nervous system, we study functional neuromimetic models of visual processing for static images. We will first present the retinal model which was introduced by Van Rullen and Thorpe [1] and which represents the multi- scale contrast values of the image using an orthonormal wavelet transform. These analog values activate a set of spiking neurons which each fire once to produce an asynchronous wave of spikes. According to this model, the image may be progressively reconstructed from this spike wave thanks to regularities in the statistics of the coefficients determined with natural images. Here, we study mathematically how the quality of information transmission carried by this temporal representation varies over time. In particular, we study how these regularities can be used to optimize information transmission by using a form of temporal cooperation of neurons to code analog values. The original model used wavelet transforms that are close to orthogonal. However, the selectivity of realistic neurons overlap, and we propose an extension of the previous model by adding a spatial cooperation between filters. This model extends the previous scheme for arbitrary ---and possibly non-orthogonal--- representations of features in the images. In particular, we compared the perfor- mance of increasingly over-complete representations in the retina. Results show that this algorithm provides an efficient spike coding strategy for low-level visual processing which may adapt to the complexity of the visual input.","tags":["assofield","asynchronous","coding","computing","images","matching-pursuit","natural","neuronal","over-complete","parallel-processing","representation","spike","statistics","temporal","ultra-rapid","vision"],"title":"Coding static natural images using spiking event times: do neurons cooperate?","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1088632800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1088632800,"objectID":"47b86c7011ae792a854ccb80949c7b57","permalink":"https://laurentperrinet.github.io/publication/perrinet-04-tauc/","publishdate":"2004-07-01T00:00:00+02:00","relpermalink":"/publication/perrinet-04-tauc/","section":"publication","summary":"A goal of low-level neural processes is to build an efficient code extracting the relevant information from the sensory input. It is believed that this is implemented in cortical areas by elementary inferential computations dynamically extracting the most likely parameters corresponding to the sensory signal. We explore here a neuro-mimetic feed-forward model of the primary visual area (V1) solving this problem in the case where the signal may be described by a robust linear gen- erative model. This model uses an over-complete dictionary of primitives which provides a distributed probabilistic representation of input features. Relying on an efficiency criterion, we derive an algorithm as an approximate solution which uses incremental greedy inference processes. This algorithm is similar to 'Matching Pursuit' and mimics the parallel architecture of neural computations. We propose here a simple implementation using a network of spiking integrate-and-fire neu- rons which communicate using lateral interactions. Numerical simulations show that this Sparse Spike Coding strategy provides an efficient model for representing visual data from a set of natural images. Even though it is simplistic, this trans- formation of spatial data into a spatio-temporal pattern of binary events provides an accurate description of some complex neural patterns observed in the spiking activity of biological neural networks.","tags":["coding","computation","dictionar-","distributed","ies","inverse","linear","matching","model","neuronal","over-complete","probabilistic","pursuit","representation","sparse","spike","spike-event"],"title":"Feature detection using spikes : the greedy approach.","type":"publication"},{"authors":["Laurent Perrinet","Manuel Samuelides","Simon Thorpe"],"categories":null,"content":"","date":1078095600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1078095600,"objectID":"05e3afe1ae15d35c01d9337299e21efd","permalink":"https://laurentperrinet.github.io/publication/perrinet-02-sparse/","publishdate":"2004-03-01T00:00:00+01:00","relpermalink":"/publication/perrinet-02-sparse/","section":"publication","summary":"","tags":["assofield","matching","pursuit"],"title":"Sparse spike coding in an asynchronous feed-forward multi-layer neural network using matching pursuit","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1072911600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072911600,"objectID":"ed4b6c8e5fb952d54a4735a2c8ecd8dd","permalink":"https://laurentperrinet.github.io/publication/perrinet-04/","publishdate":"2004-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-04/","section":"publication","summary":"To understand possible strategies of temporal spike coding in the central nervous system, we study functional neuromimetic models of visual processing for static images. We will first present the retinal model which was introduced by Van Rullen and Thorpe [1] and which represents the multi- scale contrast values of the image using an orthonormal wavelet transform. These analog values activate a set of spiking neurons which each fire once to produce an asynchronous wave of spikes. According to this model, the image may be progressively reconstructed from this spike wave thanks to regularities in the statistics of the coefficients determined with natural images. Here, we study mathematically how the quality of information transmission carried by this temporal representation varies over time. In particular, we study how these regularities can be used to optimize information transmission by using a form of temporal cooperation of neurons to code analog values. The original model used wavelet transforms that are close to orthogonal. However, the selectivity of realistic neurons overlap, and we propose an extension of the previous model by adding a spatial cooperation between filters. This model extends the previous scheme for arbitrary ---and possibly non-orthogonal--- representations of features in the images. In particular, we compared the perfor- mance of increasingly over-complete representations in the retina. Results show that this algorithm provides an efficient spike coding strategy for low-level visual processing which may adapt to the complexity of the visual input.","tags":["area-v1","sparselet","unsupervised_learning"],"title":"Finding Independent Components using spikes : a natural result of hebbian learning in a sparse spike coding scheme","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":1041375600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041375600,"objectID":"38073671c0b6396eeaa07e932fb80d62","permalink":"https://laurentperrinet.github.io/publication/perrinet-03-these/","publishdate":"2003-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-03-these/","section":"publication","summary":"","tags":["vision"],"title":"Comment d√©chiffrer le code impulsionnel de la vision ? √âtude du flux parall√®le, asynchrone et √©pars dans le traitement visuel ultra-rapide","type":"publication"},{"authors":["Laurent U. Perrinet","Manuel Samuelides","Simon J. Thorpe"],"categories":null,"content":"","date":1041375600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041375600,"objectID":"f0c0f14c99caa54516b7d24415fc5830","permalink":"https://laurentperrinet.github.io/publication/perrinet-03/","publishdate":"2003-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-03/","section":"publication","summary":"","tags":["area-v1","receptive_field","sparse_coding"],"title":"Emergence of filters from natural scenes in a sparse spike coding scheme.","type":"publication"},{"authors":["L. Perrinet"],"categories":null,"content":"","date":1022882400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1022882400,"objectID":"82997d58b8dd00474e82aa1650b63f9d","permalink":"https://laurentperrinet.github.io/publication/perrinet-02/","publishdate":"2002-06-01T00:00:00+02:00","relpermalink":"/publication/perrinet-02/","section":"publication","summary":"","tags":["stdp"],"title":"Coherence detection in a spiking neuron via Hebbian learning","type":"publication"},{"authors":["Laurent U. Perrinet","Manuel Samuelides"],"categories":null,"content":"","date":1009839600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009839600,"objectID":"3998d8ab2ad06ed206380d8b63294663","permalink":"https://laurentperrinet.github.io/publication/perrinet-02-stdp/","publishdate":"2002-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-02-stdp/","section":"publication","summary":"It is generally assumed that neurons in the central nervous system communicate through temporal firing patterns. As a first step, we will study the learning of a layer of realistic neurons in the particular case where the relevant messages are formed by temporally cor- related patterns, or synfire patterns. The model is a layer of Integrate-and-Fire (IF) neurons with synaptic current dynamics that adapts by minimizing a cost according to a gradient descent scheme. This leads to a rule similar to Spike-Time Dependent Hebbian Plasticity (STDHP). Our results show that the rule that we derive is biologically plausible and leads to the detection of the coherence in the input in an unsupervised way. An application to shape recognition is shown as an illustration.","tags":["coding","dependent","hebb","hebbian","kinetic","model","networks","neural","order","plasticity","rank","rule","spike","spiking","time"],"title":"Coherence detection in a spiking neuron via hebbian learning","type":"publication"},{"authors":["Laurent U. Perrinet","Manuel Samuelides"],"categories":null,"content":"","date":1009839600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009839600,"objectID":"c5358013414af2ac33add3a3ea23dfb9","permalink":"https://laurentperrinet.github.io/publication/perrinet-02-esann/","publishdate":"2002-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-02-esann/","section":"publication","summary":"","tags":["area-v1","receptive_field","sparse_coding"],"title":"Sparse Image Coding Using an Asynchronous Spiking Neural Network","type":"publication"},{"authors":["Laurent U. Perrinet","Manuel Samuelides"],"categories":null,"content":"","date":1009839600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009839600,"objectID":"919a9bd338518f23a5c65cdf941c15b9","permalink":"https://laurentperrinet.github.io/publication/perrinet-02-nsi/","publishdate":"2002-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-02-nsi/","section":"publication","summary":"","tags":["sparse_spike_coding"],"title":"Visual Strategies for Sparse Spike Coding","type":"publication"},{"authors":["Laurent U. Perrinet","Arnaud Delorme","Simon J. Thorpe","Manuel Samuelides"],"categories":null,"content":"","date":978303600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":978303600,"objectID":"2040df7e258d8ed71d0b292a7d20cce5","permalink":"https://laurentperrinet.github.io/publication/perrinet-01/","publishdate":"2001-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-01/","section":"publication","summary":"","tags":["integration"],"title":"Network of integrate-and-fire neurons using Rank Order Coding A: how to implement spike timing dependant plasticity.","type":"publication"},{"authors":["Arnaud Delorme","Laurent Perrinet","Simon Thorpe","Manuel Samuelides"],"categories":null,"content":"","date":978303600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":978303600,"objectID":"e80135590d9e771b012e7c67519f17bb","permalink":"https://laurentperrinet.github.io/publication/delorme-01/","publishdate":"2001-01-01T00:00:00+01:00","relpermalink":"/publication/delorme-01/","section":"publication","summary":"Rank Order Coding is an alternative to conventional rate coding schemes that uses the order in which a neuron's inputs fire to encode information. In a visual system framework, we simulated the asynchronous waves of retinal spikes produced in response to natural scenes and used them to stimulate integrate-and-fire V1 neurons that implemented a standard learning rule based on spike timing. After propagating thousands of images, orientation like receptive fields arise in these neurons despite the ...","tags":["stdp"],"title":"Network of integrate-and-fire neurons using Rank Order Coding B: spike timing dependant plasticity and emergence of orientation selectivity.","type":"publication"},{"authors":["Laurent U. Perrinet","Manuel Samuelides"],"categories":null,"content":"","date":946681200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":946681200,"objectID":"616a15db88d66df195590ab2279add09","permalink":"https://laurentperrinet.github.io/publication/perrinet-00/","publishdate":"2000-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-00/","section":"publication","summary":"","tags":["cortex","plasticity","stdp","unsupervised_learning"],"title":"A generative model for Spike Time Dependent Hebbian Plasticity","type":"publication"},{"authors":["Laurent U. Perrinet"],"categories":null,"content":"","date":915145200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":915145200,"objectID":"7fc44d4acf93dbedc536964998776b95","permalink":"https://laurentperrinet.github.io/publication/perrinet-99/","publishdate":"1999-01-01T00:00:00+01:00","relpermalink":"/publication/perrinet-99/","section":"publication","summary":"","tags":["rank-order-coding","unsupervised_learning"],"title":"Apprentissage hebbien d'un reseau de neurones asynchrone a codage par rang","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/hulk.png\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://laurentperrinet.github.io/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]