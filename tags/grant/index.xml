<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>grant on Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tags/grant/</link>
    <description>Recent content in grant on Novel visual computations</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png&#34; /&gt;&lt;/a&gt;&lt;br /&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License&lt;/a&gt;
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared.
</copyright>
    <lastBuildDate>Mon, 15 Apr 2019 10:00:00 +0200</lastBuildDate>
    
	    <atom:link href="https://laurentperrinet.github.io/tags/grant/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SpikeAI: laureat du Défi Biomimétisme (2019)</title>
      <link>https://laurentperrinet.github.io/project/spikeai/</link>
      <pubDate>Mon, 15 Apr 2019 10:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/spikeai/</guid>
      <description>

&lt;h1 id=&#34;description&#34;&gt;Description&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Le projet SpikeAI est lauréat de l&amp;rsquo;&lt;a href=&#34;http://www.cnrs.fr/mi/spip.php?article1452&amp;amp;lang=fr&#34; target=&#34;_blank&#34;&gt;appel à projets 2019 &lt;em&gt;Biomimétisme&lt;/em&gt;&lt;/a&gt; :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The SpikeAI project targets analog computing for artificial intelligence in the form of Spiking Neural Networks (SNNs). Computer vision systems widely rely on artificial intelligence and especially neural network based machine learning, which recently gained huge visibility. The training stage for deep convolutional neural networks is time-consuming and yields enormous energy consumption. In contrast, the human brain has the ability to perform visual tasks with unrivaled computational and energy efficiency. It is believed that one major factor of this efficiency is the fact that information is vastly represented by short pulses (spikes) at analog –not discrete– times. However, computer vision algorithms using such representation still lack in practice, and its high potential is largely underexploited. Inspired from biology, the project addresses the scientific question of developing a low-power, end-to-end analog sensing and processing architecture. This will be applied on the particular context of a field programmable analog array (FPAA) applied to a stereovision system dedicated to coastal surveillance using an aerial robot of 3D visual scenes, running on analog devices, without a central clock and to validate them in real-life situations. The ambitious long-term vision of the project is to develop the next generation AI paradigm that will at term compete with deep learning. We believe that neuromorphic computing, mainly studied in EU countries, will be a key technology in the next decade. It is therefore both a scientific and strategic challenge for France and EU to foster this technological breakthrough. &lt;em&gt;This call will help kickstart collaboration within this European consortium to help leverage the chance to successfully apply to future large-scale grant proposals (e.g. ANR, CHIST-ERA, ERC).&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Get &lt;a href=&#34;https://spikeai.github.io/&#34; target=&#34;_blank&#34;&gt;more information&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ANR BalaV1 (2013/2016)</title>
      <link>https://laurentperrinet.github.io/project/anr-bala-v1/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-bala-v1/</guid>
      <description>

&lt;h1 id=&#34;anr-balav1-balanced-states-in-area-v1-2013-2016&#34;&gt;ANR BalaV1: Balanced states in area V1 (&lt;sup&gt;2013&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2016&lt;/sub&gt;)&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.agence-nationale-recherche.fr/Project-ANR-13-BSV4-0014&#34; target=&#34;_blank&#34;&gt;Official website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In carnivores and primates the orientation selectivity (OS) of the cells in the primary visual cortex (V1) is organized in maps in which preferred orientations (POs) of the cells change gradually except near “pin- wheels”, around which all orientations are present. Over the last half-century the mechanism for OS has been hotly debated. However the theories that purport to explain OS have almost all considered cortical networks in which the neurons receive input preferentially from cells with similar PO. Such theories certainly capture the connectivity for neurons in orientation domains where neurons are surrounded by other cells with similar PO. However this does not necessarily hold near pinwheels: because of the discontinuous change in orientation preference at the pinwheel, neurons in this area are surrounded by cells of all preferred orientations. Thus if the probability of connection is solely dependent on anatomical distance, the inputs that these neurons receive should represent all orientations by roughly the same amount. Thus one may expect that the response of the cells near pinwheels should hardly vary with orientation, in contrast to experimental data. As a result, the common belief is that, at least near pinwheels, the connectivity depends also on the differences between preferred orientation. The situation near pinwheels in V1 of carnivores and primates is similar to that in the whole of V1 of rodents. In these species, neurons in V1 are OS but the network does not exhibit an orientation map and the surround of the cells represents all orientations roughly equally. In a recent theoretical paper (Hansel and van Vreeswijk 2012) we have demonstrated that in this situation, the response of the cells can still be orientation selective provided that the network operates in the balanced regime. Here we hypothesize that V1 with an orientation map operates in the balanced regime and therefore neurons can exhibit OS near pinwheels even in the absence of functional specific connectivity. The goal of this interdisciplinary project is to investigate whether the “balance hypothesis” holds for layer &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; in V1 of primate and carnivore and whether the functional organization observed in that layer can be accounted for without feature specific connectivity. We will combine modeling and experiments to investigate how the response of the neurons – the mean firing, the mean voltage, the inhibitory and excitatory conductances and importantly, the power spectrum of their fluctuations – vary with the location in the map, and also how a population of neurons – LFP, voltage-sensitive dye imaging or 2 photons – is affected by the various para- meters used to test the system. Whether V1 indeed operates in the balanced regime in more realistic conditions will be further investigated by determining how the local network responds to visual stimuli beyond the classical receptive field. We will investigate this issue in models of layer &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; representing multiple hyper- columns to characterize center-surround interactions and their dependence on the long-range connectivity. This will provide us with predictions for center-surround interactions for cells near pinwheels and in orientation domains. These predictions will be tested experimentally.&lt;/p&gt;

&lt;p&gt;The proposed project is new and ambitious. It aims at building a comprehensive and coherent understand- ing of the physiology of V1 layer &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; on several spatial scales from single cells to several hypercolumns and to account for this in mechanistic models. To accomplish these ambitious aims, we propose a combination of experimental and computational studies that take advantage of the unique strengths and the complementarity of expertise of 3 research teams. The Paris team has extensive experience in large-scale modeling of V1. The Toulouse and Marseille teams master both intra- and extracellular electrophysiology. In addition, the Marseille team is expert in microscopic and mesoscopic imaging techniques in V1.&lt;/p&gt;

&lt;p&gt;Acknowledgement&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This work was supported by ANR project &amp;quot;BalaV1&amp;quot; N° ANR-13-BSV4-0014-02.  
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR CausaL (2018/2022)</title>
      <link>https://laurentperrinet.github.io/project/anr-causal/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-causal/</guid>
      <description>&lt;p&gt;Humans have an extraordinary capacity to infer cause-effect relations. In particular, we excel in forming ​beliefs ​about the ​causal effect of actions​. Causal learning provides the basis for rational decision-making and allows people to engage in meaningful life and social interactions. Causal learning is a form of goal-directed learning, defined as the capacity to rapidly learn the consequence of actions and to select behaviours according to goals and motivational state. This ability is based on internal models of the consequence of our behaviors​ and relies on learning rules determined by the​ contingency between actions and outcomes​. At a first approximation, contingency Δ​P ​is operationalized as the difference between two conditional probabilities: i) P(O|A), the probability of outcome O given action A; ii) P(O|¬A), the probability of the outcome when the action is withheld. In everyday life, people perceive their actions as causing a given outcome if the contingency is positive, whereas they perceive them as preventing​ ​it​ ​if​ ​negative;​ ​when​ ​P(O|A)​ ​and​ ​P(O|¬A)​ ​are​ ​equal,​ ​people​ ​report​ ​no​ ​causal​ ​effect​​ ​. Despite the centrality of causal learning, a clear understanding of both the internal computations and neural substrates (the so-called ​cognitive architectures​) is currently missing. ​Our project will therefore address​ ​two​ ​key​ ​questions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;What are the key ​internal representations of causal beliefs and what are the ​computational processes​​ ​that​ ​enable​ ​their​ ​formation​ ​during​ ​learning?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How ​​are ​​internal​ ​representations​ ​and ​​computational​​ processes​ ​​implemented​ ​​in ​​the ​​brain? CausaL​ ​​will​ ​address​ ​these​ ​two​ ​objectives​ ​through​ ​two​ ​dedicated​ ​research​ ​work​ ​packages​ ​(WPs).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Acknowledgement&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This work was supported by ANR project ANR-18-AAPG–“CAUSAL, Cognitive Architectures of  Causal  Learning”.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR Horizontal-V1 (2017/2021)</title>
      <link>https://laurentperrinet.github.io/project/anr-horizontal-v1/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-horizontal-v1/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;Description on the official website of the &lt;a href=&#34;http://www.agence-nationale-recherche.fr/Project-ANR-17-CE37-0006&#34; target=&#34;_blank&#34;&gt;ANR&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Horizontal-V1 project aims at understanding the emergence of sensory predictions linking local shape attributes (orientation, contour) to global indices of movement (direction, speed, trajectory) at the earliest stage of cortical processing (primary visual cortex, i.e. V1). We will study how the long-distance &amp;ldquo;horizontal&amp;rdquo; connectivity, intrinsic to V1 and the feedback from higher cortical areas contribute to a dynamic processing of local-to-global features as a function of the context (eg displacement along a trajectory; during reafference change induced by eye-movements&amp;hellip;). We will search to characterize the dynamic processes based on lateral propagation intra-V1, through which spatio-temporal inferences (continuous movement or apparent motion sequences) facilitating spatial (&amp;ldquo;filling-in&amp;rdquo;) or positional (&amp;ldquo;flash-lag&amp;rdquo;) future expected responses may be generated. The project will use a variety of animations of local oriented stimuli forming, according to their spatial and temporal coherence, predictable global patterns, apparent motion sequences and/or continuous trajectories. We will measure the cortical dynamics at two scales of neuronal integration, from micro- (intracellular, SUA) to meso-scopic levels (multi-electrode arrays (MEA) and voltage sensitive dye imaging (VSDI)) in the anesthetized (cat, marmoset) and awake fixating animal (macaca mulata). In a second step, we will combine these multiscale observations to constrain a structuro-functional model of low-level perception, integrating the micro-meso constraints. Two laboratories will participate in synergy to the project: UNIC-Gif (Dir. Yves Frégnac, DRCE2 CNRS, coordinator) and INT-Marseille (NeOpTo Team Dir. Frédéric Chavane, DR2 CNRS).&lt;/p&gt;

&lt;h1 id=&#34;wp3-design-of-novel-visual-paradigms-probabilistic-model-of-v1-and-data-driven-simulations-co-lead-unic-int&#34;&gt;WP3 - Design of novel visual paradigms, probabilistic model of V1 and data-driven simulations - co lead UNIC-INT.&lt;/h1&gt;

&lt;p&gt;Objectives : This WP will have two primary goals. The first one is theoretically driven, and for sake of simplicity will ignore the dynamic features of neural integration (as expected from a statistical model of image analysis). Binding the different features of visual objects at the local scale (contours) as well as a more global level involves understanding the statistical regularities of the sensory inflow. In particular, titrating the predictions that can be done at the statistical level can be seen as a first pass to better search for critical parameters constraining the network behaviour. From these, we will build probabilistic predictive models optimized for edge co-occurrence classification and generate novel visual statistics 1) which obey rules imposed by the functional horizontal connectivity anisotropies, such as co- circularity, and 2) which facilitate binding in the orientation domain, such as log-polar planforms. These statistics generated in the first half of the grant will be implemented and tested experimentally in the second half of the grant. The second one is more data-driven (as well as phenomenological for feedback from higher cortical areas, since it will not be explored in the grant). Since model fitting will depend on close interactions with WP1 and WP2 measurements, it will be done in the second half of the grant.&lt;/p&gt;

&lt;h2 id=&#34;wp3-task-1-theoretically-oriented-workplan-lead-int-laurent-perrinet&#34;&gt;WP3-Task 1: Theoretically oriented workplan – Lead INT (Laurent Perrinet)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;WP3-Task 1.1 - theory : we will exploit our current expertise in integrating these statistics in the form of probabilistic models to make predictions both at the physiological and modelling levels. First, we will take advantage of our previous work on the quantification of the association field in different classes of natural images (Perrinet &amp;amp; Bednar, 2015). Using an existing library (&lt;a href=&#34;https://github.com/bicv/SparseEdges&#34; target=&#34;_blank&#34;&gt;https://github.com/bicv/SparseEdges&lt;/a&gt;), we will use the sparse representation of static natural images to compute histograms of edge co-occurrences. Using an existing algorithm for unsupervised learning (&lt;a href=&#34;https://github.com/bicv/SparseHebbianLearning&#34; target=&#34;_blank&#34;&gt;https://github.com/bicv/SparseHebbianLearning&lt;/a&gt;), we will learn the different independent components of edge co-occurrences. Such an algorithm fits well a traditional deep-learning convolutional neural network, but, in addition, will include constraints imposed by intra-layer horizontal connectivity. We expect that relevant features will be co-linear or co-circular pairs of edges, but also T-junctions or end-stopping features.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;WP3-Task 1.2 - image/film synthesis : We have previously found that random synthetic textures, coined &amp;ldquo;Motion Clouds&amp;rdquo;, can be used to quantify V1 implication in visual motion perception (Leon et al, 2012; Simoncini et al, 2012). Recently, the INT and UNIC, partners proved mathematically that these stimuli were optimal with respect to some common geometrical transformations, such as translation, zoom or rotations (Vacher et al, 2015). A main characteristic of these textures is to be generated with a maximally entropic arrangement of elementary textures (so-called textons).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;**        Informed by the generative model of edge co-occurrences studied in subtask 1, we will be able to extend the family of motion cloud stimuli (Leon et al, 2012; Simoncini et al, 2012) to include joint dependencies between different elements in position or orientation. An exact solution to this problem is hard to achieve as it involves a combinatorial search of all possible combinations of pairs of edges. However, numerous variational approaches are possible and fit well with our probabilistic framework. We will use the convolutional neural network described above but using a back-propagating stream to generate different images. Such a representation will then be optimized using an unsupervised learning method. This is similar to the process used in Generative Adversarial Networks in deep-learning architectures (Radford et al, Archives).
**        Finally, the regularities observed in static images will be extended to dynamical scenes by observing that a co-occurrence can be implemented by simple geometrical operations as they are operated in time. For instance a co-circularity is easily described as the set of smooth roto-translational transformations of an edge in time using the group of Galilean transformations (Sarti and Citti, 2006). This theory calls for a first prediction to understand the set of whole possible spatio-temporal co-occurrences of edges as geodesics in the lifted space of all possible trajectories. We predict that such decomposition should allow us to better understand the different classes of features that emerged in the first task.
*    WP3-Task 1.3 - Feedback of theory on experimentation : An essential aspect of this work would be to apply these stimuli in neurophysiological experiments and in the modelling. In particular, the ability to select different types of dependencies from the different classes learned above (for instance, co-circularities of a certain curvature range) will make it possible to evaluate the relative contribution of different components of the contextual information. This justifies the fact that the WP3 post-doctoral fellow should have the mobility (between INT and UNIC) and multi-disciplinar profile (theoretical and experimental) to perform this task.
*    WP3-Task 1.4 - Generic modelling : These various subtasks will allow us to determine the hierarchy of critical features relevant to describe the full statistics of the space of spatio-temporal edge co-occurrences. Indeed, in static images, we will be able to find independent component in the histograms of edge co-occurrences between metric aspect (distance or scale between edge) from configurational aspects (difference of angle or co-circularity angle).&lt;/p&gt;

&lt;p&gt;Similarly, we expect to see that the different independent features should decompose at various scales both in space and in time. For instance, we expect configurational aspects to be more local while aspects related to a motion (Perrinet and Masson, 2012; Khoei et al, 2016) or global shape (form) should be more global. This translates into a probabilistic hierarchical model that would combine dependencies from different cues. In particular, through the emergence of differential pathways for form and motion. These quantitative predictions should finally be confronted at the modelling and neurophysiological levels.&lt;/p&gt;

&lt;h2 id=&#34;wp3-task-2-data-driven-comprehensive-model-of-v1-co-lead-unic-and-int&#34;&gt;WP3-Task 2 : Data-driven comprehensive model of V1 – Co-lead UNIC and INT&lt;/h2&gt;

&lt;p&gt;The second task is more data-driven (as well as phenomenological for the feedback circuit part, since largely unknown). Since simulations will depend on close interactions with WP1 and WP2 measurements, it will be developed by the WP3-Post-Doc in the second half of the grant. It will benefit from existing structuro-functional models addressing separately two distinct levels of neural integration, microscopic (conductance-based in Kremkow et al, 2016; Antolik et al, submitted, Chariker et al, 2016) and mesoscopic (VSD-like mean field in Rankin and Chavane, 2017). Efforts will be made to merge these models to fit - in a unified multiscale biologically realistic model - the cellular and VSD data targeting critically horizontal propagation. The parameterization should be flexible enough to produce a generic cortical architecture accounting possibly for species-specificity (Antolik for cat; Chaliker for monkey)&lt;/p&gt;

&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;

&lt;p&gt;This work was supported by ANR project &amp;ldquo;Horizontal-V1&amp;rdquo; N° ANR-17-CE37-0006.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ANR PredictEye (2018/2022)</title>
      <link>https://laurentperrinet.github.io/project/anr-predicteye/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-predicteye/</guid>
      <description>&lt;p&gt;The objectives of PREDICTEYE is to rigorously test and define the functional and neurophysiological grounds of probabilistic oculomotor internal models by investigating the multiple timescales at which the trajectory of a moving target is learned and represented in a probabilistic framework (Aim #1). Second, we will investigate the role of (pre)frontal oculomotor networks in building such probabilistic representations and their impact upon two of their downstream neural targets of the brainstem premotor centers (superior colliculus for saccades; NRTP for pursuit) (Aim #2). Our third objective is to model and simulate the dynamics of target motion prediction and eye movement performance. A key question is to unveil how probabilistic information about target timing and motion (i.e. direction and speed) is sampled over trial history by neuronal populations and integrated with Prior knowledge (i.e. sequence properties and rules of conditional probabilities) in order to coordinate saccades and pursuit and optimize their precisions (Aim #3).&lt;/p&gt;

&lt;p&gt;Acknowledgement&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This work was supported by ANR project &amp;quot;PredictEye&amp;quot; ANR-XXXX.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR REM (2013/2016)</title>
      <link>https://laurentperrinet.github.io/project/anr-rem/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-rem/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://static.tvtropes.org/pmwiki/pub/images/R.E.M..jpg&#34; target=&#34;_blank&#34;&gt;http://static.tvtropes.org/pmwiki/pub/images/R.E.M..jpg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Reinforcement learning theory provides a general conceptual framework to account for behavioral changes. Recently the idea that reinforcement may be used to explain learning in motor responses has emerged. In particular, there is a growing interest in studying the effects of reinforcement learning in arm movements trajectories (Dam, Kording, &amp;amp; Wei, 2013), pointing movements (Trommershauser, Landy, &amp;amp; Maloney, 2006), or eye movements (Madelain, Champrenaut, &amp;amp; Chauvin, 2007; Madelain &amp;amp; Krauzlis, 2003b; Madelain, Paeye, &amp;amp; Wallman, 2011; Sugrue, Corrado, &amp;amp; Newsome, 2004; Takikawa, Kawagoe, Itoh, Nakahara, &amp;amp; Hikosaka, 2002; Xu-Wilson, Zee, &amp;amp; Shadmehr, 2009). However, and despite these few seminal studies, much is still unknown about both the details of the effects of reward on motor control and the underlying mechanisms. &lt;strong&gt;This proposal aims at a better understanding of how skilled motor responses are learned focusing on voluntary eye movements.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Although learning is often regarded as a restricted period of time during which a behavior undergo some changes we view learning as a continuously ongoing process. In the case of motor control every instance of a behavior is followed by some consequences that will affect some dimensions of the future response. These changes will in return affect the functional relations with the environment and this feedback process continues through lifetime. Therefore we do not regard motor learning as a special phase that allows the emergence of a particular motor response but as a continuous adaptation to the changes within the organism that affect the functional relations with her environment. This distinction is important because the learning situations that are experimentally tested over a short period of time may then be viewed as a condensed version of motor learning in the real life: the same adaptive processes are responsible for the changes in the response in both situations.&lt;/p&gt;

&lt;p&gt;An important aspect of this fundamental research project is that the theoretical propositions addressed provide a new view on motor learning that departs from conventional wisdom. We expect to gain considerable knowledge on learning by constructing new experimental paradigms to collect behavioural data, implementing new learning models based on Bayesian theories and testing dynamical mathematical models of behavioural changes. &lt;strong&gt;Whichever way the results turn out, we anticipate that these studies will provide a better understanding of motor learning and provide a well-defined and solid framework for studying other forms of motor plasticity.&lt;/strong&gt; If eye movement learning follows the rules of other operant responses (i.e. responses reinforced by their consequences), this will constitute a minor revolution in the study of motor control, both at the behavioral and neural levels, with important implications for the understanding of plasticity in other motor systems.&lt;/p&gt;

&lt;p&gt;Acknowledgement&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This work was supported by ANR project ANR-13-APPR-0008 &amp;quot;ANR R.E.M.&amp;quot;.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR SPEED (2013/2016)</title>
      <link>https://laurentperrinet.github.io/project/anr-speed/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-speed/</guid>
      <description>&lt;p&gt;Measuring speed and direction of moving objects is an essential computational step in order to move our eyes, hands or other body parts with respect to the environment. Whereas encoding and decoding of direction information is now largely understood in various neuronal systems, how the human brain accurately represents speed information remains largely unknown. Speed tuned neurons have been identified in several early cortical visual areas in monkeys. However, how such speed tuning emerges is not yet understood. A working hypothesis is that speed tuned neurons nonlinearly combine motion information extracted at different spatial and temporal scales, taking advantage of the statistical spatiotemporal properties of natural scenes. However, such pooling of information must be context dependent, varying with the spatial perceptual organization of the visual scenes. Furthermore, the population code underlying perceived speed is not elucidated either and therefore we are still far from understanding how speed information is decoded to drive and control motor responses or perceptual judgments.&lt;/p&gt;

&lt;p&gt;Recently, we have proposed that speed estimation is intrinsically a multi-scale, task-dependent problem (Simoncini et al., Nature Neuroscience 2012) and we have defined a new set of motion stimuli, constructed as random phase dynamical textures that mimic the statistics of natural scenes (Sanz-Leon et al., Journal of Neurophysiology 2012). This approach has proved to be fruitful to investigate nonlinear properties of motion integration.&lt;/p&gt;

&lt;p&gt;The current proposal brings together psychophysicists, oculomotor scientists and modelers to investigate speed processing in human. We aim at expanding this framework in order to understand how tracking eye movements and motion perception can take advantage of multiple scale processing for estimating target speed. We will design sets of high dimensional stimuli by extending our generative model. Using these natural-statistics stimuli, we will investigate how speed information is encoded by computing motion energy across different spatial and temporal filters. By analysing both perceptual and oculomotor responses we will probe the nonlinear mechanisms underlying the integration of the outputs of multiple spatiotemporal filters and implement these processes in a refined version of our model. Furthermore, we will test our working hypothesis that in natural scenes such nonlinear integration provides precise and reliable motion estimates, which leads to efficient motion-based behaviors. By comparing tracking responses with perception, we will also test a second critical hypothesis, that nonlinear speed computations are task-dependent. In particular, we will explore the extent to which the geometrical structures of visual scenes are decisive for perception beyond the motion energy computation used for early sensorimotor transformation. Finally we will investigate the role of contextual and extra-retinal, predictive information in building an efficient dynamic estimate of objects&amp;rsquo; speed for perception and action.&lt;/p&gt;

&lt;p&gt;Acknowledgement&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This work was supported by ANR project &amp;quot;ANR Speed&amp;quot; ANR-13-BSHS2-0006.    
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ANR TRAJECTORY (2016/2019)</title>
      <link>https://laurentperrinet.github.io/project/anr-trajectory/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/anr-trajectory/</guid>
      <description>

&lt;p&gt;Global motion processing is a major computational task of biological visual systems. When an object moves across the visual field, the sequence of visited positions is strongly correlated in space and time, forming a trajectory. These correlated images generate a sequence of local activation of the feed-forward stream. Local properties such as position, direction and orientation can be extracted at each time step by a feed-forward cascade of linear filters and static non-linearities. However such local, piecewise, analysis ignores the recent history of motion and faces several difficulties, such as systematic delays, ambiguous information processing (e.g., aperture and correspondence problems61) high sensitivity to noise and segmentation problems when several objects are present. Indeed, two main aspects of visual processing have been largely ignored by the dominant, classical feed-forward scheme. First, natural inputs are often ambiguous, dynamic and non-stationary as, e.g., objects moving along complex trajectories. To process them, the visual system must segment them from the scene, estimate their position and direction over time and predict their future location and velocity. Second, each of these processing steps, from the retina to the highest cortical areas, is implemented by an intricate interplay of feed-forward, feedback and horizontal interactions1. Thus, at each stage, a moving object will not only be processed locally, but also generate a lateral propagation of information. Despite decades of motion processing research, it is still unclear how the early visual system processes motion trajectories. We, among others, have proposed that anisotropic diffusion of motion information in retinotopic maps can contribute resolving many of these difficulties25 13. Under this perspective, motion integration, anticipation and prediction would be jointly achieved through the interactions between feed-forward, lateral and feedback propagations within a common spatial reference frame, the retinotopic maps.&lt;/p&gt;

&lt;p&gt;Addressing this question is particularly challenging, as it requires to probe these sequences of events at multiple scales (from individual cells to large networks) and multiple stages (retina, primary visual cortex (V1)). “TRAJECTORY” proposes such an integrated approach. Using state-of-the-art micro- and mesoscopic recording techniques combined with modeling approaches, we aim at dissecting, for the first time, the population responses at two key stages of visual motion encoding: the retina and V1. Preliminary experiments and previous computational studies demonstrate the feasibility of our work. We plan three coordinated physiology and modeling work-packages aimed to explore two crucial early visual stages in order to answer the following questions: How is a translating bar represented and encoded within a hierarchy of visual networks and for which condition does it elicit anticipatory responses? How is visual processing shaped by the recent history of motion along a more or less predictable trajectory? How much processing happens in V1 as opposed to simply reflecting transformations occurring already in the retina?&lt;/p&gt;

&lt;p&gt;The project is timely because partners master new tools such as multi-electrode arrays and voltage-sensitive dye imaging for investigating the dynamics of neuronal populations covering a large segment of the motion trajectory, both in retina and V1. Second, it is strategic: motion trajectories are a fundamental aspect of visual processing that is also a technological obstacle in computer vision and neuroprostheses design. Third, this project is unique by proposing to jointly investigate retinal and V1 levels within a single experimental and theoretical framework. Lastly, it is mature being grounded on (i) preliminary data paving the way of the three different aims and (ii) a history of strong interactions between the different groups that have decided to join their efforts.&lt;/p&gt;

&lt;h2 id=&#34;the-marseille-team&#34;&gt;The Marseille team&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Frédéric Chavane (DR, CNRS, NEOPTO team) is working in the field of vision research for about 20 years with a special interest in the role of lateral interactions in the integration of sensory input in the primary visual cortex. His recent work suggest that lateral interactions mediated by horizontal intracortical connectivity participates actively in the input normalization that controls a wide range of function, from the contrast-response gain to the representation of illusory or real motion. His expertise range from microscopic (intracellular recordings) to mesoscopic (optical imaging, multi-electrode array) recording scales in the primary visual cortex of anesthetized and awake behaving animals.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Laurent Perrinet (CR, CNRS, NEOPTO team). His scientific interests focus on bridging computational understanding of neural dynamics and low-level sensory processing by focusing on motion perception. He is the author of papers in machine learning, computational neuroscience and behavioral psychology. One key concept is the use of statistical regularities from natural scenes as a main drive to integrate local neural information into a global understanding of the scene. In a recent paper that he coauthored (in Nature Neuroscience), he developed a method to use synthesized stimuli targeted to analyze physiological data in a system-identification approach.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ivo Vanzetta (CR, CNRS, NEOPTO team). His scientific interests focus on how to optimally use photonics-based imaging methods to investigate visual information processing in low-level visual areas, in the anesthetized and awake animal (rodent &amp;amp; primate). As can be seen from his bibliographic record, these methods include optical imaging of intrinsic signals and voltage sensitive dyes and, recently, 2 photon microscopy. Finally I. Vanzetta has an ongoing collaboration with L. Perrinet on the utilization of well-controlled, synthesized nature-like visual stimuli to probe the response characteristics of the primate&amp;rsquo;s visual system (Sanz-Leon &amp;amp; al. 2012).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;progress-meeting-anr-trajectory&#34;&gt;Progress meeting ANR TRAJECTORY&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Time    January 15th, 2018&lt;/li&gt;
&lt;li&gt;Location     INT&lt;/li&gt;
&lt;li&gt;General presentation of the grant, see &lt;a href=&#34;http://invibe.net/LaurentPerrinet/TagAnrTRAJECTORY&#34; target=&#34;_blank&#34;&gt;Anr TRAJECTORY&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Overview of my current projects    &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html&#34; target=&#34;_blank&#34;&gt;https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MotionClouds with trajectories    &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2018-01-16-testing-more-complex-trajectories.html&#34; target=&#34;_blank&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2018-01-16-testing-more-complex-trajectories.html&lt;/a&gt; or &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html&#34; target=&#34;_blank&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;




&lt;figure&gt;

&lt;img src=&#34;http://invibe.net/cgi-bin/index.cgi/Presentations/2012-04-16_InriaIntMeeting?action=AttachFile&amp;amp;do=get&amp;amp;target=sequence_ABCD.gif&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;em&gt;A predictive sequence is essential in resolving the coherence problem.&lt;/em&gt;  The sequence in which a set of local motion is shown is essential for the detection of global motion. we replicate here the experiments by Scott Watamaniuk and colleagues. They have shown behaviourally that a dot in noise is much more detectable when it follows a coherent trajectory, up to an order of magnitude of 10 times what would be predicted by the local components of the trajectory. In this  movie we observe white noise and at first sight, no information is detectable. In fact, there is a dot moving along some smooth linear trajectory. Since this is compatible with a predictive sequence, it is much easier to see the dot (from left to right in the top of the image, a smooth pursuit helps to catch it). This simple experiment shows that, even if local motion is similar in both movies, a coherent trajectory is more easy to track. Obviously, we may thus conclude that the whole trajectory is more that its individual parts, and that the independence hypothesis does not hold if we want to account for the predictive information in input sequences such as seems to be crucial for the AP.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;

&lt;p&gt;This work was supported by ANR project &amp;ldquo;TRAJECTORY&amp;rdquo; N° ANR-15-CE37-0011.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DOC2AMU (2016/2019)</title>
      <link>https://laurentperrinet.github.io/project/doc-2-amu/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/doc-2-amu/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://doc2amu.univ-amu.fr/en&#34; target=&#34;_blank&#34;&gt;DOC2AMU&lt;/a&gt; is co-funded by the prestigious Marie Skłodowska-Curie COFUND action within the H2020 Research and Innovation programme of the European Union and by the Regional Council of Provence-Alpes-Côte d’Azur, with a contribution from A*MIDEX Foundation.&lt;/p&gt;

&lt;p&gt;Within this programme, the PhD fellows will sign a three-year work contract with one of the 12 Doctoral Schools of AMU. Numerous advantages&lt;/p&gt;

&lt;p&gt;These PhD fellowships are remunerated above that of a standard French PhD contract with a gross monthly salary of 2600 € and a gross monthly mobility allowance of 300 €, which after standard deductions will amount to a net salary of approximately 1625€/month (net amount may vary slightly). A 500€ travel allowance per year and per fellow is also provided for the fellows to travel between Marseille and their place of origin. Tailored training and personalised mentoring: Fellows will define and follow a Personal Career Development Plan at the beginning of their Doctoral thesis and will have access to a variety of training options and workshops. Financial support for international research training and conferences participations. A contribution to the research costs will be provided for the benefit of the fellow.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;This work was supported by the Doc2Amu project which received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 713750. Projet cofinancé par le Conseil Régional Provence-Alpes-Côte d’Azur.Projet cofinancé par le Conseil Régional Provence-Alpes-Côte d’Azur, la commission européenne et les Investissements d&amp;rsquo;Avenir.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhD ICN (2017 / 2021)</title>
      <link>https://laurentperrinet.github.io/project/phd-icn/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/phd-icn/</guid>
      <description>

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;http://neuro-marseille.org/en/phd-program-en/&#34; target=&#34;_blank&#34;&gt;Ph.D. program in Integrative and Clinical Neuroscience&lt;/a&gt; (Aix-Marseille University) is offering in 2017 three Ph.D. scholarships to Master students graduated from highly ranked international universities (outside France). We were awarded with one PhD position for Angelo Franciosini at the &amp;ldquo;Institut de Neurosciences de la Timone&amp;rdquo; (team &amp;ldquo;Inference and Visual Behavior&amp;rdquo;), CNRS, Marseille (France) to study trajectories in natural images and the sensory processing of contours.&lt;/p&gt;

&lt;p&gt;##Funding&lt;/p&gt;

&lt;p&gt;This project is funded by the Aix-Marseille Université, which was awarded the prestigious status of &amp;ldquo;Excellence Initiative&amp;rdquo; (A*MIDEX) by the French Government and considering interdisciplinary studies as one of its main axes of growth. Within this program, the PhD fellow will sign a three-year work contract. They will enroll the ICN PhD program offering personalized follow-up to the students, a wide spectrum of scientific and professional training activities including specialized courses and career development activities and interactions with multi-disciplinary researchers at Aix-Marseille University and top world-wide visiting speakers, in a vibrant international community of students.&lt;/p&gt;

&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;

&lt;p&gt;This work was supported by the Ph.D. program in Integrative and Clinical Neuroscience (formerly &amp;ldquo;Ph.D. program in Integrative and Clinical Neuroscience&amp;rdquo;). It received funding by the Aix-Marseille Université through the prestigious status of &amp;ldquo;Excellence Initiative&amp;rdquo; (A*MIDEX) awarded by the French Government.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BrainScaleS (2011/2014) </title>
      <link>https://laurentperrinet.github.io/project/brain-scales/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/brain-scales/</guid>
      <description>&lt;p&gt;List of publications that were funded by European Union&amp;rsquo;s project Number FP7-269921, &amp;ldquo;&lt;a href=&#34;http://brainscales.kip.uni-heidelberg.de/&#34; target=&#34;_blank&#34;&gt;BrainScales&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;See also:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;http://facets.kip.uni-heidelberg.de&#34; target=&#34;_blank&#34;&gt;FACETS research project&lt;/a&gt; which
ended on 31 August 2010.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/project/facets-itn/&#34; target=&#34;_blank&#34;&gt;FACETS-ITN Marie-Curie&lt;/a&gt; initital
training network for graduate training continues until August 2013&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/project/brain-scales/&#34; target=&#34;_blank&#34;&gt;BrainScaleS project&lt;/a&gt; builds on
and extends the research done in FACETS. This 4 year project started
on January 1st, 2011.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>CODDE (2008/2012)</title>
      <link>https://laurentperrinet.github.io/project/codde/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/codde/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;http://www.optimaldecisions.org/&#34; target=&#34;_blank&#34;&gt;CODDE&lt;/a&gt; network studies the links between sensory input, brain activity and motor output. It does this by combining behavioural techniques, brain imaging, movement recording and computational modelling.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FACETS (2006/2010)</title>
      <link>https://laurentperrinet.github.io/project/facets/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/facets/</guid>
      <description>&lt;p&gt;List of publications that were funded by the
&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/&#34; class=&#34;http&#34;&gt;FACETS&lt;/a&gt;
project (more
&lt;a href=&#34;http://en.wikipedia.org/wiki/Facets_%28Science%29&#34; class=&#34;http&#34;&gt;info&lt;/a&gt;).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;also available on the FACET&amp;rsquo;s
&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/jss/Publications/author_Perrinet&#34; class=&#34;http&#34;&gt;website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See also:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;http://facets.kip.uni-heidelberg.de&#34; target=&#34;_blank&#34;&gt;FACETS research project&lt;/a&gt; which
ended on 31 August 2010.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/project/facets-itn/&#34; target=&#34;_blank&#34;&gt;FACETS-ITN Marie-Curie&lt;/a&gt; initital
training network for graduate training continues until August 2013&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/project/brain-scales/&#34; target=&#34;_blank&#34;&gt;BrainScaleS project&lt;/a&gt; builds on
and extends the research done in FACETS. This 4 year project started
on January 1st, 2011.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>FACETS-ITN (2010/2013)</title>
      <link>https://laurentperrinet.github.io/project/facets-itn/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/facets-itn/</guid>
      <description>

&lt;h1 id=&#34;facets-itn-from-neuroscience-to-neuro-inspired-computing-2010-2013&#34;&gt;FACETS-ITN: From Neuroscience to neuro-inspired computing (&lt;sup&gt;2010&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2013&lt;/sub&gt;)&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; class=&#34;http&#34;&gt;&lt;img src=&#34;http://facets.kip.uni-heidelberg.de/images/e/e3/Public--ITN_PositionsPoster2.png&#34; title=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; alt=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; class=&#34;external_image&#34; style=&#34;width:25.0%&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://facets.kip.uni-heidelberg.de/ITN/index.html&#34; class=&#34;http&#34;&gt;FACETS ITN&lt;/a&gt;
project (EU funding, grant number 237955) is a &amp;lsquo;Marie-Curie Initial
Training Network&amp;rsquo; involves 15 groups at European Research Universities,
Research Centers and Industrial Partners in 6 countries. 22 Ph.D.
Positions are funded in the FACETS-ITN project in the following
scientific work areas: Neurobiology of Cells and Networks, Modelling of
Neural Systems, Neuromorphic Hardware, Neuro-Electronic Interfaces,
Computational Principles in Neural Architectures, Mechanisms of Learning
and Plasticity. &lt;span id=&#34;line-8&#34; class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;span
id=&#34;line-9&#34; class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;See also:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;http://facets.kip.uni-heidelberg.de&#34; target=&#34;_blank&#34;&gt;FACETS research project&lt;/a&gt; which
ended on 31 August 2010.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/project/facets-itn/&#34; target=&#34;_blank&#34;&gt;FACETS-ITN Marie-Curie&lt;/a&gt; initital
training network for graduate training continues until August 2013&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://laurentperrinet.github.io/project/brain-scales/&#34; target=&#34;_blank&#34;&gt;BrainScaleS project&lt;/a&gt; builds on
and extends the research done in FACETS. This 4 year project started
on January 1st, 2011.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>PACE-ITN (2015/2019)</title>
      <link>https://laurentperrinet.github.io/project/pace-itn/</link>
      <pubDate>Mon, 27 Apr 2015 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/project/pace-itn/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;http://itn-pace.eu/&#34; target=&#34;_blank&#34;&gt;PACE ITN&lt;/a&gt; project involves over 50 researchers spread across 10 full and 5 associated partners, from academia and the private sector, established in 7 different European and Associated countries, the PACE network gathers a broad range of expertise from experimental psychology, cognitive neurosciences, brain imaging, technology and clinical sciences.&lt;/p&gt;

&lt;p&gt;The PACE Project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 642961&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
