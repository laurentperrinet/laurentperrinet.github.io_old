<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Laurent U Perrinet">

  
  
  
    
  
  <meta name="description" content="Researcher in Computational Neuroscience">

  
  <link rel="alternate" hreflang="en-us" href="https://laurentperrinet.github.io/tags/bayesian-model/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.dd629241ea9333c62c071f4a25f829ff.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-140381649-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="https://www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="/tags/bayesian-model/index.xml" type="application/rss+xml" title="Novel visual computations">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://laurentperrinet.github.io/tags/bayesian-model/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@laurentperrinet">
  <meta property="twitter:creator" content="@laurentperrinet">
  
  <meta property="og:site_name" content="Novel visual computations">
  <meta property="og:url" content="https://laurentperrinet.github.io/tags/bayesian-model/">
  <meta property="og:title" content="Bayesian model | Novel visual computations">
  <meta property="og:description" content="Researcher in Computational Neuroscience"><meta property="og:image" content="https://laurentperrinet.github.io/img/hulk.png">
  <meta property="twitter:image" content="https://laurentperrinet.github.io/img/hulk.png"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2019-01-01T00:00:00&#43;02:00">
  

  


  





  <title>Bayesian model | Novel visual computations</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"><img src="/img/hulk.png" alt="Novel visual computations"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people"><span>People</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Publications</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/#publications"><span>Recent Publications</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/"><span>All Publications</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/#2"><span>Publications in journals</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/#26"><span>Publications in books</span></a>
            </li>
            
          </ul>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Events</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/talk/"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/sciblog/" target="_blank" rel="noopener"><span>BlogBook</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  












  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1 itemprop="name">Bayesian model</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
  <div>
    <h2><a href="/publication/perrinet-19-hulk/">An adaptive homeostatic algorithm for the unsupervised learning of visual features</a></h2>
    <div class="article-style">
      
      The formation of structure in the visual system, that is, of the connections between cells within neural populations, is by large an unsupervised learning process: the emergence of this architecture is mostly self-organized. In the primary visual …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-19/">The Philosophy and Science of Predictive Processing</a></h2>
    <div class="article-style">
      
      Within the central nervous system, visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by the necessity of being robust and …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/vacher-16/">Bayesian Modeling of Motion Perception using Dynamical Stochastic Textures</a></h2>
    <div class="article-style">
      
      A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-masson-perrinet-17/">The flash-lag effect as a motion-based predictive shift</a></h2>
    <div class="article-style">
      
      Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/pasturel-17-gdr/">Estimating and anticipating a dynamic probabilistic bias in visual motion direction</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-15-sfn/">Anticipating a moving target: role of vision and reinforcement</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/danion-15-sfn/">Eye tracking a self-moved target with complex hand-target dynamics</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-adams-friston-14/">Active inference, eye movements and oculomotor delays</a></h2>
    <div class="article-style">
      
      This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-04-25-kaplan-beijing/">Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-01-10-int-fest/">Axonal delays and on-time control of eye movements</a></h2>
    <div class="article-style">
      
      Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kaplan-khoei-14/">Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</a></h2>
    <div class="article-style">
      
      As it is confronted to inherent neural delays, how does the visual system create a coherent representation of a rapidly changing environment? In this paper, we investigate the role of motion-based prediction in estimating motion trajectories …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kaplan-13/">Anisotropic connectivity implements motion-based prediction in a spiking neural network</a></h2>
    <div class="article-style">
      
      Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-13-cns/">Motion-based prediction and development of the response to an &#39;on the way&#39; stimulus</a></h2>
    <div class="article-style">
      
       Based on Perrinet et al, 2012 See a followup in Khoei et al, 2013  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/adams-12/">Smooth Pursuit and Visual Occlusion: Active Inference and Oculomotor Control in Schizophrenia</a></h2>
    <div class="article-style">
      
      This paper introduces a model of oculomotor control during the smooth pursuit of occluded visual targets. This model is based upon active inference, in which subjects try to minimise their (proprioceptive) prediction error based upon posterior …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-27-fil/">Grabbing, tracking and sniffing as models for motion detection and eye movements</a></h2>
    <div class="article-style">
      
      Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-12-vision-at-ucl/">Motion-based prediction is sufficient to solve the aperture problem</a></h2>
    <div class="article-style">
      
      In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/masson-12-areadne/">Motion-based prediction is sufficient to solve the aperture problem</a></h2>
    <div class="article-style">
      
      In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-12-pred/">Motion-based prediction is sufficient to solve the aperture problem</a></h2>
    <div class="article-style">
      
      In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/friston-12/">Perceptions as Hypotheses: Saccades as Experiments</a></h2>
    <div class="article-style">
      
      If perception corresponds to hypothesis testing (Gregory, 1980); then visual searches might be construed as experiments that generate sensory data. In this work, we explore the idea that saccadic eye movements are optimal experiments, in which data …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-12-sfn/">Role of motion-based prediction in motion extrapolation</a></h2>
    <div class="article-style">
      
       Based on Perrinet et al, 2012 See a followup in Khoei et al, 2013  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2011-07-02-neuro-med-talk/">Propriétés émergentes d&#39;un modèle de prédiction probabiliste utilisant un champ neural</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/bogadhi-11/">Pursuing motion illusions: a realistic oculomotor framework for Bayesian inference</a></h2>
    <div class="article-style">
      
      Accuracy in estimating an object's global motion over time is not only affected by the noise in visual motion information but also by the spatial limitation of the local motion analyzers (aperture problem). Perceptual and oculomotor data demonstrate …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-11-ecvp/">Role of motion inertia in dynamic motion integration for smooth pursuit</a></h2>
    <div class="article-style">
      
       Based on Perrinet et al, 2012 See a followup in Khoei et al, 2013  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2010-12-17-tauc-talk/">Probabilistic models of the low-level visual system: the role of prediction in detecting motion</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2010-01-08-facets/">Models of low-level vision: linking probabilistic models and neural masses</a></h2>
    <div class="article-style">
      
       see this more recent talk @ UCL, London  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/bogadhi-10-vss/">A recurrent Bayesian model of dynamic motion integration for smooth pursuit</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-10-tauc/">Dynamical emergence of a neural solution for motion integration</a></h2>
    <div class="article-style">
      
       Based on Perrinet et al, 2012 See a followup in Khoei et al, 2013  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-10-areadne/">Dynamical emergence of a neural solution for motion integration</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-10-tauc/">Probabilistic models of the low-level visual system: the role of prediction in detecting motion</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-09-cosyne/">Decoding center-surround interactions in population of neurons for the ocular following response</a></h2>
    <div class="article-style">
      
      Short presentation of a large moving pattern elicits an Ocular Following Response (OFR) that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/barthelemy-08/">Dynamics of distributed 1D and 2D motion representations for short-latency ocular following</a></h2>
    <div class="article-style">
      
      Integrating information is essential to measure the physical 2D motion of a surface from both ambiguous local 1D motion of its elongated edges and non-ambiguous 2D motion of its features such as corners or texture elements. The dynamics of this …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-areadne/">Decoding the population dynamics underlying ocular following response using a probabilistic framework</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensorimotor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-a/">Modeling spatial integration in the ocular following response to center-surround stimulation using a probabilistic framework</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08/">What adaptive code for efficient spiking representations? A model for the formation of receptive fields of simple cells</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-07/">Dynamical Neural Networks: modeling low-level vision at short latencies</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in ocular following response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-07/">Bayesian modeling of dynamic motion integration</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-07-neurocomp/">Modeling spatial integration in the ocular following response using a probabilistic framework</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-07-b/">Visual tracking of ambiguous moving objects: A recursive Bayesian model</a></h2>
    <div class="article-style">
      
      Perceptual and oculomotor data demonstrate that, when the visual information about an object's motion differs on the local (edge-related) and global levels, the local 1D motion cues dominate initially, whereas 2D information takes progressively over …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-06-neurocomp/">Bayesian modeling of dynamic motion integration</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-neurocomp/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture problem). Perceptual and oculomotor …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2006-01-01-neurocomp/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture problem). Perceptual and oculomotor …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-05-a/">Dynamics of motion representation in short-latency ocular following: A two-pathways Bayesian model</a></h2>
    <div class="article-style">
      
      The integration of information is essential to measure the exact 2D motion of a surface from both local ambiguous 1D motion produced by elongated edges and local non-ambiguous 2D motion from features such as corners, end-points or texture elements. …
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-04-tauc/">Feature detection using spikes : the greedy approach</a></h2>
    <div class="article-style">
      
      A goal of low-level neural processes is to build an efficient code extracting the relevant information from the sensory input. It is believed that this is implemented in cortical areas by elementary inferential computations dynamically extracting the …
      
    </div>
  </div>
  

  

</div>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.16bbb3750feb7244c9bc409a5a4fe678.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&rsquo;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
