<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Laurent U Perrinet">

  
  
  
    
  
  <meta name="description" content="Researcher in Computational Neuroscience">

  
  <link rel="alternate" hreflang="en-us" href="https://laurentperrinet.github.io/tags/motion-detection/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.a9a796b4dba28c78fc94d2550173437e.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-140381649-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="/tags/motion-detection/index.xml" type="application/rss+xml" title="Novel visual computations">
  <link rel="feed" href="/tags/motion-detection/index.xml" type="application/rss+xml" title="Novel visual computations">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://laurentperrinet.github.io/tags/motion-detection/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@laurentperrinet">
  <meta property="twitter:creator" content="@laurentperrinet">
  
  <meta property="og:site_name" content="Novel visual computations">
  <meta property="og:url" content="https://laurentperrinet.github.io/tags/motion-detection/">
  <meta property="og:title" content="motion detection | Novel visual computations">
  <meta property="og:description" content="Researcher in Computational Neuroscience"><meta property="og:image" content="https://laurentperrinet.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2019-01-24T00:00:00&#43;02:00">
  

  


  





  <title>motion detection | Novel visual computations</title>

</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"><img src="/img/hulk.png" alt="Novel visual computations"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people"><span>People</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Publications</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/#publications"><span>Recent Publications</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/"><span>All Publications</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/#2"><span>Publications in journals</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/#26"><span>Publications in books</span></a>
            </li>
            
          </ul>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Events</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/talk/"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/sciblog/" target="_blank" rel="noopener"><span>BlogBook</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  












  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1 itemprop="name">motion detection</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
  <div>
    <h2><a href="/publication/ravello-19/">Speed-Selectivity in Retinal Ganglion Cells is Sharpened by Broad Spatial Frequency, Naturalistic Stimuli</a></h2>
    <div class="article-style">
      
      Motion detection represents one of the critical tasks of the visual system and has motivated a large body of research. However, it remains unclear precisely why the response of retinal ganglion cells (RGCs) to simple artificial stimuli does not â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/vacher-16/">Bayesian Modeling of Motion Perception using Dynamical Stochastic Textures</a></h2>
    <div class="article-style">
      
      A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/mansour-18-vss/">Speed uncertainty and motion perception with naturalistic random textures</a></h2>
    <div class="article-style">
      
      It is still not fully understood how visual system integrates motion energy across different spatial and temporal frequencies to build a coherent percept of the global motion under the complex, noisy naturalistic conditions. We addressed this â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/pasturel-17-gdr/">Estimating and anticipating a dynamic probabilistic bias in visual motion direction</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/mansour-17-ecvp/">How the dynamics of human smooth pursuit is influenced by speed uncertainty</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/mansour-17-gdr/">Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</a></h2>
    <div class="article-style">
      
       The properties of motion processing for driving smooth eye movements have bee investigated using simple, artificial stimuli such as gratings, small dots or random dot patterns. Motion processing in the context of complex, natural images is less â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/mansour-16-ecvp/">Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/mansour-16-gdr/">Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/mansour-16-sfn/">Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-adams-friston-14/">Active inference, eye movements and oculomotor delays</a></h2>
    <div class="article-style">
      
      This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-14-vss/">Motion-based prediction model for flash lag effect</a></h2>
    <div class="article-style">
      
      The flash lag effect (FLE) is a well known visual illusion that reveals the perceptual difference in position coding of moving and stationary flashed objects. It has been reproduced experimentally in retina and V1 along with some relevant evidences â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-14-vss/">The characteristics of microsaccadic eye movements varied with the change of strategy in a match-to-sample task</a></h2>
    <div class="article-style">
      
      Under natural viewing conditions, large eye movements are interspace by small eye movements (microsaccade). Recent works have shown that these two kinds of eye movements are generate by the same oculomotor mechanisms (Goffart et al., 2012) and are â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-04-25-kaplan-beijing/">Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-01-10-int-fest/">Axonal delays and on-time control of eye movements</a></h2>
    <div class="article-style">
      
      Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kaplan-khoei-14/">Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</a></h2>
    <div class="article-style">
      
      As it is confronted to inherent neural delays, how does the visual system create a coherent representation of a rapidly changing environment? In this paper, we investigate the role of motion-based prediction in estimating motion trajectories â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-13-jpp/">Motion-based prediction explains the role of tracking in motion extrapolation</a></h2>
    <div class="article-style">
      
      During normal viewing, the continuous stream of visual input is regularly interrupted, for instance by blinks of the eye. Despite these frequents blanks (that is the transient absence of a raw sensory source), the visual system is most often able to â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kaplan-13/">Anisotropic connectivity implements motion-based prediction in a spiking neural network</a></h2>
    <div class="article-style">
      
      Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-13-vss/">Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception</a></h2>
    <div class="article-style">
      
      The visual system does not process information instantaneously, but rather integrates over time. Integration occurs both for stationary objects and moving objects, with very similar time constants (Burr, 1981). We measured, as a function of exposure â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/khoei-13-cns/">Motion-based prediction and development of the response to an &#39;on the way&#39; stimulus</a></h2>
    <div class="article-style">
      
       Based on Perrinet et al, 2012 See a followup in Khoei et al, 2013  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/adams-12/">Smooth Pursuit and Visual Occlusion: Active Inference and Oculomotor Control in Schizophrenia</a></h2>
    <div class="article-style">
      
      This paper introduces a model of oculomotor control during the smooth pursuit of occluded visual targets. This model is based upon active inference, in which subjects try to minimise their (proprioceptive) prediction error based upon posterior â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/masson-12/">The behavioral receptive field underlying motion integration for primate tracking eye movements</a></h2>
    <div class="article-style">
      
      Short-latency ocular following are reflexive, tracking eye movements that are observed in human and non-human primates in response to a sudden and brief translation of the image. Initial, open-loop part of the eye acceleration reflects many of the â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-27-fil/">Grabbing, tracking and sniffing as models for motion detection and eye movements</a></h2>
    <div class="article-style">
      
      Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-12-vision-at-ucl/">Motion-based prediction is sufficient to solve the aperture problem</a></h2>
    <div class="article-style">
      
      In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-12-vss/">Effect of image statistics on fixational eye movements</a></h2>
    <div class="article-style">
      
      Under natural viewing conditions, small movements of the eyes prevent the maintenance of a steady direction of gaze. It is unclear how the spatiotemporal content of the fixated scene has an impact on the properties of miniatures, fixational eye â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-12-coding/">Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.</a></h2>
    <div class="article-style">
      
      To measure speed and direction of moving objects, the cortical motion system pools information across different spatiotemporal channels. One yet unsolved question is to understand how the brain pools this information and whether this pooling is â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-12/">More is not always better: dissociation between perception and action explained by adaptive gain control</a></h2>
    <div class="article-style">
      
      Moving objects generate motion information at different scales, which are processed in the visual system with a bank of spatiotemporal frequency channels. It is not known how the brain pools this information to reconstruct object speed and whether â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-11-vss/">Pattern discrimination for moving random textures: Richer stimuli are more difficult to recognize</a></h2>
    <div class="article-style">
      
      In order to analyze the characteristics of a rich dynamic visual environment, the visual system must integrate information collected at different scales through different spatiotemporal frequency channels. Still, it remains unclear how reliable â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-2011-pattern/">Pattern discrimination for moving random textures: Richer stimuli are more difficult to recognize</a></h2>
    <div class="article-style">
      
      In order to analyze the characteristics of a rich dynamic visual environment, the visual system must integrate information collected at different scales through different spatiotemporal frequency channels. Still, it remains unclear how reliable â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2011-07-02-neuro-med-talk/">PropriÃ©tÃ©s Ã©mergentes d&#39;un modÃ¨le de prÃ©diction probabiliste utilisant un champ neural</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/fleuriet-11/">Saccadic foveation of a moving visual target in the rhesus monkey</a></h2>
    <div class="article-style">
      
      When generating a saccade toward a moving target, the target displacement that occurs during the period spanning from its detection to the saccade end must be taken into account to accurately foveate the target and to initiate its pursuit. Previous â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2010-12-17-tauc-talk/">Probabilistic models of the low-level visual system: the role of prediction in detecting motion</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2010-01-08-facets/">Models of low-level vision: linking probabilistic models and neural masses</a></h2>
    <div class="article-style">
      
       see this more recent talk @ UCL, London  
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-10-vss/">Different pooling of motion information for perceptual speed discrimination and behavioral speed estimation</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-10-areadne/">Dynamical emergence of a neural solution for motion integration</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-10-tauc/">Probabilistic models of the low-level visual system: the role of prediction in detecting motion</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-09-cosyne/">Decoding center-surround interactions in population of neurons for the ocular following response</a></h2>
    <div class="article-style">
      
      Short presentation of a large moving pattern elicits an Ocular Following Response (OFR) that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-09-vss/">Inferring monkey ocular following responses from V1 population dynamics using a probabilistic model of motion integration</a></h2>
    <div class="article-style">
      
      Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/barthelemy-08/">Dynamics of distributed 1D and 2D motion representations for short-latency ocular following</a></h2>
    <div class="article-style">
      
      Integrating information is essential to measure the physical 2D motion of a surface from both ambiguous local 1D motion of its elongated edges and non-ambiguous 2D motion of its features such as corners or texture elements. The dynamics of this â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-areadne/">Decoding the population dynamics underlying ocular following response using a probabilistic framework</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensorimotor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-a/">Modeling spatial integration in the ocular following response to center-surround stimulation using a probabilistic framework</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-07/">Dynamical Neural Networks: modeling low-level vision at short latencies</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in ocular following response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-07-a/">Dynamic inference for motion tracking</a></h2>
    <div class="article-style">
      
      When the visual information about an object's motion differs at the local level, the visuomotor system needs to integrate information across time to solve this ambiguity and converge to the final motion solution. For an oblique line moving â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-07-neurocomp/">Modeling spatial integration in the ocular following response using a probabilistic framework</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-fens/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-neurocomp/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture problem). Perceptual and oculomotor â€¦
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-05-a/">Dynamics of motion representation in short-latency ocular following: A two-pathways Bayesian model</a></h2>
    <div class="article-style">
      
      The integration of information is essential to measure the exact 2D motion of a surface from both local ambiguous 1D motion produced by elongated edges and local non-ambiguous 2D motion from features such as corners, end-points or texture elements. â€¦
      
    </div>
  </div>
  

  

</div>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3394a224b26ce58ff36f44c54743e0ab.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&rsquo;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
