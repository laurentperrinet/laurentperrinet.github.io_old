<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>events | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/tags/events/</link>
      <atom:link href="https://laurentperrinet.github.io/tags/events/index.xml" rel="self" type="application/rss+xml" />
    <description>events</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Mon, 21 Oct 2019 09:00:00 +0200</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/img/hulk.png</url>
      <title>events</title>
      <link>https://laurentperrinet.github.io/tags/events/</link>
    </image>
    
    <item>
      <title>Postdoc position on Visual computations using Spatio-temporal Diffusion Kernels and Traveling Waves</title>
      <link>https://laurentperrinet.github.io/post/2019-10-28_postdoc-position/</link>
      <pubDate>Mon, 21 Oct 2019 09:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-28_postdoc-position/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Applications are welcome for a post-doctoral position at INT-Marseille, France exploring novel visual computations using spatio-temporal diffusion kernels and travelling waves. More info @ &lt;a href=&#34;https://t.co/f6tUR8XW6y&#34;&gt;https://t.co/f6tUR8XW6y&lt;/a&gt; &lt;a href=&#34;https://t.co/odzckjtloa&#34;&gt;pic.twitter.com/odzckjtloa&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1188940039293751297?ref_src=twsrc%5Etfw&#34;&gt;October 28, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;Dear colleagues,&lt;/p&gt;
&lt;p&gt;Applications are welcome for a post-doctoral position at &lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34;&gt;INT&lt;/a&gt; in &lt;a href=&#34;https://en.wikipedia.org/wiki/Marseille&#34;&gt;Marseille&lt;/a&gt;, France. Your mission will be to explore novel visual computations using spatio-temporal diffusion kernels and traveling waves. The project is funded by the &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-horizontal-v1/&#34;&gt;ANR Horizontal V1&lt;/a&gt; grant (ANR-17-CE37-0006) from the French National Research Agency (ANR) and will be coordinated by &lt;a href=&#34;https://laurentperrinet.github.io/&#34;&gt;Laurent Perrinet&lt;/a&gt;, in collaboration with &lt;a href=&#34;https://www.mullerlab.ca&#34;&gt;Lyle Muller&lt;/a&gt; and &lt;a href=&#34;http://www.int.univ-amu.fr/spip.php?page=equipe&amp;amp;equipe=NeOpTo&amp;amp;lang=en&#34;&gt;Frédéric Chavane&lt;/a&gt; at INT and &lt;a href=&#34;http://neuro-psi.cnrs.fr/spip.php?article934&amp;amp;lang=fr&#34;&gt;Yves Frégnac&lt;/a&gt; and Jan Antolik at UNIC-NeuroPSI, Gif. We are seeking candidates with a strong background in machine learning, computer vision and computational neuroscience.&lt;/p&gt;
&lt;p&gt;For more information, visit &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-28_postdoc-position&#34;&gt;&lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-28_postdoc-position&#34;&gt;https://laurentperrinet.github.io/post/2019-10-28_postdoc-position&lt;/a&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The starting date is set to January 6th, 2020 but can be flexibly extended. To obtain further information or send applications (including a full CV, a letter of motivation, 2 reference names), please contact: &lt;a href=&#34;mailto:Laurent.Perrinet@univ-amu.fr&#34;&gt;&lt;a href=&#34;mailto:Laurent.Perrinet@univ-amu.fr&#34;&gt;Laurent.Perrinet@univ-amu.fr&lt;/a&gt;&lt;/a&gt;. The appointment is for 18 month. Applications are welcome immediately and until the end of year 2019.&lt;/p&gt;
&lt;p&gt;Thanks for distributing this announcement to potential candidates!&lt;/p&gt;
&lt;h1 id=&#34;detailed-description-visual-computations-using-spatiotemporal-diffusion-kernels-and-traveling-waves&#34;&gt;Detailed description: Visual computations using Spatio-temporal Diffusion Kernels and Traveling Waves&lt;/h1&gt;
&lt;p&gt;Biological vision is surprisingly efficient. To take advantage of this efficiency, Deep learning and convolutional neural networks (CNNs) have recently produced great advances in artificial computer vision. However, these algorithms now face multiple challenges: learned architectures are often not interpretable, disproportionally energy greedy, and often lack the integration of contextual information that seems optimized in biological vision and human perception. It is clear from recent advances in system and computational neuroscience that nonlinear, recurrent interactions in visual cortical networks are key to this efficiency (&lt;a href=&#34;#Tang18&#34;&gt;Tang et al., 2018&lt;/a&gt;; &lt;a href=&#34;#Kietzmann19&#34;&gt;Kietzmann et al., 2019&lt;/a&gt;). We will use inspiration from neurophysiology and brain imaging to resolve this apparent gap between traditional CNNs and biological visual systems.&lt;/p&gt;
&lt;p&gt;**In this post-doctoral project, we propose to address these major limitations by focusing on specific dynamical features of cortical circuits: &lt;em&gt;lateral diffusion of sensory-evoked traveling waves&lt;/em&gt; (&lt;a href=&#34;#Chavane2000&#34;&gt;Chavane et al., 2011&lt;/a&gt;; &lt;a href=&#34;#muller2018cortical&#34;&gt;Muller et al., 2018&lt;/a&gt;) and &lt;em&gt;dynamic neuronal association fields&lt;/em&gt; (&lt;a href=&#34;#Fr%C3%A9gnac2012&#34;&gt;Frégnac et al., 2012&lt;/a&gt;; &lt;a href=&#34;#Fr%C3%A9gnac2016&#34;&gt;Frégnac et al., 2016&lt;/a&gt;; &lt;a href=&#34;#gerard2016synaptic&#34;&gt;Gerard-Mercier et al., 2016&lt;/a&gt;)**. Indeed, the architecture of primary visual cortex (V1), the direct target of the feedforward visual flow, contains dense local recurrent connectivity with sparse long-range connections (&lt;a href=&#34;#Voges12&#34;&gt;Voges and Perrinet, 2012&lt;/a&gt;). Such connections add to the traditional convolutional kernels representing feedforward and local recurrent amplification a novel lateral interaction kernel within a single layer (across positions and channels). Less studied, but probably decisive in active vision, recurrent cortico-cortical loops add a level of distributed top-down complexity which participates to the lateral integration of sensory input and perceptual context (&lt;a href=&#34;#Keller2019&#34;&gt;Keller et al., 2019&lt;/a&gt;). Coupled with the continuous time dynamics of cortical circuits, this elaborate multiplexed architecture provides the conditions possible for generating information diffusion through traveling waves. Inspired by recent work in neuroscience uncovering the ubiquity of these waves during visual processing, we aim to design a self-supervised CNN that will exploit these dynamics for new applications in computer vision.&lt;/p&gt;
&lt;p&gt;The proposed work will be organized as a collaboration between two labs (INT, Marseille and UNIC, Gif) along three tasks to be integrated in a unified model:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The starting point will be to extend results of self-supervised learning that we have obtained on static, natural images (&lt;a href=&#34;#BoutinFranciosiniChavaneRuffierPerrinet19&#34;&gt;Boutin et al., 2019&lt;/a&gt;) showing in a recurrent cortical-like artificial CNN architecture the emergence of interactions which phenomenologically correspond to the &amp;ldquo;association field&amp;rdquo; described at the psychophysical (&lt;a href=&#34;#Field1993&#34;&gt;Field et al., 1993&lt;/a&gt;), spiking (&lt;a href=&#34;#Li2002&#34;&gt;Li and Gilbert, 2002&lt;/a&gt;) and synaptic (&lt;a href=&#34;#gerard2016synaptic&#34;&gt;Gerard-Mercier et al., 2016&lt;/a&gt;) levels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The central aim will be to develop a dynamical version of this feedback/lateral kernel in the context of the &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-horizontal-v1/&#34;&gt;ANR Horizontal-V1&lt;/a&gt; project, linking the two labs and confronted to their recent electrophysiological data pointing to different classes of spatio-temporal diffusion and different degree of anisotropies during apparent and continuous motion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The implementation of this kernel inspired by CNN theory will be compared with a biologically realistic models of the early visual system (&lt;a href=&#34;#Antolik2019&#34;&gt;Antolik et al., 2019&lt;/a&gt;), and simulations of the lateral diffusion kernel will be developed in collaboration with &lt;a href=&#34;http://antolik.net/&#34;&gt;Jan Antolik&lt;/a&gt;, external collaborator to the ANR grant.  In parallel, using tools linking neural activity to VSD imaging (&lt;a href=&#34;#muller2014stimulus&#34;&gt;Muller et al., 2014&lt;/a&gt;; &lt;a href=&#34;#Chemla2018&#34;&gt;Chemla et al., 2019&lt;/a&gt;), we will analyze at a more mesocopic level the role of observed traveling waves in forming efficient representations of the visual world.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;expected-profile-of-the-candidate&#34;&gt;Expected profile of the candidate&lt;/h2&gt;
&lt;p&gt;Candidates should have at least a PhD degree in the domain of computational neuroscience, physics, engineering or related, and a solid training in machine learning and computer vision.&lt;/p&gt;
&lt;p&gt;The candidate has to show good skills in computer science (programming skills, architecture understanding, git versioning, &amp;hellip;), and in image processing methods. Good command of programming tools (Python scripting) is required. Multidisciplinary background would be strongly appreciated and in particular an advanced knowledge in mathematics, for a deep understanding of signal processing methods, along with strong computational skills. The candidate needs to show a keen interest in neuroscience. It is a bonus if the candidate is curious about neuroscience and visual perception.&lt;/p&gt;
&lt;p&gt;The candidate has to fluently speak English to understand publications and to attend international conferences and workshops. The preferred candidate will have the ability to work autonomously, and needs to be flexible to comply with the working method of the supervisors.&lt;/p&gt;
&lt;h2 id=&#34;research-context&#34;&gt;Research context&lt;/h2&gt;
&lt;p&gt;This project is funded by the French National Research Agency (ANR) under the &lt;a href=&#34;https://laurentperrinet.github.io/grant/anr-horizontal-v1/&#34;&gt;ANR Horizontal V1&lt;/a&gt; grant (coordinator Y. Frégnac) which aims at understanding the emergence of sensory predictions linking local shape attributes (orientation, contour) to global indices of movement (direction, speed, trajectory) at the earliest stage of cortical processing (primary visual cortex, i.e. V1). The cross-talk between physiological and theoretical approaches will be fostered by the close collaboration with the teams of Frédéric Chavane at INT and Yves Frégnac at UNIC. The theoretical work will be performed in close collaboration with &lt;a href=&#34;https://www.mullerlab.ca/&#34;&gt;Lyle Muller&lt;/a&gt; (Western U) and Jan Antolik (Prague). The project will be primarily hosted at the &lt;a href=&#34;http://www.int.univ-amu.fr/?lang=en&#34;&gt;Institut de Neurosciences de la Timone&lt;/a&gt; in &lt;a href=&#34;https://en.wikipedia.org/wiki/Marseille&#34;&gt;Marseille&lt;/a&gt;, a lively town by the Mediterranean sea in the south of France, but the applicant will be asked also to show mobility to visit the other partner lab when needed.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Antolik, J, C Monier, Y Frégnac, AP Davison. (2019). &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/416156v1&#34;&gt;A comprehensive data-driven model of cat primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;BioRxiv&lt;/em&gt;, 416156.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Boutin, Victor, Angelo Franciosini, Frédéric Chavane, Franck Ruffier, and Laurent U Perrinet. (2019). &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1902.07651&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system.&lt;/a&gt;&amp;rdquo; &lt;em&gt;arXiv&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Chavane, F., C. Monier, V. Bringuier, P. Baudot, L. Borg-Graham, J. Lorenceau, and Y. Frégnac. 2000. &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;http://invibe.net/biblio_database_dyva/woda/data/att/7a9a.file.pdf&#34;&gt;The Visual Cortical Association Field: A Gestalt Concept or a Psychophysiological Entity?&lt;/a&gt;&amp;rdquo; &lt;em&gt;Frontiers in System Neuroscience&lt;/em&gt; 4(5): 1-26.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Chavane, F., Sharon, D., Jancke, D., Marre, O., Frégnac, Y. and Grinvald, A.  (2011). &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1016/S0928-4257(00)01096-2&#34;&gt;Lateral spread of orientation selectivity in V1 is controlled by intracortical cooperativity.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Physiology Paris&lt;/em&gt; 94 (5-6): 333&amp;ndash;42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Chemla, Sandrine, Alexandre Reynaud, Matteo diVolo, Yann Zerlaut, Laurent Perrinet, Alain Destexhe, and Frédéric Chavane. &lt;!-- raw HTML omitted --&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1523/JNEUROSCI.2792-18.2019&#34;&gt;Suppressive Waves Disambiguate the Representation of Long-Range Apparent Motion in Awake Monkey V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Neuroscience&lt;/em&gt; 39 (22) 4282-4298.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Field, D.J., Hayes, A. and Hess, R.F. (1993). &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1016/0042-6989(93)90156-Q&#34;&gt;Contour integration by the human visual system: Evidence for a local “association field”.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Vision Research&lt;/em&gt; 33 (2), pp. 173-193.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Frégnac, Y. (2012)  &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://hal.archives-ouvertes.fr/hal-01685152/&#34;&gt;Reading out the synaptic echoes of low-level perception in V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;European Conference in Computer Vision&lt;/em&gt; 486-495. Springer, Berlin, Heidelberg.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Frégnac, Y., Fournier, J., Gerard-Mercier, F., Monier, C., Carelli, P., , M., Troncoso, X. (2016).  &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://link-springer-com.insb.bib.cnrs.fr/content/pdf/10.1007%2F978-3-319-28802-4_4.pdf&#34;&gt;The Visual Brain: Computing Through Multiscale Complexity.&lt;/a&gt;&amp;rdquo; In &lt;em&gt;Micro-, Meso- and Macro-Dynamics of the Brain&lt;/em&gt; pp 43-57.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Gerard-Mercier, Florian, Pedro V Carelli, Marc Pananceau, Xoana G Troncoso, and Yves Frégnac. (2016). &lt;!-- raw HTML omitted --&gt; &amp;ldquo;&lt;a href=&#34;https://www.jneurosci.org/content/36/14/3925&#34;&gt;Synaptic Correlates of Low-Level Perception in V1.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Journal of Neuroscience&lt;/em&gt; 36 (14): 3925&amp;ndash;42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Keller, A., Roth, M.M. and Scanziani, M. (2019).  &lt;!-- raw HTML omitted --&gt; 2019. &amp;ldquo;&lt;a href=&#34;https://www.abstractsonline.com/pp8/#!/7883/presentation/65856&#34;&gt;The feedback receptive field of neurons in the mammalian primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;American Society for Neuroscience Abstracts&lt;/em&gt;,  403.13. Chicago.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Kietzmann, Tim C., Courtney J. Spoerer, Lynn K. A. Sörensen, Radoslaw M. Cichy, Olaf Hauk, and Nikolaus Kriegeskorte. &lt;!-- raw HTML omitted --&gt; (2019). &amp;ldquo;&lt;a href=&#34;https://doi.org/10/gf9j2t&#34;&gt;Recurrence Is Required to Capture the Representational Dynamics of the Human Visual System.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;, October, 201905544.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Li W, Piëch V, Gilbert CD&lt;!-- raw HTML omitted --&gt;  (2006). &amp;ldquo;&lt;a href=&#34;http://www.paper.edu.cn/scholar/showpdf/MUz2UN2INTA0eQxeQh&#34;&gt;Contour saliency in primary visual cortex.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Neuron&lt;/em&gt;, 50(6):951–962.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Muller, Lyle, Alexandre Reynaud, Frédéric Chavane, and Alain Destexhe. &lt;!-- raw HTML omitted --&gt; (2014). &amp;ldquo;&lt;a href=&#34;http://www.int.univ-amu.fr/IMG/pdf/Muller_Nature_Communications2014.pdf&#34;&gt;The Stimulus-Evoked Population Response in Visual Cortex of Awake Monkey Is a Propagating Wave.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Nature Communications&lt;/em&gt; 5: 3675.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Muller, Lyle, Frédéric Chavane, John Reynolds, and Terrence J Sejnowski. &lt;!-- raw HTML omitted --&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://papers.cnl.salk.edu/PDFs/Cortical%20travelling%20waves_%20mechanisms%20and%20computational%20principles.%202018-4515.pdf&#34;&gt;Cortical Travelling Waves: Mechanisms and Computational Principles.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Nature Reviews Neuroscience&lt;/em&gt; 19 (5): 255.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Tang, Hanlin, Martin Schrimpf, William Lotter, Charlotte Moerman, Ana Paredes, Josue Ortega Caro, Walter Hardesty, David Cox, and Gabriel Kreiman. &lt;!-- raw HTML omitted --&gt; (2018). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.1073/pnas.1719397115&#34;&gt;Recurrent computations for visual pattern completion.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt; 115 (35) 8835-8840.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt; Voges, Nicole, and Laurent U Perrinet.&lt;!-- raw HTML omitted --&gt; (2012). &amp;ldquo;&lt;a href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34;&gt;Complex Dynamics in Recurrent Cortical Networks Based on Spatially Realistic Connectivities.&lt;/a&gt;&amp;rdquo; &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt; 6.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-10-10: GDR vision 2019</title>
      <link>https://laurentperrinet.github.io/post/2019-10-10_gdrvision/</link>
      <pubDate>Thu, 10 Oct 2019 12:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-10_gdrvision/</guid>
      <description>&lt;p&gt;Avec Anna Montagnini, Manuel Vidal et Françoise Vitu, nous organisons cette année le GDR Vision à Marseille les journées du 10 et 11 octobre.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plus d&#39;infos sur &lt;a href=&#34;https://gdrvision2019.sciencesconf.org/&#34;&gt;https://gdrvision2019.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;nous aurons un atelier méthodologique le jeudi matin sur les apports possibles du Deep Learning pour les sciences de la vision: &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/&#34;&gt;Utiliser l&#39;apprentissage profond en vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;la session spéciale du jeudi est sponsorisée par la &lt;a href=&#34;https://laurentperrinet.github.io/project/spikeai/&#34;&gt;projet SpikeAI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Réunions passées:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lille: &lt;a href=&#34;https://gdrvision2017.sciencesconf.org/&#34;&gt;https://gdrvision2017.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Paris: &lt;a href=&#34;https://gdrvision2018.sciencesconf.org/&#34;&gt;https://gdrvision2018.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-10-10: Atelier Utiliser l&#39;apprentissage profond en vision</title>
      <link>https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/</link>
      <pubDate>Thu, 10 Oct 2019 09:30:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-10_gdrvision-atelier/</guid>
      <description>&lt;p&gt;Date : jeudi 10 octobre de 9h30 à 12h30&lt;/p&gt;
&lt;p&gt;Intervenants : Laurent Perrinet et Chloé Pasturel&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://gdrvision2019.sciencesconf.org/resource/page/id/2&#34;&gt;programme&lt;/a&gt;: Nous proposons dans cet atelier pratique de présenter les nouveaux enjeux apportés par l&#39;apprentissage profond et plus généralement par l&#39;apprentissage machine. L&#39;objectif est de montrer sous forme de simples exercises pratiques comment ces nouveaux outils permettent 1) de catégoriser des images 2) d&#39;apprendre un tel modèles 3) de générer de nouvelles images à partir d&#39;une base existante.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SpikeAI/2019-10-10_ML-tutorial&#34;&gt;https://github.com/SpikeAI/2019-10-10_ML-tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Atelier concocté en collaboration avec &lt;a href=&#34;https://github.com/chloepasturel&#34;&gt;Chloé Pasturel&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cet atelier fait partie du &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-10_gdrvision/&#34;&gt;GDR vision 2019&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-10-07: Le temps des sens</title>
      <link>https://laurentperrinet.github.io/post/2019-10-07_neurostories/</link>
      <pubDate>Mon, 07 Oct 2019 18:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-10-07_neurostories/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Chaque année, NeuroSchool nous raconte des histoires sur un thème à la fois philosophique et scientifique. L’objectif est de faire connaître, d’une manière inventive, les recherches de pointe menées à Marseille et ailleurs, dans le domaine des neurosciences. Le format inventif associe des NeuroStories et des causeries scientifiques.&amp;rdquo; &lt;a href=&#34;http://neuroschool-stories.com/&#34;&gt;http://neuroschool-stories.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2019-05-20: Symposium on Active Inference at NeuroFrance 2019</title>
      <link>https://laurentperrinet.github.io/post/2019-05-23-neurofrance/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2019-05-23-neurofrance/</guid>
      <description>&lt;h2 id=&#34;active-inference-bridging-theoretical-and-experimental-neurosciences--inference-active-un-pont-entre-neurosciences-thoriques-et-exprimentales&#34;&gt;Active Inference: Bridging theoretical and experimental neurosciences. / Inference Active: Un pont entre neurosciences théoriques et expérimentales.&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.neurosciences.asso.fr/V2/colloques/SN19/index_en.php&#34;&gt;&lt;img src=&#34;https://neuro-marseille.org/wp-content/uploads/2018/07/capture-decran-2018-07-06-a-190423.png&#34; alt=&#34;Site NeuroFrance&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SYMPOSIUM S17&lt;/li&gt;
&lt;li&gt;When: 23.05.2019 11:00-13:00h&lt;/li&gt;
&lt;li&gt;When: Endoume 1+2&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;s171httpswwwprofessionalabstractscomnf2019iplannerpresentation1397--active-inference-and-braincomputer-interfaces--infrence-active-et-interfaces-cerveaumachine&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1397&#34;&gt;S17.1&lt;/a&gt; 	Active inference and Brain-Computer Interfaces / Inférence active et interfaces cerveau-machine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Mattout J. (Lyon, France), Mladenovic J. (Lyon, France), Frey J. (Bordeaux, France)3, Joffily M. (Lyon, France), Maby E. (Lyon, France), Lotte F. (Lyon, France)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Brain-Computer Interfaces (BCIs) devices bypass natural pathways to connect the brain with a machine, directly. They may rely on invasive or non-invasive measures of brain activity and applications cover a large domain, mostly but not restricted to clinical ones. A major objective is to restore communication and autonomy in heavily motor impaired patients.
However, no BCI has made its way to a routinely used clinical application yet. One lead for improvement is to endow the machine with learning abilities so that it can optimize its decisions and adapt to changes in the user signals over time1. Several approaches have been proposed but a generic framework is still lacking to foster the development of efficient adaptive BCIs2.
Initially proposed to model perception, learning and action by the brain, the Active Inference (AI) framework offers great promises in that aim3. It rests on an explicit generative model of the environment. In BCI, from the machine&#39;s point of view, brain signals play the role of sensory inputs on which the machine&#39;s perception of mental states will be based. Furthermore, the machine builds up decisions and trades between different actions such as: go on observing, deciding to decide, correcting its previous action or moving on.
In this talk, I will present an instantiation of AI in the context of the EEG-based P300-speller BCI for communication, showing it can flexibly combine complementary adaptive features pertaining to both perception and action, and yield significant improvements as shown on realistic simulations. We will discuss perspectives to further extend the current model and performance as well as the challenges ahead to implement this framework online.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Mattout, J. Brain-Computer Interfaces: A Neuroscience Paradigm of Social Interaction? A Matter of Perspective. Frontiers in Human Neuroscience 6, (2012).&lt;/li&gt;
&lt;li&gt;Mladenovic, J., Mattout, J. &amp;amp; Lotte, F. A Generic Framework for Adaptive EEG-Based BCI Training and Operation. in Brain-computer interfaces handbook: technological and theoretical advances (eds. Nam, C. S., Nijholt, A. &amp;amp; Lotte, F.) Chapter 31 (Taylor &amp;amp; Francis, CRC Press, 2018).&lt;/li&gt;
&lt;li&gt;Friston, K., Mattout, J. &amp;amp; Kilner, J. Action understanding and active inference. Biological Cybernetics 104, 137-160 (2011).&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;s172httpswwwprofessionalabstractscomnf2019iplannerpresentation1398--comparing-active-inference-and-reinforcement-learning-models-of-a-go-nogo-task-and-their-relationships-to-striatal-dopamine-2-receptors-assessed-using-pet--comparaison-des-modles-dinfrence-active-et-dapprentissage-par-renforcement-dans-une-tche-go--nogo--relation-avec-les-rcepteurs-dopaminergiques-d2-striataux-valus-par-tep&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1398&#34;&gt;S17.2&lt;/a&gt; 	Comparing active inference and reinforcement learning models of a Go NoGo task and their relationships to striatal dopamine 2 receptors assessed using PET / Comparaison des modèles d&#39;inférence active et d&#39;apprentissage par renforcement dans une tâche Go / NoGo : relation avec les récepteurs dopaminergiques D2 striataux évalués par TEP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;R. Adams (London)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1398&#34;&gt;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1398&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Adaptive behaviour includes the ability to choose actions that result in advantageous outcomes. It is key to survival and a fundamental function of nervous systems. Active inference (AI) and reinforcement learning (RL) are two influential models of how the brain might achieve this. A key AI parameter is the precision of beliefs about policies. Precision controls the stochasticity of action selection - similar to decision temperature in RL - and is thought to be encoded by striatal dopamine. 75 healthy subjects performed a &amp;lsquo;go/no-go&amp;rsquo; task, and we measured striatal dopamine 2/3 receptor (D2/3R) availability in a subset of 25 using [11C]-(+)-PHNO positron emission tomography. In behavioural model comparison, RL performed best across the whole group but AI performed best in accurate subjects. D2/3R availability in the limbic striatum correlated with AI policy precision and also with RL irreducible decision &amp;lsquo;noise&amp;rsquo;. Limbic striatal D2/3R availability also correlated with AI Pavlovian prior beliefs - i.e. the respective probabilities of making or withholding actions in rewarding or loss-avoiding contexts - and the RL learning rate. These findings are consistent with the notion that occupancy of inhibitory striatal D2/3Rs controls the variability of action selection.&lt;/p&gt;
&lt;h3 id=&#34;s173httpswwwprofessionalabstractscomnf2019iplannerpresentation1399--principles-and-psychophysics-of-active-inference-in-anticipating-a-dynamic-switching-probabilistic-bias--principes-et-psychophysique-de-linfrence-active-dans-lestimation-dun-biais-dynamique-et-volatile-de-probabilit&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1399&#34;&gt;S17.3&lt;/a&gt; 	Principles and psychophysics of active inference in anticipating a dynamic, switching probabilistic bias / Principes et psychophysique de l&#39;inférence active dans l´estimation d&#39;un biais dynamique et volatile de probabilité&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;L. Perrinet (Marseille)&lt;/li&gt;
&lt;li&gt;see more info on this &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-05-23-neurofrance/&#34;&gt;talk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;s174httpswwwprofessionalabstractscomnf2019iplannerpresentation1400--is-laziness-contagious-a-computational-approach-to-attitude-alignment--la-fainantise-estelle-contagieuse-une-approche-computationnelle-de-lalignement-des-attitudes&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/1400&#34;&gt;S17.4&lt;/a&gt; 	Is laziness contagious? A computational approach to attitude alignment / La fainéantise est-elle contagieuse? Une approche computationnelle de l´alignement des attitudes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;J. Daunizeau (Paris)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What do people learn from observing others´ attitudes, such as prudence, impatience or laziness? Rather than viewing these attitudes as examples of subjective and biologically entrenched personality traits, we assume that they derive from uncertain (and mostly implicit) beliefs about how to best weigh risks, delays and efforts in ensuing cost-benefit trade-offs. In this view, it is adaptive to update one´s belief after having observed others´ attitude, which provides valuable information regarding how to best behave in related difficult decision contexts. This is the starting point of our bayesian model of attitude alignment, which we derive in the light of recent neuroimaging findings. First, we disclose a few non-trivial predictions from this model. Second, we validate these predictions experimentally by profiling people´s prudence, impatience and laziness both before and after guessing a series of cost-benefit arbitrages performed by calibrated artificial agents (which are impersonating human individuals). Third, we extend these findings and assess attitude alignment in autistic individuals. Finally, we discuss the relevance and implications of this work, with a particular emphasis on the assessment of biases of social cognition.&lt;/p&gt;
&lt;h3 id=&#34;s175httpswwwprofessionalabstractscomnf2019iplannerpresentation223--generative-bayesian-modeling-for-causal-inference-between-neural-activity-and-behavior-in-drosophila-larva&#34;&gt;&lt;a href=&#34;https://www.professionalabstracts.com/nf2019/iplanner/#/presentation/223&#34;&gt;S17.5&lt;/a&gt; 	Generative Bayesian modeling for causal inference between neural activity and behavior in Drosophila larva&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;C. Barre (Paris) (TBC)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A fundamental property of the central nervous system is its ability to select appropriate behavioral patterns or sequences of behavioral patterns in response to sensory cues, but what are the biological mechanisms underlying decision making? The Drosophila larva is an ideal animal model for reverse-engineering the neural processes underlying behavior. The full connectome of the larva brain has been imaged at the individual-synapse level using electron microscopy.
The host of genetic techniques available for Drosophila allows us to optogenetically manipulate over 1,500 of its roughly 12,000 neurons individually in freely behaving larvae.
This enables us to establish causal relationships between neural activity, and behavior at the fundamental level of individual neurons and neural connections.
We have access to video record of the individual behavior of ~3,000,000 larvae. We have identified 6 stereotypical behavioral patterns using a combination of supervised and unsupervised machine learning. The behavioral identified for the larva: crawl, turn, stop, crawl backward, hunch (retract the head), and roll (lateral slide). Each realization of a behavioral pattern is characterized by a different duration, amplitude, and velocity.
Here we present a generative model that extracts the behavior of wildtype larvae using Bayesian inference, and interprets behavioral changes following neuron activation or inactivation from large-scale experimental screens. Fig. shows the average behavior of 10,000 larvae over time in a screen where a single neuron is activated at t=30s. A clear change in behavior is seen following activation is seen which is well captured by the model, illustrating its accuracy.
The generative model enables us to robustly detect behavioral modifications as significant deviations of the patterns in the larvae&#39;s sequence of activities from their equilibrium behavior.&lt;/p&gt;
&lt;h3 id=&#34;neurofrance-marseille-capitale-des-neurosciences&#34;&gt;NeuroFrance: Marseille, capitale des neurosciences&lt;/h3&gt;
&lt;p&gt;Du  22 au 24 mai 2019 au Palais des congrès de Marseille (Parc Chanot), près de 1300 chercheurs, cliniciens et étudiants venus du monde entier partageront leurs travaux lors de NeuroFrance 2019, colloque international organisé par la Société des Neurosciences.Au total, 8 conférences plénières, 42 symposiums, 6 sessions spécialisées, 525 communications affichées, ainsi qu’une exposition avec 42 entreprises et sociétés de biotechnologies, feront de ce colloque un moment exceptionnel pour mettre en lumière les avancées majeures scientifiques et technologiques sur le fonctionnement du cerveau. Vous pourrez aussi découvrir le &amp;ldquo;Neurovillage&amp;rdquo; qui permettra de vous immerger au cœur des innovations neuroscientifiques marseillaises, ainsi que  l’exposition  « L’Art en tête », composée de cinq œuvres originales créées par des artistes et des scientifiques. Plusieurs événements seront également proposés autour du colloque pour le grand public comme pour les chercheurs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-11-09 : Retinal computations</title>
      <link>https://laurentperrinet.github.io/post/2018-11-09_seminaire-escobar/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/post/2018-11-09_seminaire-escobar/</guid>
      <description>&lt;h1 id=&#34;20181109--retinal-computations-by-maria-jos-escobar-chile&#34;&gt;2018-11-09 : &amp;ldquo;Retinal computations&amp;rdquo; by Maria José Escobar (Chile)&lt;/h1&gt;
&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;http://profesores.elo.utfsm.cl/~mjescobar/&#34;&gt;María José Escobar, Ph.D.&lt;/a&gt; :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Retinal computations&amp;rdquo; : The retina is part of the nervous system and consists in well-organized layers of different cell types and functions. Those cells have been vastly studied in various animal models, and also the circuits conveying to different functional categories. All these different types of either physiological properties or computation equivalents revealed the retina as not a single light to electricity encoder but a pre-processing layer, which is in charge to extract relevant visual signals from the environment that are critical for animal survival. During this seminar, we describe some of the computations performed by the retina, and how this knowledge can be applied to solve engineering problems, such as image processing and robot controllers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.int.univ-amu.fr/IMG/200x130xsiteon0.png,q1331299836.pagespeed.ic.IKYGzK4Zu8.png&#34; alt=&#34;Sponsored by&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-04-05 : *Probabilities and Optimal Inference to understand the Brain* Workshop</title>
      <link>https://laurentperrinet.github.io/post/2018-04-05_optimal-inference-brain-workshop/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2018-04-05_optimal-inference-brain-workshop/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;IMG_20180406_164630.jpg&#34; alt=&#34;participants&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;probabilities-and-optimal-inference-to-understand-the-brain&#34;&gt;Probabilities and Optimal Inference to understand the Brain&lt;/h1&gt;
&lt;h2 id=&#34;a-2day-workshop-at-the-institute-of-neurosciences-timone-in-marseille&#34;&gt;a 2-day workshop at the Institute of Neurosciences Timone in Marseille&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;affiche&#34;&gt;&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Date&lt;/dt&gt;
&lt;dd&gt;April 5-6th 2018&lt;/dd&gt;
&lt;dt&gt;Location&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href=&#34;http://www.int.univ-amu.fr/contact&#34;&gt;Institute of Neurosciences Timone in Marseille in the south of
France&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Main site&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href=&#34;https://opt-infer-brain.sciencesconf.org/&#34;&gt;https://opt-infer-brain.sciencesconf.org/&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Full program&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href=&#34;https://opt-infer-brain.sciencesconf.org/program/details&#34;&gt;https://opt-infer-brain.sciencesconf.org/program/details&lt;/a&gt;.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;Organizing committee&lt;/dt&gt;
&lt;dd&gt;Paul Apicella, Frederic Danion, Nicole Malfait, Anna Montagnini and
Laurent Perrinet&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;&lt;img src=&#34;http://www.int.univ-amu.fr/IMG/200x130xsiteon0.png,q1331299836.pagespeed.ic.IKYGzK4Zu8.png&#34; alt=&#34;Sponsored by&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018-03-26 : PhD Program: course in Computational Neuroscience</title>
      <link>https://laurentperrinet.github.io/post/2018-03-26-cours-neuro-comp-fep/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2018-03-26-cours-neuro-comp-fep/</guid>
      <description>&lt;h1 id=&#34;phd-program-course-in-computational-neuroscience&#34;&gt;PhD Program: course in Computational Neuroscience&lt;/h1&gt;
&lt;p&gt;Context&lt;/p&gt;
&lt;p&gt;Computational neuroscience is an expending field that is proving to be essential in neurosciences. The aim of this course will be to provide a common solid background in computational neurosciences. The course will comprise historical recall of the field and a description of the different modelling approaches that are currently developed, including details about their specificities, limits and advantages.&lt;/p&gt;
&lt;p&gt;Objective&lt;/p&gt;
&lt;p&gt;The course aims at introducing students with the major tools that will be necessary during their thesis to model or analyze their neuroscientific results. While it will start by a short, generic introduction, we will then explore different systems at different scales. On the first day, we will study the different possible regimes in which a single neuron can behave, while progressively introducing the theory of dynamical systems to understand these more globally. Then, during the second day, we will introduce methods to analyze neuroscientific data in general, such as Bayesian methods and information theory. This will be implemented by simple practical examples.&lt;/p&gt;
&lt;p&gt;Language of intervention&lt;/p&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;p&gt;Number of hours&lt;/p&gt;
&lt;p&gt;~20 hours (session 1=7 + session 2=7 + session 3=4)&lt;/p&gt;
&lt;p&gt;Max participants&lt;/p&gt;
&lt;p&gt;15 for the practical sessions (afternoon Day 2 and Day 3), unlimited for theoretical courses&lt;/p&gt;
&lt;p&gt;Public priority&lt;/p&gt;
&lt;p&gt;PhD students&lt;/p&gt;
&lt;p&gt;Public concerned&lt;/p&gt;
&lt;p&gt;PhD students, interested M2 students and postdocs&lt;/p&gt;
&lt;p&gt;Location&lt;/p&gt;
&lt;p&gt;Institut des Neurosciences de la Timone (INT)&lt;/p&gt;
&lt;p&gt;Keywords&lt;/p&gt;
&lt;p&gt;neuronal modelling, neural circuit modelling, information theory, decoding and encoding&lt;/p&gt;
&lt;p&gt;Targets&lt;/p&gt;
&lt;p&gt;Understanding how computational modelling can be used to formulate and solve neuroscience problems at different spatial and temporal scales; learning the formal notions of information, encoding and decoding and experimenting their use on toy datasets&lt;/p&gt;
&lt;p&gt;Program&lt;/p&gt;
&lt;p&gt;&lt;em&gt;First session:&lt;/em&gt; Introduction to modeling single neurons (morning); An introduction to neural masses: modeling assemblies of neurons up to capturing collective oscillations and resting state dynamics in a mean-field model - presentation of the Virtual Brain software (afternoon) - &lt;em&gt;Second session:&lt;/em&gt; An overview on &amp;ldquo;What is encoding?&amp;rdquo; &amp;ldquo;What is decoding?&amp;quot;: formalization of the notion of information in neural activity; shared and transferred information; integration, segregation and complexity (morning). Bayesian probabilities, the Free-energy principle and Active Inference, with practical demonstrations in python (afternoon). &lt;em&gt;Third session:&lt;/em&gt; the problem of information estimation in practice. Practical exercices in Matlab: estimating entropy and stimulus decodability from spike trains; comparing coding hypotheses (morning).&lt;/p&gt;
&lt;p&gt;Pre-required&lt;/p&gt;
&lt;p&gt;Basic knowledge of statistics and probability and calculus (differential equations,&amp;hellip;) is useful, but steps will be explained and complex math avoided as much as possible. Practical exercises are in python and/or MATLAB, so basic knowledge of these environments is a plus.&lt;/p&gt;
&lt;h2 id=&#34;program&#34;&gt;program&lt;/h2&gt;
&lt;h3 id=&#34;day-1--20180326--an-introduction-to-computational-neuroscience&#34;&gt;day 1 : 2018-03-26 : an introduction to Computational Neuroscience&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;09:30-12:30 = &lt;a href=&#34;http://invibe.net/LaurentPerrinet/Presentations/2017-03-06_cours-NeuroComp?action=AttachFile&amp;amp;do=view&amp;amp;target=2017-03-06_LaurentPezard.pdf&#34; title=&#34;Introduction to modeling single neurons&#34;&gt;Introduction to modeling single neurons&lt;/a&gt; (LaP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14:00-17:00 = &lt;a href=&#34;http://invibe.net/LaurentPerrinet/Presentations/2017-03-06_cours-NeuroComp?action=AttachFile&amp;amp;do=view&amp;amp;target=2017-Lecture_INT_MeanField_to_TVB.pdf&#34; title=&#34;An introduction to neural masses: modeling assemblies of neurons up to capturing resting state dynamics in a mean-field model - presentation of the Virtual Brain software&#34;&gt;An introduction to neural masses: modeling assemblies of neurons up to capturing resting state dynamics in a mean-field model - presentation of the Virtual Brain software&lt;/a&gt; (DaB)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-2--20180327--information-theory--bayesian-models&#34;&gt;day 2 : 2018-03-27 : Information theory / bayesian models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;09:15-10:30 = [An overview on &amp;ldquo;What is encoding?&amp;rdquo; &amp;ldquo;What is decoding?&amp;quot;: formalization of the notion of information in neural activity](&lt;a href=&#34;http://invibe.net/LaurentPerrinet/Presentations/2017-03-06_cours-NeuroComp?action=AttachFile&amp;amp;do=view&amp;amp;target=2017-Lecture_INT_InfoTheory.pdf&#34;&gt;http://invibe.net/LaurentPerrinet/Presentations/2017-03-06_cours-NeuroComp?action=AttachFile&amp;amp;do=view&amp;amp;target=2017-Lecture_INT_InfoTheory.pdf&lt;/a&gt; &amp;ldquo;An overview on &amp;ldquo;What is encoding?&amp;rdquo; &amp;ldquo;What is decoding?&amp;quot;: formalization of the notion of information in neural activity&amp;rdquo;) (DaB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;11:00-12:15 = (&amp;hellip;continued after the coffee break: ) Live information! From sharing information to transferring information (and a glimpse into the zoo of higher-order friends) (DaB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14:00-17:10 = &lt;a href=&#34;http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp_FEP&#34;&gt;Probabilities, the Free-energy principle and Active Inference&lt;/a&gt; (LuP).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-3--20180328--practical-course-on-information-theory&#34;&gt;day 3 : 2018-03-28 : Practical course on Information theory&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;09:30-12:30 = Practical course on Information theory (DaB)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;more-material-related-to-the-course&#34;&gt;More material related to the course&lt;/h2&gt;
&lt;h3 id=&#34;day-1--morning--the-single-neuron&#34;&gt;day 1 - morning : the single neuron&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;site du livre de Gerstner et al &amp;ldquo;Neuronal Dynamics&amp;rdquo;: &lt;a href=&#34;http://neuronaldynamics.epfl.ch/&#34;&gt;http://neuronaldynamics.epfl.ch/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A (longer) introduction to the Hodgkin-Huxley model in three steps by Dr Stefano Luccioli&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez1.pdf&#34;&gt;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez1.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez2.pdf&#34;&gt;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez2.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez3.pdf&#34;&gt;http://neuro.fi.isc.cnr.it/uploads/TALKS/lez3.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An interactive course with Wulfram Gerstner &lt;a href=&#34;https://www.edx.org/course/neuronal-dynamics-computational-epflx-bio465-1x&#34;&gt;https://www.edx.org/course/neuronal-dynamics-computational-epflx-bio465-1x&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;His book ONLINE &lt;a href=&#34;http://cn.epfl.ch/~gerstner/NeuronalDynamics-MOOC1.html&#34;&gt;http://cn.epfl.ch/~gerstner/NeuronalDynamics-MOOC1.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-1--afternoon--neural-mass-models&#34;&gt;day 1 - afternoon : neural mass models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Another interactive course @ Washington University &lt;a href=&#34;https://www.coursera.org/course/compneuro&#34;&gt;https://www.coursera.org/course/compneuro&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collection of didactic material for the EU FP7 ITN Neural Engineering Transformative Technology &lt;a href=&#34;http://www.neural-engineering.eu/training/index.html&#34;&gt;http://www.neural-engineering.eu/training/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Didactic material from Lab in Computational Neuroscience &lt;a href=&#34;http://neuro.fi.isc.cnr.it/index.php?page=didactic-material&#34;&gt;http://neuro.fi.isc.cnr.it/index.php?page=didactic-material&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A open source simulator of a whole brain which runs on your laptop, &amp;ldquo;The Virtual Brain&amp;rdquo;: &lt;a href=&#34;http://thevirtualbrain.org&#34;&gt;http://thevirtualbrain.org&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-2--morning--information-theory&#34;&gt;day 2 - morning : information theory&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The best book on information theory and decoding, freely available directly from the author: &lt;a href=&#34;http://www.inference.phy.cam.ac.uk/itprnn/book.html&#34;&gt;http://www.inference.phy.cam.ac.uk/itprnn/book.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a gentle introduction to bayesian methods : &lt;a href=&#34;https://homepages.inf.ed.ac.uk/pseries/Peg_files/Chapter9_SotiropoulosSeries.pdf&#34;&gt;https://homepages.inf.ed.ac.uk/pseries/Peg_files/Chapter9_SotiropoulosSeries.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;day-2--afternoon--bayesian-models&#34;&gt;day 2 - afternoon : bayesian models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;an interesting read : &lt;a href=&#34;http://cognitrn.psych.indiana.edu/busey/q551/PDFs/PredictivCodingRaoBallard.pdf&#34;&gt;http://cognitrn.psych.indiana.edu/busey/q551/PDFs/PredictivCodingRaoBallard.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a tutorial on free-energy : some exercises : &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S0022249615000759&#34;&gt;http://www.sciencedirect.com/science/article/pii/S0022249615000759&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;solutions to the tutorial : &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contacts&#34;&gt;contacts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LaP: Laurent Pezard &amp;laquo;&lt;a href=&#34;mailto:Laurent.Pezard@univ-amu.fr&#34;&gt;Laurent.Pezard@univ-amu.fr&lt;/a&gt;&amp;raquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DaB: Demian Battaglia &amp;laquo;&lt;a href=&#34;mailto:demian.battaglia@univ-amu.fr&#34;&gt;demian.battaglia@univ-amu.fr&lt;/a&gt;&amp;raquo;, INS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LuP: Laurent Udo Perrinet &amp;laquo;&lt;a href=&#34;mailto:laurent.perrinet@univ-amu.fr&#34;&gt;laurent.perrinet@univ-amu.fr&lt;/a&gt;&amp;raquo;, INT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PhD program: Nicole Malfait &amp;laquo;&lt;a href=&#34;mailto:Nicole.Malfait@univ-amu.fr&#34;&gt;Nicole.Malfait@univ-amu.fr&lt;/a&gt;&amp;raquo;, Anna Montagnini &amp;laquo;&lt;a href=&#34;mailto:anna.montagnini@univ-amu.fr&#34;&gt;anna.montagnini@univ-amu.fr&lt;/a&gt;&amp;raquo;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://www.int.univ-amu.fr/IMG/200x130xsiteon0.png,q1331299836.pagespeed.ic.IKYGzK4Zu8.png&#34; alt=&#34;Sponsored by&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2016-10-26 : EUVIP BICV</title>
      <link>https://laurentperrinet.github.io/post/2016-10-26_euvip-bicv/</link>
      <pubDate>Wed, 26 Oct 2016 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2016-10-26_euvip-bicv/</guid>
      <description>&lt;h1 id=&#34;20161026--euvip-special-session-on-biologically-inspired-computer-vision&#34;&gt;2016-10-26 : EUVIP Special Session on &lt;em&gt;Biologically Inspired Computer Vision&lt;/em&gt;&lt;/h1&gt;
&lt;h2 id=&#34;description-of-the-session&#34;&gt;description of the session&lt;/h2&gt;
&lt;p&gt;Recent advances in imaging technologies have yielded scientific data at
unprecedented detail and volume, leading to the need of a shift of
paradigm in image processing and computer vision. Beyond the usual
classical von Neumann architecture, one strategy that is emerging in
order to process and interpret this amount of data follows from the
architecture of biological organisms and shows for instance
computational paradigms implementing asynchronous communication with a
high degree of local connectivity in sensors or brain tissues. This
session aims at bringing together researchers from different fields of
Biologically Inspired Computer Vision to present latest results in the
field, from fundamental to more specialized topics, including visual
analysis based on a computational level, hardware implementation, and
the design of new more advanced vision sensors. It is expected to
provide a comprehensive overview in the computer area of biologically
motivated vision. On the one hand, biological organisms can provide a
source of inspiration for new computationally efficient and robust
vision models and on the other hand machine vision approaches can
provide new insights for understanding biological visual systems. This
session covers a wide range of topics from fundamental to more
specialized topics, including visual analysis based on a computational
level, hardware implementation, and the design of new more advanced
vision sensors. In particular, we expect to provide an overview of a few
representative applications and current state of the art of the research
in this area.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;URL
&lt;a href=&#34;http://www-l2ti.univ-paris13.fr/euvip2016/index.php/86-euvip2016/129-tentative-technical-program-in-detail&#34;&gt;http://www-l2ti.univ-paris13.fr/euvip2016/index.php/86-euvip2016/129-tentative-technical-program-in-detail&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;date
October 26th, 2016&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Location
Ecole Centrale Marseille&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Address
&lt;a href=&#34;https://www.centrale-marseille.fr/fr/acces-0&#34;&gt;38 rue Frédéric Joliot-Curie 13013 Marseille,
France&lt;/a&gt; Phone : +33
(0)4 91 05 45 45&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Programme&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;13.50  &lt;a href=&#34;http://ieeexplore.ieee.org/document/7764586/&#34;&gt;Visual System Inspired Algorithm For Contours, Corner And T Junction Detection&lt;/a&gt;, Antoni Buades, &lt;em&gt;Rafael Grompone Von Gioi&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;13.50  &lt;a href=&#34;https://laurentperrinet.github.io/talk/2016-10-26-perrinet-16-euvip/&#34;&gt;Biologically-inspired characterization of sparseness in natural images&lt;/a&gt;, &lt;em&gt;Laurent Perrinet&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14.10 &lt;a href=&#34;http://david.alleysson.free.fr/Publications/JIST0224reprint.pdf&#34;&gt;Color filter array imitating the random nature of color arrangement in the human cone mosaic&lt;/a&gt;, Prakhar Amba, &lt;em&gt;David Alleysson&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14.30 &lt;a href=&#34;http://ieeexplore.ieee.org/document/7764601/&#34;&gt;An Illuminant-Independent Analysis Of Reflectance As Sensed By Humans, And Its Applicability To Computer Vision&lt;/a&gt;, Alban Flachot, Phelma, J.Kevin O&#39;Regan, &lt;em&gt;Edoardo Provenzi&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14.50 &lt;a href=&#34;https://laurentperrinet.github.io/talk/2016-10-26-fillatre-barlaud-perrinet-16-euvip/&#34;&gt;Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor&lt;/a&gt;, Lionel Fillatre, Michel Barlaud, &lt;em&gt;Laurent Perrinet&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2010-06-22 : CodeJamNr4</title>
      <link>https://laurentperrinet.github.io/post/2010-06-22_codejam-nr4/</link>
      <pubDate>Tue, 22 Jun 2010 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2010-06-22_codejam-nr4/</guid>
      <description>&lt;h1 id=&#34;facets-code-jam-workshop-4&#34;&gt;FACETS Code Jam Workshop #4&lt;/h1&gt;
&lt;p&gt;We held a CodeJam 22nd-24th June 2010, in Marseille.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://neuralensemble.org/media/images/codejam4_group_photo.jpg&#34; alt=&#34;Participants&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the
&lt;a href=&#34;http://neuralensemble.org/meetings/CodeJam4/&#34;&gt;website&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of the FACETS CodeJam workshops is to catalyze open-source, collaborative software development in computational and systems neuroscience and neuroinformatics, by bringing together researchers, students and engineers to share ideas, present their work, and write code together. The general format of the workshops is to dedicate the mornings to invited and contributed talks, leaving the afternoons free for discussions and code sprints. &lt;!-- raw HTML omitted --&gt;
For the 4th FACETS CodeJam, the main theme of the meeting will be workflows: what are the best practices for combining different tools (simulators, analysis tools, visualization tools, databases etc.) to ensure the efficient and reproducible flow of data and information from experiment conception to publication and archiving? &lt;!-- raw HTML omitted --&gt;
(&amp;hellip;) &lt;!-- raw HTML omitted --&gt;
The meeting organizers gratefully acknowledge the support of the European Union through the FACETS Project (grant no. IST-2005-15879), and the International Neuroinformatics Co-ordinating Facility (INCF). We also wish to express our great appreciation to the DyVA team at the Institut de Neurosciences Cognitives de la Méditerranée for providing us with a great location and much assistance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuralensemble.org/meetings/CodeJam4.html&#34;&gt;http://neuralensemble.org/meetings/CodeJam4.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://neuralensemble.org/meetings/CJ4_Program_v2.pdf&#34;&gt;http://neuralensemble.org/meetings/CJ4_Program_v2.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://facets.kip.uni-heidelberg.de/internal/jss/AttendMeeting?mI=73&#34;&gt;FACETS code jam #4&lt;/a&gt;{.https}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;Affiche&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2010-05-27 : Neurocomp08</title>
      <link>https://laurentperrinet.github.io/post/2008-10-08_neurocomp/</link>
      <pubDate>Thu, 27 May 2010 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2008-10-08_neurocomp/</guid>
      <description>&lt;h1 id=&#34;20081008--deuxime-confrence-franaise-de-neurosciences-computationnelles-neurocomp08&#34;&gt;2008-10-08 : Deuxième conférence française de Neurosciences Computationnelles, &amp;ldquo;Neurocomp08&amp;rdquo;&lt;/h1&gt;
&lt;p&gt;La deuxième conférence française de Neurosciences Computationnelles, &amp;ldquo;Neurocomp08&amp;rdquo;, s&#39;est déroulée à la Faculté de Médecine de Marseille du 8 au 11 octobre 2008. Cette conférence, organisée par le groupe de travail Neurocomp, a permis de réunir les principaux acteurs français du domaine (francophones ou non). Le champ des Neurosciences Computationnelles porte sur l&#39;étude des mécanismes de calcul qui sont à l&#39;origine de nos capacités cognitives. Cette approche nécessite l&#39;intégration constructive de nombreux domaines disciplinaires, du neurone au comportement, des sciences du vivant à la modélisation numérique. Avec ce colloque, nous avons offert un lieu d&#39;échanges afin de favoriser des collaborations interdisciplinaires entre des équipes relevant des neurosciences, des sciences de l&#39;information, de la physique statistique, de la robotique. Cette édition a également été l&#39;occasion d&#39;ouvrir le cadre à de nouveaux domaines (modèles pour l&#39;imagerie, interfaces cerveau-machine,&amp;hellip;) notamment grâce à des ateliers thématiques (une nouveauté dans cette édition). Certains des principaux enjeux du domaine ont été présentés par quatre conférenciers invités : Ad Aertsen (Freiburg, Allemagne), Gustavo Deco (Barcelone, Espagne), Gregor Schöner (Bochum, Allemagne), Andrew B. Schwartz (Pittsburgh, USA). Des interventions orale plus courtes et plus spécifiques étaient également au programme, sur la base d&#39;une sélection du comité de lecture. Une cinquantaine de posters ont également été présentés au cours de ces journées. Le premier jour était consacré aux modèles de la cellule neurale, aux modèles des traitements visuels et corticaux, ainsi qu&#39;aux modèles de réseaux de neurones bio-mimétiques. La seconde journée était consacrée aux interfaces cerveau-machine, à la dynamique des grands ensembles de neurones, à la plasticité fonctionnelle et aux interfaces neurales. Enfin, la journée de samedi était consacrée à des ateliers thématiques, l&#39;un sur les interfaces cerveau-machine, l&#39;autre sur la vision computationnnelle. Cette conférence a connu un beau succès de par l&#39;affluence (200 personnes environ) et la qualité des interventions. Ce succès tient également au fort soutien financier et organisationnel qu&#39;elle a obtenu de ses partenaires. Les organisateurs remercient le CNRS, la Société des neurosciences, le conseil régional de la région Provence Alpes Côte d&#39;Azur, le conseil général des Bouches de Rhône, la mairie de Marseille, l&#39;université de Provence, l&#39;IFR &amp;ldquo;Sciences du cerveau et de la cognition&amp;rdquo;, l&#39;INRIA, ainsi que la faculté de médecine de Marseille et l&#39;université de la Méditerranée qui ont hébergé la conférence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Les actes de la conférence regroupant les 68 contributions sont disponibles sur le &lt;a href=&#34;http://hal.archives-ouvertes.fr/NEUROCOMP08&#34;&gt;serveur HAL dédié&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;Affiche&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computational Neuroscience: From Representations to Behavior</title>
      <link>https://laurentperrinet.github.io/post/2010-05-27_neurocomp-marseille-workshop/</link>
      <pubDate>Wed, 08 Oct 2008 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/post/2010-05-27_neurocomp-marseille-workshop/</guid>
      <description>&lt;h1 id=&#34;computational-neuroscience-from-representations-to-behavior&#34;&gt;Computational Neuroscience: From Representations to Behavior&lt;/h1&gt;
&lt;h2 id=&#34;second-neurocomp-marseille-workshop&#34;&gt;Second NeuroComp Marseille Workshop&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Date: 27-28 May 2010&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Location: Amphithéâtre Charve at the Saint-Charles&amp;rsquo; University campus&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Métro :
Line 1 et 2 (St Charles), a 5 minute walk from the railway station.
&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;Map (Amphithéâtre Charve, University Main Entrance, etc.)&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;Metro, Bus and Tramway&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;li&gt;Getting to Marseille from Airport&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Computational Neuroscience emerges now as a major breakthrough in
exploring cognitive functions. It brings together theoretical tools that
elucidate fundamental mechanisms responsible for experimentally observed
behaviour in the applied neurosciences. This is the second Computational
Neuroscience Workshop organized by the &amp;ldquo;NeuroComp Marseille&amp;rdquo; network.&lt;/p&gt;
&lt;p&gt;It will focus on latest advances on the understanding of how information
may be represented in neural activity (1st day) and on computational
models of learning, decision-making and motor control (2nd day). The
workshop will bring together leading researchers in these areas of
theoretical neuroscience. The meeting will consist of invited speakers
with sufficient time to discuss and share ideas and data. All
conferences were in English.&lt;/p&gt;
&lt;h2 id=&#34;program&#34;&gt;Program&lt;/h2&gt;
&lt;p&gt;27 May 2010 &lt;strong&gt;Neural representations for sensory information &amp;amp; the
structure-function relation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;9h00-9h30&lt;/p&gt;
&lt;p&gt;Reception and coffee&lt;/p&gt;
&lt;p&gt;9h30-10h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Laurent Perrinet&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Institut de Neurosciences Cognitives de la Méditerranée, CNRS and
Université de la Méditerranée - Marseille
&lt;strong&gt;«Presentation of the Workshop and Topic»&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;10h00-11h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Gabriel Peyré&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
CNRS and Université Paris-Dauphine
&lt;!-- raw HTML omitted --&gt;**«Sparse Geometric Processing of Natural Images»**&lt;!-- raw HTML omitted --&gt;
In this talk, I will review recent works on the sparse representations
of natural images. I will in particular focus on both the application of
these emerging models to image processing problems, and their potential
implication for the modeling of visual processing.
Natural images exhibit a wide range of geometric regularities, such as
curvilinear edges and oscillating textures. Adaptive image
representations select bases from a dictionary of orthogonal or
redundant frames that are parameterized by the geometry of the image. If
the geometry is well estimated, the image is sparsely represented by
only a few atoms in this dictionary.
On an ingeniering level, these methods can be used to enhance the
resolution of super-resolution inverse problems, and can also be used to
perform texture synthesis. On a biological level, these mathematical
representations share similarities with low level grouping processes
that operate in areas V1 and V2 of the visual brain. We believe both
processing and biological application of geometrical methods work hand
in hand to design and analyze new cortical imaging methods.&lt;/p&gt;
&lt;p&gt;11h00-12h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Jean Petitot&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Centre d&#39;Analyse et de Mathématique Sociales, Ecole des Hautes Etudes en
Sciences Sociales - Paris &lt;strong&gt;«Neurogeometry of visual perception»&lt;/strong&gt;
In relation with experimental data, we propose a geometric model of the
functional architecture of the primary visual cortex (V1) explaining
contour integration. The aim is to better understand the type of
geometry algorithms implemented by this functional architecture. The
contact structure of the 1-jet space of the curves in the plane, with
its generalization to the roto-translation group, symplectifications,
and sub-Riemannian geometry, are all neurophysiologically realized by
long-range horizontal connections. Virtual structures, such as illusory
contours of the Kanizsa type, can then be explained by this model.&lt;/p&gt;
&lt;p&gt;12h00&lt;/p&gt;
&lt;p&gt;Lunch&lt;/p&gt;
&lt;p&gt;14h00-14h45&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Peggy Series&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Institute for Adaptive and Neural Computation, Edinburgh
&lt;strong&gt;«Bayesian Priors in Perception and Decision Making»&lt;/strong&gt;
We&#39;ll present two recent projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first project (with M. Chalk and A. R. Seitz) is an experimental
investigation of the influence of expectations on the perception of
simple stimuli. Using a simple task involving estimation and detection
of motion random dots displays, we examined whether expectations can be
developed quickly and implicitly and how they affect perception. We find
that expectations lead to attractive biases such that stimuli appear as
being more similar to the expected one than they really are, as well as
visual hallucinations in the absence of a stimulus. We discuss our
findings in terms of Bayesian Inference.&lt;/li&gt;
&lt;li&gt;In the second project (with A. Kalra and Q. Huys), we explore the
concepts of optimism and pessimism in decision making. Optimism is
usually assessed using questionnaires, such as the LOT-R. Here, using a
very simple behavioral task, we show that optimism can be described in
terms of a prior on expected future rewards. We examine the correlation
between the shape of this prior for individual subjects and their scores
on questionnaires, as well as with other measures of personality traits.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;14h45-15h45&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Heiko Neumann&lt;!-- raw HTML omitted --&gt;&lt;/em&gt; (in
collaboration with Florian Raudies)
Inst. of Neural Information Processing, Ulm University Germany
&lt;strong&gt;«Cortical mechanisms of transparent motion perception – a neural
model»&lt;/strong&gt;
Transparent motion is perceived when multiple motions different in
directions and/or speeds are presented in the same part of visual space.
In perceptual experiments the conditions have been studied under which
motion transparency occurs. An upper limit in the number of perceived
transparent layers has been investigated psychophysically. Attentional
signals can improve the perception of a single motion amongst several
motions. While criteria for the occurrence of transparent motion have
been identified only few potential neural mechanisms have been discussed
so far to explain the conditions and mechanisms for segregating multiple
motions.
A neurodynamical model is presented which builds upon a previously
developed neural architecture emphasizing the role of feedforward
cascade processing and feedback from higher to earlier stages for
selective feature enhancement and tuning. Results of computational
experiments are consistent with findings from physiology and
psychophysics. Finally, the model is demonstrated to cope with realistic
data from computer vision benchmark databases.
Work supported by European Union (project SEARISE), BMBF, and CELEST&lt;/p&gt;
&lt;p&gt;15h45-15h00&lt;/p&gt;
&lt;p&gt;Coffee break&lt;/p&gt;
&lt;p&gt;16h00-17h00&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CANCELED&lt;/strong&gt;
&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Rudolf Friedrich&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Institute für Theoretische Physik Westfälische Wilhelms Universität
Münster
&lt;strong&gt;«Windows to Complexity: Disentangling Trends and Fluctuations in
Complex Systems»&lt;/strong&gt;
In the present talk, we discuss how to perform an analysis of
experimental data of complex systems by disentangling the effects of
dynamical noise (fluctuations) and deterministic dynamics (trends). We
report on results obtained for various complex systems like turbulent
fields, the motion of dissipative solitons in nonequilibrium systems,
traffic flows, and biological data like human tremor data and brain
signals. Special emphasis is put on methods to predict the occurrence of
qualitative changes in systems far from equilibrium.
[1] R. Friedrich, J. Peinke, M. Reza Rahimi Tabar: Importance of
Fluctuations: Complexity in the View of stochastic Processes (in:
Springer Encyclopedia on Complexity and System Science, (2009))&lt;/p&gt;
&lt;p&gt;17h00-17h45&lt;/p&gt;
&lt;p&gt;General Discussion&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;28 May 2010 &lt;strong&gt;Computational models of learning and decision making&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;9h30-10h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Andrea Brovelli&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Institut de Neurosciences Cognitives de la Méditerranée, CNRS and
Université de la Méditerranée - Marseille
&lt;strong&gt;«An introduction to Motor Learning, Decision-Making and Motor
Control»&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;10h00-11h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Emmanuel Daucé&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Mouvement &amp;amp; Perception, UMR 6152, Faculté des sciences du sport
&lt;strong&gt;«Adapting the noise to the problem : a Policy-gradient approach of
receptive fields formation»&lt;/strong&gt;
In machine learning, Kernel methods are give a consistent framework for
applying the perceptron algorithm to non-linear problems. In
reinforcement learning, the analog of the perceptron delta-rule is
called the &amp;ldquo;policy-gradient&amp;rdquo; approch proposed by Williams in 1992 in the
framework of stochastic neural networks. Despite its generality and
straighforward applicability to continuous command problems, quite few
developments of the method have been proposed since. Here we present an
account of the use of a kernel transformation of the perception space
for learning a motor command, in the case of eye orientation and
multi-joint arm control. We show that such transformation allows the
system to learn non-linear transformation, like the log-like resolution
of a foveated retina, or the transformation from a cartesian perception
space to a log-polar command, by shaping appropriate receptive fields
from the perception to the command space. We also present a method for
using multivariate correlated noise for learning high-DOF control
problems, and propose some interpretations on the putative role of
correlated noise for learning in biological systems.&lt;/p&gt;
&lt;p&gt;11h00-12h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Máté Lengyel&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Computational &amp;amp; Biological Learning Lab, Department of Engineering,
University of Cambridge
&lt;strong&gt;«Why remember? Episodic versus semantic memories for optimal decision
making»&lt;/strong&gt;
Memories are only useful inasmuch as they allow us to act adaptively in
the world. Previous studies on the use of memories for decision making
have almost exclusively focussed on implicit rather than declarative
memories, and even when they did address declarative memories they dealt
only with semantic but not episodic memories. In fact, from a purely
computational point of view, it seems wasteful to have memories that are
episodic in nature: why should it be better to act on the basis of the
recollection of single happenings (episodic memory), rather than the
seemingly normative use of accumulated statistics from multiple events
(semantic memory)? Using the framework of reinforcement learning, and
Markov decision processes in particular, we analyze in depth the
performance of episodic versus semantic memory-based control in a
sequential decision task under risk and uncertainty in a class of simple
environments. We show that episodic control should be useful in a range
of cases characterized by complexity and inferential noise, and most
particularly at the very early stages of learning, long before
habitization (the use of implicit memories) has set in. We interpret
data on the transfer of control from the hippocampus to the striatum in
the light of this hypothesis.&lt;/p&gt;
&lt;p&gt;12h00-14h00&lt;/p&gt;
&lt;p&gt;Lunch&lt;/p&gt;
&lt;p&gt;14h00-15h00&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Rafal Bogacz&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Department of Computer Science, University of Bristol
&lt;strong&gt;«Optimal decision making and reinforcement learning in the
cortico-basal-ganglia circuit»&lt;/strong&gt;
During this talk I will present a computational model describing
decision making process in the cortico-basal ganglia circuit. The model
assumes that this circuit performs statistically optimal test that
maximizes speed of decisions for any required accuracy. In the model,
this circuit computes probabilities that considered alternatives are
correct, according to Bayes’ theorem. This talk will show that the
equation of Bayes’ theorem can be mapped onto the functional anatomy of
a circuit involving the cortex, basal ganglia and thalamus. This theory
provides many precise and counterintuitive experimental predictions,
ranging from neurophysiology to behaviour. Some of these predictions
have been already validated in existing data and others are a subject of
ongoing experiments. During the talk I will also discuss the
relationships between the above model and current theories of
reinforcement learning in the cortico-basal-ganglia circuit.&lt;/p&gt;
&lt;p&gt;15h00-15h30&lt;/p&gt;
&lt;p&gt;Coffee break&lt;/p&gt;
&lt;p&gt;15h30-16h30&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;!-- raw HTML omitted --&gt;Emmanuel Guigon&lt;!-- raw HTML omitted --&gt;&lt;/em&gt;
Institut des Systèmes Intelligents et de Robotique, UPMC - CNRS / UMR
7222
&lt;strong&gt;«Optimal feedback control as a principle for adaptive control of
posture and movement»&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;16h30-17h15&lt;/p&gt;
&lt;p&gt;General Discussion&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;sponsored-by&#34;&gt;Sponsored by&lt;/h2&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Pole 3c&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;Affiche&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
