<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Laurent Perrinet on Novel computational paradigms for vision</title>
    <link>https://laurentperrinet.github.io/authors/laurent-perrinet/</link>
    <description>Recent content in Laurent Perrinet on Novel computational paradigms for vision</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png&#34; /&gt;&lt;/a&gt;&lt;br /&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License&lt;/a&gt;
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared.
</copyright>
    <lastBuildDate>Tue, 01 Jan 2019 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="https://laurentperrinet.github.io/authors/laurent-perrinet/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Des illusions aux hallucinations visuelles: une porte sur la perception</title>
      <link>https://laurentperrinet.github.io/talk/2019-04-18_jnlf/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/talk/2019-04-18_jnlf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meaningful representations emerge from Sparse Deep Predictive Coding</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-19/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From biological vision to unsupervised hierarchical sparse coding</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-18-itwist/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-18-itwist/</guid>
      <description> From biological vision to unsupervised hierarchical sparse coding  accepted submission @ iTWIST: international Traveling Workshop on Interactions between low-complexity data models and Sensing Techniques, 21 - 23 Novemberâ€‹, 2018
 poster session scheduled on Thursday, November 22th, from 10h30 till 12h00.
 CIRM, Marseille, France. 
 get full proceedings @ https://arxiv.org/html/1812.00648
 Poster PDF
  </description>
    </item>
    
    <item>
      <title> Efficient learning of sparse image representations using homeostatic regulation</title>
      <link>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-neurofrance/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-neurofrance/</guid>
      <description> This work is a followup of Perrinet, 2010, Neural Computation code is available @ https://github.com/bicv/SparseHebbianLearning the [[attachment:BoutinRuffierPerrinet17neurofrance.pdf|poster|&amp;amp;do=get]] will be presented Thursday, May 18 @ [[http://www.professionalabstracts.com/sn2017/programme-sn2017.pdf|NeuroFrance, Bordeaux]]. see a follow-up publication on BoutinRuffierPerrinet17spars  </description>
    </item>
    
    <item>
      <title> Efficient learning of sparse image representations using homeostatic regulation</title>
      <link>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-spars/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-spars/</guid>
      <description> This work is a followup of Perrinet, 2010, Neural Computation code is available @ https://github.com/laurentperrinet/BoutinRuffierPerrinet17spars and heavily uses https://github.com/bicv/SparseHebbianLearning the [[attachment:BoutinRuffierPerrinet17neurofrance.pdf|poster|&amp;amp;do=get]] will be presented Thursday, May 18 @ [[http://www.professionalabstracts.com/sn2017/programme-sn2017.pdf|NeuroFrance, Bordeaux]].  </description>
    </item>
    
    <item>
      <title>Operant reinforcement versus reward expectancy: effects on anticipatory eye movements</title>
      <link>https://laurentperrinet.github.io/publication/damasse-16/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/damasse-16/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A dynamic model for decoding direction and orientation in macaque primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/taouali-15-vss/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/taouali-15-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On overdispersion in neuronal evoked activity</title>
      <link>https://laurentperrinet.github.io/publication/taouali-15-icmns/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/taouali-15-icmns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</title>
      <link>https://laurentperrinet.github.io/publication/taouali-14-areadne/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/taouali-14-areadne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</title>
      <link>https://laurentperrinet.github.io/publication/taouali-14-neurocomp/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/taouali-14-neurocomp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Phase space analysis of networks based on biologically realistic parameters.</title>
      <link>https://laurentperrinet.github.io/publication/voges-10-a/</link>
      <pubDate>Mon, 01 Nov 2010 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/voges-10-a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probabilistic models of the low-level visual system: the role of prediction in detecting motion</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-10-tauc/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/perrinet-10-tauc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient Source Detection Using Integrate-and-Fire Neurons</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-05/</link>
      <pubDate>Sat, 01 Jan 2005 00:00:00 +0100</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/perrinet-05/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>