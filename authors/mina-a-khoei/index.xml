<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Novel visual computations</title>
    <link>https://laurentperrinet.github.io/authors/mina-a-khoei/</link>
    <description>Recent content on Novel visual computations</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png&#34; /&gt;&lt;/a&gt;&lt;br /&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License&lt;/a&gt;
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared.
</copyright>
    
	    <atom:link href="https://laurentperrinet.github.io/authors/mina-a-khoei/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The flash-lag effect as a motion-based predictive shift</title>
      <link>https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/</link>
      <pubDate>Thu, 26 Jan 2017 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.cnrs.fr/insb/recherche/parutions/articles2017/l-perrinet.html&#34; target=&#34;_blank&#34;&gt;Press release&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;visual-illusions-their-origin-lies-in-prediction&#34;&gt;Visual illusions: their origin lies in prediction&lt;/h1&gt;

&lt;p&gt;


&lt;figure&gt;

&lt;img src=&#34;flash_lag.gif&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;em&gt;Flash-Lag Effect.&lt;/em&gt; When a visual stimulus moves along a continuous trajectory, it may be seen ahead of its veridical position with respect to an unpredictable event such as a punctuate flash. This illusion tells us something important about the visual system: contrary to classical computers, neural activity travels at a relatively slow speed. It is largely accepted that the resulting delays cause this perceived spatial lag of the flash. Still, after several decades of debates, there is no consensus regarding the underlying mechanisms.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
&lt;strong&gt;Researchers from the Timone Institute of Neurosciences bring a new theoretical hypothesis on a visual illusion discovered at the beginning of the 20th century. This illusion remained misunderstood while it poses fundamental questions about how our brains represent events in space and time. This study published on January 26, 2017 in the journal PLOS Computational Biology, shows that the solution lies in the predictive mechanisms intrinsic to the neural processing of information.&lt;/strong&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;New Research: The Flash-Lag Effect as a Motion-Based Predictive Shift &lt;a href=&#34;https://t.co/K3KWPO8l4a&#34;&gt;https://t.co/K3KWPO8l4a&lt;/a&gt; Khoei et al. &lt;a href=&#34;https://twitter.com/hashtag/vision?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#vision&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/motion?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#motion&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/neuralnetworks?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#neuralnetworks&lt;/a&gt; &lt;a href=&#34;https://t.co/RElm4Qqo58&#34;&gt;pic.twitter.com/RElm4Qqo58&lt;/a&gt;&lt;/p&gt;&amp;mdash; PLOS Comp Biol (@PLOSCompBiol) &lt;a href=&#34;https://twitter.com/PLOSCompBiol/status/829354100273745920?ref_src=twsrc%5Etfw&#34;&gt;February 8, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

Visual illusions are still popular: in a quasi-magical way, they can make objects appear where they are not expected&amp;hellip; They are also excellent opportunities to question the constraints of our perceptual system. Many illusions are based on motion, such as the flash-lag effect. Observe a luminous dot that moves along a rectilinear trajectory. If a second light dot is flashed very briefly just above the first, the moving point will always be perceived in front of the flash while they are vertically aligned.



&lt;figure&gt;

&lt;img src=&#34;https://journals.plos.org/ploscompbiol/article/figure/image?size=large&amp;amp;id=info:doi/10.1371/journal.pcbi.1005068.g002&#34; width=&#34;80%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Fig 2. &lt;em&gt;Diagonal Markov chain.&lt;/em&gt; In the current study, the estimated state vector z = {x, y, u, v} is composed of the 2D position (x and y) and velocity (u and v) of a (moving) stimulus. (A) First, we extend a classical Markov chain using Nijhawan’s diagonal model in order to take into account the known neural delay τ: At time t, information is integrated until time t − τ, using a Markov chain and a model of state transitions p(zt|zt−δt) such that one can infer the state until the last accessible information p(zt−τ|I0:t−τ). This information can then be “pushed” forward in time by predicting its trajectory from t − τ to t. In particular p(zt|I0:t−τ) can be predicted by the same internal model by using the state transition at the time scale of the delay, that is, p(zt|zt−τ). This is virtually equivalent to a motion extrapolation model but without sensory measurements during the time window between t − τ and t. Note that both predictions in this model are based on the same model of state transitions. (B) One can write a second, equivalent “pull” mode for the diagonal model. Now, the current state is directly estimated based on a Markov chain on the sequence of delayed estimations. While being equivalent to the push-mode described above, such a direct computation allows to more easily combine information from areas with different delays. Such a model implements Nijhawan’s “diagonal model”, but now motion information is probabilistic and therefore, inferred motion may be modulated by the respective precisions of the sensory and internal representations. &amp;copy; Such a diagonal delay compensation can be demonstrated in a two-layered neural network including a source (input) and a target (predictive) layer [44]. The source layer receives the delayed sensory information and encodes both position and velocity topographically within the different retinotopic maps of each layer. For the sake of simplicity, we illustrate only one 2D map of the motions (x, v). The integration of coherent information can either be done in the source layer (push mode) or in the target layer (pull mode). Crucially, to implement a delay compensation in this motion-based prediction model, one may simply connect each source neuron to a predictive neuron corresponding to the corrected position of stimulus (x + v ⋅ τ, v) in the target layer. The precision of this anisotropic connectivity map can be tuned by the width of convergence from the source to the target populations. Using such a simple mapping, we have previously shown that the neuronal population activity can infer the current position along the trajectory despite the existence of neural delays.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
Processing visual information takes time and even if these delays are remarkably short, they are not negligible and the nervous system must compensate them. For an object that moves predictably, the neural network can infer its most probable position taking into account this processing time. For the flash, however, this prediction can not be established because its appearance is unpredictable. Thus, while the two targets are aligned on the retina at the time of the flash, the position of the moving object is anticipated by the brain to compensate for the processing time: it is this differentiated treatment that causes the flash-lag effect.
The researchers show that this hypothesis also makes it possible to explain the cases where this illusion does not work: for example if the flash appears at the end of the moving dot&amp;rsquo;s trajectory or if the target reverses its path in an unexpected way. In this work, the major innovation is to use the accuracy of information in the dynamics of the model. Thus, the corrected position of the moving target is calculated by combining the sensory flux with the internal representation of the trajectory, both of which exist in the form of probability distributions. To manipulate the trajectory is to change the precision and therefore the relative weight of these two information when they are optimally combined in order to know where an object is at the present time. The researchers propose to call parodiction (from the ancient Greek paron, the present) this new theory that joins Bayesian inference with taking into account neuronal delays.



&lt;figure&gt;

&lt;img src=&#34;https://journals.plos.org/ploscompbiol/article/figure/image?size=large&amp;amp;id=10.1371/journal.pcbi.1005068.g005&#34; width=&#34;80%&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Fig 5. &lt;em&gt;Histogram of the estimated positions as a function of time for the dMBP model.&lt;/em&gt; Histograms of the inferred horizontal positions (blueish bottom panel) and horizontal velocity (reddish top panel), as a function of time frame, from the dMBP model. Darker levels correspond to higher probabilities, while a light color corresponds to an unlikely estimation. We highlight three successive epochs along the trajectory, corresponding to the flash initiated, standard (mid-point) and flash terminated cycles. The timing of the flashes are respectively indicated by the dashed vertical lines. In dark, the physical time and in green the delayed input knowing τ = 100 ms. Histograms are plotted at two different levels of our model in the push mode. The left-hand column illustrates the source layer that corresponds to the integration of delayed sensory information, including the prior on motion. The right-hand illustrates the target layer corresponding to the same information but after the occurrence of some motion extrapolation compensating for the known neural delay τ.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
Despite the simplicity of this solution, parodiction has elements that may seem counter-intuitive. Indeed, in this model, the physical world is considered &amp;ldquo;hidden&amp;rdquo;, that is to say, it can only be guessed by our sensations and our experience. The role of visual perception is then to deliver to our central nervous system the most likely information despite the different sources of noise, ambiguity and time delays. According to the authors of this publication, the visual treatment would consist in a &amp;ldquo;simulation&amp;rdquo; of the visual world projected at the present time, even before the visual information can actually modulate, confirm or cancel this simulation. This hypothesis, which seems to belong to &amp;ldquo;science fiction&amp;rdquo;, is being tested with more detailed and biologically plausible hierarchical neural network models that should allow us to better understand the mysteries underlying our perception. Visual illusions have still the power to amaze us!
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;New from Khoei et al. The Flash-Lag Effect as a &lt;a href=&#34;https://twitter.com/hashtag/Motion?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Motion&lt;/a&gt;-Based Predictive Shift &lt;a href=&#34;https://t.co/K3KWPO8l4a&#34;&gt;https://t.co/K3KWPO8l4a&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/neuralnetworks?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#neuralnetworks&lt;/a&gt; &lt;a href=&#34;https://t.co/iWsd9nK5qp&#34;&gt;pic.twitter.com/iWsd9nK5qp&lt;/a&gt;&lt;/p&gt;&amp;mdash; PLOS Comp Biol (@PLOSCompBiol) &lt;a href=&#34;https://twitter.com/PLOSCompBiol/status/829474896023474176?ref_src=twsrc%5Etfw&#34;&gt;February 8, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Motion-based prediction model for flash lag effect</title>
      <link>https://laurentperrinet.github.io/publication/khoei-14-vss/</link>
      <pubDate>Fri, 22 Aug 2014 00:00:00 +0300</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-14-vss/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt; and &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2013&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</title>
      <link>https://laurentperrinet.github.io/talk/2014-04-25-kaplan-beijing/</link>
      <pubDate>Fri, 25 Apr 2014 00:00:00 +0300</pubDate>
      
      <guid>https://laurentperrinet.github.io/talk/2014-04-25-kaplan-beijing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WP5 - Demo 1.3 : Spiking model of motion-based prediction</title>
      <link>https://laurentperrinet.github.io/talk/2014-03-20-manchester/</link>
      <pubDate>Thu, 20 Mar 2014 13:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/talk/2014-03-20-manchester/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</title>
      <link>https://laurentperrinet.github.io/publication/kaplan-khoei-14/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/kaplan-khoei-14/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2013&lt;/a&gt;



&lt;figure&gt;

&lt;img src=&#34;https://www.frontiersin.org/files/Articles/53894/fncom-07-00112-r2/image_m/fncom-07-00112-g003.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Figure 4: &lt;em&gt;Rasterplot of input and output spikes.&lt;/em&gt; The raster plot from excitatory neurons is ordered according to their position. Each input spike is a blue dot and each output spike is a black dot. While input is scattered during blanking periods (Figure 1), the network output shows shows some tuned activity during the blank (compare with the activity before visual stimulation). To decode such patterns of activity we used a maximum-likelihood estimation technique based on the tuning curve of the neurons.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Motion-based prediction explains the role of tracking in motion extrapolation</title>
      <link>https://laurentperrinet.github.io/publication/khoei-13-jpp/</link>
      <pubDate>Thu, 14 Nov 2013 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-13-jpp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2017&lt;/a&gt;



&lt;figure&gt;

&lt;img src=&#34;figure1.jpg&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Figure 1: The problem of fragmented trajectories and motion extrapolation. As an object moves in visual space (as represented here for commodity by the red trajectory of a tennis ball in a space–time diagram with a one-dimensional space on the vertical axis), the sensory flux may be interrupted by a sudden and transient blank (as denoted by the vertical, gray area and the dashed trajectory). How can the instantaneous position of the dot be estimated at the time of reappearance? This mechanism is the basis of motion extrapolation and is rooted on the prior knowledge on the coherency of trajectories in natural images. We show below the typical eye velocity profile that is observed during Smooth Pursuit Eye Movements (SPEM) as a prototypical sensory response. It consists of three phases: first, a convergence of the eye velocity toward the physical speed, second, a drop of velocity during the blank and finally, a sudden catch-up of speed at reappearance (Becker and Fuchs, 1985).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Motion-based prediction and development of the response to an &#39;on the way&#39; stimulus</title>
      <link>https://laurentperrinet.github.io/publication/khoei-13-cns/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-13-cns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2013&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Role of motion-based prediction in motion extrapolation</title>
      <link>https://laurentperrinet.github.io/publication/khoei-12-sfn/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-12-sfn/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2013&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Role of motion inertia in dynamic motion integration for smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/khoei-11-ecvp/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-11-ecvp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2013&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamical emergence of a neural solution for motion integration</title>
      <link>https://laurentperrinet.github.io/publication/khoei-10-tauc/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0200</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-10-tauc/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34; target=&#34;_blank&#34;&gt;Khoei et al, 2013&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/mina-a-khoei/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/authors/mina-a-khoei/</guid>
      <description>

&lt;h1 id=&#34;emerging-properties-in-a-neural-field-model-implementing-probabilistic-prediction-phd-2011-2014&#34;&gt;Emerging properties in a neural field model implementing probabilistic prediction (PhD, 2011-2014)&lt;/h1&gt;

&lt;p&gt;In the early visual system, information about the visual world as represented by neural activity is dynamically building up from sensory input but also by contextual information coming from neighboring cells and re-entrant signal from other cortical areas. Low-level sensory areas are therefore an excellent model for exploring how neural computations solve the problem of selecting a single, coherent and global representation from the dispersed information collected locally and in parallel by neurons. Our goal in this program is to study the dynamics of neural fields implementing probabilistic computations for early sensory processing. Emphasis will be put onto the role of anisotropic diffusion, in particular within a cortical area through lateral interactions.&lt;/p&gt;

&lt;p&gt;We have previously elaborated probabilistic (Perrinet &amp;amp; Masson, 2010) or dynamical (Tlapale et al., 2010) models of motion information diffusion along cortical retinotopic trajectories. Probabilistic models give a complete representation of the information that is represented by populations of neurons. In such a dynamical system, prediction acts as a prior, filtering possible future states knowing the current one. An approximation using particle filtering methods will be used to investigate how this propagation can solve low-level computational problems such as integration, extrapolation or prediction in visual (Mason &amp;amp; Ilg, 2010) or somatosensory (Shulz et al. 2006) cortices.&lt;/p&gt;

&lt;p&gt;Using this architecture, we will explore the consequences of such context-dependent propagation in terms of coding and of learning. First at the time scale of coding, knowing the prior, we will study the emergent properties of the system like its ability to track objects independently of their shape or to segment parts of the scene that are moving coherently. We will study of this motion information may help shape the selectivity of neurons in a given area, for instance orientation selectivity on the priamry visual cortex. At the time scale of learning, we will build models exploring the emergence of maps of cortical receptive fields optimally tuned to elaborate sparse, multi-scale representations of the visual or tactile world. In fact, a simple functional model allows to understand emergence in a model of a simple macro-column of the primary visual cortex (Perrinet, 2010). One challenging question is whether these functional models of self-organization can be translated to large-scale networks of the early sensory system. Using the probabilistic model, we will investigate how spatio-temporal receptive fields can emerge through learning of statistical regularities in the images and study how hierarchic structures can arise as a self-organized property.&lt;/p&gt;

&lt;h1 id=&#34;propriétés-émergentes-d-un-modèle-de-prédiction-probabiliste-utilisant-un-champ-neural&#34;&gt;Propriétés émergentes d&amp;rsquo;un modèle de prédiction probabiliste utilisant un champ neural&lt;/h1&gt;

&lt;p&gt;Dans le système visuel de bas niveau, des informations sur le monde visuel tel que celles représentées par l&amp;rsquo;activité neuronale est dynamiquement causée par l&amp;rsquo;entrée sensorielle, mais aussi par des informations contextuelles provenant de cellules voisines et par le signal réentrant d&amp;rsquo;autres aires corticales. Les aires sensorielles primaires sont donc un excellent modèle pour étudier comment les neurones peuvent résoudre le problème de la sélection d&amp;rsquo;une seul représentation globale et cohérente depuis l&amp;rsquo;information collectée localement et en parallèle par les neurones. Notre objectif dans ce programme est d&amp;rsquo;étudier la dynamique de champs neuronaux mettant en œuvre des calculs probabilistes pour le traitement sensoriel précoce.&lt;/p&gt;

&lt;p&gt;L&amp;rsquo;accent sera mis sur le rôle de la diffusion anisotrope, en particulier celle implémentée par les interactions latérales dans une aire corticale. Nous avons déjà élaboré des modèles probabiliste (Perrinet &amp;amp; Masson, 2010) ou dynamique (Tlapale et al., 2010) de diffusion de l&amp;rsquo;information de mouvement le long de trajectoires. Les modèles probabilistes donnent une représentation complète de l&amp;rsquo;information qui est représentée par des populations de neurones. Dans un tel système dynamique, la prédiction agit comme un prior, qui permet un filtrage des états futurs possibles en sachant la distribution de probabilité de l&amp;rsquo;état actuel. Une approximation à l&amp;rsquo;aide des méthodes de filtrage particulaires seront utilisées pour étudier comment cette propagation peut résoudre des problèmes de calcul de bas niveau telles que l&amp;rsquo;intégration, l&amp;rsquo;extrapolation ou la prédiction dans les système visuel (Mason &amp;amp; Ilg, 2010) ou somatosensoriel (Shulz et al. 2006).&lt;/p&gt;

&lt;p&gt;En utilisant cette architecture, nous allons explorer les conséquences de la propagation dépendant du contexte tant en termes de codage que d&amp;rsquo;apprentissage. Premièrement, à l&amp;rsquo;échelle de temps de codage, connaissant l&amp;rsquo;architecture du réseau, nous allons étudier les propriétés émergentes du système, comme sa capacité à suivre les objets indépendamment de leur forme ou à segmenter des parties de la scène qui se déplacent de façon cohérente. Nous allons étudier le mouvement de cette information peut aider à façonner la sélectivité des neurones, par exemple la sélectivité à l&amp;rsquo;orientation sur le cortex visuel primaire. À l&amp;rsquo;échelle de temps d&amp;rsquo;apprentissage, nous allons construire des modèles d&amp;rsquo;émergence de cartes de champs récepteurs corticaux optimisées pour élaborer des représentations multi-échelles efficaces de l&amp;rsquo;univers visuel ou tactile. En fait, un modèle fonctionnel simple permet de comprendre l&amp;rsquo;émergence d&amp;rsquo;un modèle d&amp;rsquo;une simple macro-colonne du cortex visuel primaire (Perrinet, 2010). Une question difficile est de savoir si ces modèles fonctionnels d&amp;rsquo;auto-organisation peuvent être traduits à des réseaux à grande échelle du système sensoriel primaire. En utilisant ce modèle probabiliste, nous allons étudier comment des champs récepteurs spatio-temporels peuvent émerger à travers l&amp;rsquo;apprentissage des régularités statistiques dans les images et comment des structures hiérarchiques peuvent apparaitre comme la solution d&amp;rsquo;une propriété d&amp;rsquo;efficacité fonctionnelle.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
