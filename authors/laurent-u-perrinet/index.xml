<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Laurent U Perrinet on Novel computational paradigms for vision</title>
    <link>https://laurentperrinet.github.io/authors/laurent-u-perrinet/</link>
    <description>Recent content in Laurent U Perrinet on Novel computational paradigms for vision</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png&#34; /&gt;&lt;/a&gt;&lt;br /&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License&lt;/a&gt;
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared.
</copyright>
    
	<atom:link href="https://laurentperrinet.github.io/authors/laurent-u-perrinet/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Active inference, eye movements and oculomotor delays.</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-13-cns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/perrinet-13-cns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active inference, smooth pursuit and oculomotor delays.</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-12-areadne/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/perrinet-12-areadne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anisotropic connectivity implements motion-based prediction in a spiking neural network</title>
      <link>https://laurentperrinet.github.io/publication/kaplan-13/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/kaplan-13/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anticipating a moving target: role of vision and reinforcement</title>
      <link>https://laurentperrinet.github.io/publication/montagnini-15-sfn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/montagnini-15-sfn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Modeling of Motion Perception using Dynamical Stochastic Textures</title>
      <link>https://laurentperrinet.github.io/publication/vacher-16/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/vacher-16/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biologically Inspired Dynamic Textures for Probing Motion Perception</title>
      <link>https://laurentperrinet.github.io/publication/vacher-15-nips/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/vacher-15-nips/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compensation of oculomotor delays in the visual system&#39;s network.</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-16-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/perrinet-16-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differential response of the retinal neural code with respect to the sparseness of natural images</title>
      <link>https://laurentperrinet.github.io/publication/ravello-16-droplets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/ravello-16-droplets/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eye tracking a self-moved target with complex hand-target dynamics</title>
      <link>https://laurentperrinet.github.io/publication/danion-15-sfn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/danion-15-sfn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>M2APix: a bio-inspired auto-adaptive visual sensor for robust ground height estimation</title>
      <link>https://laurentperrinet.github.io/publication/dupeyroux-boutin-serres-perrinet-viollet-18/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/dupeyroux-boutin-serres-perrinet-viollet-18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Role of motion-based prediction in motion extrapolation</title>
      <link>https://laurentperrinet.github.io/publication/khoei-12-sfn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/khoei-12-sfn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Speed-Selectivity in Retinal Ganglion Cells is Sharpened by Broad Spatial Frequency, Naturalistic Stimuli</title>
      <link>https://laurentperrinet.github.io/publication/ravello-19/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/ravello-19/</guid>
      <description>Dès la rétine, le système visuel préfère des images naturelles Dans la rétine, au premier étage du traitement de l&amp;rsquo;image visuelle, on peut obtenir des représentations extrêmement fines. Une collaboration entre des chercheurs français et chiliens a permis de mettre en évidence que, dans la rétine de rongeurs, une représentation de la vitesse de l&amp;rsquo;image visuelle est précisément codée. Dans cette collaboration pluridisciplinaire, l&amp;rsquo;utilisation d&amp;rsquo;un modèle du fonctionnement de la rétine a permis de générer un nouveau type de stimuli visuels qui a révélé des résultats expérimentaux surprenants.</description>
    </item>
    
    <item>
      <title>Testing the odds of inherent vs. observed overdispersion in neural spike counts.</title>
      <link>https://laurentperrinet.github.io/publication/taouali-16/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://laurentperrinet.github.io/publication/taouali-16/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>