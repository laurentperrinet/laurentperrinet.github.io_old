<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Authors | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/authors/</link>
      <atom:link href="https://laurentperrinet.github.io/authors/index.xml" rel="self" type="application/rss+xml" />
    <description>Authors</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Sun, 27 Sep 2020 00:00:00 +0200</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/img/hulk.png</url>
      <title>Authors</title>
      <link>https://laurentperrinet.github.io/authors/</link>
    </image>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/angelo-franciosini/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/angelo-franciosini/</guid>
      <description>&lt;h1 id=&#34;trajectories-in-natural-images-and-the-sensory-processing-of-contours-phd-position-2017--2021&#34;&gt;Trajectories in natural images and the sensory processing of contours (PhD position, 2017 / 2021)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Venue: Aix-Marseille Université&amp;rsquo;s 
&lt;a href=&#34;https://laurentperrinet.github.io/project/phd-icn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neuroschool PhD program in Neuroscience&lt;/a&gt;
 (formerly known as &amp;ldquo;Ph.D. program in Integrative and Clinical Neuroscience&amp;rdquo;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keywords: Vision, Neural Networks, Bio-Inspired Computer Vision, contours, learning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Thesis director: Dr. Laurent PERRINET, Director&amp;rsquo;s research unit: Institut de Neurosciences de la Timone (INT)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description-of-the-phd-thesis-project&#34;&gt;Description of the PHD thesis project&lt;/h2&gt;
&lt;p&gt;Binding the different features of objects in images is at the core of visual perception. As such, the visual system needs to detect local edges and to bind them together to form contours at a higher, more global level. A state-of-the art theory is that of the “association field”: the confidence of an edge depends on the configuration of neighboring edges. For instance it is facilitated for co-linear or co-circular edges. This process takes advantage of the statistical regularities of edges that are present in natural images. In particular, we have developed a method to quantify the association field in different classes of natural images (
&lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-bednar-15/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Perrinet &amp;amp; Bednar, 2015&lt;/a&gt;
). Using an 
&lt;a href=&#34;https://github.com/bicv/SparseEdges&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;existing library&lt;/a&gt;
, it is possible to compute histograms of edge co-occurrences from the sparse representation of static natural images. We have already shown that these different statistics were sufficient to categorize images, for instance to know if they contain an animal or not.  At the neural level, modeling the representation of the image, such as that formed in the primary visual cortex of primates (V1), this heuristics translates to a set of rules that adapts dynamically the activity of isolated neurons representing edges into the coherent population activity of contours. &amp;lsquo;&amp;lsquo;&amp;lsquo;Yet, we miss an understanding of the link between these statistics and the probabilistic rules that binds features together and how this information is dynamically encoded in V1.&amp;rsquo;&amp;rsquo;&amp;rsquo;&lt;/p&gt;
&lt;h3 id=&#34;objectives&#34;&gt;Objectives&lt;/h3&gt;
&lt;p&gt;In this computational neuroscience project, we will exploit our current expertise in computer vision for the statistical integration of visual of objects to translate them in the form of probabilistic predictive models for biological vision. &amp;lsquo;&amp;lsquo;&amp;lsquo;Our core hypothesis is that in natural scenes, contours follow coherent trajectories and that this knowledge is integrated (learned) by the visual system to optimally inform the representation of the image.&amp;rsquo;&amp;rsquo;&amp;rsquo;&lt;/p&gt;
&lt;h3 id=&#34;methods&#34;&gt;Methods&lt;/h3&gt;
&lt;p&gt;First, we will learn the different classes of edge co-occurrences that are relevant to natural images. Using an 
&lt;a href=&#34;https://github.com/bicv/SparseHebbianLearning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;existing  unsupervised learning algorithm&lt;/a&gt;
, we will learn these as an independent components analysis. Such an algorithm extends well to a deep-learning convolutional neural network, but importantly, it will be informed by our expertise of modeling neural networks in low-level visual areas by including horizontal connectivity. We expect that relevant features will be mainly the predictable arrangements, such as co-linear or co-circular pairs of edges, but also highly surprising ones, such as T-junctions or end-stopping features. Importantly, we will be able to compare this representation with that present in higher level areas and to refine our knowledge on the representation of natural-like images. Second, we have previously found that using synthetic textures could further advance our understanding of neural computations and perception. These random synthetic textures, coined “Motion Clouds” were initially targeted to quantify the integration properties of visual motion perception (
&lt;a href=&#34;https://laurentperrinet.github.io/publication/sanz-12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Leon et al, 2012&lt;/a&gt;
, 
&lt;a href=&#34;https://laurentperrinet.github.io/publication/simoncini-12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simoncini et al, 2012&lt;/a&gt;
). Informed by the generative model of edge co-occurrences studied above, an extension to such stimuli would be to include dependencies between different elements. As such, we will be able to manipulate the level of dependency between different elements, whether in space, time or feature space (orientations). A potential outcome will be to use these in neurophysiological and psychophysical experiments within the team. In particular, the ability to select different classes of dependencies learned above will make it possible to evaluate the relative contribution of each component to the association field.&lt;/p&gt;
&lt;h3 id=&#34;expected-results&#34;&gt;Expected results&lt;/h3&gt;
&lt;p&gt;Finally, those two tasks converge to a long-term goal of &amp;lsquo;&amp;lsquo;&amp;lsquo;understanding the impact of the spatio-temporal structure of natural images in the neural computations implementing visual processing in low-level visual areas and perception&amp;rsquo;&#39;&#39;. Indeed, the regularities observed in static images can be extended to dynamical scenes by observing that a co-occurrence in time can be implemented by simple geometrical operations as they are operated during that period. For instance a co-circularity can be described as a smooth roto-translational transformation of an edge along a smooth trajectory. Importantly, such a distinction should allow us to determine the hierarchy of different features relevant to describe the full statistics of the feature space (that is, of spatio-temporal edge co-occurrences). We expect to see that the different independent features should decompose at various scales both in space and in time. This translates into a probabilistic hierarchical model that would combine dependencies from different cues. In particular, we expect to see the emergence of differential pathways for form and motion.&lt;/p&gt;
&lt;h3 id=&#34;feasibility&#34;&gt;Feasibility&lt;/h3&gt;
&lt;p&gt;The project is based on existing expertise and libraries in computer vision and computational neuroscience. The extension of this expertise to the dynamical domain will be made possible thanks to an existing collaboration (
&lt;a href=&#34;http://www.cmla.ens-cachan.fr/version-francaise/haut-de-page/annuaire/morel-jean-michel-780.kjsp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JM Morel at ENS-Cachan&lt;/a&gt;
, 
&lt;a href=&#34;http://www.gpeyre.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;G Peyré at ENS-Ulm&lt;/a&gt;
). The groundbreaking nature of the work takes advantage of the interaction with  neurophysiological and psychophysical experiments thanks to the use of synthetic textures (collaboration with F Chavane, INT; Y Fregnac, UNIC) as planned in a the parallel (approved) grant 
&lt;a href=&#34;https://laurentperrinet.github.io/project/anr-horizontal-v1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Horizontal-V1&lt;/a&gt;
.&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/publication/simoncini-12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simoncini C, Perrinet LU, Montagnini A, Mamassian P, Masson GS (2012)&lt;/a&gt;
 More is not always better: dissociation between perception and action explained by adaptive gain control. Nature Neuroscience, 15:1596–1603&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/publication/friston-12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Friston KJ, Adams RA, Perrinet LU, Breakspear M (2012)&lt;/a&gt;
 Perceptions as Hypotheses: Saccades as Experiments. Frontiers in Psychology, 3&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-adams-friston-12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Perrinet LU, Adams RA, Friston KJ. (2014)&lt;/a&gt;
 Active inference, eye movements and oculomotor delays. Biological Cybernetics, 108(6):777-801&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-bednar-15/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Perrinet LU, Bednar JA (2015)&lt;/a&gt;
 Edge co-occurrences can account for rapid categorization of natural versus animal images. Scientific Reports, 5:11400&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Khoei M, Masson GS, Perrinet LU (2017)&lt;/a&gt;
 The flash-lag effect as a motion-based predictive shift. PLoS Computational Biology, 13(1):e1005068&lt;/li&gt;
&lt;li&gt;we keep a bibliography on the project @ &lt;a href=&#34;https://www.mendeley.com/community/edgetracks/&#34;&gt;https://www.mendeley.com/community/edgetracks/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/laurent-u-perrinet/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/laurent-u-perrinet/</guid>
      <description>&lt;p&gt;Laurent Perrinet is a computational neuroscientist specialized in large scale neural network models of low-level vision, perception and action, currently at the &amp;ldquo;Institut de Neurosciences de la Timone&amp;rdquo; (France), a joint research unit (CNRS / Aix-Marseille Université). He co-authored more than 40 articles in computational neuroscience and computer vision. He graduated from the aeronautics engineering school SUPAERO, in Toulouse (France) with a signal processing and applied mathematics degree. He received a PhD in Cognitive Science in 2003 on the mathematical analysis of temporal spike coding of images by using a multi-scale and adaptive representation of natural scenes. His research program is focusing in bridging the complex dynamics of realistic, large-scale models of spiking neurons with functional models of low-level vision. In particular, as part of the FACETS and BrainScaleS consortia, he has developed experimental protocols in collaboration with neurophysiologists to characterize the response of population of neurons. Recently, he extended models of visual processing in the framework of predictive processing in collaboration with the team of Karl Friston at the University College of London. This method aims at characterizing the processing of dynamical flow of information as an active inference process. His current challenge within the &lt;a href=&#34;http://www.int.univ-amu.fr/spip.php?page=equipe&amp;equipe=NeOpTo&amp;lang=en&#34;&gt;NeOpTo team&lt;/a&gt; is to translate, or &lt;em&gt;compile&lt;/em&gt; in computer terminology, this mathematical formalism with the event-based nature of neural information with the aim of pushing forward the frontiers of Artificial Intelligence systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/victor-boutin/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/victor-boutin/</guid>
      <description>&lt;h1 id=&#34;controlling-an-aerial-robot-by-human-semaphore-gestures-using-a-bio-inspired-neural-network-phd-122016---022020&#34;&gt;Controlling an aerial robot by human semaphore gestures using a bio-inspired neural network (PhD, 12/2016 - 02/2020)&lt;/h1&gt;
&lt;p&gt;The brain is a complex machinery that is incredibly efficient and flexible. Thanks to efficient training processes, it tackles a high diversity of tasks with a high robustness. In contrast, states-of-the-art machine learning algorithms exhibit great performances, but are also highly task-specialized. Consequently, neuroscience is potentially a great source of inspiration to design more efficient artificial intelligence algorithms.&lt;/p&gt;
&lt;p&gt;In particular, vision is predominant compared to other senses in terms of computational resources. So understanding visual processing has the potential to reveal the core computational mechanisms that give the brain such performances. In my research, I am interested in extracting the fundamental principles that are at stake in the visual system, and to apply them to develop better machine learning algorithms. As I consequence, I tend to adopt a cross-level analysis approach. I develop algorithms that simultaneously model low-level neural mechanisms and account for higher-level visual tasks such as object recognition, denoising, inpainting, image generation, etc.&lt;/p&gt;
&lt;p&gt;The ultimate objective would be to develop a framework that successfully solves all these visual tasks without being extensively retrained from scratch for each of those tasks. Such an algorithm would be a first step towards the ultimate goal of every researcher in machine learning, that is, general artificial intelligence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Venue: Aix-Marseille University 
&lt;a href=&#34;https://doc2amu.univ-amu.fr/fr/victor-boutin-doctorant-promotion-2016&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOC2AMU&lt;/a&gt;
 is an innovative H2020-MSCA-COFUND&lt;/li&gt;
&lt;li&gt;Keywords: Aerial Robots, Vision, Neural Networks, Bio-Inspired Computer Vision, Gaze orientation, learning&lt;/li&gt;
&lt;li&gt;Thesis director: Dr. Laurent PERRINET, Director&amp;rsquo;s research unit: Institut de Neurosciences de la Timone (INT)&lt;/li&gt;
&lt;li&gt;Thesis co-supervisition: Dr. Franck RUFFIER Co-director&amp;rsquo;s research unit: Institut des Sciences du Mouvement (ISM)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description-of-the-phd-thesis-project&#34;&gt;Description of the PHD thesis project&lt;/h2&gt;
&lt;p&gt;Robotics is a rapidly evolving technology that allows for fast, low-risk
and low-cost tasks with a worldwide market of over 80 billion dollars
over the next few years. In particular, aerial robots, also known as
drones, provide a breakthrough to easily image and access all sorts of
terrains and situations and are useful for instance in surveillance and
forensics, emergency industrial inspection or a search and rescue
operation. A major difficulty for their global acceptance is the
difficulty for controlling their flight and interacting with them.&lt;/p&gt;
&lt;p&gt;Indeed, aerial robots are generally operated using a (central) ground
station which is not compatible with the time pressure required by
emergency conditions, for instance when
rescuing a person out of reach with the ground station. This PhD project
aims at concealing such obstacles and construct an aerial robot which is
able to be autonomously and interactively controlled by simple human
gestures, for instance that of a rescuer. The main scientific challenges
are (i) to embed in the aerial robot all the electronics for the visual
system from the retina to the control signals to the propellers, (ii) to
very quickly recognize a variety of simple gestures on-board using a
neuromimetic architecture and (iii) to make the robot react in real time
to these gestures. As such, this project is inter-disciplinary by
positively combining advanced algorithms from event-based bio-inspired
computer vision and the latest technology in aerial robots.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;R. Benosman , S.-H. Leng , C. Clercq , C. Bartolozzi &amp;amp; M. Srinivasan (2012) “Asynchronous frameless event-based optical flow”, Neural Networks - Elsevier&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;S.-C. Liu &amp;amp; T. Delbruck (2010) “Neuromorphic sensory systems”, Current opinion in neurobiology - Elsevier&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;J. Nagi, A. Giusti, G. A. Di Caro, L. M. Gambardella (2014) “HRI in the Sky, Controlling UAVs using Face Poses and Hand Gestures”, HRI&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;3i-dimensions-and-other-aspects-of-the-project&#34;&gt;3I dimensions and other aspects of the project&lt;/h2&gt;
&lt;p&gt;The present PhD proposal is at the crossroad between various
disciplines. It first concerns biology and neuroscience because its
event-based approach is strongly inspired from the neuronal network
observed in animals such as insects to primates and used for navigation,
obstacle avoidance, and sensori-motor control. It is also covering
electronics, aerial robotics and signal processing as the main project
achievement is to create a working spike-based electronic architecture
able to recognize body movement, and to use it to control the robot.
Such an oucome will have beneficial outcomes with respects to the SRI-S3
regional strategy, in particular with respect to “risks, security and
safety”.&lt;/p&gt;
&lt;p&gt;This project is a partnership between two different doctoral schools
based in Marseille: the EDSMH at ISM for the robotic part, and the EDSVS
at INT concerning visual processing and spike-based processing methods.
This partnership will provide the ESR with the best resources to achieve
his goals. In particular, the ISM owns a brand new flying arena (funded
by Robotex project, &lt;a href=&#34;http://www.marseilles-flying-arena.eu&#34;&gt;www.marseilles-flying-arena.eu&lt;/a&gt;) equipped with
high-tech motion capture tools (Vicon) and the INT has a entire
technological platform dedicated for high-performance computing and
measurement tool prototyping.&lt;/p&gt;
&lt;p&gt;Combining neuroscience and robotics to design novel electronic
architectures is an innovative and a valuable approach in Robotics. The
doctoral student selected for this project will acquire experience in
bio-inspired hardware architectures, which is going to be valuable in
his career as there is a need to adapt actual electronic architecture to
for instance spike-based visual processing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/anna-montagnini/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/anna-montagnini/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chloé Pasturel</title>
      <link>https://laurentperrinet.github.io/authors/chloe-pasturel/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/chloe-pasturel/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/frederic-y-chavane/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/frederic-y-chavane/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/wahiba-taouali/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/wahiba-taouali/</guid>
      <description>&lt;h1 id=&#34;motion-integration-by-v1-population--post-doc-2013-03--2015-01&#34;&gt;Motion Integration By V1 Population  (Post-Doc, 2013-03 / 2015-01)&lt;/h1&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Wahiba hold the postdoctoral position at the 
&lt;a href=&#34;http://www.int.univ-amu.fr/spip.php?rubrique2&amp;amp;lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Institut de Neurosciences de la Timone&amp;rdquo;&lt;/a&gt;
, CNRS, Marseille (France) to study object motion integration and representation at the level of V1 populations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The objective is in modeling, with Laurent Perrinet, anisotropic diffusive processes, such as observed in V1, at the functional and neural levels.&lt;/li&gt;
&lt;li&gt;The work was done in collaboration with a post-doc in physiology, with Frédéric Chavane, that focused on the role of propagation and diffusion of activity at the level of neuronal population in V1 of awake monkeys (using Voltage-sensitive dye imaging and UTAH array recording).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wahiba is now scientific software developper at 
&lt;a href=&#34;https://www.enthought.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Enthought&lt;/a&gt;
.&lt;/p&gt;
&lt;h2 id=&#34;context&#34;&gt;Context&lt;/h2&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://brainscales.kip.uni-heidelberg.de/images/thumb/e/e2/Public--BrainScalesLogo.svg/100px-Public--BrainScalesLogo.svg.png&#34; data-caption=&#34;This grant was funded by a large European integrated project called BrainScales whose aim is to understand brain information processing at multiple spatial and temporal scales. The successful applicants will have the opportunity to interact with a large and exciting consortium composed of 18 europeans teams working in biology, modeling and hardware.&#34;&gt;


  &lt;img src=&#34;https://brainscales.kip.uni-heidelberg.de/images/thumb/e/e2/Public--BrainScalesLogo.svg/100px-Public--BrainScalesLogo.svg.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    This grant was funded by a large European integrated project called &lt;a href=&#34;https://brainscales.kip.uni-heidelberg.de/index.html&#34;&gt;BrainScales&lt;/a&gt; whose aim is to understand brain information processing at multiple spatial and temporal scales. The successful applicants will have the opportunity to interact with a large and exciting consortium composed of 18 europeans teams working in biology, modeling and hardware.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;References::&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reynaud A., Masson G. S. and Chavane F. 
&lt;a href=&#34;http://www.jneurosci.org/content/32/36/12558.abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dynamics of Local Input Normalization Result from Balanced Short- and Long-Range Intracortical Interactions in Area V1&lt;/a&gt;
 Journal of Neuroscience, 2012, 32(36): 12558-12569&lt;/li&gt;
&lt;li&gt;Reynaud A., Takerkart S, Masson G. S. and Chavane F. 
&lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1053811910011237&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linear model decomposition for voltage-sensitive dye imaging signals: Application in awake behaving monkey.&lt;/a&gt;
 Neuroimage, 2011, 54(2), 1196–1210&lt;/li&gt;
&lt;li&gt;Perrinet, L. and Masson G. 
&lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;
 Neural Computation, 2012&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Giacomo Benvenuti</title>
      <link>https://laurentperrinet.github.io/authors/giacomo-benvenuti/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/giacomo-benvenuti/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/emmanuel-dauce/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/emmanuel-dauce/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pierre Albigès</title>
      <link>https://laurentperrinet.github.io/authors/pierre-albiges/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/pierre-albiges/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alain Destexhe</title>
      <link>https://laurentperrinet.github.io/authors/alain-destexhe/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/alain-destexhe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alexandre Reynaud</title>
      <link>https://laurentperrinet.github.io/authors/alexandre-reynaud/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/alexandre-reynaud/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Matteo diVolo</title>
      <link>https://laurentperrinet.github.io/authors/matteo-divolo/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/matteo-divolo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sandrine Chemla</title>
      <link>https://laurentperrinet.github.io/authors/sandrine-chemla/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/sandrine-chemla/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Yann Zerlaut</title>
      <link>https://laurentperrinet.github.io/authors/yann-zerlaut/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/yann-zerlaut/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Franck Ruffier</title>
      <link>https://laurentperrinet.github.io/authors/franck-ruffier/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/franck-ruffier/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adrián G Palacios</title>
      <link>https://laurentperrinet.github.io/authors/adrian-g-palacios/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/adrian-g-palacios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cesar U Ravello</title>
      <link>https://laurentperrinet.github.io/authors/cesar-u-ravello/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/cesar-u-ravello/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Maria-José Escobar</title>
      <link>https://laurentperrinet.github.io/authors/maria-jose-escobar/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/maria-jose-escobar/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/hugo-ladret/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/hugo-ladret/</guid>
      <description>&lt;h1 id=&#34;phd-student-2019-09--2013-11-a-multiscale-cortical-model-to-account-for-orientation-selectivity-in-natural-like-stimulations&#34;&gt;PhD Student (2019-09 / 2013-11): A multiscale cortical model to account for orientation selectivity in natural-like stimulations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Aix-Marseille Université, Institut des Neurosciences de la Timone&lt;/li&gt;
&lt;li&gt;Université de Montréal, Laboratoire des Neurosciences de la Vision&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;master-2b-undergrad-2019-01-12--2019-05-24&#34;&gt;master 2B (undergrad, 2019-01-12 / 2019-05-24)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Université de Montréal, Laboratoire des Neurosciences de la Vision&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;master-2a-undergrad-2018-09-10--2019-01-11--learning-temporal-integrations-in-a-visual-spiking-neural-network&#34;&gt;master 2A (undergrad, 2018-09-10 / 2019-01-11) : Learning temporal integrations in a visual spiking neural network&lt;/h1&gt;
&lt;p&gt;Building upon our previous work, we are investigating how recurrent neural networks learn to integrate temporal information, a dimension which is absent in most deep learning networks but provides a wealth of information in biological neural networks.&lt;/p&gt;
&lt;p&gt;To be able to generalize our findings, I created a model of the early visual pathway (retina and thalamus) that generates neural activity from any natural image, based on data gathered in biological systems for the past several decades.
The output from this early visual pathway is then processed by a recurrent spiking neural network whose dynamics match that of the primary visual cortex.&lt;/p&gt;
&lt;p&gt;We showed that Spike Timing Dependant Plasticity (STDP) and recurrence are key components that allow spiking neural networks to extract patterns from noisy input and build strong internal representations. Such representations not only correctlt predict spatial informations (for example the organization of a visual scene) but also predict temporal structure underlying such informations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;source code : &lt;a href=&#34;https://github.com/hugoladret/InternshipM2&#34;&gt;https://github.com/hugoladret/InternshipM2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;neuroscience-specialist-for-artistic-creation-2018-07--2018-09&#34;&gt;Neuroscience Specialist for Artistic Creation (2018-07 / 2018-09)&lt;/h1&gt;
&lt;p&gt;I developed computational neuroscience and computational physics models, in collaboration with well-known contemporary artist Etienne Rey at Friche la Belle de Mai (Marseille) and AI researcher Laurent Perrinet. The idea behind our project was to create works of art by distributing particles in a constrained, semi-stable space, thereby creating discrete illusory perceptions.&lt;/p&gt;
&lt;p&gt;To dive into more technical details, my work included the implementation of a Boltzmann lattice for computational fluid dynamics (D2Q9 structure), as well as various electro-magnetic interaction models. On the neuroscience side, I used Deep Convoluted Generative Adverserial Networks (DCGAN), Kohonen maps and Canny edge detectors to generate triangulated graphs with a hidden underlying structure.
In order to facilitate collaboration between the three of us, I also developed a GUI and multi-threading support that allowed us to work efficiently and use at best each our respective skill set.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;source code : &lt;a href=&#34;https://github.com/NaturalPatterns/&#34;&gt;https://github.com/NaturalPatterns/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;master-1-undergrad-2018-04--2018-06-orientation-selectivity-in-a-ring-model-of-the-primary-visual-cortex&#34;&gt;master 1 (undergrad, 2018-04 / 2018-06): Orientation selectivity in a ring model of the primary visual cortex&lt;/h1&gt;
&lt;p&gt;I created a ring model that performs orientation discrimination tasks, using an hybrid model of convolutionnal and recurrent networks. This work was, to our knowledge, the first visual ring model based on deep learning techniques.&lt;/p&gt;
&lt;p&gt;The recurrence in the network plays a role akin to that of lateral interactions within the primary visual cortex. We have shown in this work that these lateral interactions provide robustness to noisy inputs in the model, which we infer to also be the  the case in the brain.
To verify this assessment, I designed a 2-outcome discriminative psychophysics task (2AFC) and compared various metrics for human and model trials. The results showed that the lateral interactions allowed human-like performance, which is a strong qualitative argument in favor of the biological plausiblity of this model.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all material is available @ &lt;a href=&#34;https://github.com/hugoladret/InternshipM1&#34;&gt;https://github.com/hugoladret/InternshipM1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Christian Casanova</title>
      <link>https://laurentperrinet.github.io/authors/christian-casanova/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/christian-casanova/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nelson Cortes</title>
      <link>https://laurentperrinet.github.io/authors/nelson-cortes/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/nelson-cortes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Andrew Isaac Meso</title>
      <link>https://laurentperrinet.github.io/authors/andrew-isaac-meso/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/andrew-isaac-meso/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Gabriel Peyré</title>
      <link>https://laurentperrinet.github.io/authors/gabriel-peyre/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/gabriel-peyre/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jonathan Vacher</title>
      <link>https://laurentperrinet.github.io/authors/jonathan-vacher/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jonathan-vacher/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/jean-bernard-damasse/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jean-bernard-damasse/</guid>
      <description>&lt;h1 id=&#34;smooth-pursuit-eye-movements-and-learning-role-of-motion-probability-and-reinforcement-contingencies-phd-2014-2017&#34;&gt;Smooth pursuit eye movements and learning: Role of motion probability and reinforcement contingencies (PhD, 2014-2017)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Thesis director: Anna Montagnini&lt;/li&gt;
&lt;li&gt;Thesis co-supervisition: Laurent Perrinet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the continuous flow of sensory evidence, cognitive systems must provide rapid behavioral choices across different time scales. For instance, seeing a moving object may result in various responses such as catching or avoiding collision depending on the trajectory and the nature of the object, but also depending on the recent experience and the expectations associated with that object and its motion properties. The principal goal of the larger scientific project in which this PhD thesis is inscribed (see ANR-REM project) is the analysis of reinforcement learning processes in the domain of voluntary eye movements (saccades and smooth pursuit eye movements) in humans. Within this PhD project we will use a dual approach, based on behavioural experiments on human subjects and on computational modelling of the experimental data, in order to address this important question, with a particular emphasis on the time course of learning effects and on the hypothesised role of probabilistic inference as underlying mechanism. &amp;laquo;BR&amp;raquo; Visually driven eye movements provide an ideal experimental preparation to probe sensorimotor behavior across different time-scales, processing levels (from sensory encoding to the final categorical choice) and movement repertoire (e.g. smooth pursuit and saccades). In addition, a remarkable flexibility of oculomotor behaviors has been highlighted by manipulating the expectancy for sensory features or the outcome associated to particular motor responses.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;thesis available @ &lt;a href=&#34;https://www.theses.fr/s137225&#34;&gt;https://www.theses.fr/s137225&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/laurent-madelain/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/laurent-madelain/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/etienne-rey/</link>
      <pubDate>Thu, 25 Jan 2018 18:30:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/etienne-rey/</guid>
      <description>&lt;h1 id=&#34;collaboration-avec-etienne-rey&#34;&gt;collaboration avec Etienne Rey&lt;/h1&gt;
&lt;p&gt;Le travail d’Etienne Rey explore la notion même d’espace. L’enjeu est de produire des déplacements de perception. La question du lieu et de l’environnement, de l’in situ et de l’architecture participent à la découverte de structures spatiales par le biais de déplacements et de la démultiplication des points de vue.&lt;/p&gt;
&lt;p&gt;Les diverses installations ont pour point commun d’inviter à des expériences constituées de matériel et d’immatériel, d’énergies et d’attractions qui mettent en jeu des phénomènes physiques dont le vecteur principal est la lumière. Des transformations réflexives s’opèrent entre perception, propre à chacun, et conscience de l’impact de notre présence. L’intention est de produire des expériences d’espace. Les pièces dévoilent la façon dont ce dernier se structure. Entre installations immatérielles faites de brume et de lumière et celles employant des matériaux aux propriétés optiques, toutes les oeuvres élaborent des filtres perceptifs de l’environnement nous amenant à questionner notre relation au réel.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lire un portrait dans le journal 
&lt;a href=&#34;https://www.journalventilo.fr/19691-2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ventilo&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/kiana-mansour-pour/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/kiana-mansour-pour/</guid>
      <description>&lt;h1 id=&#34;predicting-and-selecting-sensory-events-inference-for-smooth-eye-movements-phd-2015---2019&#34;&gt;Predicting and selecting sensory events: inference for smooth eye movements (PhD: 2015 - 2019)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Funding: This position is funded by the Marie Skodowska-Curie program of the H2020 European Union program, as part of the 
&lt;a href=&#34;https://laurentperrinet.github.io/project/pace-itn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Innovative Training Network PACE (Perception and Action in Complex Environments)&lt;/a&gt;
.&lt;/li&gt;
&lt;li&gt;Thesis director: Anna Montagnini&lt;/li&gt;
&lt;li&gt;Thesis co-supervisition: Guillaume Masson, Laurent Perrinet&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description-of-the-phd-thesis-project&#34;&gt;Description of the PHD thesis project&lt;/h2&gt;
&lt;p&gt;In everyday life, we constantly need to track relevant moving targets in complex environments with our eyes such as, for instance, when we try to catch someone running in the crowd. However, this seemingly simple task demands to deal with several dynamic sources of uncertainty, related to intrinsic, target-related properties or to external, environment-related factors. In addition, one single object has to be selected at a time for accurate visual processing and ocular tracking in presence of a multitude of competing signals. &amp;laquo;BR&amp;raquo; The PhD project aims at understanding the dynamic inference and decision processes underlying smooth eye movements. The PhD fellow will conduct psychophysics and oculomotor recordings on healthy subjects, as well as modeling work, in order to elucidate the effects of sensory uncertainty on the accuracy and the dynamics of visuomotor decisions. Bayesian Inference will provide a general and solid framework for behavioral models. Oculomotor decision times, such as those characterizing the dynamic switch between smooth pursuit and saccades during motion tracking, or transitions between two alternative tracking solutions, will be modeled and benchmarked against the predictions of current models of choice reaction times (&amp;ldquo;accumulation-to-threshold&amp;rdquo; models).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Guillaume S Masson</title>
      <link>https://laurentperrinet.github.io/authors/guillaume-s-masson/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/guillaume-s-masson/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Julien Dupeyroux</title>
      <link>https://laurentperrinet.github.io/authors/julien-dupeyroux/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/julien-dupeyroux/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Julien R Serres</title>
      <link>https://laurentperrinet.github.io/authors/julien-r-serres/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/julien-r-serres/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nikos Gekas</title>
      <link>https://laurentperrinet.github.io/authors/nikos-gekas/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/nikos-gekas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pascal Mamassian</title>
      <link>https://laurentperrinet.github.io/authors/pascal-mamassian/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/pascal-mamassian/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stéphane Viollet</title>
      <link>https://laurentperrinet.github.io/authors/stephane-viollet/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/stephane-viollet/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/mina-a-khoei/</link>
      <pubDate>Thu, 26 Jan 2017 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/mina-a-khoei/</guid>
      <description>&lt;h1 id=&#34;emerging-properties-in-a-neural-field-model-implementing-probabilistic-prediction-phd-2011-2014&#34;&gt;Emerging properties in a neural field model implementing probabilistic prediction (PhD, 2011-2014)&lt;/h1&gt;
&lt;p&gt;In the early visual system, information about the visual world as represented by neural activity is dynamically building up from sensory input but also by contextual information coming from neighboring cells and re-entrant signal from other cortical areas. Low-level sensory areas are therefore an excellent model for exploring how neural computations solve the problem of selecting a single, coherent and global representation from the dispersed information collected locally and in parallel by neurons. Our goal in this program is to study the dynamics of neural fields implementing probabilistic computations for early sensory processing. Emphasis will be put onto the role of anisotropic diffusion, in particular within a cortical area through lateral interactions.&lt;/p&gt;
&lt;p&gt;We have previously elaborated probabilistic (Perrinet &amp;amp; Masson, 2010) or dynamical (Tlapale et al., 2010) models of motion information diffusion along cortical retinotopic trajectories. Probabilistic models give a complete representation of the information that is represented by populations of neurons. In such a dynamical system, prediction acts as a prior, filtering possible future states knowing the current one. An approximation using particle filtering methods will be used to investigate how this propagation can solve low-level computational problems such as integration, extrapolation or prediction in visual (Mason &amp;amp; Ilg, 2010) or somatosensory (Shulz et al. 2006) cortices.&lt;/p&gt;
&lt;p&gt;Using this architecture, we will explore the consequences of such context-dependent propagation in terms of coding and of learning. First at the time scale of coding, knowing the prior, we will study the emergent properties of the system like its ability to track objects independently of their shape or to segment parts of the scene that are moving coherently. We will study of this motion information may help shape the selectivity of neurons in a given area, for instance orientation selectivity on the priamry visual cortex. At the time scale of learning, we will build models exploring the emergence of maps of cortical receptive fields optimally tuned to elaborate sparse, multi-scale representations of the visual or tactile world. In fact, a simple functional model allows to understand emergence in a model of a simple macro-column of the primary visual cortex (Perrinet, 2010). One challenging question is whether these functional models of self-organization can be translated to large-scale networks of the early sensory system. Using the probabilistic model, we will investigate how spatio-temporal receptive fields can emerge through learning of statistical regularities in the images and study how hierarchic structures can arise as a self-organized property.&lt;/p&gt;
&lt;h1 id=&#34;propriétés-émergentes-dun-modèle-de-prédiction-probabiliste-utilisant-un-champ-neural&#34;&gt;Propriétés émergentes d&amp;rsquo;un modèle de prédiction probabiliste utilisant un champ neural&lt;/h1&gt;
&lt;p&gt;Dans le système visuel de bas niveau, des informations sur le monde visuel tel que celles représentées par l&amp;rsquo;activité neuronale est dynamiquement causée par l&amp;rsquo;entrée sensorielle, mais aussi par des informations contextuelles provenant de cellules voisines et par le signal réentrant d&amp;rsquo;autres aires corticales. Les aires sensorielles primaires sont donc un excellent modèle pour étudier comment les neurones peuvent résoudre le problème de la sélection d&amp;rsquo;une seul représentation globale et cohérente depuis l&amp;rsquo;information collectée localement et en parallèle par les neurones. Notre objectif dans ce programme est d&#39;étudier la dynamique de champs neuronaux mettant en œuvre des calculs probabilistes pour le traitement sensoriel précoce.&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;accent sera mis sur le rôle de la diffusion anisotrope, en particulier celle implémentée par les interactions latérales dans une aire corticale. Nous avons déjà élaboré des modèles probabiliste (Perrinet &amp;amp; Masson, 2010) ou dynamique (Tlapale et al., 2010) de diffusion de l&amp;rsquo;information de mouvement le long de trajectoires. Les modèles probabilistes donnent une représentation complète de l&amp;rsquo;information qui est représentée par des populations de neurones. Dans un tel système dynamique, la prédiction agit comme un prior, qui permet un filtrage des états futurs possibles en sachant la distribution de probabilité de l&#39;état actuel. Une approximation à l&amp;rsquo;aide des méthodes de filtrage particulaires seront utilisées pour étudier comment cette propagation peut résoudre des problèmes de calcul de bas niveau telles que l&amp;rsquo;intégration, l&amp;rsquo;extrapolation ou la prédiction dans les système visuel (Mason &amp;amp; Ilg, 2010) ou somatosensoriel (Shulz et al. 2006).&lt;/p&gt;
&lt;p&gt;En utilisant cette architecture, nous allons explorer les conséquences de la propagation dépendant du contexte tant en termes de codage que d&amp;rsquo;apprentissage. Premièrement, à l&#39;échelle de temps de codage, connaissant l&amp;rsquo;architecture du réseau, nous allons étudier les propriétés émergentes du système, comme sa capacité à suivre les objets indépendamment de leur forme ou à segmenter des parties de la scène qui se déplacent de façon cohérente. Nous allons étudier le mouvement de cette information peut aider à façonner la sélectivité des neurones, par exemple la sélectivité à l&amp;rsquo;orientation sur le cortex visuel primaire. À l&#39;échelle de temps d&amp;rsquo;apprentissage, nous allons construire des modèles d&#39;émergence de cartes de champs récepteurs corticaux optimisées pour élaborer des représentations multi-échelles efficaces de l&amp;rsquo;univers visuel ou tactile. En fait, un modèle fonctionnel simple permet de comprendre l&#39;émergence d&amp;rsquo;un modèle d&amp;rsquo;une simple macro-colonne du cortex visuel primaire (Perrinet, 2010). Une question difficile est de savoir si ces modèles fonctionnels d&amp;rsquo;auto-organisation peuvent être traduits à des réseaux à grande échelle du système sensoriel primaire. En utilisant ce modèle probabiliste, nous allons étudier comment des champs récepteurs spatio-temporels peuvent émerger à travers l&amp;rsquo;apprentissage des régularités statistiques dans les images et comment des structures hiérarchiques peuvent apparaitre comme la solution d&amp;rsquo;une propriété d&amp;rsquo;efficacité fonctionnelle.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jeremie Jozefowiez</title>
      <link>https://laurentperrinet.github.io/authors/jeremie-jozefowiez/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jeremie-jozefowiez/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lionel Fillatre</title>
      <link>https://laurentperrinet.github.io/authors/lionel-fillatre/</link>
      <pubDate>Wed, 26 Oct 2016 13:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/lionel-fillatre/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Michel Barlaud</title>
      <link>https://laurentperrinet.github.io/authors/michel-barlaud/</link>
      <pubDate>Wed, 26 Oct 2016 13:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/michel-barlaud/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pascal Wallisch</title>
      <link>https://laurentperrinet.github.io/authors/pascal-wallisch/</link>
      <pubDate>Fri, 22 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/pascal-wallisch/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/jens-kremkow/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jens-kremkow/</guid>
      <description>&lt;h1 id=&#34;correlating-excitation-and-inhibition-in-visual-cortical-circuits-functional-consequences-and-biological-feasibility--phd-2006-01--2009-05&#34;&gt;Correlating Excitation and Inhibition in Visual Cortical Circuits: Functional Consequences and Biological Feasibility  (PhD, 2006-01 / 2009-05)&lt;/h1&gt;
&lt;p&gt;The goal of the FACETS (Fast Analog Computing with Emergent Transient States) project was to create a theoretical and experimental foundation for the realisation of novel computing paradigms which exploit the concepts experimentally observed in biological nervous systems. The continuous interaction and scientific exchange between biological experiments, computer modelling and hardware emulations within the project provides a unique research infrastructure that will in turn provide an improved insight into the computing principles of the brain. This insight may potentially contribute to an improved understanding of mental disorders in the human brain and help to develop remedies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Venue: Thèse de Doctorat de l’Université d’Aix-Marseille II, Ecole Doctorale des Sciences de la Vie et de la Santé Marseille, France en Cotutelle avec la Fakultät für Biologie Albert-Ludwigs-Universität Freiburg im Breisgau, Allemagne&lt;/li&gt;
&lt;li&gt;Thesis director: Guillaume MASSON and Dr. Laurent PERRINET&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description-of-the-phd-thesis-project&#34;&gt;Description of the PHD thesis project&lt;/h2&gt;
&lt;p&gt;The primary visual cortex (V1) is one of the most studied cortical area in neuroscience. Together with the retina and the lateral geniculate nucleus (LGN), it forms the early visual system, which has become a common model for studying computational principles in the sensory systems. Simple artificial stimuli (such as drifting gratings (DG)) have given precious insights into the neural basis of visual processing. However, recently more researchers have used more complex natural images (NI) visual stimuli, arguing that the low dimensional artificial stimuli are not sufficient for a complete understanding of the visual system. For example, whereas the responses of V1 neurons to DG are dense but with variable spike timings, the neurons are activated with only few and precise spikes to NI. Furthermore, if linear receptive field models provide a good fit to responses during simple stimuli, they often fail during NI.&lt;/p&gt;
&lt;p&gt;To investigate the mechanisms behind the stimulus dependent responses of cortical neurons we have built a biophysical, yet simple and comprehensible, model of the early visual system. We show how the spatial and temporal stimulus properties interact with the model architecture to give rise to differential response behaviour. Our results show in particular that during NI, the LGN afferents show epochs of correlated activity. These temporal correlations are necessary to induce transient excitatory synaptic inputs, and result in precise spike timings in V1. Furthermore, the sparseness of the responses to NI can be explained by a hardwired, correlated and lagging inhibitory conductance, or conductance temporal window, which is induced by the interactions of the thalamocortical circuit with the spatiotemporal correlations in the stimulus.&lt;/p&gt;
&lt;p&gt;We continue by investigating the origin of nonlinear responses during NI in the temporal window, by comparing models of different complexity. Our results suggest first that adaptive processes shape the responses, depending on the temporal properties of the stimuli. The different spatial properties can result in nonlinear inputs through the recurrent cortical network. We then study the functional consequences of correlated excitatory and inhibitory condutances in more details in general models. These results show that: (1) spiking of individual neurons becomes sparse and precise, (2) the selectivity of signal propagation increases and the detailed delay allows to gate the propagation through feed-forward structures (3) and recurrent cortical networks are more stable and more likely to elicit in vivo type activity states.
Lastly our work illustrates new advances in methods of constructing and exchanging models of neuronal systems by the means of a simulator independent description language (called PyNN). We use this new tool to investigate the feasibility of comparing software simulations with neuromorphic hardware emulations. The presented work give new perspectives on the way conductances can be used for computations and it opens the door for more elaborated models of visual system&amp;rsquo;s mechanisms.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/rick-a-adams/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/rick-a-adams/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/yves-fregnac/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/yves-fregnac/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ad M Aertsen</title>
      <link>https://laurentperrinet.github.io/authors/ad-m-aertsen/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/ad-m-aertsen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cyril Monier</title>
      <link>https://laurentperrinet.github.io/authors/cyril-monier/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/cyril-monier/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jose-Manuel Alonso</title>
      <link>https://laurentperrinet.github.io/authors/jose-manuel-alonso/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jose-manuel-alonso/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Karl J Friston</title>
      <link>https://laurentperrinet.github.io/authors/karl-j-friston/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/karl-j-friston/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Gabriel Cristóbal</title>
      <link>https://laurentperrinet.github.io/authors/gabriel-cristobal/</link>
      <pubDate>Wed, 04 Nov 2015 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/gabriel-cristobal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Matthias S Keil</title>
      <link>https://laurentperrinet.github.io/authors/matthias-s-keil/</link>
      <pubDate>Wed, 04 Nov 2015 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/matthias-s-keil/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/james-a-bednar/</link>
      <pubDate>Tue, 04 Aug 2015 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/james-a-bednar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Caroline Landelle</title>
      <link>https://laurentperrinet.github.io/authors/caroline-landelle/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/caroline-landelle/</guid>
      <description></description>
    </item>
    
    <item>
      <title>F. Olivares</title>
      <link>https://laurentperrinet.github.io/authors/f.-olivares/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/f.-olivares/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fréderic Danion</title>
      <link>https://laurentperrinet.github.io/authors/frederic-danion/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/frederic-danion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R. Herzog</title>
      <link>https://laurentperrinet.github.io/authors/r.-herzog/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/r.-herzog/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Claudio Simoncini</title>
      <link>https://laurentperrinet.github.io/authors/claudio-simoncini/</link>
      <pubDate>Fri, 22 Aug 2014 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/claudio-simoncini/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anders Lansner</title>
      <link>https://laurentperrinet.github.io/authors/anders-lansner/</link>
      <pubDate>Fri, 25 Apr 2014 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/anders-lansner/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bernhard A Kaplan</title>
      <link>https://laurentperrinet.github.io/authors/bernhard-a-kaplan/</link>
      <pubDate>Fri, 25 Apr 2014 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/bernhard-a-kaplan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bharath Chandra Talluri</title>
      <link>https://laurentperrinet.github.io/authors/bharath-chandra-talluri/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/bharath-chandra-talluri/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jean-Luc Stevens</title>
      <link>https://laurentperrinet.github.io/authors/jean-luc-stevens/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jean-luc-stevens/</guid>
      <description></description>
    </item>
    
    <item>
      <title>P Philipp Rudiger</title>
      <link>https://laurentperrinet.github.io/authors/p-philipp-rudiger/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/p-philipp-rudiger/</guid>
      <description></description>
    </item>
    
    <item>
      <title>David Fitzpatrick</title>
      <link>https://laurentperrinet.github.io/authors/david-fitzpatrick/</link>
      <pubDate>Fri, 05 Jul 2013 13:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/david-fitzpatrick/</guid>
      <description></description>
    </item>
    
    <item>
      <title>James A. Bednar</title>
      <link>https://laurentperrinet.github.io/authors/james-a.-bednar/</link>
      <pubDate>Fri, 05 Jul 2013 13:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/james-a.-bednar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Boris Escalante-Ramirez</title>
      <link>https://laurentperrinet.github.io/authors/boris-escalante-ramirez/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/boris-escalante-ramirez/</guid>
      <description></description>
    </item>
    
    <item>
      <title>J Victor Marcos</title>
      <link>https://laurentperrinet.github.io/authors/j-victor-marcos/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/j-victor-marcos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Raúl S J Estépar</title>
      <link>https://laurentperrinet.github.io/authors/raul-s-j-estepar/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/raul-s-j-estepar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rodrigo Nava</title>
      <link>https://laurentperrinet.github.io/authors/rodrigo-nava/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/rodrigo-nava/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ivo Vanzetta</title>
      <link>https://laurentperrinet.github.io/authors/ivo-vanzetta/</link>
      <pubDate>Wed, 14 Mar 2012 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/ivo-vanzetta/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paula S Leon</title>
      <link>https://laurentperrinet.github.io/authors/paula-s-leon/</link>
      <pubDate>Wed, 14 Mar 2012 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/paula-s-leon/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/nicole-voges/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/nicole-voges/</guid>
      <description>&lt;h1 id=&#34;complex-dynamics-in-recurrent-cortical-networks-based-on-spatially-realistic-connectivities-post-doc-2008--2010&#34;&gt;Complex dynamics in recurrent cortical networks based on spatially realistic connectivities (Post-Doc, 2008 / 2010)&lt;/h1&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Most studies on the dynamics of recurrent cortical networks are either based on purely random wiring or neighborhood couplings. Neuronal cortical connectivity, however, shows a complex spatial pattern composed of local and remote patchy connections. We ask to what extent such geometric traits influence the &amp;ldquo;idle&amp;rdquo; dynamics of two-dimensional (2d) cortical network models composed of conductance-based integrate-and-fire (iaf) neurons. In contrast to the typical 1 mm2 used in most studies, we employ an enlarged spatial set-up of 25 mm2 to provide for long-range connections. Our models range from purely random to distance-dependent connectivities including patchy projections, i.e., spatially clustered synapses. Analyzing the characteristic measures for synchronicity and regularity in neuronal spiking, we explore and compare the phase spaces and activity patterns of our simulation results. Depending on the input parameters, different dynamical states appear, similar to the known synchronous regular (SR) or asynchronous irregular (AI) firing in random networks. Our structured networks, however, exhibit shifted and sharper transitions, as well as more complex activity patterns. Distance-dependent connectivity structures induce a spatio-temporal spread of activity, e.g., propagating waves, that random networks cannot account for. Spatially and temporally restricted activity injections reveal that a high amount of local coupling induces rather unstable AI dynamics. We find that the amount of local versus long-range connections is an important parameter, whereas the structurally advantageous wiring cost optimization of patchy networks has little bearing on the phase space.&lt;/p&gt;
&lt;h2 id=&#34;context&#34;&gt;Context&lt;/h2&gt;
&lt;p&gt;The goal of the FACETS (Fast Analog Computing with Emergent Transient States) project was to create a theoretical and experimental foundation for the realisation of novel computing paradigms which exploit the concepts experimentally observed in biological nervous systems. The continuous interaction and scientific exchange between biological experiments, computer modelling and hardware emulations within the project provides a unique research infrastructure that will in turn provide an improved insight into the computing principles of the brain. This insight may potentially contribute to an improved understanding of mental disorders in the human brain and help to develop remedies.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reynaud A., Masson G. S. and Chavane F. 
&lt;a href=&#34;http://www.jneurosci.org/content/32/36/12558.abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dynamics of Local Input Normalization Result from Balanced Short- and Long-Range Intracortical Interactions in Area V1&lt;/a&gt;
 Journal of Neuroscience, 2012, 32(36): 12558-12569&lt;/li&gt;
&lt;li&gt;Reynaud A., Takerkart S, Masson G. S. and Chavane F. 
&lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1053811910011237&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linear model decomposition for voltage-sensitive dye imaging signals: Application in awake behaving monkey.&lt;/a&gt;
 Neuroimage, 2011, 54(2), 1196–1210&lt;/li&gt;
&lt;li&gt;Perrinet, L. and Masson G. 
&lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;
 Neural Computation, 2012&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Michael Breakspear</title>
      <link>https://laurentperrinet.github.io/authors/michael-breakspear/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/michael-breakspear/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Amarender Bogadhi</title>
      <link>https://laurentperrinet.github.io/authors/amarender-bogadhi/</link>
      <pubDate>Fri, 22 Apr 2011 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/amarender-bogadhi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jérôme Fleuriet</title>
      <link>https://laurentperrinet.github.io/authors/jerome-fleuriet/</link>
      <pubDate>Tue, 01 Feb 2011 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jerome-fleuriet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Laurent Goffart</title>
      <link>https://laurentperrinet.github.io/authors/laurent-goffart/</link>
      <pubDate>Tue, 01 Feb 2011 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/laurent-goffart/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sandrine Hugues</title>
      <link>https://laurentperrinet.github.io/authors/sandrine-hugues/</link>
      <pubDate>Tue, 01 Feb 2011 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/sandrine-hugues/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Thierry Vieville</title>
      <link>https://laurentperrinet.github.io/authors/thierry-vieville/</link>
      <pubDate>Tue, 24 Nov 2009 18:30:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/thierry-vieville/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Andrew P Davison</title>
      <link>https://laurentperrinet.github.io/authors/andrew-p-davison/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/andrew-p-davison/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Daniel Bruderle</title>
      <link>https://laurentperrinet.github.io/authors/daniel-bruderle/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/daniel-bruderle/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dejan Pecevski</title>
      <link>https://laurentperrinet.github.io/authors/dejan-pecevski/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/dejan-pecevski/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eilif Muller</title>
      <link>https://laurentperrinet.github.io/authors/eilif-muller/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/eilif-muller/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jochen Eppler</title>
      <link>https://laurentperrinet.github.io/authors/jochen-eppler/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/jochen-eppler/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Michael Schmuker</title>
      <link>https://laurentperrinet.github.io/authors/michael-schmuker/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/michael-schmuker/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pierre Yger</title>
      <link>https://laurentperrinet.github.io/authors/pierre-yger/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/pierre-yger/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eric Castet</title>
      <link>https://laurentperrinet.github.io/authors/eric-castet/</link>
      <pubDate>Mon, 04 Feb 2008 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/eric-castet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Frédéric V Barthélemy</title>
      <link>https://laurentperrinet.github.io/authors/frederic-v-barthelemy/</link>
      <pubDate>Mon, 04 Feb 2008 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/frederic-v-barthelemy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Manu Levy</title>
      <link>https://laurentperrinet.github.io/authors/manu-levy/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/manu-levy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Olivier Marre</title>
      <link>https://laurentperrinet.github.io/authors/olivier-marre/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/olivier-marre/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pierre Baudot</title>
      <link>https://laurentperrinet.github.io/authors/pierre-baudot/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/pierre-baudot/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/manuel-samuelides/</link>
      <pubDate>Sun, 04 Mar 2007 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/manuel-samuelides/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bruno Cessac</title>
      <link>https://laurentperrinet.github.io/authors/bruno-cessac/</link>
      <pubDate>Sun, 04 Mar 2007 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/bruno-cessac/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Filip Šroubek</title>
      <link>https://laurentperrinet.github.io/authors/filip-sroubek/</link>
      <pubDate>Sat, 13 Jan 2007 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/filip-sroubek/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rafael Redondo</title>
      <link>https://laurentperrinet.github.io/authors/rafael-redondo/</link>
      <pubDate>Sat, 13 Jan 2007 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/rafael-redondo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sylvain Fischer</title>
      <link>https://laurentperrinet.github.io/authors/sylvain-fischer/</link>
      <pubDate>Sat, 13 Jan 2007 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/sylvain-fischer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adrien Wohrer</title>
      <link>https://laurentperrinet.github.io/authors/adrien-wohrer/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/adrien-wohrer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Frédéric V. Barthélemy</title>
      <link>https://laurentperrinet.github.io/authors/frederic-v.-barthelemy/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/frederic-v.-barthelemy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pierre Kornprobst</title>
      <link>https://laurentperrinet.github.io/authors/pierre-kornprobst/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/pierre-kornprobst/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/simon-j-thorpe/</link>
      <pubDate>Sat, 04 Sep 2004 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/authors/simon-j-thorpe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Arnaud Delorme</title>
      <link>https://laurentperrinet.github.io/authors/arnaud-delorme/</link>
      <pubDate>Mon, 01 Jan 2001 00:00:00 +0100</pubDate>
      <guid>https://laurentperrinet.github.io/authors/arnaud-delorme/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://laurentperrinet.github.io/authors/karl-friston/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/authors/karl-friston/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
