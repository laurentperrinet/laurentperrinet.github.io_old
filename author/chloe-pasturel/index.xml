<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chloé Pasturel | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/author/chloe-pasturel/</link>
      <atom:link href="https://laurentperrinet.github.io/author/chloe-pasturel/index.xml" rel="self" type="application/rss+xml" />
    <description>Chloé Pasturel</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Sun, 26 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/author/chloe-pasturel/avatar_hucfafec1f19aab4f9e024b0deff0af481_1015588_270x270_fill_lanczos_center_3.png</url>
      <title>Chloé Pasturel</title>
      <link>https://laurentperrinet.github.io/author/chloe-pasturel/</link>
    </image>
    
    <item>
      <title>Humans adapt their anticipatory eye movements to the volatility of visual motion properties</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/</guid>
      <description>&lt;h1 id=&#34;humans-adapt-their-anticipatory-eye-movements-to-the-volatility-of-visual-motion-properties&#34;&gt;&amp;ldquo;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&amp;rdquo;&lt;/h1&gt;
&lt;p&gt;








  





&lt;video controls  &gt;
  &lt;source src=&#34;https://raw.githubusercontent.com/chloepasturel/AnticipatorySPEM/master/2020-03_video-abstract/PasturelMontagniniPerrinet2020_video-abstract.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;check out our new paper &lt;a href=&#34;https://twitter.com/PLOSCompBiol?ref_src=twsrc%5Etfw&#34;&gt;@PLOSCompBiol&lt;/a&gt; : &amp;quot;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&amp;quot; with Chloé Pasturel and &lt;a href=&#34;https://twitter.com/MontagniniAnna?ref_src=twsrc%5Etfw&#34;&gt;@MontagniniAnna&lt;/a&gt;  - talks about how to perform optimal decisions when the environment abruptly switches its statistics... &lt;a href=&#34;https://t.co/GKg87lGqdS&#34;&gt;pic.twitter.com/GKg87lGqdS&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1253715266124611586?ref_src=twsrc%5Etfw&#34;&gt;April 24, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;h2 id=&#34;at-what-point-should-we-become-alarmed-when-faced-with-changes-in-the-environment-the-sensory-system-provides-an-effective-response&#34;&gt;At what point should we become alarmed? When faced with changes in the environment, the sensory system provides an effective response.&lt;/h2&gt;
&lt;p&gt;The current health situation has shown us how abruptly our environment can change from one state to another, tragically illustrating the volatility we can face. To understand this notion of volatility, let&amp;rsquo;s take the case of a doctor who, among the patients he receives, usually diagnoses one out of ten cases of flu. Suddenly, he gets 5 out of 10 patients who test positive. Is this an unfortunate coincidence or are we now sure that there is a switch to a flu episode? Recent events have shown us how difficult it is to make a rational decision in times of uncertainty, and in particular to decide &lt;em&gt;when&lt;/em&gt; to act. However, mathematical solutions exist that adapt our behavior by optimally combining the information explored recently with that exploited in the past. In an article published in PLoS Computational Biology, Pasturel, Montagnini and Perrinet show that our brain responds to changes in the sensory environment in the same way as this mathematical model.














&lt;figure  id=&#34;figure-by-manipulating-the-probability-bias-of-the-presentation-of-a-visual-target-on-a-screen-this-experiment-manipulates-the-volatility-of-the-environment-in-a-controlled-way-by-introducing-switches-in-the-probability-bias-these-switches-randomly-change-the-bias-among-different-degrees-of-probability-both-left-and-right-at-each-trial-the-bias-then-generates-a-realization-either-left-l-or-right-r--the-target-moves-in-blocks-of-50-trials-1-to-50-and-these-realizations-are-the-only-ones-to-be-observed-the-evolution-of-the-bias-and-its-shifts-remaining-hidden-from-the-observer-compared-to-the-floating-average-that-is-conventionally-used-a-mathematical-model-can-be-deduced-as-a-predictive-average-that-allows-to-better-follow-the-dynamics-of-the-probability-bias-thanks-to-psychophysical-experiments-we-have-shown-that-observers-preferentially-follow-the-predictive-mean-rather-than-the-floating-mean-both-in-explicit-judgements-predictive-betting-and-more-surprisingly-in-the-anticipatory-movements-of-the-eyes-that-are-carried-out-without-the-observers-being-aware-of-them&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34; By manipulating the probability bias of the presentation of a visual target on a screen, this experiment manipulates the volatility of the environment in a controlled way by introducing switches in the probability bias. These switches randomly change the bias among different degrees of probability (both left and right). At each trial, the bias then generates a realization, either left (L) or right (R).  The target moves in blocks of 50 trials (1 to 50) and these realizations are the only ones to be observed, the evolution of the bias and its shifts remaining hidden from the observer. Compared to the floating average that is conventionally used, a mathematical model can be deduced as a predictive average that allows to better follow the dynamics of the probability bias. Thanks to psychophysical experiments, we have shown that observers preferentially follow the predictive mean, rather than the floating mean, both in explicit judgements (predictive betting) and, more surprisingly, in the anticipatory movements of the eyes that are carried out without the observers being aware of them. &#34; srcset=&#34;
               /publication/pasturel-montagnini-perrinet-20/synthesis_hu2604416ccc807da517dbfcd6542c544b_578813_a83f56b8e35a8b4cc220d852aac82f2e.webp 400w,
               /publication/pasturel-montagnini-perrinet-20/synthesis_hu2604416ccc807da517dbfcd6542c544b_578813_f0dda557df66e7e39ff25b2c99922a86.webp 760w,
               /publication/pasturel-montagnini-perrinet-20/synthesis_hu2604416ccc807da517dbfcd6542c544b_578813_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/synthesis_hu2604416ccc807da517dbfcd6542c544b_578813_a83f56b8e35a8b4cc220d852aac82f2e.webp&#34;
               width=&#34;80%&#34;
               height=&#34;461&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      By manipulating the probability bias of the presentation of a visual target on a screen, this experiment manipulates the volatility of the environment in a controlled way by introducing switches in the probability bias. These switches randomly change the bias among different degrees of probability (both left and right). At each trial, the bias then generates a realization, either left (L) or right (R).  The target moves in blocks of 50 trials (1 to 50) and these realizations are the only ones to be observed, the evolution of the bias and its shifts remaining hidden from the observer. Compared to the floating average that is conventionally used, a mathematical model can be deduced as a predictive average that allows to better follow the dynamics of the probability bias. Thanks to psychophysical experiments, we have shown that observers preferentially follow the predictive mean, rather than the floating mean, both in explicit judgements (predictive betting) and, more surprisingly, in the anticipatory movements of the eyes that are carried out without the observers being aware of them.
    &lt;/figcaption&gt;&lt;/figure&gt;
These theoretical and experimental results show that in this realistic situation in which the context changes at random moments throughout the experiment, our sensory system adapts to volatility in an adaptive manner over the course of the trials. In particular, the experiments show in two behavioural experiments that humans adapt to volatility at the early sensorimotor level, through their anticipatory eye movements, but also at a higher cognitive level, through explicit evaluations. These results thus suggest that humans (and future artificial systems) can use much richer adaptation strategies than previously assumed. They provide a better understanding of how humans adapt to changing environments in order to make judgements or plan responses based on information that varies over time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;read the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/784116v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preprint&lt;/a&gt; (the official online &lt;a href=&#34;https://doi.org/10.1371/journal.pcbi.1007438&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;publication&lt;/a&gt; or in &lt;a href=&#34;https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1007438&amp;amp;type=printable&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt; is &lt;em&gt;wrongly&lt;/em&gt; typeset by interverting figures 2 &amp;amp; 3 - the poilicy of the journal is to issue a correction, but not to correct it.)&lt;/li&gt;
&lt;li&gt;get a )&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/784116v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/784116v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/784116v3.full.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;supplementary info : &lt;a href=&#34;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020/blob/master/Pasturel_etal2020_PLoS-CB_SI.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020/blob/master/Pasturel_etal2020_PLoS-CB_SI.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.insb.cnrs.fr/fr/cnrsinfo/la-reponse-du-cerveau-aux-changements-de-lenvironnement-sensoriel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Communiqué de presse INSB-CNRS (en français)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for paper: &lt;a href=&#34;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for framework: &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/chloepasturel/AnticipatorySPEM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code for figures &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/blob/master/1_protocole.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figure 1&lt;/a&gt;, &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/blob/master/2_raw-results.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figure 2&lt;/a&gt;, &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/blob/master/3_Results_1-theory_BBCP.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figure 3&lt;/a&gt;, &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/blob/master/4_Results_2_fitting_BBCP.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figure 4&lt;/a&gt;, &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/blob/master/5_Meta_analysis.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figure 5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chloepasturel/AnticipatorySPEM/master/2020-03_video-abstract/PasturelMontagniniPerrinet2020_video-abstract.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video abstract&lt;/a&gt; (and the &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/blob/master/2020-03_video-abstract/2020-03-24_video-abstract.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt; for generating the video abstract)&lt;/li&gt;
&lt;li&gt;Notre papier avec Chloé Pasturel et @MontagniniAnna  figure dans les &lt;a href=&#34;https://indd.adobe.com/view/ea980f21-e298-43e8-abd7-fff6909d6755&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;faits marquants 2020 de la Société des Neurosciences&lt;/a&gt;! Voir aussi  &lt;a href=&#34;https://lejournal.cnrs.fr/nos-blogs/aux-frontieres-du-cerveau/les-faits-marquants-2020-de-la-societe-de-neurosciences&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://lejournal.cnrs.fr/nos-blogs/aux-frontieres-du-cerveau/les-faits-marquants-2020-de-la-societe-de-neurosciences&lt;/a&gt; :
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;fr&#34; dir=&#34;ltr&#34;&gt;Notre papier avec Chloé Pasturel et &lt;a href=&#34;https://twitter.com/MontagniniAnna?ref_src=twsrc%5Etfw&#34;&gt;@MontagniniAnna&lt;/a&gt;  figure dans les faits marquants 2020 de la Société des Neurosciences! &lt;a href=&#34;https://t.co/w825oTz1o5&#34;&gt;https://t.co/w825oTz1o5&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/neuroscience?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#neuroscience&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/actu?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#actu&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/sciences?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#sciences&lt;/a&gt;  &lt;a href=&#34;https://twitter.com/SocNeuro_Tweets?ref_src=twsrc%5Etfw&#34;&gt;@SocNeuro_Tweets&lt;/a&gt;&lt;a href=&#34;https://twitter.com/CNRS?ref_src=twsrc%5Etfw&#34;&gt;@CNRS&lt;/a&gt; &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt; &lt;a href=&#34;https://t.co/KeKh5MNWu2&#34;&gt;https://t.co/KeKh5MNWu2&lt;/a&gt; &lt;a href=&#34;https://t.co/eojTqsp6gD&#34;&gt;https://t.co/eojTqsp6gD&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1371420462056620036?ref_src=twsrc%5Etfw&#34;&gt;March 15, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias</title>
      <link>https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/</link>
      <pubDate>Thu, 05 Apr 2018 14:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See the final publication @ 









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/chloe-pasturel/&#34;&gt;Chloé Pasturel&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/anna-montagnini/&#34;&gt;Anna Montagnini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/784116v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/784116v3.full.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/pasturel-montagnini-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1007438&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2016-10-13-law/&#34;&gt;LAW, Lyon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/&#34;&gt;INVIBE FEST, Paris&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-01-18-laconeu/&#34;&gt;LACONEU, Chile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-04-05-bbcp-causal-kickoff/&#34;&gt;CAUSAL Kick-off, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-05-23-neurofrance/&#34;&gt;NeuroFrance, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See the final publication @ 









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/chloe-pasturel/&#34;&gt;Chloé Pasturel&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/anna-montagnini/&#34;&gt;Anna Montagnini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/784116v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/784116v3.full.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/pasturel-montagnini-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1007438&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2016-10-13-law/&#34;&gt;LAW, Lyon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/&#34;&gt;Brain workshop, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-01-18-laconeu/&#34;&gt;LACONEU, Chile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-04-05-bbcp-causal-kickoff/&#34;&gt;CAUSAL Kick-off, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-05-23-neurofrance/&#34;&gt;NeuroFrance, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ANEMO: Quantitative tools for the ANalysis of Eye MOvements</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-18-anemo/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-18-anemo/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;as presented at &lt;a href=&#34;https://eyemovements.sciencesconf.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://eyemovements.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://github.com/invibe/ANEMO/raw/master/2018-05-04_Poster_Grenoble/Pasturel_etal2018_grenoble.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code : &lt;a href=&#34;https://github.com/invibe/ANEMO/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/invibe/ANEMO/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-18-grenoble/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-18-grenoble/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;as presented at &lt;a href=&#34;https://eyemovements.sciencesconf.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://eyemovements.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/raw/master/Poster/2018-06-05_Poster_Workshop_Grenoble/Pasturel_etal2018grenoble.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code : &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/chloepasturel/AnticipatorySPEM/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-18/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-18/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias</title>
      <link>https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-17-gdr/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-17-gdr/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
