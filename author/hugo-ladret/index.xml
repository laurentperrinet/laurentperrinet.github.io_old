<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hugo Ladret | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/author/hugo-ladret/</link>
      <atom:link href="https://laurentperrinet.github.io/author/hugo-ladret/index.xml" rel="self" type="application/rss+xml" />
    <description>Hugo Ladret</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Sun, 16 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/author/hugo-ladret/avatar_hud84a483f73decf0a7d85ed2f62cffba3_42123_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Hugo Ladret</title>
      <link>https://laurentperrinet.github.io/author/hugo-ladret/</link>
    </image>
    
    <item>
      <title>Learning heterogeneous delays of spiking neurons for motion detection</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-icip/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-icip/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up as journal paper: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-bc/&#34;&gt;Learning heterogeneous delays in a layer of spiking neurons for fast motion detection&lt;/a&gt;.
   &lt;em&gt;Submitted&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-bc/grimaldi-22-bc.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/grimaldi-22-bc/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;to be presented at &lt;a href=&#34;https://2022.ieeeicip.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICIP 2022&lt;/a&gt; 16-19 October 2022 in Bordeaux, France&lt;/li&gt;
&lt;li&gt;paper &lt;a href=&#34;https://cmsworkshops.com/ICIP2022/papers/accepted_papers.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3241&lt;/a&gt; (note that the title of the paper was slightly changed)&lt;/li&gt;
&lt;li&gt;time of presentation:&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 20:30 - 20:45 China Standard Time (UTC +8)&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 14:30 - 14:45 Central European Time (UTC +2)&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 12:30 - 12:45 UTC&lt;/li&gt;
&lt;li&gt;Tue, 18 Oct, 08:30 - 08:45 Eastern Time (UTC -4)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;session-neuromorphic-and-perception-based-image-acquisition-and-analysis&#34;&gt;Session &amp;ldquo;Neuromorphic and perception-based image acquisition and analysis&amp;rdquo;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cmsworkshops.com/ICIP2022/view_session.php?SessionID=1009&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TQ-L.A Special session on Tueasday, October 18 from 14:00 to 16:00&lt;/a&gt;
&lt;a href=&#34;https://cmsworkshops.com/ICIP2022/view_session.php?SessionID=1009&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;program.png&#34; srcset=&#34;
               /publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_f8a7cb42bd03234f7da5bec1c350d0bc.webp 400w,
               /publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_89309a4e4d488ee921a24367811bf50c.webp 760w,
               /publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/program_hu1d0ae805a3d35d6cc581e61ccb48e3fd_526410_f8a7cb42bd03234f7da5bec1c350d0bc.webp&#34;
               width=&#34;760&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organized by Dr. Marc Antonini, Dr. Panagiotis Tsakalides, and Dr. Effrosyni Doutsi:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;During the last decade much attention has been paid to understanding the human brain properties and functions in order to mimic the computational mechanisms of this highly intelligent processing “machine” that seems to be able to address several technological challenges that the scientific community is currently facing. Digital sobriety is quite important among these challenges as it concerns the reduction of the energy footprint caused by the use and transmission of the digital information. According to recent studies, almost 80% of global data flows is due to online videos stored in big data centers ready to be accessed on demand at any time by several users all over the world. As a result, scientists are urged to find energy-saving solutions to capture, process, understand, compress and stream this great volume of visual information in an environmental responsible and greener manner.
&lt;em&gt;Brain-inspired or neuro-inspired or spike-based or event-based computing are all terms used to describe the emerging technological trend motivated by the brain capability to dynamically capture and to spatio-temporally process and transform the great volume of the 3D visual information into a very compact spike train that is fed forward to the visual cortex of the brain passing through a very dense neural network. This is an energy efficient process, a fact that triggered the attention of the signal processing community trying to design more sober video services.&lt;/em&gt;
Indeed, every step of the brain processing pipeline provides inspiration towards novel disruptive implementations of image and video processing components: (i) visual sensors responsible for capturing and projecting the visual information into a neuromorphic chip, (ii) image understanding utilizing spiking neural networks to better approximate the dense interconnected network of neurons along the visual pathway, (iii) image processing and compression motivated by the exceptional compactness of the spike trains, capable of providing an ultra-high-definition perception of the visual world. In addition, the last decade has witnessed the progress of neuromorphic algorithms and hardware, which has already reached performance and manufacturing levels that is beyond the state- of-the-art.
The objective of this special session is to highlight the importance of neuromorphic computing in image and video processing. We are interested in bringing together scientists working on different spike-based computational models, from sensing to understanding, who will share their knowledge and discuss about the advantages and the limitations of this type of systems. The aim is to progress towards an end-to-end and robust technology where the hardware and software will both follow the same neuro-inspired principles, addressing important challenges of the current conventional systems. Last but not least, this special session would be a great opportunity to build a strong international consortium between different teams to attract European and international funding to further study and promote neuromorphic computing for different signal processing open challenges.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Recurrent cortical connectivity in the primary visual cortex supports robust encoding of natural sensory inputs</title>
      <link>https://laurentperrinet.github.io/publication/ladret-22-fens/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-22-fens/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Given prior activity on &lt;a href=&#34;https://twitter.com/hashtag/NeuroTwitter?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NeuroTwitter&lt;/a&gt; these past days, you probably can guess that this is my &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; tweet ! Come chat with me about natural vision, recurrent processing and neural decoding on Monday afternoon, poster S04-550 ! &lt;a href=&#34;https://t.co/ZnZ6vJIT2b&#34;&gt;pic.twitter.com/ZnZ6vJIT2b&lt;/a&gt;&lt;/p&gt;&amp;mdash; Hugo Ladret (@hugoladret) &lt;a href=&#34;https://twitter.com/hugoladret/status/1545743191198121985?ref_src=twsrc%5Etfw&#34;&gt;July 9, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;This poster is presented in the following preprint (in submission)  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/nelson-cortes/&#34;&gt;Nelson Cortes&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/lamyae-ikan/&#34;&gt;Lamyae Ikan&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/frederic-chavane/&#34;&gt;Frederic Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/christian-casanova/&#34;&gt;Christian Casanova&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-22/&#34;&gt;Dynamical processing of orientation precision in the primary visual cortex&lt;/a&gt;.
  &lt;em&gt;bioRxiv&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/ladret-22/ladret-22.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-22/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1101/2021.03.30.437692&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A resilient neural code in V1 to process natural images</title>
      <link>https://laurentperrinet.github.io/publication/ladret-22-areadne/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-22-areadne/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Tonight is &lt;a href=&#34;https://twitter.com/hashtag/AREADNE2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#AREADNE2022&lt;/a&gt;&amp;#39;s final poster session and I&amp;#39;ll be presenting new results about the visual cortex. &lt;br&gt;How does V1 adapt to varying precision of natural images ? Does adding a picture of Santorini in your introduction boost attendance ? Swing by poster 83 to find out ! &lt;a href=&#34;https://t.co/0bhmtFPgPg&#34;&gt;pic.twitter.com/0bhmtFPgPg&lt;/a&gt;&lt;/p&gt;&amp;mdash; Hugo Ladret (@hugoladret) &lt;a href=&#34;https://twitter.com/hugoladret/status/1542724828658016256?ref_src=twsrc%5Etfw&#34;&gt;July 1, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-22-fens/&#34;&gt;Recurrent cortical connectivity in the primary visual cortex supports robust encoding of natural sensory inputs&lt;/a&gt;.
  &lt;em&gt;Proceedings of the FENS Forum 2022&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-22-fens/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;This poster is presented in the following preprint (in submission)  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/nelson-cortes/&#34;&gt;Nelson Cortes&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/lamyae-ikan/&#34;&gt;Lamyae Ikan&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/frederic-chavane/&#34;&gt;Frederic Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/christian-casanova/&#34;&gt;Christian Casanova&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-22/&#34;&gt;Dynamical processing of orientation precision in the primary visual cortex&lt;/a&gt;.
  &lt;em&gt;bioRxiv&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/ladret-22/ladret-22.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-22/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1101/2021.03.30.437692&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Decoding spiking motifs using neurons with heterogeneous delays</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-areadne/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-areadne/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to efficiently make use of time in neural computations? ⏱️&lt;br&gt;With &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; we developed a model of spiking neuron including, in addition to synaptic weights, synaptic delays. &lt;a href=&#34;https://t.co/eztnd5CUMn&#34;&gt;https://t.co/eztnd5CUMn&lt;/a&gt;&lt;br&gt;Come see this work on Tuesday morning at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; poster n° 547 🪩&lt;/p&gt;&amp;mdash; Antoine Grimaldi (@A_Grismaldi) &lt;a href=&#34;https://twitter.com/A_Grismaldi/status/1546471536571342849?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/camille-besnainou/&#34;&gt;Camille Besnainou&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/&#34;&gt;Learning heterogeneous delays of spiking neurons for motion detection&lt;/a&gt;.
  &lt;em&gt;Proceedings of ICIP 2022&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-icip/grimaldi-22-icip.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-22-icip/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/ICIP46576.2022.9897394&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://2022.ieeeicip.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Statistics of the sparse representations of natural images</title>
      <link>https://laurentperrinet.github.io/talk/2022-03-22-siam-is-22/</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2022-03-22-siam-is-22/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see previous work: &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/posts/2018-11-05-statistics-of-the-natural-input-to-a-ring-model.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/sciblog/posts/2018-11-05-statistics-of-the-natural-input-to-a-ring-model.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mini-symposium-learning-from-vision-efficient-representation-sparse-coding-and-modelling&#34;&gt;Mini-Symposium &amp;ldquo;Learning from vision: Efficient representation, sparse coding, and modelling&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;Although recent years have seen a striking improvement in imaging techniques, there are many tasks for which human interaction is still essential, as color gamut correction in the cinema industry. This suggests that a better understanding of the mechanisms underlying the visual system is instrumental to advances in imaging techniques.
Along these lines, various ideas from computational neurosciences have found application in imaging, from pattern recognition to image inpainting. A promising line of investigation is built on methods based on models of the primary visual cortex and on neural coding, in particular via the efficient representation principle. These methods have recently allowed to define new artificial neural networks paradigms and to reproduce complex visual illusions.
In this mini-symposium we aim to gather together experts working in the field of mathematical neuroscience and imaging, with a focus on these methods. In particular, the speakers will present recent results based on sparse coding and models of the visual system.&lt;/p&gt;
&lt;h3 id=&#34;organizer-dario-prandi&#34;&gt;Organizer: Dario Prandi&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;12:40-1:05 &lt;em&gt;The intrinsically nonlinear nature of receptive fields in vision: implications for imaging, vision science and artificial neural networks&lt;/em&gt; Marcelo Bertalmío, Spanish National Research Council, Spain&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1:10-1:35 &lt;em&gt;ChebLieNet: Invariant Spectral Graph Nns Turned Equivariant by Sub-Riemannian Geometry on Lie Groups&lt;/em&gt; Erik Bekkers, University of Amsterdam, Netherlands&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1:40-2:05 &lt;em&gt;Deep Predictive Coding for More Robust and Human-Like Vision&lt;/em&gt; Rufin VanRullen, Centre de Recherche Cerveau et Cognition (CerCo), France&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2:10-2:35 &lt;em&gt;Statistics of the Sparse Representations of Natural Images&lt;/em&gt; Hugo Ladret and Laurent U. Perrinet, CNRS &amp;amp; Aix-Marseille Université, Marseille, France&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More on &lt;a href=&#34;https://meetings.siam.org/sess/dsp_programsess.cfm?sessioncode=73028&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://meetings.siam.org/sess/dsp_programsess.cfm?sessioncode=73028&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dynamical processing of orientation precision in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/ladret-22/</link>
      <pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-22/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;now (2:00 PM - 3:00 PM CEST on Thursday, May 20), you can hear Hugo Ladret &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt; present his poster P4.47 &amp;quot;Processing of orientation precision in the primary visual cortex&amp;quot;&lt;a href=&#34;https://t.co/vuT6gegwtO&#34;&gt;https://t.co/vuT6gegwtO&lt;/a&gt;&lt;br&gt;Neurofrance 2021 &lt;a href=&#34;https://twitter.com/hashtag/NF2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NF2021&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/NeuroFrance2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NeuroFrance2021&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SocNeuro_Tweets?ref_src=twsrc%5Etfw&#34;&gt;@SocNeuro_Tweets&lt;/a&gt; &lt;a href=&#34;https://t.co/YQNF9FiB6m&#34;&gt;pic.twitter.com/YQNF9FiB6m&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1395351843035828224?ref_src=twsrc%5Etfw&#34;&gt;May 20, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

</description>
    </item>
    
    <item>
      <title>Decoding orientation distributions from noisy observations in V1</title>
      <link>https://laurentperrinet.github.io/publication/ladret-21-crs/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-21-crs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamical processing of orientation precision in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/talk/2021-08-27-ddxl/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2021-08-27-ddxl/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This is 40th edition of Dynamicsdays&lt;/li&gt;
&lt;li&gt;Nice, 23-27 August 2021 - &lt;a href=&#34;https://dynamicsdays2021.univ-cotedazur.fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://dynamicsdays2021.univ-cotedazur.fr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;check out the &lt;a href=&#34;https://dynamicsdays2021.univ-cotedazur.fr/assets/dynamicsdays_nice_2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;book of abstracts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In this talk, we will present the following paper : 
 
 
 
 
 
 
 
 
 
&lt;/li&gt;
&lt;li&gt;Preliminary Program:
&lt;ul&gt;
&lt;li&gt;Bruno Cessac, &lt;em&gt;The Retina as a Dynamical System&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Hugo Ladret &amp;amp; Laurent Perrinet, &lt;em&gt;Dynamics of the processing of orientation precision in the primary visual cortex&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Gianluigi Mongillo, &lt;em&gt;Glassy phase in dynamically balanced networks&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Romain Veltz, &lt;em&gt;Spatial and color hallucinations in a mathematical model of primary visual cortex&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamical processing of orientation precision in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/talk/2021-05-20-neuro-france/</link>
      <pubDate>Thu, 20 May 2021 14:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2021-05-20-neuro-france/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;As presented during the &lt;a href=&#34;https://www.neurosciences.asso.fr/SN21/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroFrance 2021&lt;/a&gt; meeting
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;now (2:00 PM - 3:00 PM CEST on Thursday, May 20), you can hear Hugo Ladret &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt; present his poster P4.47 &amp;quot;Processing of orientation precision in the primary visual cortex&amp;quot;&lt;a href=&#34;https://t.co/vuT6gegwtO&#34;&gt;https://t.co/vuT6gegwtO&lt;/a&gt;&lt;br&gt;Neurofrance 2021 &lt;a href=&#34;https://twitter.com/hashtag/NF2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NF2021&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/NeuroFrance2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NeuroFrance2021&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SocNeuro_Tweets?ref_src=twsrc%5Etfw&#34;&gt;@SocNeuro_Tweets&lt;/a&gt; &lt;a href=&#34;https://t.co/YQNF9FiB6m&#34;&gt;pic.twitter.com/YQNF9FiB6m&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1395351843035828224?ref_src=twsrc%5Etfw&#34;&gt;May 20, 2021&lt;/a&gt;&lt;/blockquote&gt;
 &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://www.professionalabstracts.com/nf2021/programme-nf2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;abstract book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In this talk, we will present the following paper : 
 
 
 
 
 
 
 
 
 
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modulation of orientation selectivity by orientation precision</title>
      <link>https://laurentperrinet.github.io/publication/ladret-21-sfn/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-21-sfn/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Interested in understanding how the precision of visual features may be encoded in the brain?&lt;br&gt;&lt;br&gt;Come see &lt;a href=&#34;https://twitter.com/hugoladret?ref_src=twsrc%5Etfw&#34;&gt;@hugoladret&lt;/a&gt; poster P538.07 at virtual &lt;a href=&#34;https://twitter.com/hashtag/SfN21?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#SfN21&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SfNtweets?ref_src=twsrc%5Etfw&#34;&gt;@SfNtweets&lt;/a&gt; &lt;a href=&#34;https://t.co/yxU58qEMFo&#34;&gt;https://t.co/yxU58qEMFo&lt;/a&gt; &lt;br&gt;&lt;br&gt;It&amp;#39;s today November 8, 2021, 1:30 PM CST / 8:30 PM CET - details 👉 &lt;a href=&#34;https://t.co/jpl3zFtoka&#34;&gt;https://t.co/jpl3zFtoka&lt;/a&gt; &lt;a href=&#34;https://t.co/y9Su9yAaVS&#34;&gt;pic.twitter.com/y9Su9yAaVS&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1457644824723705856?ref_src=twsrc%5Etfw&#34;&gt;November 8, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Hy2UlLDkPyU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning dynamics in a neural network model of the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/ladret-20-aes/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-20-aes/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See also &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-19-sfn/&#34;&gt;Ladret and Perrinet, 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Orientation selectivity to synthetic natural patterns in a cortical-like model of the cat primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/ladret-19-sfn/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-19-sfn/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Interested in orientation selectivity in V1?  at &lt;a href=&#34;https://twitter.com/hashtag/sfn2019?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#sfn2019&lt;/a&gt; ? &lt;br&gt;We tested a model getting different precision levels and then tested these predictions in real neurons ! Check out poster 403.16 / P20 @ &lt;a href=&#34;https://t.co/iHUv0AHuzl&#34;&gt;https://t.co/iHUv0AHuzl&lt;/a&gt; &lt;br&gt;-&amp;gt; more info :&lt;a href=&#34;https://t.co/JkXXgC5IVp&#34;&gt;https://t.co/JkXXgC5IVp&lt;/a&gt;&lt;br&gt;🤝 &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt; &lt;a href=&#34;https://twitter.com/CNRS?ref_src=twsrc%5Etfw&#34;&gt;@CNRS&lt;/a&gt; &lt;a href=&#34;https://t.co/MVBz0UGH70&#34;&gt;pic.twitter.com/MVBz0UGH70&lt;/a&gt;&lt;/p&gt;&amp;mdash; @laurentperrinet@neuromatch.social (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1186513282326257665?ref_src=twsrc%5Etfw&#34;&gt;October 22, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-20-aes/&#34;&gt;Ladret and Perrinet, 2020&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Selectivity to oriented patterns of different precisions</title>
      <link>https://laurentperrinet.github.io/publication/ladret-18-gdr/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-18-gdr/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;poster présenté au &lt;a href=&#34;https://gdrvision2018.sciencesconf.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GDR vision, Paris&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;program : &lt;a href=&#34;https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hugoladret/InternshipM1/raw/master/2018-06_POSTER_final.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Poster (pdf)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code : &lt;a href=&#34;https://github.com/hugoladret/InternshipM1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/hugoladret/InternshipM1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
