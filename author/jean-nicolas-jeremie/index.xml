<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jean-Nicolas Jérémie | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/author/jean-nicolas-jeremie/</link>
      <atom:link href="https://laurentperrinet.github.io/author/jean-nicolas-jeremie/index.xml" rel="self" type="application/rss+xml" />
    <description>Jean-Nicolas Jérémie</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/author/jean-nicolas-jeremie/avatar_hua40b5f042c40f2b2bbad89397dde279b_69684_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Jean-Nicolas Jérémie</title>
      <link>https://laurentperrinet.github.io/author/jean-nicolas-jeremie/</link>
    </image>
    
    <item>
      <title>Ultra-Fast Image Categorization in biology and in neural models</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;this is a follow-up of: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2021).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-21-crs/&#34;&gt;Ultra-fast categorization of images containing animals in vivo and in computo&lt;/a&gt;.
   &lt;em&gt;Champalimaud Research Symposium (CRS21)&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/jeremie-21-crs/jeremie-21-crs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-21-crs/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;see an extension to visual search in: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
   &lt;em&gt;Proceedings of AREADNE&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/jeremie-22-areadne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-22-areadne/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://areadne.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Precise spiking motifs in neurobiological and neuromorphic data</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/</link>
      <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/</guid>
      <description>








  





&lt;video controls  &gt;
  &lt;source src=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/2022-12-23_polychrony-review_video-abstract.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;ul&gt;
&lt;li&gt;read the paper &lt;a href=&#34;https://doi.org/10.3390/brainsci13010068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt; or in &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/grimaldi-22-polychronies.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/2022-12-23_polychrony-review_video-abstract.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;join the &lt;a href=&#34;https://www.zotero.org/groups/4562620/polychronies&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zotero group&lt;/a&gt; to add and discuss more items&lt;/li&gt;
&lt;li&gt;code for paper (including revisions): &lt;a href=&#34;https://github.com/SpikeAI/2022_polychronies-review&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SpikeAI/2022_polychronies-review&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  id=&#34;figure-core-mechanism-of-polychrony-detection-left-in-this-example-three-presynaptic-neurons-denoted-b-c-and-d-are-fully-connected-to-two-post-synaptic-neurons-a-and-e-with-different-delays-of-respectively-1-5-and-9-ms-for-a-and-8-5-and-1-ms-for-e-middle-if-three-synchronous-pulses-are-emitted-from-presynaptic-neurons-this-will-generate-post-synaptic-potentials-that-will-reach-a-and-e-asynchronously-because-of-the-heterogeneous-delays-and-they-may-not-be-sufficient-to-reach-the-membrane-threshold-in-either-of-the-post-synaptic-neurons-therefore-no-spike-will-be-emitted-as-this-is-not-sufficient-to-reach-the-membrane-threshold-of-the-post-synaptic-neuron-so-no-output-spike-is-emitted-right-if-the-pulses-are-emitted-from-presynaptic-neurons-such-that-taking-into-account-the-delays-they-reach-the-post-synaptic-neuron-a-at-the-same-time-here-at-t--10-ms-the-post-synaptic-potentials-evoked-by-the-three-pre-synaptic-neurons-sum-up-causing-the-voltage-threshold-to-be-crossed-and-thus-to-the-emission-of-an-output-spike-red-color-while-none-is-emitted-from-post-synaptic-neuron-e&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/izhikevich.png&#34; alt=&#34;**Core mechanism of polychrony detection.** *(Left)* In this example, three presynaptic neurons denoted *b*, *c* and *d* are fully connected to two post-synaptic neurons *a* and *e*, with different delays of respectively 1, 5, and 9 ms for *a* and 8, 5, and 1 ms for *e*. *(Middle)* If three synchronous pulses are emitted from presynaptic neurons, this will generate post-synaptic potentials that will reach a and e asynchronously because of the heterogeneous delays, and they may not be sufficient to reach the membrane threshold in either of the post-synaptic neurons; therefore, no spike will be emitted, as this is not sufficient to reach the membrane threshold of the post synaptic neuron, so no output spike is emitted. *(Right)* If the pulses are emitted from presynaptic neurons such that, taking into account the delays, they reach the post-synaptic neuron *a* at the same time (here, at t = 10 ms), the post-synaptic potentials evoked by the three pre-synaptic neurons sum up, causing the voltage threshold to be crossed and thus to the emission of an output spike (red color), while none is emitted from post-synaptic neuron *e*.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Core mechanism of polychrony detection.&lt;/strong&gt; &lt;em&gt;(Left)&lt;/em&gt; In this example, three presynaptic neurons denoted &lt;em&gt;b&lt;/em&gt;, &lt;em&gt;c&lt;/em&gt; and &lt;em&gt;d&lt;/em&gt; are fully connected to two post-synaptic neurons &lt;em&gt;a&lt;/em&gt; and &lt;em&gt;e&lt;/em&gt;, with different delays of respectively 1, 5, and 9 ms for &lt;em&gt;a&lt;/em&gt; and 8, 5, and 1 ms for &lt;em&gt;e&lt;/em&gt;. &lt;em&gt;(Middle)&lt;/em&gt; If three synchronous pulses are emitted from presynaptic neurons, this will generate post-synaptic potentials that will reach a and e asynchronously because of the heterogeneous delays, and they may not be sufficient to reach the membrane threshold in either of the post-synaptic neurons; therefore, no spike will be emitted, as this is not sufficient to reach the membrane threshold of the post synaptic neuron, so no output spike is emitted. &lt;em&gt;(Right)&lt;/em&gt; If the pulses are emitted from presynaptic neurons such that, taking into account the delays, they reach the post-synaptic neuron &lt;em&gt;a&lt;/em&gt; at the same time (here, at t = 10 ms), the post-synaptic potentials evoked by the three pre-synaptic neurons sum up, causing the voltage threshold to be crossed and thus to the emission of an output spike (red color), while none is emitted from post-synaptic neuron &lt;em&gt;e&lt;/em&gt;.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;more posts on &lt;a href=&#34;https://www.reddit.com/r/neuroscience/comments/104q30e/precise_spiking_motifs_in_neurobiological_and/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;reddit&lt;/a&gt;, &lt;a href=&#34;https://www.researchgate.net/publication/365497113_Precise_Spiking_Motifs_in_Neurobiological_and_Neuromorphic_Data&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RG&lt;/a&gt;, &lt;a href=&#34;https://magazine.sciencepod.net/2023/01/01/precise-spiking-motifs-in-neurobiological-and-neuromorphic-data/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sciowire&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/Preprints_org/status/1593167106907979777,&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twit&lt;/a&gt; or &lt;a href=&#34;https://hal.science/hal-03918338&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HAL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ultra-rapid visual search in natural images using active deep learning</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-22-fens/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-22-fens/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;👉🏼 Jean-Nicolas Jérémie &lt;a href=&#34;https://twitter.com/JnJerem?ref_src=twsrc%5Etfw&#34;&gt;@JnJerem&lt;/a&gt; &lt;br&gt;📍Poster session at &lt;a href=&#34;https://twitter.com/hashtag/FENS2022?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENS2022&lt;/a&gt; &lt;br&gt;🎯 Ultra-rapid visual search in natural images using active deep learning.&lt;a href=&#34;https://twitter.com/hashtag/FENSAmbassador?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FENSAmbassador&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SocNeuro_Tweets?ref_src=twsrc%5Etfw&#34;&gt;@SocNeuro_Tweets&lt;/a&gt; &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; 1/2 &lt;a href=&#34;https://t.co/ldGJMCQb4c&#34;&gt;pic.twitter.com/ldGJMCQb4c&lt;/a&gt;&lt;/p&gt;&amp;mdash; Mélina Cordeau (@CordeauMelina) &lt;a href=&#34;https://twitter.com/CordeauMelina/status/1546389505917206531?ref_src=twsrc%5Etfw&#34;&gt;July 11, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;This work extends to natural scenes a previous work on visual search on a simplified task formulated in  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/pierre-albiges/&#34;&gt;Pierre Albigès&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
  &lt;em&gt;Journal of Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;follows  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
  &lt;em&gt;Proceedings of AREADNE&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/jeremie-22-areadne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/jeremie-22-areadne/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














  
  
  
    
  
  
  
  
  
    
  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://areadne.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
    URL&lt;/a&gt;

&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;It is based on a first work on transfer learning and its application to a natural task : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/&#34;&gt;Ultra-Fast Image Categorization in biology and in neural models&lt;/a&gt;.
   &lt;em&gt;Vision&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://arxiv.org/abs/2205.03635&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-23-ultra-fast-cat/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision7020029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;in particular, we found retinotopic mapping to be adapted to that extension : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/&#34;&gt;Retinotopic mapping improves the reliability of image classification&lt;/a&gt;.
   &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/2022-06-19-neuro-vision-retinotopic.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/talk/2022-06-19-neuro-vision-retinotopic/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ultra-rapid visual search in natural images using active deep learning</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-22-areadne/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-22-areadne/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This work extends to natural scenes a previous work on visual search on a simplified task formulated in  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/pierre-albiges/&#34;&gt;Pierre Albigès&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
  &lt;em&gt;Journal of Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;It is based on a first work on transfer learning and its application to a natural task : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/&#34;&gt;Ultra-Fast Image Categorization in biology and in neural models&lt;/a&gt;.
   &lt;em&gt;Vision&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://arxiv.org/abs/2205.03635&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-23-ultra-fast-cat/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision7020029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;in particular, we found retinotopic mapping to be adapted to that extension : 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/&#34;&gt;Retinotopic mapping improves the reliability of image classification&lt;/a&gt;.
   &lt;em&gt;NeuroVision Workshop in conjunction with CVPR 2022&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/2022-06-19-neuro-vision-retinotopic.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/talk/2022-06-19-neuro-vision-retinotopic/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://sites.google.com/uci.edu/neurovision2022/schedule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-fens/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
  &lt;em&gt;Proceedings of the FENS Forum 2022&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/jeremie-22-fens/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Retinotopic mapping improves the reliability of image classification</title>
      <link>https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Follows a previous work 









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/pierre-albiges/&#34;&gt;Pierre Albigès&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
  &lt;em&gt;Journal of Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://laurentperrinet.github.io/talk/2022-06-19-neuro-vision-retinotopic/2022-06-10_Jeremie-etal-NeuroVision_video-abstract.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;ul&gt;
&lt;li&gt;for a follow-up, check out  









  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-fens/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
  &lt;em&gt;Proceedings of the FENS Forum 2022&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/jeremie-22-fens/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Retinotopic mapping improves the reliability of image categorization</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-22-bc/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-22-bc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ultra-fast categorization of images containing animals in vivo and in computo</title>
      <link>https://laurentperrinet.github.io/publication/jeremie-21-crs/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/jeremie-21-crs/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2023).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/&#34;&gt;Ultra-Fast Image Categorization in biology and in neural models&lt;/a&gt;.
   &lt;em&gt;Vision&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
   
   
     
   
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://arxiv.org/abs/2205.03635&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   Preprint
 &lt;/a&gt;
 
 
 
 
   
 
 
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-23-ultra-fast-cat/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision7020029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   DOI
 &lt;/a&gt;
 
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;li&gt;see an extension to visual search in: 
 
 
 
 
 
 
 
 
 
   
 
 
 &lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
   &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
 
   
   
 
   &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
     
 
   &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/jean-nicolas-jeremie/&#34;&gt;Jean-Nicolas Jérémie&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
       &lt;a href=&#34;https://laurentperrinet.github.io/author/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
   &lt;/span&gt;
   (2022).
   &lt;a href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/&#34;&gt;Ultra-rapid visual search in natural images using active deep learning&lt;/a&gt;.
   &lt;em&gt;Proceedings of AREADNE&lt;/em&gt;.
   
   &lt;p&gt;
 
 
 
 
 
 
 
 
   
 
 
 
 &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/jeremie-22-areadne/jeremie-22-areadne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
   PDF
 &lt;/a&gt;
 
 
 
 &lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
         data-filename=&#34;/publication/jeremie-22-areadne/cite.bib&#34;&gt;
   Cite
 &lt;/a&gt;
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
   
   
     
   
   
   
   
   
     
   
   &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://areadne.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
     URL&lt;/a&gt;
 
 &lt;/p&gt;
 
   
   
 &lt;/div&gt;
 
 
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
