<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jean Martinet | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/author/jean-martinet/</link>
      <atom:link href="https://laurentperrinet.github.io/author/jean-martinet/index.xml" rel="self" type="application/rss+xml" />
    <description>Jean Martinet</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/author/jean-martinet/avatar_hu1fb3148343823105600c1093497f8340_7839_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Jean Martinet</title>
      <link>https://laurentperrinet.github.io/author/jean-martinet/</link>
    </image>
    
    <item>
      <title>Stakes of Neuromorphic Foveation: a promising future for embedded event cameras</title>
      <link>https://laurentperrinet.github.io/publication/gruel-23-bc/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/gruel-23-bc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Precise spiking motifs in neurobiological and neuromorphic data</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/</link>
      <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/</guid>
      <description>








  





&lt;video controls  &gt;
  &lt;source src=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/2022-12-23_polychrony-review_video-abstract.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;ul&gt;
&lt;li&gt;read the paper &lt;a href=&#34;https://doi.org/10.3390/brainsci13010068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt; or in &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/grimaldi-22-polychronies.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/2022-12-23_polychrony-review_video-abstract.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;join the &lt;a href=&#34;https://www.zotero.org/groups/4562620/polychronies&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zotero group&lt;/a&gt; to add and discuss more items&lt;/li&gt;
&lt;li&gt;code for paper (including revisions): &lt;a href=&#34;https://github.com/SpikeAI/2022_polychronies-review&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SpikeAI/2022_polychronies-review&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  id=&#34;figure-core-mechanism-of-polychrony-detection-left-in-this-example-three-presynaptic-neurons-denoted-b-c-and-d-are-fully-connected-to-two-post-synaptic-neurons-a-and-e-with-different-delays-of-respectively-1-5-and-9-ms-for-a-and-8-5-and-1-ms-for-e-middle-if-three-synchronous-pulses-are-emitted-from-presynaptic-neurons-this-will-generate-post-synaptic-potentials-that-will-reach-a-and-e-asynchronously-because-of-the-heterogeneous-delays-and-they-may-not-be-sufficient-to-reach-the-membrane-threshold-in-either-of-the-post-synaptic-neurons-therefore-no-spike-will-be-emitted-as-this-is-not-sufficient-to-reach-the-membrane-threshold-of-the-post-synaptic-neuron-so-no-output-spike-is-emitted-right-if-the-pulses-are-emitted-from-presynaptic-neurons-such-that-taking-into-account-the-delays-they-reach-the-post-synaptic-neuron-a-at-the-same-time-here-at-t--10-ms-the-post-synaptic-potentials-evoked-by-the-three-pre-synaptic-neurons-sum-up-causing-the-voltage-threshold-to-be-crossed-and-thus-to-the-emission-of-an-output-spike-red-color-while-none-is-emitted-from-post-synaptic-neuron-e&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/izhikevich.png&#34; alt=&#34;**Core mechanism of polychrony detection.** *(Left)* In this example, three presynaptic neurons denoted *b*, *c* and *d* are fully connected to two post-synaptic neurons *a* and *e*, with different delays of respectively 1, 5, and 9 ms for *a* and 8, 5, and 1 ms for *e*. *(Middle)* If three synchronous pulses are emitted from presynaptic neurons, this will generate post-synaptic potentials that will reach a and e asynchronously because of the heterogeneous delays, and they may not be sufficient to reach the membrane threshold in either of the post-synaptic neurons; therefore, no spike will be emitted, as this is not sufficient to reach the membrane threshold of the post synaptic neuron, so no output spike is emitted. *(Right)* If the pulses are emitted from presynaptic neurons such that, taking into account the delays, they reach the post-synaptic neuron *a* at the same time (here, at t = 10 ms), the post-synaptic potentials evoked by the three pre-synaptic neurons sum up, causing the voltage threshold to be crossed and thus to the emission of an output spike (red color), while none is emitted from post-synaptic neuron *e*.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;strong&gt;Core mechanism of polychrony detection.&lt;/strong&gt; &lt;em&gt;(Left)&lt;/em&gt; In this example, three presynaptic neurons denoted &lt;em&gt;b&lt;/em&gt;, &lt;em&gt;c&lt;/em&gt; and &lt;em&gt;d&lt;/em&gt; are fully connected to two post-synaptic neurons &lt;em&gt;a&lt;/em&gt; and &lt;em&gt;e&lt;/em&gt;, with different delays of respectively 1, 5, and 9 ms for &lt;em&gt;a&lt;/em&gt; and 8, 5, and 1 ms for &lt;em&gt;e&lt;/em&gt;. &lt;em&gt;(Middle)&lt;/em&gt; If three synchronous pulses are emitted from presynaptic neurons, this will generate post-synaptic potentials that will reach a and e asynchronously because of the heterogeneous delays, and they may not be sufficient to reach the membrane threshold in either of the post-synaptic neurons; therefore, no spike will be emitted, as this is not sufficient to reach the membrane threshold of the post synaptic neuron, so no output spike is emitted. &lt;em&gt;(Right)&lt;/em&gt; If the pulses are emitted from presynaptic neurons such that, taking into account the delays, they reach the post-synaptic neuron &lt;em&gt;a&lt;/em&gt; at the same time (here, at t = 10 ms), the post-synaptic potentials evoked by the three pre-synaptic neurons sum up, causing the voltage threshold to be crossed and thus to the emission of an output spike (red color), while none is emitted from post-synaptic neuron &lt;em&gt;e&lt;/em&gt;.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;more posts on &lt;a href=&#34;https://www.reddit.com/r/neuroscience/comments/104q30e/precise_spiking_motifs_in_neurobiological_and/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;reddit&lt;/a&gt;, &lt;a href=&#34;https://www.researchgate.net/publication/365497113_Precise_Spiking_Motifs_in_Neurobiological_and_Neuromorphic_Data&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RG&lt;/a&gt;, &lt;a href=&#34;https://magazine.sciencepod.net/2023/01/01/precise-spiking-motifs-in-neurobiological-and-neuromorphic-data/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sciowire&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/Preprints_org/status/1593167106907979777,&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twit&lt;/a&gt; or &lt;a href=&#34;https://hal.science/hal-03918338&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HAL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>APROVIS3D (2019/2023)</title>
      <link>https://laurentperrinet.github.io/grant/aprovis-3-d/</link>
      <pubDate>Tue, 10 Sep 2019 10:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/grant/aprovis-3-d/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Le projet APROVIS3D est lauréat de l&amp;rsquo;&lt;a href=&#34;http://www.chistera.eu/projects/aprovis3d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;appel à projets 2018 &lt;em&gt;CHIST-ERA&lt;/em&gt;&lt;/a&gt; :&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/H1_dDB3t8lI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;APROVIS3D project targets analog computing for artificial intelligence in the form of Spiking Neural Networks (SNNs) on a mixed analog and digital architecture. The project includes including field programmable analog array (FPAA) and SpiNNaker applied to a stereopsis system dedicated to coastal surveillance using an aerial robot. Computer vision systems widely rely on artificial intelligence and especially neural network based machine learning, which recently gained huge visibility. The training stage for deep convolutional neural networks is both time and energy consuming. In contrast, the human brain has the ability to perform visual tasks with unrivalled computational and energy efficiency. It is believed that one major factor of this efficiency is the fact that information is vastly represented by short pulses (spikes) at analog – not discrete – times. However, computer vision algorithms using such representation still lack in practice, and its high potential is largely underexploited. Inspired from biology, the project addresses the scientific question of developing a low-power, end-to-end analog sensing and processing architecture of 3D visual scenes, running on analog devices, without a central clock and aims to validate them in real-life situations. More specifically, the project will develop new paradigms for biologically inspired vision, from sensing to processing, in order to help machines such as Unmanned Autonomous Vehicles (UAV), autonomous vehicles, or robots gain high-level understanding from visual scenes. The ambitious long-term vision of the project is to develop the next generation AI paradigm that will eventually compete with deep learning. We believe that neuromorphic computing, mainly studied in EU countries, will be a key technology in the next decade. It is therefore both a scientific and strategic challenge for the EU to foster this technological breakthrough. The consortium from four EU countries offers a unique combination of expertise that the project requires. SNNs specialists from various fields, such as visual sensors (IMSE, Spain), neural network architecture and computer vision (Uni. of Lille, France) and computational neuroscience (INT, France) will team up with robotics and automatic control specialists (NTUA, Greece), and low power integrated systems designers (ETHZ, Switzerland) to help geoinformatics researchers (UNIWA, Greece) build a demonstrator UAV for coastal surveillance (TRL5). Adding up to the shared interest regarding analog based computing and computer vision, all team members have a lot to offer given their different and complementary points of view and expertise. Key challenges of this project will be end-to-end analog system design (from sensing to AI-based control of the UAV and 3D coastal volumetric reconstruction), energy efficiency, and practical usability in real conditions. We aim to show that such a bioinspired analog design will bring large benefits in terms of power efficiency, adaptability and efficiency needed to make coastal surveillance with UAVs practical and more efficient than digital approaches.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type de contrat : Subvention / Aide&lt;/li&gt;
&lt;li&gt;Durée: 3 ans, à partir du 1er avril 2020 (prolongation demandée)&lt;/li&gt;
&lt;li&gt;Budget total: 867 k€ , bugdget INT: 150 k€&lt;/li&gt;
&lt;li&gt;Partenaire(s) : AGENCE NATIONALE DE LA RECHERCHE&lt;/li&gt;
&lt;li&gt;Objet : AAP 2019 - CHIST-ERA &amp;ldquo;Analog PROcessing of bioinspired VIsion Sensors for 3D reconstruction&amp;rdquo; ANR-19-CHR3-0008-03&lt;/li&gt;
&lt;li&gt;Responsable Scientifique INT : PERRINET Laurent (UMR7289)&lt;/li&gt;
&lt;li&gt;“This project has received funding from the European Union’s ERA-NET CHIST-ERA 2018 research and innovation programme under grant agreement No ANR-19-CHR3-0008-03”&lt;/li&gt;
&lt;li&gt;Find more on the &lt;a href=&#34;http://aprovis3d.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;official website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
