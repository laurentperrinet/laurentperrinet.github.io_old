<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/publication-type/1/</link>
      <atom:link href="https://laurentperrinet.github.io/publication-type/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Fri, 27 Aug 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_512x512_fill_lanczos_center_3.png</url>
      <title>1</title>
      <link>https://laurentperrinet.github.io/publication-type/1/</link>
    </image>
    
    <item>
      <title>Dynamical processing of orientation precision in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/event/2021-08-27-ddxl/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2021-08-27-ddxl/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This is 40th edition of Dynamicsdays&lt;/li&gt;
&lt;li&gt;Nice, 23-27 August 2021 - &lt;a href=&#34;https://dynamicsdays2021.univ-cotedazur.fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://dynamicsdays2021.univ-cotedazur.fr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;check out the &lt;a href=&#34;https://dynamicsdays2021.univ-cotedazur.fr/assets/dynamicsdays_nice_2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;book of abstracts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In this talk, we will present the following paper : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nelson-cortes/&#34;&gt;Nelson Cortes&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/lamyae-ikan/&#34;&gt;Lamyae Ikan&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/christian-casanova/&#34;&gt;Christian Casanova&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u.-perrinet/&#34;&gt;Laurent U. Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-21/&#34;&gt;Dynamical processing of orientation precision in the primary visual cortex&lt;/a&gt;.
  &lt;em&gt;bioRxiv&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/early/2021/05/28/2021.03.30.437692&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/ladret-21/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-21/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1101/2021.03.30.437692&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;Preliminary Program:
&lt;ul&gt;
&lt;li&gt;Bruno Cessac, &lt;em&gt;The Retina as a Dynamical System&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Hugo Ladret &amp;amp; Laurent Perrinet, &lt;em&gt;Dynamics of the processing of orientation precision in the primary visual cortex&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Gianluigi Mongillo, &lt;em&gt;Glassy phase in dynamically balanced networks&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Romain Veltz, &lt;em&gt;Spatial and color hallucinations in a mathematical model of primary visual cortex&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A homeostatic gain control mechanism to improve event-driven object recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;to be presented at the &lt;a href=&#34;https://cbmi2021.univ-lille.fr/call-for-contributions#callforpapersspecialbioinspired&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bio-inspired circuits, systems and algorithms for multimedia&lt;/a&gt; special session of the &lt;a href=&#34;https://cbmi2021.univ-lille.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/a&gt; conference&lt;/li&gt;
&lt;li&gt;this proceedings paper follows up he poster presented in : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/&#34;&gt;A robust bio-inspired approach to event-driven object recognition&lt;/a&gt;.
  &lt;em&gt;Computational and Systems Neuroscience (Cosyne) 2021&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/grimaldi-21-cosyne.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-21-cosyne/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;Antoine Grimaldi and Laurent Perrinet received funding from the European Union ERA-NET CHIST-ERA 2018 research and innovation program under grant agreement No ANR-19-CHR3-0008-03.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Pooling in a predictive model of V1 explains functional and structural diversity across species</title>
      <link>https://laurentperrinet.github.io/event/2021-06-15-smb/</link>
      <pubDate>Tue, 15 Jun 2021 11:15:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2021-06-15-smb/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Presenting my poster tonight at 8:00p &lt;a href=&#34;https://twitter.com/hashtag/cosyne2020?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#cosyne2020&lt;/a&gt;, a work developed using Sparse Deep Predictive Coding (SDPC) during my PhD &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; &lt;a href=&#34;https://twitter.com/NeuroSchool_mrs?ref_src=twsrc%5Etfw&#34;&gt;@NeuroSchool_mrs&lt;/a&gt; &lt;a href=&#34;https://t.co/LtUEBnlPNt&#34;&gt;pic.twitter.com/LtUEBnlPNt&lt;/a&gt;&lt;/p&gt;&amp;mdash; AF (@Angelo_RDN) &lt;a href=&#34;https://twitter.com/Angelo_RDN/status/1233458739220504578?ref_src=twsrc%5Etfw&#34;&gt;February 28, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;This is from:&lt;br&gt;Koray Kavukcuoglu, Marc&amp;#39;Aurelio Ranzato, Rob Fergus and Yann LeCun: Learning Invariant Features through Topographic Filter Maps, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR&amp;#39;09), IEEE, 2009 &lt;a href=&#34;https://t.co/4gH6L3dmaJ&#34;&gt;pic.twitter.com/4gH6L3dmaJ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Yann LeCun (@ylecun) &lt;a href=&#34;https://twitter.com/ylecun/status/1384940135419101187?ref_src=twsrc%5Etfw&#34;&gt;April 21, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;poster.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In this talk, I will present the following paper : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/franciosini-21/&#34;&gt;Pooling in a predictive model of V1 explains functional and structural diversity across species&lt;/a&gt;.
  &lt;em&gt;bioRxiv&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/franciosini-21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/franciosini-21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/franciosini-21/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1101/2021.04.19.440444&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamical processing of orientation precision in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/event/2021-05-20-neuro-france/</link>
      <pubDate>Thu, 20 May 2021 14:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2021-05-20-neuro-france/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;As presented during the &lt;a href=&#34;https://www.neurosciences.asso.fr/SN21/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroFrance 2021&lt;/a&gt; meeting
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;now (2:00 PM - 3:00 PM CEST on Thursday, May 20), you can hear Hugo Ladret &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt; present his poster P4.47 &amp;quot;Processing of orientation precision in the primary visual cortex&amp;quot;&lt;a href=&#34;https://t.co/vuT6gegwtO&#34;&gt;https://t.co/vuT6gegwtO&lt;/a&gt;&lt;br&gt;Neurofrance 2021 &lt;a href=&#34;https://twitter.com/hashtag/NF2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NF2021&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/NeuroFrance2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#NeuroFrance2021&lt;/a&gt; &lt;a href=&#34;https://twitter.com/SocNeuro_Tweets?ref_src=twsrc%5Etfw&#34;&gt;@SocNeuro_Tweets&lt;/a&gt; &lt;a href=&#34;https://t.co/YQNF9FiB6m&#34;&gt;pic.twitter.com/YQNF9FiB6m&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1395351843035828224?ref_src=twsrc%5Etfw&#34;&gt;May 20, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://www.professionalabstracts.com/nf2021/programme-nf2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;abstract book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In this talk, we will present the following paper : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/hugo-ladret/&#34;&gt;Hugo Ladret&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nelson-cortes/&#34;&gt;Nelson Cortes&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/lamyae-ikan/&#34;&gt;Lamyae Ikan&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/christian-casanova/&#34;&gt;Christian Casanova&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u.-perrinet/&#34;&gt;Laurent U. Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-21/&#34;&gt;Dynamical processing of orientation precision in the primary visual cortex&lt;/a&gt;.
  &lt;em&gt;bioRxiv&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/early/2021/05/28/2021.03.30.437692&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/ladret-21/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-21/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1101/2021.03.30.437692&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A robust bio-inspired approach to event-driven object recognition</title>
      <link>https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Tomorrow Antoine Grimaldi will present our joint work on &amp;quot;A robust bio-inspired approach to event-driven object recognition&amp;quot; at &lt;a href=&#34;https://twitter.com/hashtag/cosyne2021?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#cosyne2021&lt;/a&gt; check-out the poster now &lt;a href=&#34;https://t.co/DUNQPcv1mx&#34;&gt;https://t.co/DUNQPcv1mx&lt;/a&gt; or meet him tomorrow during the poster session ! &lt;a href=&#34;https://t.co/wKTJPZbR6B&#34;&gt;pic.twitter.com/wKTJPZbR6B&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1364962423120265218?ref_src=twsrc%5Etfw&#34;&gt;February 25, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_6addd6032e070db213990d755e0990ef.png 400w,
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_3dd529985de4ac9b9209492398140982.png 760w,
               /publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cosyne/poster_hu42b2ccf5f39928908036dc7d8a4b9d24_7115951_6addd6032e070db213990d755e0990ef.png&#34;
               width=&#34;100%&#34;
               height=&#34;555&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;see the poster online on the &lt;a href=&#34;https://app.hopin.com/events/cosyne-2021/expo/377631&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hopin platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/antoine-grimaldi/&#34;&gt;Antoine Grimaldi&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/sio-hoi-ieng/&#34;&gt;Sio-Hoi Ieng&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/ryad-benosman/&#34;&gt;Ryad Benosman&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/&#34;&gt;A homeostatic gain control mechanism to improve event-driven object recognition&lt;/a&gt;.
  &lt;em&gt;Content-Based Multimedia Indexing (CBMI) 2021&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/grimaldi-21-cbmi/grimaldi-21-cbmi.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/grimaldi-21-cbmi/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1109/CBMI50038.2021.9461901&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;Antoine Grimaldi and Laurent Perrinet received funding from the European Union ERA-NET CHIST-ERA 2018 research and innovation program under grant agreement No ANR-19-CHR3-0008-03.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Visual search as active inference</title>
      <link>https://laurentperrinet.github.io/publication/dauce-20-iwai/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/dauce-20-iwai/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;a follow-up of: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/pierre-albiges/&#34;&gt;Pierre Albigès&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34;&gt;A dual foveal-peripheral visual processing model implements efficient saccade selection&lt;/a&gt;.
  &lt;em&gt;Journal of Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/725879v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/WhereIsMyMNIST&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1167/jov.20.8.22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  


&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;the mathematical details are described as a talk the 1st International WS on &lt;a href=&#34;https://twitter.com/hashtag/ActiveInference?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ActiveInference&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/IWAI2020?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#IWAI2020&lt;/a&gt; at &lt;a href=&#34;https://twitter.com/ECMLPKDD?ref_src=twsrc%5Etfw&#34;&gt;@ECMLPKDD&lt;/a&gt; &lt;a href=&#34;https://t.co/4s7gHbMxiT&#34;&gt;https://t.co/4s7gHbMxiT&lt;/a&gt; and paper &amp;quot;Visual search as active inference&amp;quot; &lt;a href=&#34;https://t.co/yNCOFHf7FS&#34;&gt;https://t.co/yNCOFHf7FS&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1305488089989754883?ref_src=twsrc%5Etfw&#34;&gt;September 14, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/laurentperrinet/2020-09-14_IWAI/blob/master/2020-09-10_video-abstract.gif?raw=true&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;What:: talk @ &lt;a href=&#34;https://iwaiworkshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1st International Workshop on Active Inference (IWAI 2020)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Who:: Emmanuel Daucé and Laurent Perrinet&lt;/li&gt;
&lt;li&gt;Where: Ghent (Belgium), gone virtual, see &lt;a href=&#34;https://laurentperrinet.github.io/talk/2020-09-14-iwai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/talk/2020-09-14-iwai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;When: 14/09/2020, time: 12:20:00-12:40:00&lt;/li&gt;
&lt;li&gt;What:
&lt;ul&gt;
&lt;li&gt;Slides @ &lt;a href=&#34;https://laurentperrinet.github.io/2020-09-14_IWAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/2020-09-14_IWAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code for slides @ &lt;a href=&#34;https://github.com/laurentperrinet/2020-09-14_IWAI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/2020-09-14_IWAI/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modelling Complex-cells and topological structure in the visual cortex of mammals using Sparse Predictive Coding</title>
      <link>https://laurentperrinet.github.io/publication/franciosini-20-cosyne/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/franciosini-20-cosyne/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Presenting my poster tonight at 8:00p &lt;a href=&#34;https://twitter.com/hashtag/cosyne2020?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#cosyne2020&lt;/a&gt;, a work developed using Sparse Deep Predictive Coding (SDPC) during my PhD &lt;a href=&#34;https://twitter.com/laurentperrinet?ref_src=twsrc%5Etfw&#34;&gt;@laurentperrinet&lt;/a&gt; &lt;a href=&#34;https://twitter.com/NeuroSchool_mrs?ref_src=twsrc%5Etfw&#34;&gt;@NeuroSchool_mrs&lt;/a&gt; &lt;a href=&#34;https://t.co/LtUEBnlPNt&#34;&gt;pic.twitter.com/LtUEBnlPNt&lt;/a&gt;&lt;/p&gt;&amp;mdash; AF (@Angelo_RDN) &lt;a href=&#34;https://twitter.com/Angelo_RDN/status/1233458739220504578?ref_src=twsrc%5Etfw&#34;&gt;February 28, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/franciosini-20-cosyne/poster_hu869adeac44b17d85c28add0c262e1474_334775_7b1ba1bd24a9ac870619b5a01afce506.jpg 400w,
               /publication/franciosini-20-cosyne/poster_hu869adeac44b17d85c28add0c262e1474_334775_4df08bb9aec35464458273efa7becba8.jpg 760w,
               /publication/franciosini-20-cosyne/poster_hu869adeac44b17d85c28add0c262e1474_334775_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/publication/franciosini-20-cosyne/poster_hu869adeac44b17d85c28add0c262e1474_334775_7b1ba1bd24a9ac870619b5a01afce506.jpg&#34;
               width=&#34;100%&#34;
               height=&#34;540&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;see the follow-up paper in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/franciosini-21/&#34;&gt;Pooling in a predictive model of V1 explains functional and structural diversity across species&lt;/a&gt;.
  &lt;em&gt;bioRxiv&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/franciosini-21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/franciosini-21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/franciosini-21/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1101/2021.04.19.440444&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  


&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;This is from:&lt;br&gt;Koray Kavukcuoglu, Marc&amp;#39;Aurelio Ranzato, Rob Fergus and Yann LeCun: Learning Invariant Features through Topographic Filter Maps, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR&amp;#39;09), IEEE, 2009 &lt;a href=&#34;https://t.co/4gH6L3dmaJ&#34;&gt;pic.twitter.com/4gH6L3dmaJ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Yann LeCun (@ylecun) &lt;a href=&#34;https://twitter.com/ylecun/status/1384940135419101187?ref_src=twsrc%5Etfw&#34;&gt;April 21, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Understanding natural vision using deep predictive coding</title>
      <link>https://laurentperrinet.github.io/event/2020-09-25-irphe/</link>
      <pubDate>Fri, 25 Sep 2020 15:45:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2020-09-25-irphe/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;What:: talk @ &lt;a href=&#34;https://laurentperrinet.github.io/talk/2020-09-25-irphe&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Séminaire à l&amp;rsquo;Institut de Recherche sur les Phénomènes Hors Équilibre (IRPHÉ)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Who:: Perrinet, Laurent U&lt;/li&gt;
&lt;li&gt;Where: Marseille (France), see &lt;a href=&#34;https://laurentperrinet.github.io/talk/2020-09-25-irphe&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/talk/2020-09-25-irphe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;When: 25/09/2020, time: 15:45:00-16:30:00&lt;/li&gt;
&lt;li&gt;What:
&lt;ul&gt;
&lt;li&gt;Slides @ &lt;a href=&#34;https://laurentperrinet.github.io/2020-09-25_IRPHE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/2020-09-25_IRPHE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code for slides @ &lt;a href=&#34;https://github.com/laurentperrinet/2020-09-25_IRPHE/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/2020-09-25_IRPHE/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Abstract: Building models which efficiently process images is a great source of inspiration to better understand the processes which underly our visual perception. I will present some classical models stemming from the Machine Learning community and propose some extensions inspired by Nature. For instance, Sparse Coding (SC) is one of the most successful frameworks to model neural computations at the local scale in the visual cortex. It directly derives from the efficient coding hypothesis and could be thought of as a competitive mechanism that describes visual stimulus using the activity of a small fraction of neurons. At the structural scale of the ventral visual pathways, feedforward models of vision (CNNs in the terminology  of deep learning) take into account neurophysiological observations and provide as of today the most successful framework for object recognition tasks. Nevertheless, these models do not leverage the high density of feedback and lateral interactions observed in the visual cortex. In particular, these connections are known to integrate contextual and attentional modulations to feedforward signals. The Predictive Coding (PC) theory has been proposed to model top-down and bottom-up interaction between cortical regions. We will here introduce a model combining Sparse Coding and Predictive Coding in a hierarchical and convolutional architecture. Our model, called Sparse Deep Predictive Coding (SDPC), was trained on several different databases including faces and natural images. We analyze the SPDC from a computational and a biological perspective and we combine neuroscientific evidence with machine learning methods to analyze the impact of recurrent processing at both the neural organization and representational levels. These results from the SDPC model additionally demonstrate that neuro-inspiration might be the right methodology to design more powerful and more robust computer vision algorithms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Visual search as active inference</title>
      <link>https://laurentperrinet.github.io/event/2020-09-14-iwai/</link>
      <pubDate>Mon, 14 Sep 2020 18:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2020-09-14-iwai/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see proceedings paper: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/emmanuel-dauce/&#34;&gt;Emmanuel Daucé&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/dauce-20-iwai/&#34;&gt;Visual search as active inference&lt;/a&gt;.
  &lt;em&gt;IWAI 2020&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/dauce-20-iwai/dauce-20-iwai.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/dauce-20-iwai/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/2020-09-14_IWAI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;








  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/2020-09-14_IWAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Slides
&lt;/a&gt;





&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1007/978-3-030-64919-7_17&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  


&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;the mathematical details are described as a talk the 1st International WS on &lt;a href=&#34;https://twitter.com/hashtag/ActiveInference?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ActiveInference&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/IWAI2020?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#IWAI2020&lt;/a&gt; at &lt;a href=&#34;https://twitter.com/ECMLPKDD?ref_src=twsrc%5Etfw&#34;&gt;@ECMLPKDD&lt;/a&gt; &lt;a href=&#34;https://t.co/4s7gHbMxiT&#34;&gt;https://t.co/4s7gHbMxiT&lt;/a&gt; and paper &amp;quot;Visual search as active inference&amp;quot; &lt;a href=&#34;https://t.co/yNCOFHf7FS&#34;&gt;https://t.co/yNCOFHf7FS&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1305488089989754883?ref_src=twsrc%5Etfw&#34;&gt;September 14, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/laurentperrinet/2020-09-14_IWAI/blob/master/2020-09-10_video-abstract.gif?raw=true&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;What:: talk @ &lt;a href=&#34;https://iwaiworkshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1st International Workshop on Active Inference (IWAI 2020)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Who:: Emmanuel Daucé and Laurent Perrinet&lt;/li&gt;
&lt;li&gt;Where: Ghent (Belgium), gone virtual, see &lt;a href=&#34;https://laurentperrinet.github.io/talk/2020-09-14-iwai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/talk/2020-09-14-iwai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;When: 14/09/2020, time: 12:20:00-12:40:00&lt;/li&gt;
&lt;li&gt;What:
&lt;ul&gt;
&lt;li&gt;Slides @ &lt;a href=&#34;https://laurentperrinet.github.io/2020-09-14_IWAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/2020-09-14_IWAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code for slides @ &lt;a href=&#34;https://github.com/laurentperrinet/2020-09-14_IWAI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/2020-09-14_IWAI/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Abstract: Visual search is an essential cognitive ability, offering a prototypical control problem to be addressed with Active Inference. Under a Naive Bayes assumption, the maximisation of the information gain objective is consistent with the separation of the visual sensory flow in two independent pathways, namely the &amp;ldquo;What&amp;rdquo; and the &amp;ldquo;Where&amp;rdquo; pathways. On the &amp;ldquo;What&amp;rdquo; side, the processing of the central part of the visual field (the fovea) provides the current interpretation of the scene, here the category of the target. On the &amp;ldquo;Where&amp;rdquo; side, the processing of the full visual field (at lower resolution) is expected to provide hints about future central foveal processing given the potential realisation of saccadic movements. A map of the classification accuracies, as obtained by such counterfactual saccades, defines a utility function on the motor space, whose maximal argument prescribes the next saccade. The comparison of the foveal and the peripheral predictions finally forms an estimate of the future information gain, providing a simple and resource-efficient way to implement information gain seeking policies in active vision. This dual-pathway information processing framework is found efficient on a synthetic visual search task and we show here quantitatively the role of the precision encoded within the accuracy map. More importantly, it is expected to draw connections toward a more general actor-critic principle in action selection, with the accuracy of the central processing taking the role of a value (or intrinsic reward) of the previous saccade.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>From the retina to action: Understanding visual processing</title>
      <link>https://laurentperrinet.github.io/event/2020-04-ue-neurosciences-computationnelles/</link>
      <pubDate>Fri, 03 Apr 2020 16:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2020-04-ue-neurosciences-computationnelles/</guid>
      <description>&lt;h1 id=&#34;2020-04_ue-neurosciences-computationnelles-matériel-pour-le-cours-de-modélisation&#34;&gt;2020-04_UE-neurosciences-computationnelles, matériel pour le cours de modélisation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Où: Marseille (France)&lt;/li&gt;
&lt;li&gt;Quoi: Master Neurosciences et Sciences Cognitives&lt;/li&gt;
&lt;li&gt;But de ce travail: lire un article scientifique, pouvoir le reproduire avec des simulations d&amp;rsquo;un neurone et afin d&amp;rsquo;améliorer sa compréhension.&lt;/li&gt;
&lt;li&gt;Modalités: les étudiants s&amp;rsquo;organisent seuls, en binome ou en trinome pour fournir un mémoire sous forme de &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;notebook&lt;/a&gt; complété à partir &lt;a href=&#34;https://raw.githubusercontent.com/laurentperrinet/2020-04_UE-neurosciences-computationnelles/master/MainenSejnowski1995.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;du modèle qui est fourni&lt;/a&gt;. Suivez les balises &lt;code&gt;TODO&lt;/code&gt; dans le notebook pour vous guider dans cette rédaction. Les commentaires doivent être fait en français (ou en anglais si nécessaire) dans le notebook (n&amp;rsquo;oubliez-pas de sauver vos changements) et envoyé par e-mail à mailto:laurent.perrinet@univ-amu.fr une fois votre travail fini (de préférence avant le 31 avri).&lt;/li&gt;
&lt;li&gt;Outils nécessaires: &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter&lt;/a&gt;, avec &lt;a href=&#34;https://numpy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;numpy&lt;/a&gt; et &lt;a href=&#34;https://matplotlib.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matplotlib&lt;/a&gt;. Ce sont des outils standard et qui sont facilement installables sur toute plateforme. Si vous avez des problèmes, me joindre par e-mail ou sur le &lt;a href=&#34;https://spik.xyz/nc/index.php/call/xuswegwv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;forum&lt;/a&gt; 👇&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modelling Complex-cells and topological structure in the visual cortex of mammals using Sparse Predictive Coding</title>
      <link>https://laurentperrinet.github.io/publication/franciosini-20-sigma/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/franciosini-20-sigma/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Des illusions aux hallucinations visuelles: une porte sur la perception</title>
      <link>https://laurentperrinet.github.io/event/2020-01-20-atelier-sciences-cinema/</link>
      <pubDate>Mon, 20 Jan 2020 10:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2020-01-20-atelier-sciences-cinema/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;fr&#34; dir=&#34;ltr&#34;&gt;Watch “ÇA TOURNE” on &lt;a href=&#34;https://twitter.com/hashtag/Vimeo?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Vimeo&lt;/a&gt; &lt;a href=&#34;https://t.co/nzUAEwjTeD&#34;&gt;https://t.co/nzUAEwjTeD&lt;/a&gt; (english subs) réalisé par Camille Goujon et par les élèves du Lycée Professionnel Domaine Eguille, Vedène (France) - &lt;a href=&#34;https://t.co/EhVz0YZdPs&#34;&gt;https://t.co/EhVz0YZdPs&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/StopMotion?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#StopMotion&lt;/a&gt;  &lt;a href=&#34;https://twitter.com/hashtag/vision?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#vision&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/neuroscience?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#neuroscience&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/outreach?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#outreach&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1284791644240347138?ref_src=twsrc%5Etfw&#34;&gt;July 19, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://player.vimeo.com/video/398661322&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;vimeo video&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ÇA TOURNE a été sélectionné pour participer à la compétition du « Alexandre Trauner ART/Film Festival » (Szolnok, Hongrie) : &lt;a href=&#34;http://www.ataff.hu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.ataff.hu/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;visible aux Soirée Courts Métrages Ciné Rencontre de la Ville de Berre l&amp;rsquo;Étang &lt;a href=&#34;https://www.berreletang.fr/soiree-courts-metrages?periode=2021-04-30%2017%3A23%3A26&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.berreletang.fr/soiree-courts-metrages?periode=2021-04-30%2017%3A23%3A26&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ÇA TOURNE de Camille Goujon, a été sélectionné au 27ème Festival national du film d&amp;rsquo;animation de Rennes Métropole, dans la catégorie Autoproductions du 7 au 11 octobre 2021 &lt;a href=&#34;http://festival-film-animation.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://festival-film-animation.fr/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;le court-métrage a été sélectionné pour participer au « Happy Valley Animation Festival » (Pennsylvanie, USA) : &lt;a href=&#34;https://happyvalleyanimationfestival.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://happyvalleyanimationfestival.org/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Le film &amp;ldquo;ÇA TOURNE&amp;rdquo; a été sélectionné pour faire partie de la compétition catégorie «FILMS SCOLAIRES&amp;quot; diffusée du 4 au 7 novembre 2020 dans le cadre du festival &amp;ldquo;7ème Art Jeunes Talent! : &lt;a href=&#34;http://www.festivaltournezjeunesse.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.festivaltournezjeunesse.com&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dans le cadre d&amp;rsquo;un projet Région (APERLA) les élèves de seconde Bac Pro Menuisiers agenceurs ont conçu ce film sous la direction de leur professeur Mme Bomont et  sous la direction artistique de &lt;a href=&#34;https://www.youtube.com/user/camillegoujon1/videos&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Camille Goujon&lt;/a&gt;, artiste et cinéaste d&amp;rsquo;animation &lt;a href=&#34;https://www.domaine-eguilles.fr/realisation-collective-de-lyceens-sous-la-direction-artistique-de-camille-goujon-artiste-et-cineaste-d-animation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.domaine-eguilles.fr/realisation-collective-de-lyceens-sous-la-direction-artistique-de-camille-goujon-artiste-et-cineaste-d-animation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ce court métrage fait partie des 7 films réalisés dans le cadre des « Ateliers de réalisation Cinésciences » proposés par l’association Polly Maggoo &lt;a href=&#34;http://festivalrisc.org/films-dateliers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://festivalrisc.org/films-dateliers/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ref sur &lt;a href=&#34;http://www.lussasdoc.org/film-ca_tourne-1,53288.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.lussasdoc.org/film-ca_tourne-1,53288.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Le texte de cette présentation est reprise dans cet article de &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-temps/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Conversation&lt;/a&gt; (&lt;a href=&#34;https://theconversation.com/temps-et-cerveau-comment-notre-perception-nous-fait-voyager-dans-le-temps-127567&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;lien direct&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Voir la @ &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-10-07_neurostories/&#34;&gt;présentation au NeuroStories&lt;/a&gt; sur un thème similaire&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Learning dynamics in a neural network model of the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/ladret-20-aes/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-20-aes/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See also &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-19-sfn/&#34;&gt;Ladret and Perrinet, 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A dynamic model for decoding direction and orientation in macaque primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-19-nccd/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-19-nccd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning where to look: a foveated visuomotor control model</title>
      <link>https://laurentperrinet.github.io/event/2019-07-15-cns/</link>
      <pubDate>Mon, 15 Jul 2019 12:20:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2019-07-15-cns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;download a &lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-07-15-cns/2019-07-15-cns.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preliminary PDF&lt;/a&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Emmanuel Daucé @ &lt;a href=&#34;https://twitter.com/hashtag/CNS2019Barcelona?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CNS2019Barcelona&lt;/a&gt; speaks about our joint work on « Learning where to look: a foveated visuomotor control model » more info @ &lt;a href=&#34;https://t.co/HREjuIgNCn&#34;&gt;https://t.co/HREjuIgNCn&lt;/a&gt; &lt;a href=&#34;https://twitter.com/CNSorg?ref_src=twsrc%5Etfw&#34;&gt;@CNSorg&lt;/a&gt; &lt;a href=&#34;https://t.co/GbbXhWL1k1&#34;&gt;pic.twitter.com/GbbXhWL1k1&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1150713758643380226?ref_src=twsrc%5Etfw&#34;&gt;July 15, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;















&lt;figure  id=&#34;figure-problem-setting-in-generic-ecological-settings-the-visual-system-faces-a-tricky-problem-when-searching-for-one-target-from-a-class-of-targets-in-a-cluttered-environment-a-it-is-synthesized-in-the-following-experiment-after-a-fixation-period-of-200-ms-an-observer-is-presented-with-a-luminous-display--showing-a-single-target-from-a-known-class-here-digits-and-at-a-random-position-the-display-is-presented-for-a-short-period-of-500-ms-light-shaded-area-in-b-that-is-enough-to-perform-at-most-one-saccade-here-successful-on-the-potential-target-finally-the-observer-has-to-identify-the-digit-by-a-keypress-b-prototypical-trace-of-a-saccadic-eye-movement-to-the-target-position-in-particular-we-show-the-fixation-window-and-the-temporal-window-during-which-a-saccade-is-possible-green-shaded-area-c-simulated-reconstruction-of-the-visual-information-from-the-interoceptive-retinotopic-map-at-the-onset-of-the-display-and-after-a-saccade-the-dashed-red-box-indicating-the-visual-area-of-the-what-pathway-in-contrast-to-an-exteroceptive-representation-see-a-this-demonstrates-that-the-position-of-the-target-has-to-be-inferred-from-a-degraded-sampled-image-in-particular-the-configuration-of-the-display-is-such-that-by-adding-clutter-and-reducing-the-size-of-the-digit-it-may-become-necessary-to-perform-a-saccade-to-be-able-to-identify-the-digit-the-computational-pathway-mediating-the-action-has-to-infer-the-location-of-the-target-emphbefore-seeing-it-that-is-before-being-able-to-actually-identify-the-targets-category-from-a-central-fixation&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/SpikeAI/2019-07-15_CNS/master/figures/fig_intro.jpg&#34; alt=&#34;Problem setting: In generic, ecological settings, the visual system faces a tricky problem when searching for one target (from a class of targets) in a cluttered environment. **A)** It is synthesized in the following experiment: After a fixation period of 200 ms, an observer is presented with a luminous display  showing a single target from a known class (here digits) and at a random position. The display is presented for a short period of 500 ms (light shaded area in B), that is enough to perform at most one saccade (here, successful) on the potential target. Finally, the observer has to identify the digit by a keypress. **B)** Prototypical trace of a saccadic eye movement to the target position. In particular, we show the fixation window and the temporal window during which a saccade is possible (green shaded area). **C)** Simulated reconstruction of the visual information from the (interoceptive) retinotopic map at the onset of the display and after a saccade, the dashed red box indicating the visual area of the ``what&amp;#39;&amp;#39; pathway. In contrast to an exteroceptive representation (see A), this demonstrates that the position of the target has to be inferred from a degraded (sampled) image. In particular, the configuration of the display is such that by adding clutter and reducing the size of the digit, it may become necessary to perform a saccade to be able to identify the digit. The computational pathway mediating the action has to infer the location of the target \emph{before seeing it}, that is, before being able to actually identify the target&amp;#39;s category from a central fixation. &#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Problem setting: In generic, ecological settings, the visual system faces a tricky problem when searching for one target (from a class of targets) in a cluttered environment. &lt;strong&gt;A)&lt;/strong&gt; It is synthesized in the following experiment: After a fixation period of 200 ms, an observer is presented with a luminous display  showing a single target from a known class (here digits) and at a random position. The display is presented for a short period of 500 ms (light shaded area in B), that is enough to perform at most one saccade (here, successful) on the potential target. Finally, the observer has to identify the digit by a keypress. &lt;strong&gt;B)&lt;/strong&gt; Prototypical trace of a saccadic eye movement to the target position. In particular, we show the fixation window and the temporal window during which a saccade is possible (green shaded area). &lt;strong&gt;C)&lt;/strong&gt; Simulated reconstruction of the visual information from the (interoceptive) retinotopic map at the onset of the display and after a saccade, the dashed red box indicating the visual area of the ``what&#39;&#39; pathway. In contrast to an exteroceptive representation (see A), this demonstrates that the position of the target has to be inferred from a degraded (sampled) image. In particular, the configuration of the display is such that by adding clutter and reducing the size of the digit, it may become necessary to perform a saccade to be able to identify the digit. The computational pathway mediating the action has to infer the location of the target \emph{before seeing it}, that is, before being able to actually identify the target&amp;rsquo;s category from a central fixation.
    &lt;/figcaption&gt;&lt;/figure&gt;














&lt;figure  id=&#34;figure-results-success&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://spikeai.github.io/2019-07-15_CNS/figures/CNS-saccade-20.png&#34; alt=&#34;Results: success&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Results: success
    &lt;/figcaption&gt;&lt;/figure&gt;














&lt;figure  id=&#34;figure-results-failure-to-classify&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://spikeai.github.io/2019-07-15_CNS/figures/CNS-saccade-32.png&#34; alt=&#34;Results: failure to classify&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Results: failure to classify
    &lt;/figcaption&gt;&lt;/figure&gt;














&lt;figure  id=&#34;figure-results-failure-to-locate&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://spikeai.github.io/2019-07-15_CNS/figures/CNS-saccade-47.png&#34; alt=&#34;Results: failure to locate&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Results: failure to locate
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Should I stay or should I go? Adaption of human observers to the volatility of visual inputs</title>
      <link>https://laurentperrinet.github.io/event/2019-04-05-bbcp-causal-kickoff/</link>
      <pubDate>Fri, 05 Apr 2019 15:45:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2019-04-05-bbcp-causal-kickoff/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See the final publication @ 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/chloe-pasturel/&#34;&gt;Chloé Pasturel&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/anna-montagnini/&#34;&gt;Anna Montagnini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-20/&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/784116v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://www.biorxiv.org/content/10.1101/784116v3.full.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/pasturel-montagnini-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/PasturelMontagniniPerrinet2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1007438&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/event/2016-10-13-law/&#34;&gt;LAW, Lyon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/event/2018-02-01-bcp-invibe-fest/&#34;&gt;INVIBE FEST, Paris&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/event/2018-04-05-bcp-talk/&#34;&gt;Brain workshop, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;previous talk @ &lt;a href=&#34;https://laurentperrinet.github.io/event/2019-01-18-laconeu/&#34;&gt;LACONEU, Chile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;next talk @ &lt;a href=&#34;https://laurentperrinet.github.io/event/2019-05-23-neurofrance/&#34;&gt;NeuroFrance, Marseille&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>From the retina to action: Understanding visual processing</title>
      <link>https://laurentperrinet.github.io/event/2019-04-03-a-course-on-vision-and-modelization/</link>
      <pubDate>Wed, 03 Apr 2019 16:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2019-04-03-a-course-on-vision-and-modelization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system</title>
      <link>https://laurentperrinet.github.io/publication/boutin-20-sigma/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-20-sigma/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;presented during this &lt;a href=&#34;https://laurentperrinet.github.io/event/2019-03-25-hdr-robin-baures/&#34;&gt;talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Rencontre avec les collégiens marseillais</title>
      <link>https://laurentperrinet.github.io/event/2019-01-10-polly-maggoo/</link>
      <pubDate>Thu, 10 Jan 2019 09:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2019-01-10-polly-maggoo/</guid>
      <description>&lt;h1 id=&#34;cinéma-et-sciences--rencontre-avec-les-collégiens-marseillais&#34;&gt;Cinéma et sciences : rencontre avec les collégiens marseillais&lt;/h1&gt;
&lt;p&gt;L&amp;rsquo;Association Polly Maggoo &lt;a href=&#34;http://www.pollymaggoo.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.pollymaggoo.org/&lt;/a&gt; met en place
tout le long de l’année, des actions de culture scientifique et
artistique en direction du grand public et des lycées, au cours
desquelles l&amp;rsquo;association programme des films à caractère scientifique.
Les projections se déroulent en présence de chercheurs et/ou de
cinéastes dans la perspective d’un développement de la culture
cinématographique et scientifique en direction des publics scolaires.
Le jeudi 10 janvier 2019, je suis venu échanger au côté de Serge Dentin
autour de films traitant du rapport fiction/réel, des illusion visuelles
(&amp;quot; Qu’est ce qu’une image? &amp;ldquo;), des rapports d’échelles, de la
perception, &amp;hellip; et qui sont projetés lors de la séance, avec les élèves
de deux classes de 4ème. Une occasion aussi de parler du métier de
chercheur.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
10 janvier 2019&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
collège André Malraux, Marseille&lt;/li&gt;
&lt;li&gt;Programmation&lt;br&gt;
&amp;ldquo;LAZARUS MIRAGES : TÉLÉPATHIE À L&amp;rsquo;UNIVERSITÉ DE SHANGAI&amp;rdquo; de Patric
JEAN et Henry BROCH (France, 2012, documentaire, 3&#39;21)
/&amp;ldquo;CARLITOPOLIS&amp;rdquo; / / &amp;ldquo;BIG DATA, BIG BUSINESS&amp;rdquo; / &amp;ldquo;&lt;a href=&#34;https://www.youtube.com/watch?v=RVeHxUVkW4w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Centrifuge
Brain Project, A Short Film by Till
Nowak&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A hierarchical, multi-layer convolutional sparse coding algorithm based on predictive coding</title>
      <link>https://laurentperrinet.github.io/publication/franciosini-perrinet-19-neurofrance/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/franciosini-perrinet-19-neurofrance/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modelling Complex Cells of Early Visual Cortex using Predictive Coding</title>
      <link>https://laurentperrinet.github.io/publication/franciosini-perrinet-19-cns/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/franciosini-perrinet-19-cns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Orientation selectivity to synthetic natural patterns in a cortical-like model of the cat primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/ladret-19-sfn/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-19-sfn/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Interested in orientation selectivity in V1?  at &lt;a href=&#34;https://twitter.com/hashtag/sfn2019?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#sfn2019&lt;/a&gt; ? &lt;br&gt;We tested a model getting different precision levels and then tested these predictions in real neurons ! Check out poster 403.16 / P20 @ &lt;a href=&#34;https://t.co/iHUv0AHuzl&#34;&gt;https://t.co/iHUv0AHuzl&lt;/a&gt; &lt;br&gt;-&amp;gt; more info :&lt;a href=&#34;https://t.co/JkXXgC5IVp&#34;&gt;https://t.co/JkXXgC5IVp&lt;/a&gt;&lt;br&gt;🤝 &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt; &lt;a href=&#34;https://twitter.com/CNRS?ref_src=twsrc%5Etfw&#34;&gt;@CNRS&lt;/a&gt; &lt;a href=&#34;https://t.co/MVBz0UGH70&#34;&gt;pic.twitter.com/MVBz0UGH70&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1186513282326257665?ref_src=twsrc%5Etfw&#34;&gt;October 22, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-20-aes/&#34;&gt;Ladret and Perrinet, 2020&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Sparse Deep Predictive Coding to model visual object recognition</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-19-sfn/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-19-sfn/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;If you’re at &lt;a href=&#34;https://twitter.com/hashtag/sfn2019?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#sfn2019&lt;/a&gt; and have an interest in &lt;a href=&#34;https://twitter.com/hashtag/sparse?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#sparse&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/deep?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#deep&lt;/a&gt; Predictive Coding, checkout &lt;a href=&#34;https://twitter.com/VictorBoutin?ref_src=twsrc%5Etfw&#34;&gt;@VictorBoutin&lt;/a&gt; ‘s poster 403.16 / P20:&lt;a href=&#34;https://t.co/2VLEsl98oU&#34;&gt;https://t.co/2VLEsl98oU&lt;/a&gt;&lt;br&gt;&lt;br&gt;It shows today + comes with a (timely) preprint &lt;a href=&#34;https://t.co/FfKi9tjqrN&#34;&gt;https://t.co/FfKi9tjqrN&lt;/a&gt; !&lt;br&gt; &lt;a href=&#34;https://twitter.com/hashtag/SfN19?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#SfN19&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#MachineLearning&lt;/a&gt; &lt;a href=&#34;https://t.co/ep0RrPjzzZ&#34;&gt;pic.twitter.com/ep0RrPjzzZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; laurentperrinet (@laurentperrinet) &lt;a href=&#34;https://twitter.com/laurentperrinet/status/1186196186170044421?ref_src=twsrc%5Etfw&#34;&gt;October 21, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Top-down connection in Hierarchical Sparse Coding</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-19-gdr-robotics/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-19-gdr-robotics/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>La modélisation biomorphique de la perception visuelle</title>
      <link>https://laurentperrinet.github.io/event/2018-10-11-bio-morphisme/</link>
      <pubDate>Thu, 11 Oct 2018 18:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2018-10-11-bio-morphisme/</guid>
      <description>&lt;h1 id=&#34;la-modélisation-biomorphique-de-la-perception-visuelle&#34;&gt;La modélisation biomorphique de la perception visuelle&lt;/h1&gt;
&lt;h2 id=&#34;in-la-modélisation-de-la-genèse-physico-mathématique-du-vivant&#34;&gt;in &amp;ldquo;La modélisation de la genèse physico-mathématique du vivant&amp;rdquo;&lt;/h2&gt;
&lt;h2 id=&#34;biomorphisme-et-creation-artistique-session-3&#34;&gt;BIOMORPHISME ET CREATION ARTISTIQUE – Session 3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
11 Octobre 2018&lt;/li&gt;
&lt;li&gt;Atelier&lt;br&gt;
Séminaire/workshop organisé dans le cadre du projet Biomorphisme.
Approches sensibles et conceptuelles des formes du vivant
&lt;a href=&#34;http://lesa.univ-amu.fr/?q=node/391&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://lesa.univ-amu.fr/?q=node/391&lt;/a&gt; &lt;a href=&#34;http://centregranger.cnrs.fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://centregranger.cnrs.fr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
Bâtiment Egger, dans la salle E 215 (2ème étage côté voie ferrée) -
3 avenue R. Schuman - Aix-en-Provence&lt;/li&gt;
&lt;li&gt;Visuels&lt;br&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2018-10-11_BioMorphisme.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Organisation&lt;br&gt;
Jean Arnaud, PR arts plastiques au LESA-AMU ; Julien Bernard, MCF
philosophe des sciences au Centre GG Granger-AMU ; Sylvie Pic,
artiste&lt;/li&gt;
&lt;li&gt;Résumé&lt;br&gt;
La vision utilise un faisceau d&amp;rsquo;informations de différentes qualités
pour atteindre une perception unifiée du monde environnant. Elle
interagit avec lui en créant son propre modèle génératif de sa
structure physico-mathématique. Avec &lt;a href=&#34;https://laurentperrinet.github.io/LaurentPerrinet/EtienneRey&#34;&gt;Etienne
Rey&lt;/a&gt; de l&amp;rsquo;atelier Ondes Parallèles,
nous avons utilisé lors de plusieurs projets art-science (voir
&lt;a href=&#34;https://github.com/NaturalPatterns&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NaturalPatterns&lt;/a&gt;) des installations permettant
de manipuler explicitement des composantes de ce flux d&amp;rsquo;information
et de révéler des ambiguités dans notre perception. Dans
l&amp;rsquo;installation
&lt;a href=&#34;https://github.com/NaturalPatterns/Tropique&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tropique&lt;/a&gt;, des
faisceaux de lames lumineuses sont arrangés dans l&amp;rsquo;espace assombri
de l&amp;rsquo;installation. Les spectateurs les observent grâce à leur
interaction avec une brume invisible qui est diffusée dans l&amp;rsquo;espace.
L&amp;rsquo;ensemble des faisceaux évolue comme autant de lames lumineuses à
partir de 6 video-projecteurs placés dans l&amp;rsquo;espace de
l&amp;rsquo;installation, suivant une dynamique autonome. En même temps, la
position des spectateurs est captée et permet d&amp;rsquo;alterner entre une
vision de ces sculptures d&amp;rsquo;un point de vue introceptif à un point de
vue exteroceptif. Dans «&lt;a href=&#34;https://github.com/NaturalPatterns/elasticite&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trame
Élasticité&lt;/a&gt;», 25
parallélépipèdes de miroirs (3m de haut) sont arrangés verticalement
sur une ligne horizontale. Ces lames sont rotatives et leurs
mouvements est synchronisé. Suivant la dyamique qui est imposé à ces
lames, la perception de l’espace environnent fluctue conduisant à
recomposer l’espace de la concentration à l’expansion, ou encore à
générer un surface semblant transparente ou inverser la visons de
ce qui est située devant et derrière l’observateur. Enfin, dans
«&lt;a href=&#34;https://github.com/NaturalPatterns/TRAMES&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trames&lt;/a&gt;», nous
explorons l&amp;rsquo;interaction de séries périodiques de points placées sur
des surfaces transparentes. À partir de premières expérimentations
utilisant une technique novatrice de sérigraphie, ces trames de
points sont placées afin de faire émerger des structures selon le
point de vue du spectateur. Ce qui est en jeu ici c’est l’émergence
de l’apparition de motifs virtuels résultat de la relation entre une
réalité physique, la grandeur et l’ordonnancement de trames et notre
physiologie qui conduit à cette état de perception. Lorsqu’on est
fasse à ces motifs ce qui saute au yeux plus que le motif réel c’est
sa résultante, instable et éphémère qui fait apparaitre une richesse
de figures géométriques qui se transforment et évoluent en fonction
du temps d’observation et du point de vue. Sur ce principe de
dispositif optique, le travail de chacun des motifs, lié à un
séquençage de trames conduit à faire apparaitre une composition et
des émergences de formes spécifiques. L’expérience de perception de
chacun des motifs explore les notions d’instabilité, de flux,
d’émergences … dont l’expérience donne à entrevoir des formes que
l’on retrouve dans la nature ou les phénomènes naturels: le dessin
du pelage d’un zèbre, une accumulation de bulles de savons, ou plus
généralement dans les compositions chimiques issue de la théorie de
la morphogénèse de Turing. De manière générale, nous montrerons ici
les différentes méthodes utilisées, comme l&amp;rsquo;utilisation des limites
perceptives, et aussi les résultats apportés par une telle
collaboration.&lt;/li&gt;
&lt;li&gt;Mots-Clés&lt;br&gt;
art cinétique ; science ; vision ; perception ; modèle interne&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Intervention fête de la science 2018</title>
      <link>https://laurentperrinet.github.io/event/2018-10-10-polly-maggoo/</link>
      <pubDate>Wed, 10 Oct 2018 18:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2018-10-10-polly-maggoo/</guid>
      <description>&lt;h1 id=&#34;fête-de-la-science-2018--alcazar--merlan&#34;&gt;FÊTE DE LA SCIENCE 2018 : Alcazar / MERLAN&lt;/h1&gt;
&lt;p&gt;L&amp;rsquo;Association Polly Maggoo &lt;a href=&#34;http://www.pollymaggoo.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.pollymaggoo.org/&lt;/a&gt; met en place
tout le long de l’année, des actions de culture scientifique et
artistique en direction du grand public et des lycées, au cours
desquelles l&amp;rsquo;association programme des films à caractère scientifique.
Les projections se déroulent en présence de chercheurs et/ou de
cinéastes dans la perspective d’un développement de la culture
cinématographique et scientifique en direction des publics scolaires.
Le samedi 6 octobre et le mercredi 10 octobre, je suis venu échanger au
côté de Serge Dentin autour de films traitant du rapport fiction/réel,
des illusion visuelles (&amp;quot; Qu’est ce qu’une image? &amp;ldquo;), des rapports
d’échelles, de la perception, &amp;hellip; et qui sont projetés lors de la
séance, avec tout public (samedi) ou des élèves de lycée (mercredi).
Une occasion aussi de parler du métier de chercheur.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
6 octobre 2018&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
bibliothèque de l&amp;rsquo;Alcazar (BMVR), Marseille&lt;/li&gt;
&lt;li&gt;Programmation&lt;br&gt;
&lt;em&gt;SAMSUNG GALAXY&lt;/em&gt; de Romain CHAMPALAUNE (France, 2015),
documentaire-fiction, 7′ / &lt;em&gt;LA DRÔLE DE GUERRE D’ALAN TURING&lt;/em&gt; de
Denis VAN WAEREBEKE (France, 2014), documentaire, 60’&lt;/li&gt;
&lt;li&gt;URL&lt;br&gt;
&lt;a href=&#34;http://pollymaggoo.org/fete-de-la-science-2018-alcazar-bmvr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://pollymaggoo.org/fete-de-la-science-2018-alcazar-bmvr/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Date&lt;br&gt;
10 octobre 2018&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
bibliothèque du Merlan, Marseille&lt;/li&gt;
&lt;li&gt;Programmation&lt;br&gt;
&lt;em&gt;SAMSUNG GALAXY&lt;/em&gt; de Romain CHAMPALAUNE (France, 2015),
documentaire-fiction, 7′ / &amp;ldquo;JE TE SUIS (JAG FÖLJER DIG)&amp;rdquo; / &amp;ldquo;OS
Love_EN&amp;rdquo; / &amp;ldquo;BIG DATA, BIG BUSINESS&amp;rdquo; / COPIER-CLONER / et en bonus
&amp;ldquo;&lt;a href=&#34;https://www.youtube.com/watch?v=RVeHxUVkW4w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Centrifuge Brain Project, A Short Film by Till
Nowak&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A low-cost, accessible eye tracking framework</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-18-gdr/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-18-gdr/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;poster presented @ [[https://gdrvision2018.sciencesconf.org/|GDR vision, Paris]].&lt;/li&gt;
&lt;li&gt;program : &lt;a href=&#34;https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;poster : &lt;a href=&#34;https://github.com/laurentperrinet/Perrinet18gdr/raw/master/Perrinet18gdr.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/Perrinet18gdr/raw/master/Perrinet18gdr.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;poster (code) :  &lt;a href=&#34;https://github.com/laurentperrinet/Perrinet18gdr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/Perrinet18gdr/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;source code for this framework: &lt;a href=&#34;https://github.com/laurentperrinet/CatchTheEye&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/CatchTheEye&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ANEMO: Quantitative tools for the ANalysis of Eye MOvements</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-18-anemo/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-18-anemo/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-19/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;as presented at &lt;a href=&#34;https://eyemovements.sciencesconf.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://eyemovements.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://github.com/invibe/ANEMO/raw/master/2018-05-04_Poster_Grenoble/Pasturel_etal2018_grenoble.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code : &lt;a href=&#34;https://github.com/invibe/ANEMO/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/invibe/ANEMO/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-18-grenoble/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-18-grenoble/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-19/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;as presented at &lt;a href=&#34;https://eyemovements.sciencesconf.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://eyemovements.sciencesconf.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/raw/master/Poster/2018-06-05_Poster_Workshop_Grenoble/Pasturel_etal2018grenoble.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code : &lt;a href=&#34;https://github.com/chloepasturel/AnticipatorySPEM/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/chloepasturel/AnticipatorySPEM/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-18/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-18/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-19/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>From biological vision to unsupervised hierarchical sparse coding</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-18-itwist/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-18-itwist/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;accepted submission @ &lt;a href=&#34;https://sites.google.com/view/itwist18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;iTWIST: international Traveling Workshop on Interactions between low-complexity data models and Sensing Techniques&lt;/a&gt;, 21 - 23 November​, 2018&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/view/itwist18/program#h.p_9OOcrreKb--s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster session&lt;/a&gt; scheduled on Thursday, November 22th, from 10h30 till 12h00.&lt;/li&gt;
&lt;li&gt;CIRM, Marseille, France. &lt;span id=&#34;line-10&#34; class=&#34;anchor&#34;&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;get the &lt;a href=&#34;https://arxiv.org/html/1812.00648&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;full proceedings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Poster as &lt;a href=&#34;boutin-franciosini-ruffier-perrinet-18-itwist.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>M2APix: a bio-inspired auto-adaptive visual sensor for robust ground height estimation</title>
      <link>https://laurentperrinet.github.io/publication/dupeyroux-boutin-serres-perrinet-viollet-18/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/dupeyroux-boutin-serres-perrinet-viollet-18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Origins of Hierarchy in Visual Processing</title>
      <link>https://laurentperrinet.github.io/publication/franciosini-perrinet-18-cs/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/franciosini-perrinet-18-cs/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Selectivity to oriented patterns of different precisions</title>
      <link>https://laurentperrinet.github.io/publication/ladret-18-gdr/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-18-gdr/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;poster présenté au &lt;a href=&#34;https://gdrvision2018.sciencesconf.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GDR vision, Paris&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;program : &lt;a href=&#34;https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gdrvision2018.sciencesconf.org/data/pages/posters_GDRVision2018.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hugoladret/InternshipM1/raw/master/2018-06_POSTER_final.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Poster (pdf)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code : &lt;a href=&#34;https://github.com/hugoladret/InternshipM1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/hugoladret/InternshipM1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Speed uncertainty and motion perception with naturalistic random textures</title>
      <link>https://laurentperrinet.github.io/publication/mansour-18-vss/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/mansour-18-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unsupervised Hierarchical Sparse Coding algorithm inspired by Biological Vision</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-18-doctoral-day/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-18-doctoral-day/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Participation au jury</title>
      <link>https://laurentperrinet.github.io/event/2017-11-17-festival-interferences/</link>
      <pubDate>Fri, 17 Nov 2017 18:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2017-11-17-festival-interferences/</guid>
      <description>&lt;h1 id=&#34;festival-interférences&#34;&gt;FESTIVAL INTERFÉRENCES​&lt;/h1&gt;
&lt;h2 id=&#34;cinéma-documentaire-et-débat-public&#34;&gt;Cinéma Documentaire et Débat Public&lt;/h2&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-festival-interférences&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://static.wixstatic.com/media/e37617_35d8c5b48dd340a481db5f711aeaa35a~mv2_d_1772_2480_s_2.jpg/v1/fill/w_600,h_797,al_c,q_85,usm_0.66_1.00_0.01/e37617_35d8c5b48dd340a481db5f711aeaa35a~mv2_d_1772_2480_s_2.jpg&#34; alt=&#34;FESTIVAL INTERFÉRENCES​&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      FESTIVAL INTERFÉRENCES​
    &lt;/figcaption&gt;&lt;/figure&gt;

Le collectif Scènes Publiques composé de citoyens, chercheurs et
cinéastes, organise la deuxième édition du Festival Interférences du 8
au 18 novembre 2017 à Lyon. J&amp;rsquo;ai eu la chance de pouvoir participer au
jury autour de documentaires avec un regard scientifiques. Une occasion
aussi de parler du métier de chercheur.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
17 et 18 Novembre 2017&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
Lyon&lt;/li&gt;
&lt;li&gt;Programmation&lt;br&gt;
&lt;a href=&#34;http://www.lacitedoc.com/interferences-programmation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.lacitedoc.com/interferences-programmation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Controlling an aerial robot with human gestures using bio-inspired algorithm</title>
      <link>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-17-doctoral-day/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-17-doctoral-day/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/frederic-y-chavane/&#34;&gt;Frédéric Chavane&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/&#34;&gt;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1902.07651&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-chavane-ruffier-perrinet-20/boutin-franciosini-chavane-ruffier-perrinet-20.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-chavane-ruffier-perrinet-20/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/VictorBoutin/InteractionMap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1008629&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;more about the role of top-down connections: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/victor-boutin/&#34;&gt;Victor Boutin&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/angelo-franciosini/&#34;&gt;Angelo Franciosini&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/franck-ruffier/&#34;&gt;Franck Ruffier&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/&#34;&gt;Effect of top-down connections in Hierarchical Sparse Coding&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/2002.00892&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/boutin-franciosini-ruffier-perrinet-20-feedback.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/boutin-franciosini-ruffier-perrinet-20-feedback/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic modulation of volatility by reward contingencies: effects on anticipatory smooth eye movement</title>
      <link>https://laurentperrinet.github.io/publication/damasse-17-vss/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/damasse-17-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient learning of sparse image representations using homeostatic regulation</title>
      <link>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-neurofrance/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-neurofrance/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This work is a followup of 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/&#34;&gt;Role of homeostasis in learning sparse representations&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-00156610&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/perrinet-10-shl.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-10-shl/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco.2010.05-08-795&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;the &lt;a href=&#34;https://github.com/laurentperrinet/BoutinRuffierPerrinet17spars/raw/master/docs/BoutinRuffierPerrinet17neurofrance.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster (PDF)&lt;/a&gt; will be presented Thursday, May 18 @ &lt;a href=&#34;http://www.professionalabstracts.com/sn2017/programme-sn2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroFrance, Bordeaux&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;see a follow-up publication on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2019).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-hulk/&#34;&gt;An adaptive homeostatic algorithm for the unsupervised learning of visual features&lt;/a&gt;.
  &lt;em&gt;Vision&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-hulk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-hulk/perrinet-19-hulk.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-19-hulk/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/SpikeAI/HULK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3390/vision3030047&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Efficient learning of sparse image representations using homeostatic regulation</title>
      <link>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-spars/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/boutin-ruffier-perrinet-17-spars/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This work is a followup of &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-10-shl/&#34;&gt;Perrinet, 2010, Neural Computation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code is available @ &lt;a href=&#34;https://github.com/laurentperrinet/BoutinRuffierPerrinet17spars&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/laurentperrinet/BoutinRuffierPerrinet17spars&lt;/a&gt; and heavily uses &lt;a href=&#34;https://github.com/bicv/SparseHebbianLearning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/bicv/SparseHebbianLearning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;the &lt;a href=&#34;https://github.com/laurentperrinet/BoutinRuffierPerrinet17spars/raw/master/docs/BoutinRuffierPerrinet17spars.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poster (PDF)&lt;/a&gt;  will be presented Thursday, June 8 @ &lt;a href=&#34;http://spars2017.lx.it.pt/index_files/SPARS2017_program.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPARS, Lisbon&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Estimating and anticipating a dynamic probabilistic bias in visual motion direction</title>
      <link>https://laurentperrinet.github.io/publication/pasturel-17-gdr/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/pasturel-17-gdr/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a write-up in &amp;ldquo;&lt;a href=&#34;https://laurentperrinet.github.io/publication/pasturel-montagnini-perrinet-19/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Humans adapt their anticipatory eye movements to the volatility of visual motion properties&lt;/a&gt;&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Expériences autour de la perception de la forme en art et science</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-17-gdr/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-17-gdr/</guid>
      <description>&lt;h1 id=&#34;expériences-autour-de-la-perception-de-la-forme-en-art-et-science&#34;&gt;Expériences autour de la perception de la forme en art et science&lt;/h1&gt;
&lt;p&gt;La vision utilise un faisceau d&amp;rsquo;informations de différentes qualités pour atteindre une perception unifiée du monde environnant. Nous avons utilisé lors de plusieurs projets art-science (voir &lt;a href=&#34;https://github.com/NaturalPatterns&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NaturalPatterns&lt;/a&gt;) des installations permettant de manipuler explicitement des composantes de ce flux d&amp;rsquo;information et de révéler des ambiguités dans notre perception.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://ondesparalleles.org/wp-content/uploads/2014/02/tropique_fiche_b.jpg&#34; alt=&#34;Tropique&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://ondesparalleles.org/wp-content/uploads/2014/02/tropique_fiche_a.jpg&#34; alt=&#34;Tropique&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

Dans l&amp;rsquo;installation «Tropique», des faisceaux de lames lumineuses sont arrangés dans l&amp;rsquo;espace assombri de l&amp;rsquo;installation. Les spectateurs les observent grâce à leur interaction avec une brume invisible qui est diffusée dans l&amp;rsquo;espace. Dans «Trame Élasticité», 25 parallélépipèdes de miroirs (3m de haut) sont arrangés verticalement sur une ligne horizontale. Ces lames sont rotatives et leurs mouvements est synchronisé. Suivant la dyamique qui est imposé à ces lames, la perception de l’espace environnent fluctue conduisant à recomposer l’espace de la concentration à l’expansion, ou encore à générer un surface semblant transparente ou inverser la visons de ce qui est située devant et derrière l’observateur. Enfin, dans «Trame instabilité», nous explorons l&amp;rsquo;interaction de séries périodiques de points placées sur des surfaces transparentes. À partir de premières expérimentations utilisant une technique novatrice de sérigraphie, ces trames de points sont placées afin de faire émerger des structures selon le point de vue du spectateur. De manière générale, nous montrerons ici les différentes méthodes utilisées, comme l&amp;rsquo;utilisation des limites perceptives, et aussi les résultats apportés par une telle collaboration.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://ondesparalleles.org/wp-content/uploads/2017/01/EtienneRey-TRAME-Vasarely-B.jpg&#34; alt=&#34;Elasticité&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://ondesparalleles.org/wp-content/uploads/2017/01/EtienneRey-TRAME-Vasarely-D.jpg&#34; alt=&#34;Elasticité&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;poster présenté au &lt;a href=&#34;https://gdrvision2017.sciencesconf.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GDR vision 2017, Lille&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;abstract: &lt;a href=&#34;https://github.com/NaturalPatterns/2017-10-12_GDR/raw/master/2017-10-12_PerrinetRey2017abstract_168363.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NaturalPatterns/2017-10-12_GDR/raw/master/2017-10-12_PerrinetRey2017abstract_168363.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;poster : &lt;a href=&#34;https://github.com/NaturalPatterns/2017-10-12_GDR/raw/master/2017-10-12_PerrinetRey2017poster.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NaturalPatterns/2017-10-12_GDR/raw/master/2017-10-12_PerrinetRey2017poster.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;poster (code) : &lt;a href=&#34;https://github.com/NaturalPatterns/2017-10-12_GDR/blob/master/2017-10-12_PerrinetRey2017poster.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NaturalPatterns/2017-10-12_GDR/blob/master/2017-10-12_PerrinetRey2017poster.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;more code : &lt;a href=&#34;https://github.com/NaturalPatterns&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NaturalPatterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>How the dynamics of human smooth pursuit is influenced by speed uncertainty</title>
      <link>https://laurentperrinet.github.io/publication/mansour-17-ecvp/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/mansour-17-ecvp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/mansour-17-gdr/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/mansour-17-gdr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Participation au jury et entretien avec Clara Delmon</title>
      <link>https://laurentperrinet.github.io/event/2016-11-20-polly-maggoo/</link>
      <pubDate>Sun, 20 Nov 2016 09:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2016-11-20-polly-maggoo/</guid>
      <description>&lt;h1 id=&#34;rencontres-internationales-sciences--cinémas&#34;&gt;RENCONTRES INTERNATIONALES SCIENCES &amp;amp; CINÉMAS&lt;/h1&gt;
&lt;h2 id=&#34;cinéma-les-variétés&#34;&gt;cinéma les Variétés&lt;/h2&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-httppollymaggooorgwp-contentuploads201610risc2016_a3-724x1024jpg&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://pollymaggoo.org/wp-content/uploads/2016/10/RISC2016_A3-724x1024.jpg&#34; alt=&#34;http://pollymaggoo.org/wp-content/uploads/2016/10/RISC2016_A3-724x1024.jpg&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;http://pollymaggoo.org/wp-content/uploads/2016/10/RISC2016_A3-724x1024.jpg&#34;&gt;http://pollymaggoo.org/wp-content/uploads/2016/10/RISC2016_A3-724x1024.jpg&lt;/a&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;

L&amp;rsquo;Association Polly Maggoo &lt;a href=&#34;http://www.pollymaggoo.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.pollymaggoo.org/&lt;/a&gt; programme la
10e édition des RENCONTRES INTERNATIONALES SCIENCES &amp;amp; CINÉMAS (RISC) à
Marseille, au cours desquelles l&amp;rsquo;association programme des films à
caractère scientifique. Les projections se déroulent en présence de
chercheurs et/ou de cinéastes dans la perspective d’un développement de
la culture cinématographique et scientifique en direction des publics
scolaires.
Ce dimanche 20 novembre, je suis venu échanger au côté de Serge Dentin
et Caroline Renard (Maître de conférences en études cinématographiques à
Aix-Marseille Université), autour de films traitant du rapport
fiction/réel, de la mémoire, et du temps. Une occasion aussi de parler
du métier de chercheur.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
25 Avril 2016&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
cinéma les Variétés&lt;/li&gt;
&lt;li&gt;Programmation&lt;br&gt;
&amp;ldquo;addendum&amp;rdquo; court métrage de Jérôme Lefdup et &amp;ldquo;Poétique du cerveau&amp;rdquo;
long métrage de Nurith Aviv&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;entretien-avec-clara-delmon&#34;&gt;entretien avec Clara Delmon&lt;/h1&gt;
&lt;p&gt;L&amp;rsquo;occasion aussi d&amp;rsquo;un entretien avec Clara Delmon dans le cadre de son
mémoire de DSAA (Diplôme Supérieur d’Arts Appliqués) mention Design
Graphique à Marseille, disponible sur
&lt;a href=&#34;http://www.tonerkebab.fr/wiki/doku.php/wiki:proto-memoires:clara-delmon:clara-delmon&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.tonerkebab.fr/wiki/doku.php/wiki:proto-memoires:clara-delmon:clara-delmon&lt;/a&gt;
et &lt;a href=&#34;https://www.behance.net/claradelmon&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.behance.net/claradelmon&lt;/a&gt; &lt;a href=&#34;http://www.tonerkebab.fr/wiki/lib/exe/fetch.php/wiki:proto-memoires:clara-delmon:clara_synthe_se.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;L’échec de la
perception&amp;rdquo;&lt;/a&gt;.
Entretien avec Laurent PERRINET, rencontré à la 10e édition des RISC
(Rencontres Internationales de la Science et du Cinéma) chercheur au
CNRS (Centre National de la Recherche Scientifque) à l’Institut de
Neurosciences de la Timone à Marseille, spécialisé en perception
visuelle.&lt;/p&gt;
&lt;h2 id=&#34;entretien&#34;&gt;Entretien&lt;/h2&gt;
&lt;p&gt;Entretien avec Laurent PERRINET, rencontré à la 10e édition des RISC
(Rencontres Internationales de la Science et du Cinéma)chercheur au CNRS
(Centre National de la Recherche Scientifque) à l’Institut de
Neurosciences de la Timone à Marseille, spécialisé en perception
visuelle. ﻿
&lt;strong&gt;1 / Vous faites les Rencontres Internationales de la Science et du
Cinéma depuis quelques années déjà, la science est de plus en plus
présente dans les arts, comme avec certains courants artistiques comme
l’Art Cinétique ou l’Art Optique, pourquoi pensez-vous qu’une telle
interaction est présente à notre époque ? J’ai la sensation qu’il y a
un intérêt grandissant pour l’étude du cerveau dans le domaine des
arts et de la communication. À votre avis, pourquoi un tel besoin de
donner de la poésie au cerveau, (ou du cerveau à la poésie) ?&lt;/strong&gt;
En effet, je participe aux Rencontres Internationales de la Science et
du Cinéma depuis déjà deux ans déjà. Le but est simplement de
rentrer en contact avec le grand public et partager ma passion pour
l’étude de la perception visuelle et du cerveau plus généralement.
J’attache beaucoup d’importance à ces rencontres car elle nous
permettent aussi de mieux comprendre l’intérêt public pour le cerveau
dans son fonctionnement normal mais aussi dans ses dysfonctions. C’est
aussi une source d’inspiration pour savoir dans quelle direction il est
important de plus creuser nos recherches.
&lt;strong&gt;2 / Vous travaillez notamment avec Etienne Rey sur des installations
interactives, où la place et le ressenti du spectateur font l’œuvre. La
vue est alors votre outil de travail essentiel, pourquoi ce sens est-il
plus sensiblement exposé à l’expérience de l’illusion ? Qu’apporte
l’expérience perceptive au spectateur ?&lt;/strong&gt;
En effet, en parallèle de ces actions de partage avec le public, je
travaille aussi avec &lt;em&gt;Étienne Rey&lt;/em&gt;, un artiste plasticien résidant à
la Friche Belle de mai à Marseille. Notre travail s’articule autour de
l’ambiguïté de l’expérience perceptive du spectateur.
Est-il en train de se regarder lui-même dans un miroir ou le miroir
est-il lui-même une œuvre d’art ?
&lt;strong&gt;3 / Les graphistes d’aujourd’hui ont tendance à brouiller les codes,
déformer, rendre illisible, en bref utiliser la complexité de l’image
pour en complexifier la lecture. Pensez-vous qu’une image où on ne voit
rien puisse en dire plus ? C’est-à-dire, pensez-vous qu’en accentuant
l’acte de lecture, le designer graphique amène à son lecteur une
activité qui consisterait non plus seulement à déchiffrer un message
(présentation d’un évènement, publicité&amp;hellip;) mais à s’observer
lui-même en tant que lecteur ?&lt;/strong&gt;
Le travail du système visuel est de décoder les messages ambigus qui
lui sont délivrés par la rétine. En créant des oeuvres graphiques
qui brouillent les codes et en les déformants, on oblige le cerveau à
avoir une démarche plus active par rapport au décodage du message
fourni.
Tout le travail du graphiste consiste donc à indiquer ce processus
actif tout en conservant l’intégrité du message.
&lt;strong&gt;4 / Ces images utilisent le plus souvent des trames, des rayures, des
distorsions qui captent notre attention. Pourquoi notre œil est plus
attiré par ce qui est en mouvement ?&lt;/strong&gt;
Notre oeil est attiré par tout ce qui est surprenant. Cela inclut donc
tout ce qui ne peut pas arriver par hasard comme des bouts de lignes
alignés. Mais notre oeil est aussi attiré par ce qu’il trouve
surprenant de ne pas pouvoir prédire, comme par exemple des lignes qui
sont légèrement décalées ou un objet qui est en mouvement. Un
processus actif s’établit alors pour comprendre cette stimulation avec
de nouvelles hypothèses.
&lt;strong&gt;5 / Il semblerait que notre œil soit attiré par des formes, des
couleurs, des objets particuliers qui diffèrent pour chacun d’entre
nous. Il y a dans la perception visuelle des notions de pulsions, de
désirs, un besoin de voir, comment expliquez-vous que le cerveau soit
sans cesse en quête et en attente d’images ?&lt;/strong&gt;
Pour moi la perception visuelle n’est pas juste un cinéma à
l’intérieur du cerveau !
C’est un processus vital qui sert à mieux interagir avec
l’environnement. À ce titre il est toujours en quête de nouvelles
images pour améliorer ce rapport au monde que l’on construit sans
cesse. Il faut voir par exemple comment un enfant manipule des objets.
Il le fait pour mieux comprendre les images de ces objets et la façon
dont il peut interagir avec le monde.
&lt;strong&gt;6 / On l’a vu notamment dans le film Poétique du Cerveau de Nurith
Aviv diffusé à cette 10e édition du RISC, la mémoire et
l’expérience visuelle de chacun influent sur notre perception. Vous
avez parlé d’ « autopoïèse », cela signifie-t-il que nous voyons tous
les choses différemment ? Est-ce qu’un système de données
pré-établies est formé par notre cerveau au cours de nos années de
vie et sert de « lunettes » pour voir le monde ?&lt;/strong&gt;
La perception visuelle est un processus actif de compréhension d’une
représentation du monde. Elle est donc propre à chacun car elle se
construit avec notre expérience et la façon dont nous interagissons
avec le monde visuel. Mais ce monde est le même pour chaque individu et
nous partageons les mêmes codes et les mêmes systèmes pour apprendre
à nous représenter ce monde.
Nos « lunettes » sont donc propres à notre expérience mais elles ont
sûrement beaucoup en commun entre individus.
&lt;strong&gt;7 / Peut-on enlever ces lunettes? Des expérimentations optiques comme
celles d’Etienne Rey ou celles de designers graphiques conduisants une
réflexion sur notre vision peuvent-elles amener une nouvelle
expérience visuelle remettant en question notre activité
perceptive?&lt;/strong&gt;
On ne pourra jamais enlever ses lunettes ! Pour voir, on est obligé
d’interagir avec le monde. Toute perception est une interprétation et
ne pourra jamais être absolue : le monde physique nous est « caché »
par la médiation avec nos sens, qui par essence sont toujours ambigus.
Par contre, ces expérimentations optiques permettent de mieux
comprendre les limites de cet aspect de notre perception visuelle et
ainsi de donner un accès plus direct avec cette conscience du monde
visuel.
&lt;strong&gt;8 / Le mécanisme d’anticipation mis à l’œuvre dans notre cerveau
faisant intervenir notre mémoire et notre imagination dans la
constitution d’une image stable ne nous éloigne-t-il pas trop de la
réalité ? Il y a une « imagination anticipative » et une confirmation
de ce réel par la mise en tension de nos projections avec la situation
présente, ce système n’est-il pas proche de celui de l’illusion
d’optique ?&lt;/strong&gt;
Au contraire je pense que ces mécanismes d’anticipation sont plus
proches de la réalité que celle qu’on imagine être la « vraie »
réalité. Par exemple on ne voit que dans un spectre de lumière très
défini alors que les objets visuels existent potentiellement par
exemple dans la lumière ultraviolette. Cette réalité là n’est
visible qu’avec des appareils spécialisés.
Pour moi la seule réalité qui vaille, c’est la réalité de la
construction qui est opérée dans la perception visuelle et non la
réalité généralement établie du monde physique externe à nos
sens.
En comprenant mieux les mécanismes qui nous permettent de simuler cette
réalité physique externe, nous sommes plus objectifs par rapport aux
limites de notre connaissance du monde.
À ce titre je pense que ces mécanismes d’anticipation sont donc plus
proches de la réalité par rapport à une réalité objective telle
qu’on se la représente traditionnellement.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Biologically-inspired characterization of sparseness in natural images</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-16-euvip/</link>
      <pubDate>Sat, 22 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-16-euvip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Operant reinforcement versus reward expectancy: effects on anticipatory eye movements</title>
      <link>https://laurentperrinet.github.io/publication/damasse-16-vss/</link>
      <pubDate>Thu, 22 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/damasse-16-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Les illusions visuelles, un révélateur du fonctionnement de notre cerveau</title>
      <link>https://laurentperrinet.github.io/event/2016-04-28-mejanes/</link>
      <pubDate>Thu, 28 Apr 2016 18:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2016-04-28-mejanes/</guid>
      <description>&lt;h1 id=&#34;les-illusions-visuelles-un-révélateur-du-fonctionnement-de-notre-cerveau&#34;&gt;Les illusions visuelles, un révélateur du fonctionnement de notre cerveau&lt;/h1&gt;
&lt;h2 id=&#34;cycle-de-conférences-tous-connectés-bibliothèque-de-méjanes&#34;&gt;Cycle de conférences &amp;ldquo;Tous connectés&amp;rdquo;, Bibliothèque de Méjanes&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;conférence tout public à la Bibliothèque de Méjanes (Aix-en-Provence, Avril 2016)&#34; srcset=&#34;
               /event/2016-04-28-mejanes/featured_hu6f6d5fb2faa25e28f30d4d4a74ac9231_213872_ecd3ed628d8b16db821bef957567a03e.jpg 400w,
               /event/2016-04-28-mejanes/featured_hu6f6d5fb2faa25e28f30d4d4a74ac9231_213872_ccb52b444f8ecb6c784ec834b7921dca.jpg 760w,
               /event/2016-04-28-mejanes/featured_hu6f6d5fb2faa25e28f30d4d4a74ac9231_213872_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/event/2016-04-28-mejanes/featured_hu6f6d5fb2faa25e28f30d4d4a74ac9231_213872_ecd3ed628d8b16db821bef957567a03e.jpg&#34;
               width=&#34;570&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
28 Avril 2016&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
Bibliothèque de Méjanes&lt;/li&gt;
&lt;li&gt;Visuels&lt;br&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2016-04-28_mejanes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTML&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Les illusions visuelles, un révélateur du fonctionnement de notre cerveau</title>
      <link>https://laurentperrinet.github.io/event/2016-04-25-polly-maggoo/</link>
      <pubDate>Mon, 25 Apr 2016 09:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2016-04-25-polly-maggoo/</guid>
      <description>&lt;h1 id=&#34;les-illusions-visuelles-un-révélateur-du-fonctionnement-de-notre-cerveau&#34;&gt;Les illusions visuelles, un révélateur du fonctionnement de notre cerveau&lt;/h1&gt;
&lt;h2 id=&#34;cinésciences-collège-clair-soleil&#34;&gt;Cinésciences, collège Clair Soleil&lt;/h2&gt;
&lt;p&gt;L&amp;rsquo;Association Polly Maggoo &lt;a href=&#34;http://www.pollymaggoo.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.pollymaggoo.org/&lt;/a&gt; met en place
tout le long de l’année, des actions de culture scientifique et
artistique en direction des collèges et des lycées, les &lt;em&gt;Cinésciences&lt;/em&gt;,
au cours desquelles l&amp;rsquo;association programme des films à caractère
scientifique, au sein d’établissements scolaires. Les projections se
déroulent en présence de chercheurs et/ou de cinéastes dans la
perspective d’un développement de la culture cinématographique et
scientifique en direction des publics scolaires.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;br&gt;
25 Avril 2016&lt;/li&gt;
&lt;li&gt;Location&lt;br&gt;
collège Clair Soleil, Marseille&lt;/li&gt;
&lt;li&gt;Visuels&lt;br&gt;
&lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2016-04-25_pollymagoo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTML&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A dynamic model for decoding direction and orientation in macaque primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/taouali-15-vss/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/taouali-15-vss/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in this &lt;a href=&#34;https://laurentperrinet.github.io/publication/taouali-16-areadne/&#34;&gt;poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;This is a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A dynamic model for decoding direction and orientation in macaque primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/taouali-16-areadne/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/taouali-16-areadne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compensation of oculomotor delays in the visual system&#39;s network</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-16-networks/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-16-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effects of motion predictability on anticipatory and visually-guided eye movements: a common prior for sensory processing and motor control?</title>
      <link>https://laurentperrinet.github.io/publication/montagnini-16-ecvp/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/montagnini-16-ecvp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modeling the effect of dynamic contingencies on anticipatory eye movements</title>
      <link>https://laurentperrinet.github.io/publication/damasse-16-ecvp/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/damasse-16-ecvp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/mansour-16-ecvp/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/mansour-16-ecvp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/mansour-16-gdr/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/mansour-16-gdr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Voluntary tracking the moving clouds : Effects of speed variability on human smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/mansour-16-sfn/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/mansour-16-sfn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sparse Coding Of Natural Images Using A Prior On Edge Co-Occurences</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-15-eusipco/</link>
      <pubDate>Sat, 22 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-15-eusipco/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Mathematical Account of Dynamic Texture Synthesis for Probing Visual Perception</title>
      <link>https://laurentperrinet.github.io/publication/vacher-15-icms/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/vacher-15-icms/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/jonathan-vacher/&#34;&gt;Jonathan Vacher&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/andrew-isaac-meso/&#34;&gt;Andrew Isaac Meso&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/gabriel-peyre/&#34;&gt;Gabriel Peyré&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/vacher-16/&#34;&gt;Bayesian Modeling of Motion Perception using Dynamical Stochastic Textures&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1611.01390&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/vacher-16/vacher-16.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/vacher-16/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01142&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Anticipating a moving target: role of vision and reinforcement</title>
      <link>https://laurentperrinet.github.io/publication/montagnini-15-sfn/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/montagnini-15-sfn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anticipatory smooth eye movements and reinforcement</title>
      <link>https://laurentperrinet.github.io/publication/damasse-15-vss/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/damasse-15-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anticipatory smooth eye movements as operant behavior</title>
      <link>https://laurentperrinet.github.io/publication/damasse-15-gdr/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/damasse-15-gdr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eye tracking a self-moved target with complex hand-target dynamics</title>
      <link>https://laurentperrinet.github.io/publication/danion-15-sfn/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/danion-15-sfn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On overdispersion in neuronal evoked activity</title>
      <link>https://laurentperrinet.github.io/publication/taouali-15-icmns/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/taouali-15-icmns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in this &lt;a href=&#34;https://laurentperrinet.github.io/publication/taouali-16/&#34;&gt;publication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Spatiotemporal tuning of retinal ganglion cells dependent on the context of signal presentation</title>
      <link>https://laurentperrinet.github.io/publication/ravello-15/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ravello-15/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond simply faster and slower: exploring paradoxes in speed perception</title>
      <link>https://laurentperrinet.github.io/publication/meso-14-vss/</link>
      <pubDate>Fri, 22 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/meso-14-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Edge co-occurrences are sufficient to categorize natural versus animal images</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-bednar-14-vss/</link>
      <pubDate>Fri, 22 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-bednar-14-vss/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/james-a-bednar/&#34;&gt;James A Bednar&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2015).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-bednar-15/&#34;&gt;Edge co-occurrences can account for rapid categorization of natural versus animal images&lt;/a&gt;.
  &lt;em&gt;Scientific Reports&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01202447&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://www.nature.com/articles/srep11400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-bednar-15/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/PerrinetBednar15&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1038/srep11400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Motion-based prediction model for flash lag effect</title>
      <link>https://laurentperrinet.github.io/publication/khoei-14-vss/</link>
      <pubDate>Fri, 22 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/khoei-14-vss/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/perrinet-12-pred.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-12-pred/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on motion extrapolation: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2013).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34;&gt;Motion-based prediction explains the role of tracking in motion extrapolation&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/khoei-13-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-13-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2013.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on the flash-lag effect: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34;&gt;The flash-lag effect as a motion-based predictive shift&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01771125&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-masson-perrinet-17/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/Khoei_2017_PLoSCB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1005068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The characteristics of microsaccadic eye movements varied with the change of strategy in a match-to-sample task</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-14-vss/</link>
      <pubDate>Fri, 22 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-14-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</title>
      <link>https://laurentperrinet.github.io/publication/taouali-14-areadne/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/taouali-14-areadne/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in this &lt;a href=&#34;https://laurentperrinet.github.io/publication/taouali-16/&#34;&gt;publication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</title>
      <link>https://laurentperrinet.github.io/publication/taouali-14-neurocomp/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/taouali-14-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up in this &lt;a href=&#34;https://laurentperrinet.github.io/publication/taouali-16/&#34;&gt;publication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic Textures For Probing Motion Perception</title>
      <link>https://laurentperrinet.github.io/publication/vacher-14-ihp/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/vacher-14-ihp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/jonathan-vacher/&#34;&gt;Jonathan Vacher&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/andrew-isaac-meso/&#34;&gt;Andrew Isaac Meso&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/gabriel-peyre/&#34;&gt;Gabriel Peyré&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/vacher-16/&#34;&gt;Bayesian Modeling of Motion Perception using Dynamical Stochastic Textures&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://arxiv.org/abs/1611.01390&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/vacher-16/vacher-16.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/vacher-16/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1162/neco_a_01142&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>On the nature of anticipatory eye movements and the factors affecting them</title>
      <link>https://laurentperrinet.github.io/publication/damasse-14-gdr/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/damasse-14-gdr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Relationship between natural image statistics and lateral connectivity in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/rudiger-14-cosyne/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/rudiger-14-cosyne/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/james-a-bednar/&#34;&gt;James A Bednar&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2015).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-bednar-15/&#34;&gt;Edge co-occurrences can account for rapid categorization of natural versus animal images&lt;/a&gt;.
  &lt;em&gt;Scientific Reports&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01202447&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://www.nature.com/articles/srep11400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-bednar-15/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/PerrinetBednar15&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1038/srep11400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</title>
      <link>https://laurentperrinet.github.io/publication/kaplan-khoei-14/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/kaplan-khoei-14/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/perrinet-12-pred.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-12-pred/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on motion extrapolation: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2013).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34;&gt;Motion-based prediction explains the role of tracking in motion extrapolation&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/khoei-13-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-13-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2013.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on the flash-lag effect: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34;&gt;The flash-lag effect as a motion-based predictive shift&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01771125&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-masson-perrinet-17/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/Khoei_2017_PLoSCB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1005068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  
















&lt;figure  id=&#34;figure-figure-4-rasterplot-of-input-and-output-spikes-the-raster-plot-from-excitatory-neurons-is-ordered-according-to-their-position-each-input-spike-is-a-blue-dot-and-each-output-spike-is-a-black-dot-while-input-is-scattered-during-blanking-periods-figure-1-the-network-output-shows-shows-some-tuned-activity-during-the-blank-compare-with-the-activity-before-visual-stimulation-to-decode-such-patterns-of-activity-we-used-a-maximum-likelihood-estimation-technique-based-on-the-tuning-curve-of-the-neurons&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://www.frontiersin.org/files/Articles/53894/fncom-07-00112-r2/image_m/fncom-07-00112-g003.jpg&#34; alt=&#34;Figure 4: *Rasterplot of input and output spikes.* The raster plot from excitatory neurons is ordered according to their position. Each input spike is a blue dot and each output spike is a black dot. While input is scattered during blanking periods (Figure 1), the network output shows shows some tuned activity during the blank (compare with the activity before visual stimulation). To decode such patterns of activity we used a maximum-likelihood estimation technique based on the tuning curve of the neurons.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 4: &lt;em&gt;Rasterplot of input and output spikes.&lt;/em&gt; The raster plot from excitatory neurons is ordered according to their position. Each input spike is a blue dot and each output spike is a black dot. While input is scattered during blanking periods (Figure 1), the network output shows shows some tuned activity during the blank (compare with the activity before visual stimulation). To decode such patterns of activity we used a maximum-likelihood estimation technique based on the tuning curve of the neurons.
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Active inference, eye movements and oculomotor delays</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-13-cns/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-13-cns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active inference, eye movements and oculomotor delays</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-13-jffos/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-13-jffos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How and why do image frequency properties influence perceived speed?</title>
      <link>https://laurentperrinet.github.io/publication/meso-13-vss/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/meso-13-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-13-vss/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-13-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Motion-based prediction and development of the response to an &#39;on the way&#39; stimulus</title>
      <link>https://laurentperrinet.github.io/publication/khoei-13-cns/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/khoei-13-cns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/perrinet-12-pred.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-12-pred/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on motion extrapolation: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2013).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34;&gt;Motion-based prediction explains the role of tracking in motion extrapolation&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/khoei-13-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-13-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2013.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on the flash-lag effect: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34;&gt;The flash-lag effect as a motion-based predictive shift&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01771125&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-masson-perrinet-17/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/Khoei_2017_PLoSCB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1005068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Active inference, smooth pursuit and oculomotor delays</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-12-areadne/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-12-areadne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect of image statistics on fixational eye movements</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-12-vss/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-12-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-12-coding/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-12-coding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Motion-based prediction is sufficient to solve the aperture problem</title>
      <link>https://laurentperrinet.github.io/publication/masson-12-areadne/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/masson-12-areadne/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Pattern discrimination for moving random textures: Richer stimuli are more difficult to recognize</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-11-vss/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-11-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Role of motion-based prediction in motion extrapolation</title>
      <link>https://laurentperrinet.github.io/publication/khoei-12-sfn/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/khoei-12-sfn/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/perrinet-12-pred.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-12-pred/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on motion extrapolation: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2013).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34;&gt;Motion-based prediction explains the role of tracking in motion extrapolation&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/khoei-13-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-13-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2013.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on the flash-lag effect: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34;&gt;The flash-lag effect as a motion-based predictive shift&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01771125&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-masson-perrinet-17/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/Khoei_2017_PLoSCB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1005068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Pattern discrimination for moving random textures: Richer stimuli are more difficult to recognize</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-11-pattern/</link>
      <pubDate>Fri, 23 Sep 2011 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-11-pattern/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-11-sfn/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-11-sfn/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/james-a-bednar/&#34;&gt;James A Bednar&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2015).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-bednar-15/&#34;&gt;Edge co-occurrences can account for rapid categorization of natural versus animal images&lt;/a&gt;.
  &lt;em&gt;Scientific Reports&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01202447&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;http://www.nature.com/articles/srep11400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-bednar-15/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/PerrinetBednar15&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1038/srep11400&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Role of motion inertia in dynamic motion integration for smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/khoei-11-ecvp/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/khoei-11-ecvp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/perrinet-12-pred.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-12-pred/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on motion extrapolation: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2013).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34;&gt;Motion-based prediction explains the role of tracking in motion extrapolation&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/khoei-13-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-13-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2013.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on the flash-lag effect: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34;&gt;The flash-lag effect as a motion-based predictive shift&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01771125&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-masson-perrinet-17/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/Khoei_2017_PLoSCB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1005068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Diffraction monochromatique, spectre audiographique</title>
      <link>https://laurentperrinet.github.io/event/2010-04-14-ondes-paralleles/</link>
      <pubDate>Wed, 14 Apr 2010 19:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2010-04-14-ondes-paralleles/</guid>
      <description>&lt;h1 id=&#34;diffraction-monochromatique-spectre-audiographique&#34;&gt;Diffraction monochromatique, spectre audiographique&lt;/h1&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;ttp://ondesparalleles.org/wp-content/uploads/2014/02/cloche_fiche_a.jpg&#34; alt=&#34;Diffraction&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diffraction est une sculpture en suspension composée d’une multitude de plaques de matière transparente et réfléchissante. L’installation met en jeu notre perception de l’espace par des phénomènes de résonance et de réflection de la lumière. Chaque lieu d’exposition donne à expérimenter et à élaborer, in situ, de nouvelles formes. A Seconde Nature, Etienne Rey abordera la relation entre le volume et le son en prenant comme base de construction un spectre audio, en collaboration avec l’artiste sonore Mathias Delplanque.&lt;/li&gt;
&lt;li&gt;Live de Mathias Delplanque et rencontre autour de Diffraction, le Mercredi 14 avril 2010: A l’occasion de cette rencontre publique, quatre chercheurs spécialistes de l’architecture, de la perception, du son, et de la lumière exposeront depuis leurs domaines de recherches les processus engagés autour de Diffraction.`&lt;/li&gt;
&lt;li&gt;Farid Ameziane, Ecole Nationale Supérieure d’Architecture de Marseille Luminy (EAML), Directeur de l’InsARTis, Marseille&lt;/li&gt;
&lt;li&gt;Guillaume Bonello, Chargé de mission, POPsud, co/OAMP, Marseille&lt;/li&gt;
&lt;li&gt;Fabrice Mortessagne, Directeur du laboratoire de Physique de la Matière Condensée (LPMC), Nice-Sophia Antipolis&lt;/li&gt;
&lt;li&gt;Laurent Perrinet, Chercheur à l’Institut de Neurosciences Cognitives de Méditerranée, Equipe DyVA, Marseille&lt;/li&gt;
&lt;li&gt;Modératrice : Colette Tron, Fondatrice d’Alphabetville, Marseille&lt;/li&gt;
&lt;li&gt;Entrée libre &amp;amp; gratuite - 19h, durée 2h.&lt;/li&gt;
&lt;li&gt;Renseignements pratiques :&lt;/li&gt;
&lt;li&gt;Espace Sextius investi par Seconde Nature  :&lt;/li&gt;
&lt;li&gt;27bis rue du 11 novembre,&lt;/li&gt;
&lt;li&gt;13100 Aix-en-Provence&lt;/li&gt;
&lt;li&gt;(!) visitez le site de Seconde Nature&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;notes-de-lintervention-de-laurent-perrinet&#34;&gt;notes de l&amp;rsquo;intervention de Laurent Perrinet&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Qu&amp;rsquo;est-ce que voir?&lt;/strong&gt; En perception, les neurones « parlent » tous
en même temps par de brèves impulsions électrochimiques, générant un
mélange de signaux, un bruit. Pourtant c&amp;rsquo;est par eux que nous
pensons, voyons, sentons. Les ordinateurs sont différents, plus
rapides. Ils sont construits avec pour modèle la grammaire humaine
autour d’une unité centrale, car on imaginait la cognition sous cet
angle à leur invention. Le bit est le quantum d’un &lt;strong&gt;algorithme
mécanique&lt;/strong&gt; (thèse de Church-Turing). Une théorie tranche par
rapport à la précédente, proposée par «von Neumann» : beaucoup
d’unités sont présentes dans le cerveau. Comparée à la chaîne
logique du langage, dans cet algorithme, beaucoup d’autres chaînes
et logiques se mêlent. Comment vont-elles « parler » entre elles ?
Existe-t-il des &lt;strong&gt;algorithmes biologiques&lt;/strong&gt; ?
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;OUCHI&#34; srcset=&#34;
               /event/2010-04-14-ondes-paralleles/ouchi_hu23e83ca23d06ab08652e13fad64505cb_81281_c1aed44624f5063f3e677c755350ce6f.jpg 400w,
               /event/2010-04-14-ondes-paralleles/ouchi_hu23e83ca23d06ab08652e13fad64505cb_81281_48cc57093c700134e53f7d57d4a7bcf7.jpg 760w,
               /event/2010-04-14-ondes-paralleles/ouchi_hu23e83ca23d06ab08652e13fad64505cb_81281_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/event/2010-04-14-ondes-paralleles/ouchi_hu23e83ca23d06ab08652e13fad64505cb_81281_c1aed44624f5063f3e677c755350ce6f.jpg&#34;
               width=&#34;405&#34;
               height=&#34;332&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

Définir ce « langage », c&amp;rsquo;est comprendre comment une &lt;strong&gt;somme
d’informations locales&lt;/strong&gt; peut produire une &lt;strong&gt;perception globale&lt;/strong&gt;.
Comment en jouant avec les atomes du code, en les superposant, les «
cassant » pour les mettre en résonance, les neurosciences et l&amp;rsquo;artiste
questionnent le langage de notre pensée ? Quel est le code utilisé par
les neurones pour communiquer (code neuronal ? existe-t-il un même
&lt;strong&gt;vocabulaire&lt;/strong&gt; au sens homomorphique ?). En pratique, on apprend par
exemple la sélectivité à l&amp;rsquo;orientation. Les phénomènes d’orientation
sont radicaux à la fin de l’expérience, « gelant » son évolution. Un
lien évident avec l’installation &lt;em&gt;Phytosphère&lt;/em&gt; d’Etienne Rey.
L’information dans le cerveau se propage &lt;strong&gt;par diffusion, par
diffraction&lt;/strong&gt; (contamination des informations entre neurones pour
occuper l’espace), en &lt;strong&gt;lien avec le travail sur la lumière d’Etienne
Rey.&lt;/strong&gt; L&amp;rsquo;image a besoin de 30 millisecondes pour se diffuser de l’œil
vers l’arrière du crâne et 85 millisecondes pour produire un réflexe
oculaire. Les neurosciences cherchent à savoir comment comprendre la
&lt;strong&gt;globalité par l&amp;rsquo;émergence&lt;/strong&gt;.
Il y a donc une &lt;strong&gt;superposition d’états&lt;/strong&gt;, comme dans la &lt;em&gt;diffraction&lt;/em&gt;
d’Etienne Rey.
En perception, le mécanisme
neuronal cherche à &lt;strong&gt;sortir de l’ambiguïté&lt;/strong&gt; première quand il connaît
une image : il &lt;strong&gt;superpose&lt;/strong&gt; des particules élémentaires d&amp;rsquo;information,
les diffuse pour les prendre toutes. Ce qui émerge est non linéaire. Le
cerveau interfère ces particules, donc les met en compétition, en
coopération (voir expérience plus haut avec les neurones rouges et
bleus), dans une dynamique où ces particules se réorientent elles-mêmes.
Elles créent des phénomènes d’organisation, se collent, deviennent plus
lumineuses. &lt;strong&gt;La perception n’est donc pas séquentielle mais fluide&lt;/strong&gt; et
la sortie de l&amp;rsquo;ambiguité depuis l&amp;rsquo;image pixel vient de l&amp;rsquo;introduction de
ces contraintes. Ainsi quand nous voyons un objet, nous le « capturons
». Quand nous sommes vus, nous cherchons à nous séparer de cette
capture.
Un problème classique est l&amp;rsquo;ambiguité du monde sensible. Une couleur que
l’on ne voit pas va apparaître visuellement. &lt;strong&gt;L’inpainting&lt;/strong&gt; créé une
œuvre qui correspond à un mécanisme neuronal, cherchant à reproduire
toujours une même structure. La mémoire iconique du monde extérieur va
imprégner le cerveau, s’y figer. Tout le problème de la perception pour
les neurosciences repose sur deux dialectiques. La première présente une
analogie avec les images informatiques par pixels : ce serait en
neurosciences une métaphore de la sensation pure. La seconde rappelle
l’image vectorisée : pour s’extraire de la sensation pure, le cerveau
retiendra des règles proches des algorithmes. En cognition, il permet de
mettre en lumière le symptome d**&amp;lsquo;autisme**. Dans un schéma montrant un
bloc derrière un arbre, dépassant des deux côtés, sera découpé
visuellement par l’autiste en plusieurs morceaux distincts. Il ne
généralise pas l’information.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;diffractionFriche_0134.jpg&#34; srcset=&#34;
               /event/2010-04-14-ondes-paralleles/featured_huf8e22210a5b712d30ed9259f43294b7e_139525_d6b35fab08f9a9ef418cac7666cfc25b.jpg 400w,
               /event/2010-04-14-ondes-paralleles/featured_huf8e22210a5b712d30ed9259f43294b7e_139525_2c5b007887e57a911a4487ec8540b3cb.jpg 760w,
               /event/2010-04-14-ondes-paralleles/featured_huf8e22210a5b712d30ed9259f43294b7e_139525_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://laurentperrinet.github.io/event/2010-04-14-ondes-paralleles/featured_huf8e22210a5b712d30ed9259f43294b7e_139525_d6b35fab08f9a9ef418cac7666cfc25b.jpg&#34;
               width=&#34;760&#34;
               height=&#34;505&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

Comment être sûr d’une perception globale
en désignant les modules de l’installation d’Etienne Rey, ou signifiants
des atomes, dans ce passage du local au global ? Les modules ne se
voient pas forcément dans l’installation, mais d’autres aspects sont
perçus. La relation à l’atome, même si elle n’est pas signifiante pour
le public, n’est pas primordiale. Le public voit une accumulation de «
choses », car par principe quand un phénomène est concentré « il se
passe des choses » par jeu de contraste. Le fait de bouger face à
l’installation rend unique à l&amp;rsquo;individu la perception et réalise la
globalité de l’œuvre: on a alors passage de l’atome à la forme globale.
Cette résolution rejoint Giotto et les débuts de la perspective en art
pictural. Il a révélé la question du point de vue, par positionnement et
déplacement. En effet, les personnes penchent la tête dans
l’installation s*pirale* en container, d’Etienne Rey, pour le festival
Ozosphère à Strasbourg. Ce phénomène est à rattaché aux théories sur la
perception.
**Biographie** Laurent Perrinet, chercheur à l’Institut de Neurosciences
Cognitives de la Méditerranée à Marseille, unité mixte du CNRS, aime
citer « La vie de Brian » des Monty Python : (Brian:) &amp;ldquo;You have to work
it out for yourselves!&amp;rdquo; (Crowd:) &amp;ldquo;Yes, we have to work it out for
ourselves&amp;hellip; (silence) Tell us more!&amp;rdquo;. L’individualité et la perception
du monde… Dans l’équipe DyVA (pour Dynamique de la perception visuelle
et de l&amp;rsquo;action), Laurent Perrinet s&amp;rsquo;intéresse aux neurones impulsionnels
et au codage neuronal, ainsi qu’à la perception des mouvements
spatio-temporels. Ces processus définis comme des algorithmes, la
représentation du flux vidéo modélise via l’informatique ces
interactions au niveau cellulaire (colonnes corticales) et au niveau
cognitif (aires corticales). Il cherche à comprendre le fonctionnement
des calculs corticaux dans le système visuel. Cette recherche fournit
des réponses aux problèmes cognitifs. Après un diplôme d&amp;rsquo;ingénieur de
traitement du signal et de modélisation stochastique de l&amp;rsquo;école
d’aéronautique Supaéro à Toulouse et des études à San Diego et à
Pasadena (Californie) pour la Nasa, Laurent Perrinet obtient un doctorat
de Sciences Cognitives. Répondant aux questions « Peut-on parler
d’intelligence mécanique ? », « Pourquoi une grenouille gobe mieux une
mouche qu’un robot ? » ou « Quelle est la différence entre intelligence
et algorithme ? », il intervient en 2009 au colloque marseillais « Les
chemins de l’intelligence ». Parmi ses publications : *Role of
homeostasis in learning sparse representations*, et sa thèse *Comment
déchiffrer le code impulsionnel de la vision ? Étude du flux parallèle,
asynchrone et épars dans le traitement visuel ultra-rapide*&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A recurrent Bayesian model of dynamic motion integration for smooth pursuit</title>
      <link>https://laurentperrinet.github.io/publication/bogadhi-10-vss/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/bogadhi-10-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Different pooling of motion information for perceptual speed discrimination and behavioral speed estimation</title>
      <link>https://laurentperrinet.github.io/publication/simoncini-10-vss/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/simoncini-10-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamical emergence of a neural solution for motion integration</title>
      <link>https://laurentperrinet.github.io/publication/khoei-10-tauc/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/khoei-10-tauc/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Motion-based prediction is sufficient to solve the aperture problem&lt;/a&gt;.
  &lt;em&gt;Neural Computation&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/perrinet-12-pred.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/perrinet-12-pred/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on motion extrapolation: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2013).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/&#34;&gt;Motion-based prediction explains the role of tracking in motion extrapolation&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-13-jpp/khoei-13-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-13-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2013.08.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up on the flash-lag effect: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/mina-a-khoei/&#34;&gt;Mina A Khoei&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/guillaume-s-masson/&#34;&gt;Guillaume S Masson&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34;&gt;The flash-lag effect as a motion-based predictive shift&lt;/a&gt;.
  &lt;em&gt;PLoS Computational Biology&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-01771125&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/khoei-masson-perrinet-17/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/khoei-masson-perrinet-17/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/laurentperrinet/Khoei_2017_PLoSCB&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1371/journal.pcbi.1005068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamical emergence of a neural solution for motion integration</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-10-areadne/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-10-areadne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Phase space analysis of networks based on biologically realistic parameters</title>
      <link>https://laurentperrinet.github.io/publication/voges-10-neurocomp/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/voges-10-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/&#34;&gt;Phase space analysis of networks based on biologically realistic parameters&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/voges-10-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-10-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2009.11.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-12/&#34;&gt;Complex dynamics in recurrent cortical networks based on spatially realistic connectivities&lt;/a&gt;.
  &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-12/voges-12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-12/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Probabilistic models of the low-level visual system: the role of prediction in detecting motion</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-10-tauc/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-10-tauc/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Peut-on parler d&#39;intelligence mécanique?</title>
      <link>https://laurentperrinet.github.io/event/2009-11-24-intelligence-mecanique/</link>
      <pubDate>Tue, 24 Nov 2009 18:30:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/event/2009-11-24-intelligence-mecanique/</guid>
      <description>&lt;p&gt;Nous parlerons de cette partie &amp;ldquo;mécanique&amp;rdquo; du cerveau animal ou humain qui permet de percevoir les mouvements et de &amp;hellip; survivre au sein de l&amp;rsquo;environnement. On verra, par exemple, que notre cerveau peut-être &lt;a href=&#34;http://interstices.info/classificateur&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;plus rapide que nous&lt;/a&gt;, qu&amp;rsquo;il y a des solutions &amp;ldquo;stupides&amp;rdquo; qui marchent remarquablement bien pour &lt;a href=&#34;http://interstices.info/generation-trajectoires&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sortir d&amp;rsquo;un labyrinthe&lt;/a&gt;, et qui si la grenouille sait &lt;a href=&#34;http://interstices.info/grenouille&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gober une mouche bien mieux qu&amp;rsquo;un robot&lt;/a&gt; &amp;hellip; elle n&amp;rsquo;est pas plus maligne ! Parce que ce qu&amp;rsquo;il ne faut pas confondre ici c&amp;rsquo;est &lt;a href=&#34;https://interstices.info/calculer-penser/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;la différence entre calculer et penser&lt;/a&gt;, entre &lt;a href=&#34;http://interstices.info/algo-mode-emploi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;intelligence et algorithmes&lt;/a&gt;. En comprenant cela, avec &lt;a href=&#34;http://fr.wikipedia.org/wiki/Alan_Turing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alan Mathison Turing&lt;/a&gt;, le Gutenberg du XXème siècle, l&amp;rsquo;humanité a basculé des temps modernes à l&amp;rsquo;ère du numérique.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(!) visitez le &lt;a href=&#34;https://interstices.info/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;site d&amp;rsquo;interstices&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Decoding center-surround interactions in population of neurons for the ocular following response</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-09-cosyne/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-09-cosyne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamical state spaces of cortical networks representing various horizontal connectivities</title>
      <link>https://laurentperrinet.github.io/publication/voges-09-cosyne/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/voges-09-cosyne/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/&#34;&gt;Phase space analysis of networks based on biologically realistic parameters&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/voges-10-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-10-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2009.11.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-12/&#34;&gt;Complex dynamics in recurrent cortical networks based on spatially realistic connectivities&lt;/a&gt;.
  &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-12/voges-12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-12/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamics of cortical networks including long-range patchy connections</title>
      <link>https://laurentperrinet.github.io/publication/voges-09-gns/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/voges-09-gns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/&#34;&gt;Phase space analysis of networks based on biologically realistic parameters&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/voges-10-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-10-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2009.11.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-12/&#34;&gt;Complex dynamics in recurrent cortical networks based on spatially realistic connectivities&lt;/a&gt;.
  &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-12/voges-12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-12/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Functional consequences of correlated excitation and inhibition on single neuron integration and signal propagation through synfire chains</title>
      <link>https://laurentperrinet.github.io/publication/kremkow-09-gns/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/kremkow-09-gns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see this subsequent paper in the &lt;a href=&#34;https://laurentperrinet.github.io/publication/kremkow-10-jcns/&#34;&gt;Journal of Computational Neuroscience&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Inferring monkey ocular following responses from V1 population dynamics using a probabilistic model of motion integration</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-09-vss/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-09-vss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NeuralEnsemble: Towards a meta-environment for network modeling and data analysis</title>
      <link>https://laurentperrinet.github.io/publication/yger-09-gns/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/yger-09-gns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/andrew-p-davison/&#34;&gt;Andrew P Davison&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/daniel-bruderle/&#34;&gt;Daniel Bruderle&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/jochen-eppler/&#34;&gt;Jochen Eppler&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/jens-kremkow/&#34;&gt;Jens Kremkow&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/eilif-muller/&#34;&gt;Eilif Muller&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/dejan-pecevski/&#34;&gt;Dejan Pecevski&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/pierre-yger/&#34;&gt;Pierre Yger&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2008).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/davison-08/&#34;&gt;PyNN: A Common Interface for Neuronal Network Simulators&lt;/a&gt;.
  &lt;em&gt;Frontiers in Neuroinformatics&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-00586786&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/davison-08/davison-08.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/davison-08/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;





  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/project/open-science/&#34;&gt;
    Project
  &lt;/a&gt;
  









&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/neuro.11.011.2008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing cortical network dynamics with respect to different connectivity assumptions</title>
      <link>https://laurentperrinet.github.io/publication/voges-08-neurocomp/</link>
      <pubDate>Wed, 22 Oct 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/voges-08-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/&#34;&gt;Phase space analysis of networks based on biologically realistic parameters&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/voges-10-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-10-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2009.11.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-12/&#34;&gt;Complex dynamics in recurrent cortical networks based on spatially realistic connectivities&lt;/a&gt;.
  &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-12/voges-12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-12/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Functional properties of feed-forward inhibition</title>
      <link>https://laurentperrinet.github.io/publication/kremkow-08-neurocomp/</link>
      <pubDate>Wed, 22 Oct 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/kremkow-08-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see this subsequent paper in the &lt;a href=&#34;https://laurentperrinet.github.io/publication/kremkow-10-jcns/&#34;&gt;Journal of Computational Neuroscience&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive Sparse Spike Coding : applications of Neuroscience to the compression of natural images</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-08-spie/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-08-spie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Control of the temporal interplay between excitation and inhibition by the statistics of visual input: a V1 network modelling study</title>
      <link>https://laurentperrinet.github.io/publication/kremkow-08-sfn/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/kremkow-08-sfn/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see this subsequent paper in the &lt;a href=&#34;https://laurentperrinet.github.io/publication/kremkow-10-jcns/&#34;&gt;Journal of Computational Neuroscience&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Decoding the population dynamics underlying ocular following response using a probabilistic framework</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-08-areadne/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-08-areadne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamics of cortical networks based on patchy connectivity patterns</title>
      <link>https://laurentperrinet.github.io/publication/voges-08/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/voges-08/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Based on 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/&#34;&gt;Phase space analysis of networks based on biologically realistic parameters&lt;/a&gt;.
  &lt;em&gt;Journal of Physiology-Paris&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-10-jpp/voges-10-jpp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-10-jpp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jphysparis.2009.11.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;li&gt;see  follow-up : 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/nicole-voges/&#34;&gt;Nicole Voges&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2012).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/voges-12/&#34;&gt;Complex dynamics in recurrent cortical networks based on spatially realistic connectivities&lt;/a&gt;.
  &lt;em&gt;Frontiers in Computational Neuroscience&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/voges-12/voges-12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/voges-12/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/fncom.2012.00041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modeling spatial integration in the ocular following response to center-surround stimulation using a probabilistic framework</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-08-a/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-08-a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What adaptive code for efficient spiking representations? A model for the formation of receptive fields of simple cells</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-08/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-08/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;perrinet-08.png&#34; alt=&#34;header&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Synchrony in thalamic inputs enhances propagation of activity through cortical layers</title>
      <link>https://laurentperrinet.github.io/publication/kremkow-07-cns/</link>
      <pubDate>Fri, 06 Jul 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/kremkow-07-cns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see this subsequent paper in the &lt;a href=&#34;https://laurentperrinet.github.io/publication/kremkow-10-jcns/&#34;&gt;Journal of Computational Neuroscience&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic inference for motion tracking</title>
      <link>https://laurentperrinet.github.io/publication/montagnini-07-a/</link>
      <pubDate>Mon, 01 Jan 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/montagnini-07-a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neural Codes for Adaptive Sparse Representations of Natural Images</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-07-mipm/</link>
      <pubDate>Mon, 01 Jan 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-07-mipm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On efficient sparse spike coding schemes for learning natural scenes in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-07-cns/</link>
      <pubDate>Mon, 01 Jan 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-07-cns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PyNN: towards a universal neural simulator API in Python</title>
      <link>https://laurentperrinet.github.io/publication/davison-07-cns/</link>
      <pubDate>Mon, 01 Jan 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/davison-07-cns/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;see a follow-up: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/andrew-p-davison/&#34;&gt;Andrew P Davison&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/daniel-bruderle/&#34;&gt;Daniel Bruderle&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/jochen-eppler/&#34;&gt;Jochen Eppler&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/jens-kremkow/&#34;&gt;Jens Kremkow&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/eilif-muller/&#34;&gt;Eilif Muller&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/dejan-pecevski/&#34;&gt;Dejan Pecevski&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/pierre-yger/&#34;&gt;Pierre Yger&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2008).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/davison-08/&#34;&gt;PyNN: A Common Interface for Neuronal Network Simulators&lt;/a&gt;.
  &lt;em&gt;Frontiers in Neuroinformatics&lt;/em&gt;.
  
  &lt;p&gt;





  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hal-amu.archives-ouvertes.fr/hal-00586786&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Preprint
&lt;/a&gt;




  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/davison-08/davison-08.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/davison-08/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;





  
  &lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/project/open-science/&#34;&gt;
    Project
  &lt;/a&gt;
  









&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.3389/neuro.11.011.2008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  

&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Visual tracking of ambiguous moving objects: A recursive Bayesian model</title>
      <link>https://laurentperrinet.github.io/publication/montagnini-07-b/</link>
      <pubDate>Mon, 01 Jan 2007 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/montagnini-07-b/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An efficiency razor for model selection and adaptation in the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-06-cns/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-06-cns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian modeling of dynamic motion integration</title>
      <link>https://laurentperrinet.github.io/publication/montagnini-06-neurocomp/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/montagnini-06-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contrast sensitivity adaptation in a virtual spiking retina and its adequation with mammalians retinas</title>
      <link>https://laurentperrinet.github.io/publication/wohrer-06/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/wohrer-06/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamical contrast gain control mechanisms in a layer 2/3 model of the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-06-ciotat/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-06-ciotat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamical contrast gain control mechanisms in a layer 2/3 model of the primary visual cortex</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-06-fab/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-06-fab/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-06-fens/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-06-fens/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;See a followup in &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-12-pred/&#34;&gt;Perrinet et al, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modeling of simple cells through a sparse overcomplete gabor wavelet representation based on local inhibition and facilitation</title>
      <link>https://laurentperrinet.github.io/publication/redondo-05/</link>
      <pubDate>Mon, 22 Aug 2005 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/redondo-05/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;relies on log-Gabor filters: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/sylvain-fischer/&#34;&gt;Sylvain Fischer&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/filip-sroubek/&#34;&gt;Filip Šroubek&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/rafael-redondo/&#34;&gt;Rafael Redondo&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/gabriel-cristobal/&#34;&gt;Gabriel Cristóbal&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2007).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/fischer-07-cv/&#34;&gt;Self-Invertible 2D Log-Gabor Wavelets&lt;/a&gt;.
  &lt;em&gt;International Journal of Computer Vision&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/fischer-07-cv/fischer-07-cv.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/fischer-07-cv/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/bicv/LogGabor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1007/s11263-006-0026-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  
















&lt;figure  id=&#34;figure-schematic-structure-of-the-primary-visual-cortex-implemented-in-the-present-study-simple-cortical-cells-are-modeled-through-log-gabor-functions-they-are-organized-in-pairs-in-quadrature-of-phase-dark-gray-circles-for-each-position-the-set-of-different-orientations-compose-a-pinwheel-large-light-gray-circles-the-retinotopic-organization-induces-that-adjacent-spatial-positions-are-arranged-in-adjacent-pinwheels-inhibition-interactions-occur-towards-the-closest-adjacent-positions-which-are-in-the-direc-tions-perpendicular-to-the-cell-preferred-orientation-and-toward-adjacent-orientations-light-red-connections-facilitation-occurs-to-wards-co-aligned-cells-up-to-a-larger-distance-dark-blue-connections&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://laurentperrinet.github.io/publication/fischer-07/figure2.png&#34; alt=&#34;Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections). &#34; loading=&#34;lazy&#34; data-zoomable width=&#34;80%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections).
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Sparse Gabor wavelets by local operations</title>
      <link>https://laurentperrinet.github.io/publication/fischer-05-a/</link>
      <pubDate>Wed, 29 Jun 2005 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/fischer-05-a/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;relies on log-Gabor filters: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/sylvain-fischer/&#34;&gt;Sylvain Fischer&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/filip-sroubek/&#34;&gt;Filip Šroubek&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/rafael-redondo/&#34;&gt;Rafael Redondo&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/gabriel-cristobal/&#34;&gt;Gabriel Cristóbal&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2007).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/fischer-07-cv/&#34;&gt;Self-Invertible 2D Log-Gabor Wavelets&lt;/a&gt;.
  &lt;em&gt;International Journal of Computer Vision&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/fischer-07-cv/fischer-07-cv.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/fischer-07-cv/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/bicv/LogGabor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1007/s11263-006-0026-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  
















&lt;figure  id=&#34;figure-schematic-structure-of-the-primary-visual-cortex-implemented-in-the-present-study-simple-cortical-cells-are-modeled-through-log-gabor-functions-they-are-organized-in-pairs-in-quadrature-of-phase-dark-gray-circles-for-each-position-the-set-of-different-orientations-compose-a-pinwheel-large-light-gray-circles-the-retinotopic-organization-induces-that-adjacent-spatial-positions-are-arranged-in-adjacent-pinwheels-inhibition-interactions-occur-towards-the-closest-adjacent-positions-which-are-in-the-direc-tions-perpendicular-to-the-cell-preferred-orientation-and-toward-adjacent-orientations-light-red-connections-facilitation-occurs-to-wards-co-aligned-cells-up-to-a-larger-distance-dark-blue-connections&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://laurentperrinet.github.io/publication/fischer-07/figure2.png&#34; alt=&#34;Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections). &#34; loading=&#34;lazy&#34; data-zoomable width=&#34;80%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections).
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamics of motion representation in short-latency ocular following: A two-pathways Bayesian model</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-05-a/</link>
      <pubDate>Sat, 01 Jan 2005 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-05-a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient representation of natural images using local cooperation</title>
      <link>https://laurentperrinet.github.io/publication/fischer-05/</link>
      <pubDate>Sat, 01 Jan 2005 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/fischer-05/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;relies on log-Gabor filters: 






  
    

&lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/sylvain-fischer/&#34;&gt;Sylvain Fischer&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/filip-sroubek/&#34;&gt;Filip Šroubek&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent U Perrinet&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/rafael-redondo/&#34;&gt;Rafael Redondo&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://laurentperrinet.github.io/authors/gabriel-cristobal/&#34;&gt;Gabriel Cristóbal&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2007).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/fischer-07-cv/&#34;&gt;Self-Invertible 2D Log-Gabor Wavelets&lt;/a&gt;.
  &lt;em&gt;International Journal of Computer Vision&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/fischer-07-cv/fischer-07-cv.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/fischer-07-cv/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;


  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://github.com/bicv/LogGabor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Code
&lt;/a&gt;












&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1007/s11263-006-0026-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;

  
















&lt;figure  id=&#34;figure-schematic-structure-of-the-primary-visual-cortex-implemented-in-the-present-study-simple-cortical-cells-are-modeled-through-log-gabor-functions-they-are-organized-in-pairs-in-quadrature-of-phase-dark-gray-circles-for-each-position-the-set-of-different-orientations-compose-a-pinwheel-large-light-gray-circles-the-retinotopic-organization-induces-that-adjacent-spatial-positions-are-arranged-in-adjacent-pinwheels-inhibition-interactions-occur-towards-the-closest-adjacent-positions-which-are-in-the-direc-tions-perpendicular-to-the-cell-preferred-orientation-and-toward-adjacent-orientations-light-red-connections-facilitation-occurs-to-wards-co-aligned-cells-up-to-a-larger-distance-dark-blue-connections&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://laurentperrinet.github.io/publication/fischer-07/figure2.png&#34; alt=&#34;Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections). &#34; loading=&#34;lazy&#34; data-zoomable width=&#34;80%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Schematic structure of the primary visual cortex implemented in the present study. Simple cortical cells are modeled through log-Gabor functions. They are organized in pairs in quadrature of phase (dark-gray circles). For each position the set of different orientations compose a pinwheel (large light-gray circles). The retinotopic organization induces that adjacent spatial positions are arranged in adjacent pinwheels. Inhibition interactions occur towards the closest adjacent positions which are in the direc-tions perpendicular to the cell preferred orientation and toward adjacent orientations (light-red connections). Facilitation occurs to-wards co-aligned cells up to a larger distance (dark-blue connections).
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Efficient Source Detection Using Integrate-and-Fire Neurons</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-05/</link>
      <pubDate>Sat, 01 Jan 2005 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-05/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sparse Image Coding Using an Asynchronous Spiking Neural Network</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-02-esann/</link>
      <pubDate>Tue, 01 Jan 2002 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-02-esann/</guid>
      <description>













&lt;figure  id=&#34;figure-progressive-reconstruction-of-a-static-image-using-spikes-in-a-laplacian-pyramid&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;*Progressive reconstruction of a static image using spikes in a Laplacian pyramid.*&#34;
           src=&#34;https://laurentperrinet.github.io/publication/perrinet-02-esann/lena256pyr.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;em&gt;Progressive reconstruction of a static image using spikes in a Laplacian pyramid.&lt;/em&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Visual Strategies for Sparse Spike Coding</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-02-nsi/</link>
      <pubDate>Tue, 01 Jan 2002 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-02-nsi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A generative model for Spike Time Dependent Hebbian Plasticity</title>
      <link>https://laurentperrinet.github.io/publication/perrinet-00/</link>
      <pubDate>Sat, 01 Jan 2000 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/perrinet-00/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
