<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>article-journal | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/publication-type/article-journal/</link>
      <atom:link href="https://laurentperrinet.github.io/publication-type/article-journal/index.xml" rel="self" type="application/rss+xml" />
    <description>article-journal</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Mon, 01 Jan 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_512x512_fill_lanczos_center_3.png</url>
      <title>article-journal</title>
      <link>https://laurentperrinet.github.io/publication-type/article-journal/</link>
    </image>
    
    <item>
      <title>Kernel Heterogeneity Improves Sparseness of Natural Images Representations</title>
      <link>https://laurentperrinet.github.io/publication/ladret-24-sparse/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://laurentperrinet.github.io/publication/ladret-24-sparse/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This work is a followup of 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Hugo Ladret&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2023).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-23-iclr/&#34;&gt;Convolutional Sparse Coding is improved by heterogeneous uncertainty modeling&lt;/a&gt;.
  &lt;em&gt;ICLR 2023 SNN Workshop&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/ladret-23-iclr/ladret-23-iclr.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-23-iclr/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In a nutshell: We found that sparse coding of images (here extended in a convolutional framework) is improved when using kernels with heterogeneous precision in how they encode orientation information. This was confirmed by learning, but also by comparison with what is observed in the statistics of natural images and in our recordings from neurons in primary visual cortex.


















&lt;figure  id=&#34;figure-epistemic-uncertainty-in-a-csc-dictionary-improves-both-sparseness-and-reconstruction-performance-a-elements-from-dictionaries-with-fixed-epistemic-uncertainty-before-green-and-after-dictionary-learning-orange-b-elements-from-a-dictionary-with-heterogeneous-epistemic-uncertainty-before-blue-and-after-dictionary-learning-purple-c-elements-from-a-dictionary-learned-from-scratch-d-distribution-of-the-sparseness-top-and-peak-signal-to-noise-ratio-psnr-right-of-the-five-dictionaries-shown-as-a-scatter-plot-for-each-of-the-600-images-of-the-dataset-center-median-values-are-shown-as-dashed-line-on-the-histograms&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;fig_dicos.png&#34; alt=&#34;Epistemic uncertainty in a CSC dictionary improves both sparseness and reconstruction performance. **(a)** Elements from dictionaries with fixed epistemic uncertainty before (green) and after dictionary learning (orange). **(b)** Elements from a dictionary with heterogeneous epistemic uncertainty before (blue) and after dictionary learning (purple). **(c)** Elements from a dictionary learned from scratch. **(d)** Distribution of the sparseness (top) and Peak Signal-to-Noise Ratio (PSNR, right) of the five dictionaries, shown as a scatter plot for each of the 600 images of the dataset (center). Median values are shown as dashed line on the histograms.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption data-pre=&#34;Figure&amp;nbsp;&#34; data-post=&#34;:&amp;nbsp;&#34; class=&#34;numbered&#34;&gt;
      Epistemic uncertainty in a CSC dictionary improves both sparseness and reconstruction performance. &lt;strong&gt;(a)&lt;/strong&gt; Elements from dictionaries with fixed epistemic uncertainty before (green) and after dictionary learning (orange). &lt;strong&gt;(b)&lt;/strong&gt; Elements from a dictionary with heterogeneous epistemic uncertainty before (blue) and after dictionary learning (purple). &lt;strong&gt;(c)&lt;/strong&gt; Elements from a dictionary learned from scratch. &lt;strong&gt;(d)&lt;/strong&gt; Distribution of the sparseness (top) and Peak Signal-to-Noise Ratio (PSNR, right) of the five dictionaries, shown as a scatter plot for each of the 600 images of the dataset (center). Median values are shown as dashed line on the histograms.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This theoretical work accompanies a similar study in neurophysiology: 











  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      Hugo Ladret&lt;/span&gt;, &lt;span &gt;
      Nelson Cortes&lt;/span&gt;, &lt;span &gt;
      Lamyae Ikan&lt;/span&gt;, &lt;span &gt;
      Frederic Chavane&lt;/span&gt;, &lt;span &gt;
      Christian Casanova&lt;/span&gt;, &lt;span &gt;
      Laurent U Perrinet&lt;/span&gt;
  &lt;/span&gt;
  (2023).
  &lt;a href=&#34;https://laurentperrinet.github.io/publication/ladret-23/&#34;&gt;Cortical recurrence supports resilience to sensory variance in the primary visual cortex&lt;/a&gt;.
  &lt;em&gt;Nature Communications Biology&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://laurentperrinet.github.io/publication/ladret-23/ladret-23.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/ladret-23/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1038/s42003-023-05042-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;


&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
