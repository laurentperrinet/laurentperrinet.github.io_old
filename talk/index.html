<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Laurent U Perrinet" />

  
  
  
    
  
  <meta name="description" content="Researcher in Computational Neuroscience" />

  
  <link rel="alternate" hreflang="en-us" href="https://laurentperrinet.github.io/talk/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.e99c138d2f23efd05bc7edb273d8d0b4.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-140381649-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-140381649-1', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  
    <link rel="alternate" href="/talk/index.xml" type="application/rss+xml" title="Novel visual computations" />
  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_32x32_fill_lanczos_center_2.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_180x180_fill_lanczos_center_2.png" />

  <link rel="canonical" href="https://laurentperrinet.github.io/talk/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
    <meta property="twitter:site" content="@laurentperrinet" />
    <meta property="twitter:creator" content="@laurentperrinet" />
  
  <meta property="og:site_name" content="Novel visual computations" />
  <meta property="og:url" content="https://laurentperrinet.github.io/talk/" />
  <meta property="og:title" content="Recent &amp; Upcoming Talks | Novel visual computations" />
  <meta property="og:description" content="Researcher in Computational Neuroscience" /><meta property="og:image" content="https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_512x512_fill_lanczos_center_2.png" />
    <meta property="twitter:image" content="https://laurentperrinet.github.io/media/icon_hu064773317e508d3c994dd612a46c4bf9_247868_512x512_fill_lanczos_center_2.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="og:updated_time" content="2021-06-15T11:15:00&#43;00:00" />
    
  

  



  

  





  <title>Recent &amp; Upcoming Talks | Novel visual computations</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="940e4d81a086f8048aeb251400fbfb10" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.f16be01fc8fb2b5885dd67ce942d1185.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Novel visual computations</a>
    </div>
    

    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Novel visual computations</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    












  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>Recent &amp; Upcoming Talks</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
    
    
    
    <div>
      <h2><a href="/talk/2021-06-15-smb/" >Pooling in a predictive model of V1 explains functional and structural diversity across species</a></h2>
      <div class="article-style">
        
          Presenting my poster tonight at 8:00p #cosyne2020, a work developed using Sparse Deep Predictive Coding (SDPC) during my PhD @laurentperrinet @NeuroSchool_mrs pic.twitter.com/LtUEBnlPNt
&mdash; Angelo Franciosini (@Angelo_RDN) February 28, 2020  This is from:
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2020-09-25-irphe/" >Understanding natural vision using deep predictive coding</a></h2>
      <div class="article-style">
        
          Building models which efficiently process images is a great source of inspiration to better understand the processes which underly our visual perception. I will present some classical models stemming from the Machine Learning community and propose …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2020-09-14-iwai/" >Visual search as active inference</a></h2>
      <div class="article-style">
        
          Visual search is an essential cognitive ability, offering a prototypical control problem to be addressed with Active Inference. Under a Naive Bayes assumption, the maximization of the information gain objective is consistent with the separation of …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2020-04-ue-neurosciences-computationnelles/" >From the retina to action: Understanding visual processing</a></h2>
      <div class="article-style">
        
          Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2020-01-20-atelier-sciences-cinema/" >Des illusions aux hallucinations visuelles: une porte sur la perception</a></h2>
      <div class="article-style">
        
          Les illusions visuelles sont des créations d'artistes, de scientifiques et plus récemment, grâce aux réseaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-07-15-cns/" >Learning where to look: a foveated visuomotor control model</a></h2>
      <div class="article-style">
        
          In computer vision, the visual search task consists in extracting a scarce and specific visual information (the target) from a large and crowded visual display. This task is usually implemented by scanning the different possible target identities at …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-05-23-neurofrance/" >Should I stay or should I go? Humans adapt to the volatility of visual motion properties, and know about it</a></h2>
      <div class="article-style">
        
          Animal behavior must constantly adapt to changes, for example when the state of an environmental context changes unexpectedly. For an agent that interacts with this volatile setting, it is important to react accurately and as quickly as possible. For …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-04-18-jnlf/" >Des illusions aux hallucinations visuelles: une porte sur la perception</a></h2>
      <div class="article-style">
        
          Les objectifs sont : -- mieux comprendre la fonction de la perception visuelle en explorant certaines limites ; -- mieux comprendre l'importance de l'aspect dynamique de la perception ; -- mieux comprendre le rôle de l'action dans la perception.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-04-05-bbcp-causal-kickoff/" >Should I stay or should I go? Adaption of human observers to the volatility of visual inputs</a></h2>
      <div class="article-style">
        
          Animal behavior has to constantly adapt to changes, for instance when unexpectedly switching the state of an environmental context. For an agent interacting with this kind of volatile environment, it is important to respond to such switches …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-04-03-a-course-on-vision-and-modelization/" >From the retina to action: Understanding visual processing</a></h2>
      <div class="article-style">
        
          Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-03-25-hdr-robin-baures/" >From the retina to action: Predictive processing in the visual system</a></h2>
      <div class="article-style">
        
          Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-01-18-laconeu/" >Should I stay or should I go? Adaption of human observers to the volatility of visual inputs</a></h2>
      <div class="article-style">
        
          See the final publication @  Chloé Pasturel, Anna Montagnini, Laurent U Perrinet  (2020). Humans adapt their anticipatory eye movements to the volatility of visual motion properties. PLoS Computational Biology.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-01-17-laconeu/" >Role of dynamics in neural computations underlying visual processing</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-01-16-laconeu/" >Efficient coding of visual information in neural computations</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-01-14-laconeu/" >Modelling spiking neural networks using Brian, Nest and pyNN</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2019-01-10-polly-maggoo/" >Rencontre avec les collégiens marseillais</a></h2>
      <div class="article-style">
        
          Le jeudi 10 janvier 2019, je suis venu échanger au côté de Serge Dentin autour de films traitant du rapport fiction/réel, des illusion visuelles (\" Qu'est ce qu'une image? \"), des rapports d'échelles, de la perception, ... et qui sont projetés lors …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2018-10-11-bio-morphisme/" >La modélisation biomorphique de la perception visuelle</a></h2>
      <div class="article-style">
        
          La modélisation biomorphique de la perception visuelle in &ldquo;La modélisation de la genèse physico-mathématique du vivant&rdquo; BIOMORPHISME ET CREATION ARTISTIQUE – Session 3  Date
11 Octobre 2018 Atelier
Séminaire/workshop organisé dans le cadre du projet Biomorphisme.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2018-10-10-polly-maggoo/" >Intervention fête de la science 2018</a></h2>
      <div class="article-style">
        
          FÊTE DE LA SCIENCE 2018 : Alcazar / MERLAN L&rsquo;Association Polly Maggoo http://www.pollymaggoo.org/ met en place tout le long de l’année, des actions de culture scientifique et artistique en direction du grand public et des lycées, au cours desquelles l&rsquo;association programme des films à caractère scientifique.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2018-04-05-bcp-talk/" >Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias</a></h2>
      <div class="article-style">
        
          See the final publication @  Chloé Pasturel, Anna Montagnini, Laurent U Perrinet  (2020). Humans adapt their anticipatory eye movements to the volatility of visual motion properties. PLoS Computational Biology.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2018-03-26-cours-neuro-comp-fep/" >Probabilities, Bayes and the Free-energy principle</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2018-02-01-bcp-invibe-fest/" >Estimating and anticipating a dynamic probabilistic bias in visual motion direction</a></h2>
      <div class="article-style">
        
          See the final publication @  Chloé Pasturel, Anna Montagnini, Laurent U Perrinet  (2020). Humans adapt their anticipatory eye movements to the volatility of visual motion properties. PLoS Computational Biology.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2018-01-25-meetup-neuronautes/" >Expériences autour de la perception de la forme en art et science</a></h2>
      <div class="article-style">
        
          Meetup Art et Neurosciences  Quoi
Meetup Art et Neurosciences Qui
Association NeuroNautes Quand
25 Janvier 2018 Où
Salle des voutes campus Saint Charles Support visuel
https://laurentperrinet.github.io/sciblog/files/2018-01-25_meetup-neuronautes.html (notes: la présentation peut mettre un certain temps à charger.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-11-24-neurosciences-robotique/" >Unsupervised learning applied to robotic vision</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-11-17-festival-interferences/" >Participation au jury</a></h2>
      <div class="article-style">
        
          FESTIVAL INTERFÉRENCES​ Cinéma Documentaire et Débat Public Le collectif Scènes Publiques composé de citoyens, chercheurs et cinéastes, organise la deuxième édition du Festival Interférences du 8 au 18 novembre 2017 à Lyon.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-11-15-colloque-master/" >What dynamic neural codes for efficient visual processing</a></h2>
      <div class="article-style">
        
          This seminar is an exercise to introduce the AMU masters into the format of international conferences. As such, we will try to introduce new concepts and results which will not be found in textbooks.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-06-28-telluride/" >Back to the present: dealing with delays in biological and neuromorphic systems</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-06-30-telluride/" >Tutorial on predictive coding</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-01-20-laconeu/" >Tutorial: Active inference for eye movements: Bayesian methods, neural inference, dynamics</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-01-19-laconeu/" >Tutorial: Sparse optimization in neural computations</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2017-01-18-laconeu/" >Back to the present: how neurons deal with delays</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-11-20-polly-maggoo/" >Participation au jury et entretien avec Clara Delmon</a></h2>
      <div class="article-style">
        
          RENCONTRES INTERNATIONALES SCIENCES &amp; CINÉMAS cinéma les Variétés L&rsquo;Association Polly Maggoo http://www.pollymaggoo.org/ programme la 10e édition des RENCONTRES INTERNATIONALES SCIENCES &amp; CINÉMAS (RISC) à Marseille, au cours desquelles l&rsquo;association programme des films à caractère scientifique.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-11-03-sigma/" >The flash-lag effect as a motion-based predictive shift</a></h2>
      <div class="article-style">
        
           Based on Perrinet et al, 2012 and Khoei et al, 2013 See a followup in Khoei et al, 2017  
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-11-03-gdr/" >Reinforcement contingencies modulate anticipatory smooth eye movements</a></h2>
      <div class="article-style">
        
          Natural environments potentially contain several interesting targets for goal-directed behavior. Thus sensorimotor systems need to operate a competitive selection based on behaviorally meaningful parameters. Recently, it has been observed that …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-10-26-perrinet-16-euvip/" >Biologically-inspired characterization of sparseness in natural images</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-10-26-fillatre-barlaud-perrinet-16-euvip/" >Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor</a></h2>
      <div class="article-style">
        
           See a followup in  Laurent U Perrinet, James A Bednar  (2015). Edge co-occurrences can account for rapid categorization of natural versus animal images. Scientific Reports.  Preprint  PDF  Cite  Code  DOI     
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-10-13-law/" >Eye movements as a model for active inference</a></h2>
      <div class="article-style">
        
          See the final publication @  Chloé Pasturel, Anna Montagnini, Laurent U Perrinet  (2020). Humans adapt their anticipatory eye movements to the volatility of visual motion properties. PLoS Computational Biology.
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-07-07-edp-proba/" >Modelling the dynamics of cognitive processes: from the Bayesian brain to particles</a></h2>
      <div class="article-style">
        
           See a followup in Perrinet et al, 2012  
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-04-28-mejanes/" >Les illusions visuelles, un révélateur du fonctionnement de notre cerveau</a></h2>
      <div class="article-style">
        
          Les illusions visuelles sont des créations d'artistes, de scientifiques et plus récemment, grâce aux réseaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2016-04-25-polly-maggoo/" >Les illusions visuelles, un révélateur du fonctionnement de notre cerveau</a></h2>
      <div class="article-style">
        
          Ce lundi 25 avril de 9h à 12h, je suis venu échanger au côté de Serge Dentin autour de films traitant du rapport fiction/réel, des illusion visuelles (\" Qu'est ce qu'une image? \"), des rapports d'échelles, de la perception, ... et qui sont projetés …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2015-11-05-chile/" >Motion-based prediction with neuromorphic hardware</a></h2>
      <div class="article-style">
        
          We stand at a point in history where our phones have become smart but lack a feature which prevails in most forms of living intelligence: vision. The ability to see is indeed an essential facet of intelligence which is developed in an autonomous …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2015-10-07-gdr-bio-comp/" >Motion-based prediction with neuromorphic hardware</a></h2>
      <div class="article-style">
        
          We stand at a point in history where our phones have become smart but lack a feature which prevails in most forms of living intelligence: vision. The ability to see is indeed an essential facet of intelligence which is developed in an autonomous …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2014-04-25-kaplan-beijing/" >Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</a></h2>
      <div class="article-style">
        
           see Kaplan and al, 2014  
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2014-03-20-manchester/" >WP5 - Demo 1.3 : Spiking model of motion-based prediction</a></h2>
      <div class="article-style">
        
          The question how the visual system is able to create a coherent representation of a rapidly changing environment in the presence of neural delays is not fully resolved. In this paper we use an abstract probabilistic framework and a spiking neural …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2014-01-10-int-fest/" >Axonal delays and on-time control of eye movements</a></h2>
      <div class="article-style">
        
          Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2013-11-26-brain-scales-demos/" >Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps</a></h2>
      <div class="article-style">
        
          Together with Bernhard Kaplan, we talked about how we aim at &ldquo;compiling&rdquo; a predictive motion-based approach as a spiking neural networks and then as a parallel wafer systems in the BrainscaleS project (Demo 1, Task4).
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2013-07-05-cerco/" >Edge co-occurrences and categorizing natural images</a></h2>
      <div class="article-style">
        
           See a followup in  Laurent U Perrinet, James A Bednar  (2015). Edge co-occurrences can account for rapid categorization of natural versus animal images. Scientific Reports.  Preprint  PDF  Cite  Code  DOI     
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2013-03-21-marseille/" >Why methods and tools are the key to artificial brain-like systems</a></h2>
      <div class="article-style">
        
          This session aims at presenting new ideas that emerged during the first years of BrainScaleS. Indeed, the collaborations that were initiated within the consortium led to the creation of novel tools as planned in the proposal but also some of which …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2012-05-10-itwist/" >Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
      <div class="article-style">
        
          Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2012-03-23-juelich/" >Apparent motion in V1 - Probabilistic approaches</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2012-03-22-juelich/" >MotionClouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2012-01-27-fil/" >Grabbing, tracking and sniffing as models for motion detection and eye movements</a></h2>
      <div class="article-style">
        
          Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2012-01-24-edinburgh/" >Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
      <div class="article-style">
        
          Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2012-01-12-vision-at-ucl/" >Motion-based prediction is sufficient to solve the aperture problem</a></h2>
      <div class="article-style">
        
          In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2011-11-15-sfn/" >Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
      <div class="article-style">
        
          Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2011-10-05-brain-scales-ess/" >Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2011-09-28-ermites/" >Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
      <div class="article-style">
        
          Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2011-07-02-neuro-med-talk/" >Propriétés émergentes d&#39;un modèle de prédiction probabiliste utilisant un champ neural</a></h2>
      <div class="article-style">
        
          Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2010-12-17-tauc-talk/" >Probabilistic models of the low-level visual system: the role of prediction in detecting motion</a></h2>
      <div class="article-style">
        
          Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2010-04-14-ondes-paralleles/" >Diffraction monochromatique, spectre audiographique</a></h2>
      <div class="article-style">
        
          En perception, les neurones « parlent » tous en même temps par de brèves impulsions électrochimiques, générant un mélange de signaux, un bruit. Pourtant c'est par eux que nous pensons, voyons, sentons. Les ordinateurs sont différents, plus rapides. …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2010-01-08-facets/" >Models of low-level vision: linking probabilistic models and neural masses</a></h2>
      <div class="article-style">
        
           see this more recent talk @ UCL, London  
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2009-11-30-vss/" >Reading out the dynamics of lateral interactions in the primary visual cortex from VSD data</a></h2>
      <div class="article-style">
        
          Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2009-11-24-intelligence-mecanique/" >Peut-on parler d&#39;intelligence mécanique?</a></h2>
      <div class="article-style">
        
          Nous parlerons de cette partie \"mécanique\" du cerveau animal ou humain qui permet de percevoir les mouvements et de ... survivre au sein de l'environnement. On verra, par exemple, que notre cerveau peut-être plus rapide que nous, qu'il y a des …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2009-07-18-kremkow-09-cnstalk/" >Control of the temporal interplay between excitation and inhibition by the statistics of visual input</a></h2>
      <div class="article-style">
        
           see this subsequent paper in the Journal of Computational Neuroscience  
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2009-04-01-int/" >Decoding low-level neural information to track visual motion</a></h2>
      <div class="article-style">
        
           Moving the eyes rapidly to track a visual object moving in a cluttered environment is an essential function. However, doing so rapidly and efficiently is constrained by a number of noise sources in the visual system and by the fact that information …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2008-06-01-ulm/" >Decoding the population dynamics underlying ocular following response using a probabilistic framework</a></h2>
      <div class="article-style">
        
          The machinery behind the visual perception of motion and the subsequent sensorimotor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2008-04-01-incm/" >From neural activity to behavior: computational neuroscience as a synthetic approach for understanding the neural code.</a></h2>
      <div class="article-style">
        
          Computational Neuroscience is a synthetic, inter-disciplinary approach aiming at understanding cognition by analyzing the mechanisms underlying neural computations. We present in this seminar our attempt in modeling low-level vision by bridging …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2008-02-01-toledo/" >Modeling of spikes, sparseness and adaptation in the primary visual cortex: applications to imaging</a></h2>
      <div class="article-style">
        
           related publications @ FENS 2006, @ NeuroComp 2008 and @ AREADNE 2008  
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2007-12-01-rankprize/" >What efficient code for adaptive spiking representations?</a></h2>
      <div class="article-style">
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2007-09-01-mipm/" >Neural Codes for Adaptive Sparse Representations of Natural Images</a></h2>
      <div class="article-style">
        
          I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm …
        
      </div>
    </div>
  
    
    
    
    <div>
      <h2><a href="/talk/2006-01-01-neurocomp/" >Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
      <div class="article-style">
        
          The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limitation of the visual motion analyzers (aperture problem). Perceptual and oculomotor data …
        
      </div>
    </div>
  

  

</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  <p class="powered-by">
    This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&rsquo;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared.
  </p>

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.71e713848164e269bc250f377042949d.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
