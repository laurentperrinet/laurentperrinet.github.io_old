@inproceedings{2023-12-14-jraf,
 author = {Adrien Fois and Perrinet, Laurent U},
 booktitle = {Journ√©es sur l'apprentissage frugal (JRAF)},
 date = {2023-12-14},
 location = {Grenoble (France)},
 projects = {computational neuroscience,event-based vision,neuromorphic hardware},
 time_start = {2023-12-14T14:00:00},
 time_end = {2023-12-14T14:45:00},
 title = {Event-based vision},
 url_link = {https://laurentperrinet.github.io/talk/2023-12-14-jraf},
    abstract = {Event-based cameras mimic the way biological retinas process visual information: each pixel independently reports brightness changes as asynchronous temporal events. This departs from conventional cameras that capture static frames at fixed intervals. I will first discuss how the biological retina detects light intensity changes and communicates this to the brain. Compared to traditional cameras, the event-based paradigm enables new vision applications with high-speed, low latency and energy-efficiency. I will highlight recent works applying event cameras to tasks such as visual odometry, motion detection or gesture recognition. The goal is to demonstrate the advantages for computer vision that emulate biological principles inspired by neurosciences.},
year = {2023}
}

