<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Novel visual computations</title>
    <link>https://laurentperrinet.github.io/project/</link>
      <atom:link href="https://laurentperrinet.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&#39;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. 
This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. </copyright><lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0200</lastBuildDate>
    <image>
      <url>https://laurentperrinet.github.io/img/hulk.png</url>
      <title>Projects</title>
      <link>https://laurentperrinet.github.io/project/</link>
    </image>
    
    <item>
      <title>Art &lt;&gt; Sciences</title>
      <link>https://laurentperrinet.github.io/project/art-science/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/project/art-science/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Open Science</title>
      <link>https://laurentperrinet.github.io/project/motion-clouds/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/project/motion-clouds/</guid>
      <description>

&lt;h1 id=&#34;biologically-inspired-computer-vision&#34;&gt;Biologically inspired computer vision&lt;/h1&gt;

&lt;h2 id=&#34;slip-a-simple-library-for-image-processing&#34;&gt;SLIP: a Simple Library for Image Processing&lt;/h2&gt;

&lt;p&gt;This library collects different Image Processing tools for use with the  &lt;a href=&#34;https://pythonhosted.org/LogGabor/&#34; target=&#34;_blank&#34;&gt;LogGabor&lt;/a&gt; and  &lt;a href=&#34;https://pythonhosted.org/SparseEdges/&#34; target=&#34;_blank&#34;&gt;SparseEdges&lt;/a&gt; libraries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pythonhosted.org/SLIP/&#34; target=&#34;_blank&#34;&gt;Web-site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bicv/SLIP/&#34; target=&#34;_blank&#34;&gt;Source code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;loggabor-a-simple-library-for-image-processing&#34;&gt;LogGabor: a Simple Library for Image Processing&lt;/h2&gt;

&lt;p&gt;This library collects different Image Processing tools for use with the  &lt;a href=&#34;https://pythonhosted.org/LogGabor/&#34; target=&#34;_blank&#34;&gt;LogGabor&lt;/a&gt; and  &lt;a href=&#34;https://pythonhosted.org/SparseEdges/&#34; target=&#34;_blank&#34;&gt;SparseEdges&lt;/a&gt; libraries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[Web-site]((&lt;a href=&#34;https://pythonhosted.org/LogGabor&#34; target=&#34;_blank&#34;&gt;https://pythonhosted.org/LogGabor&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bicv/LogGabor/&#34; target=&#34;_blank&#34;&gt;Source code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sparseedges-sparse-coding-of-natural-images&#34;&gt;SparseEdges: sparse coding of natural images&lt;/h2&gt;

&lt;p&gt;Our goal here is to build practical algorithms of sparse coding for computer vision.&lt;/p&gt;

&lt;p&gt;This class exploits the &lt;a href=&#34;https://pythonhosted.org/SLIP/&#34; target=&#34;_blank&#34;&gt;SLIP&lt;/a&gt; and &lt;a href=&#34;https://pythonhosted.org/LogGabor/&#34; target=&#34;_blank&#34;&gt;LogGabor&lt;/a&gt; libraries to provide with a sparse representation of edges in images.&lt;/p&gt;

&lt;p&gt;This algorithm was presented in the following paper, which is available as a reprint @ &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-15-bicv/&#34; target=&#34;_blank&#34;&gt;https://laurentperrinet.github.io/publication/perrinet-15-bicv/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pythonhosted.org/SparseEdges&#34; target=&#34;_blank&#34;&gt;Web-site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bicv/SparseEdges/&#34; target=&#34;_blank&#34;&gt;Source code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;motionclouds&#34;&gt;MotionClouds&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;MotionClouds&lt;/strong&gt; are random dynamic stimuli optimized to study motion perception.&lt;/p&gt;

&lt;p&gt;Motion Clouds are random, textured dynamical stimuli synthesized such as to challenge spatio-temporal integration properties of the early visual system. Unlike classical low-entropy stimuli such as gratings, these stimuli are less susceptible to create interference patterns when mixed together. This is essential to study integrative and discriminative properties of the low-level sensory systems. Moreover, this pseudo-random stimulation protocol allows to make a trial-by-trial analysis locked to the stimulation onset. This allows to study experimentally trial-by-trial variability and relative importance between measurement noise and contextual uncertainty.&lt;/p&gt;

&lt;p&gt;This is a first step before extending synthesis to probabilistic synthesis models of the texture&amp;rsquo;s geometric structure. The model will use geometrical multi-scale transformations extending the classical wavelet representation. For instance, these transformations synthesize the stimuli as randomized superposition of geometrical wavelets that match the spatio-temporal profile of association fields in V1. These will be implemented by computing evolutions of partial differential equations with randomized initial conditions. Finally, models are designed such that we explicitly tune the statistics of the generative model and thus control the structural complexity of the stimuli, such as different scales of smoothness in the spatio-temporal dynamics as displayed by natural scenes.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.motionclouds.invibe.net&#34; target=&#34;_blank&#34;&gt;Web-site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NeuralEnsemble/MotionClouds&#34; target=&#34;_blank&#34;&gt;Source code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Tout public!</title>
      <link>https://laurentperrinet.github.io/project/tout-public/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      <guid>https://laurentperrinet.github.io/project/tout-public/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
