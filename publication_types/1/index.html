

<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.0.0">
  <meta name="generator" content="Hugo 0.54.0" />

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Laurent Perrinet">

  
  
  
    
  
  <meta name="description" content="Researcher in Computational Neuroscience">

  
  <link rel="alternate" hreflang="en-us" href="https://laurentperrinet.github.io/publication_types/1/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://laurentperrinet.github.io/publication_types/1/index.xml" type="application/rss+xml" title="Novel visual computations">
  <link rel="feed" href="https://laurentperrinet.github.io/publication_types/1/index.xml" type="application/rss+xml" title="Novel visual computations">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://laurentperrinet.github.io/publication_types/1/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@laurentperrinet">
  <meta property="twitter:creator" content="@laurentperrinet">
  
  <meta property="og:site_name" content="Novel visual computations">
  <meta property="og:url" content="https://laurentperrinet.github.io/publication_types/1/">
  <meta property="og:title" content="1 | Novel visual computations">
  <meta property="og:description" content="Researcher in Computational Neuroscience"><meta property="og:image" content="https://laurentperrinet.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2019-01-01T00:00:00&#43;01:00">
  

  

  

  <title>1 | Novel visual computations</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"><img src="/img/hulk.png" alt="Novel visual computations"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true">
            
            <span>Publications</span>
            
            <span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/#publications">
                
                <span>Recent Publications</span>
                
              </a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/">
                
                <span>All Publications</span>
                
              </a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/#2">
                
                <span>Publications in journals</span>
                
              </a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/publication/#26">
                
                <span>Publications in books</span>
                
              </a>
            </li>
            
          </ul>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/talk/">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/grants/">
            
            <span>Grants</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>















  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1 itemprop="name">1</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
  <div>
    <h2><a href="/talk/2019-01-16-laconeu/">Efficient coding of visual information in neural computations</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2019-01-14-laconeu/">Modelling spiking neural networks using Brian, Nest and pyNN</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2019-01-17-laconeu/">Role of dynamics in neural computations underlying  visual processing</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2018-02-01-bcp-invibe-fest/">Estimating and anticipating a dynamic probabilistic bias in visual motion direction</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2018-01-25-meetup-neuronautes/">Exp√©riences autour de la perception de la forme en art et science</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2018-04-05-active-inference/">Principles and psychophysics of Active Inference</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2018-04-05-bcp-talk/">Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2018-03-26-cours-neuro-comp-fep/">Probabilities, Bayes and the Free-energy principle</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-06-28-telluride/">Back to the present: dealing with delays in biological and neuromorphic systems</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-01-18-laconeu/">Back to the present: how neurons deal with delays</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-06-30-telluride/">Tutorial on predictive coding</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-01-20-laconeu/">Tutorial: Active inference for eye movements: Bayesian methods, neural inference, dynamics</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-01-19-laconeu/">Tutorial: Sparse optimization in neural computations</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-11-24-neurosciences-robotique/">Unsupervised learning applied to robotic vision</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2017-11-15-colloque-master/">What dynamic neural codes for efficient visual processing</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2016-10-26-perrinet-16-euvip/">Biologically-inspired characterization of sparseness in natural images</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2016-10-26-fillatre-barlaud-perrinet-16-euvip/">Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2016-10-13-law/">Eye movements as a model for active inference</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2016-07-07-edp-proba/">Modelling the dynamics of cognitive processes: from the Bayesian brain to particles</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2016-11-03-gdr/">Reinforcement contingencies modulate anticipatory smooth eye movements</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2016-11-03-sigma/">The flash-lag effect as a motion-based predictive shift</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2015-10-07-gdr-bio-comp/">Motion-based prediction with neuromorphic hardware</a></h2>
    <div class="article-style">
      
        We stand at a point in history where our phones have become smart but  lack a feature which prevails in most forms of living intelligence:  vision. The ability to see is indeed an essential facet of intelligence  which is developed in an autonomous ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2015-11-05-chile/">Motion-based prediction with neuromorphic hardware</a></h2>
    <div class="article-style">
      
       We stand at a point in history where our phones have become smart but  lack a feature which prevails in most forms of living intelligence:  vision. The ability to see is indeed an essential facet of intelligence  which is developed in an autonomous ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-01-10-int-fest/">Axonal delays and on-time control of eye movements</a></h2>
    <div class="article-style">
      
      Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-04-25-kaplan-beijing/">Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2014-03-20-manchester/">WP5 - Demo 1.3 : Spiking model of motion-based prediction</a></h2>
    <div class="article-style">
      
          The question how the visual system is able to create a coherent representation of a rapidly changing environment in the presence of neural delays is not fully resolved. In this paper we use an abstract probabilistic framework and a spiking neural ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2013-11-26-brain-scales-demos/">Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2013-07-05-cerco/">Edge co-occurrences and categorizing natural images</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2013-03-21-marseille/">Why methods and tools are the key to artificial brain-like systems</a></h2>
    <div class="article-style">
      
      This session aims at presenting new ideas that emerged during the first years of BrainScaleS. Indeed, the collaborations that were initiated within the consortium led to the creation of novel tools as planned in the proposal but also some of which ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-03-23-juelich/">Apparent motion in V1 - Probabilistic approaches</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-24-edinburgh/">Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
    <div class="article-style">
      
      Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-05-10-itwist/">Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
    <div class="article-style">
      
      Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-27-fil/">Grabbing, tracking and sniffing as models for motion detection and eye movements</a></h2>
    <div class="article-style">
      
      Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-03-22-juelich/">Motion Clouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2012-01-12-vision-at-ucl/">Motion-based prediction is sufficient to solve the aperture problem</a></h2>
    <div class="article-style">
      
      In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2011-10-05-brain-scales-ess/">Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2011-09-28-ermites/">Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
    <div class="article-style">
      
      Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2011-11-15-sfn/">Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
    <div class="article-style">
      
      Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2011-07-02-neuro-med-talk/">Propri√©t√©s √©mergentes d&#39;un mod√®le de pr√©diction probabiliste utilisant un champ neural</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2010-12-17-tauc-talk/">Probabilistic models of the low-level visual system: the role of prediction in detecting motion</a></h2>
    <div class="article-style">
      
      Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2009-07-18-kremkow-09-cnstalk/">Control of the temporal interplay between excitation and inhibition by the statistics of visual input</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2009-04-int/">Decoding low-level neural information to track visual motion</a></h2>
    <div class="article-style">
      
       Moving the eyes rapidly to track a visual object moving in a cluttered environment is an essential  function. However, doing so rapidly and efficiently is constrained by a number of noise sources in the  visual system and by the fact that ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2009-11-30-vss/">Reading out the dynamics of lateral interactions in the primary visual cortex from VSD data</a></h2>
    <div class="article-style">
      
      Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2008-06-ulm/">Decoding the population dynamics underlying ocular following response using a probabilistic framework</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensorimotor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate‚Äôs visual system. We may ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2008-04-incm/">From neural activity to behavior: computational neuroscience as a synthetic approach for understanding the neural code.</a></h2>
    <div class="article-style">
      
      Computational Neuroscience is a synthetic, inter-disciplinary approach aiming at understanding cognition by analyzing the mechanisms underlying neural computations. We present in this seminar our attempt in modeling low-level vision by bridging ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2008-02-toledo/">Modeling of spikes, sparseness and adaptation in the primary visual cortex: applications to imaging</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2007-09-mipm/">Neural Codes for Adaptive Sparse Representations of Natural Images</a></h2>
    <div class="article-style">
      
      I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2007-12-rankprize/">What efficient code for adaptive spiking representations?</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/talk/2006-neurocomp/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/fischer-05-a/">Sparse Gabor wavelets by local operations</a></h2>
    <div class="article-style">
      
      Efficient sparse coding of overcomplete transforms remains still anopen problem. Different methods have been proposed in theliterature, but most of them are limited by a heavy computationalcost and by difficulties to find the optimal solutions. We ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/vacher-15-icms/">A Mathematical Account of Dynamic Texture Synthesis for Probing Visual Perception</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/taouali-14-areadne/">A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/taouali-14-neurocomp/">A Simple Model of Orientation Encoding Accounting For Multivariate Neural Noise</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/taouali-15-vss/">A dynamic model for decoding direction and orientation in macaque primary visual cortex</a></h2>
    <div class="article-style">
      
      Natural scenes generally contain objects in motion. The local orientation of their contours and the direction of motion are two essential components of visual information which are processed in parallel in the early visual areas. Focusing on the ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-00/">A generative model for Spike Time Dependent Hebbian Plasticity</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/bogadhi-10-vss/">A recurrent Bayesian model of dynamic motion integration for smooth pursuit</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-13-cns/">Active inference, eye movements and oculomotor delays.</a></h2>
    <div class="article-style">
      
      We consider the problem of sensorimotor delays in the optimal control of movement under un- certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-13-jffos/">Active inference, eye movements and oculomotor delays.</a></h2>
    <div class="article-style">
      
      We consider the problem of sensorimotor delays in the optimal control of movement under un- certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-12-areadne/">Active inference, smooth pursuit and oculomotor delays.</a></h2>
    <div class="article-style">
      
      We consider the problem of sensorimotor delays in the optimal control of movement under un- certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-spie/">Adaptive Sparse Spike Coding : applications of Neuroscience to the compression of natural images</a></h2>
    <div class="article-style">
      
      If modern computers are sometimes superior to cognition in some specialized tasks such as playing chess or browsing a large database, they can't beat the efficiency of biological vision for such simple tasks as recognizing a relative or following an ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-cns/">An efficiency razor for model selection and adaptation in the primary visual cortex</a></h2>
    <div class="article-style">
      
      We describe the theoretical formulation of a learning algorithm in a model of the primary visual cortex (V1) and present results of the efficiency of this algorithm by comparing it to the SparseNet algorithm (Olshausen, 1996). As the SparseNet ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/voges-08-neurocomp/">Analyzing cortical network dynamics with respect to different connectivity assumptions</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-15-sfn/">Anticipating a moving target: role of vision and reinforcement</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/damasse-15-vss/">Anticipatory smooth eye movements and reinforcement</a></h2>
    <div class="article-style">
      
      When an object is moving in the visual field, we are able to accurately track it with a combination of saccades and smooth eye movements. These movements allow us to align and stabilize the object on the fovea, thus enabling visual analysis with high ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-16-euvip/">Biologically-inspired characterization of sparseness in natural images</a></h2>
    <div class="article-style">
      
      Natural images follow statistics inherited by the structure of our physical (visual) environment. In particular, a prominent facet of this structure is that images can be described by a relatively sparse number of features. We designed a sparse ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-16-networks/">Compensation of oculomotor delays in the visual system&#39;s network.</a></h2>
    <div class="article-style">
      
      We consider the problem of sensorimotor delays in the optimal control of movement under un- certainty. Specifically, we consider axonal conduction delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/wohrer-06/">Contrast sensitivity adaptation in a virtual spiking retina and its adequation with mammalians retinas</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kremkow-08-sfn/">Control of the temporal interplay between excitation and inhibition by the statistics of visual input: a V1 network modelling study</a></h2>
    <div class="article-style">
      
      In the primary visual cortex (V1), single cell responses to simple visual stimuli (gratings) are usually dense but with a high trial-by-trial variability. In contrast, when exposed to full field natural scenes, the firing patterns of these neurons ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-09-cosyne/">Decoding center-surround interactions in population of neurons for the ocular following response</a></h2>
    <div class="article-style">
      
      Short presentation of a large moving pattern elicits an Ocular Following Response (OFR) that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-areadne/">Decoding the population dynamics underlying ocular following response using a probabilistic framework</a></h2>
    <div class="article-style">
      
      The machinery behind the visual perception of motion and the subsequent sensorimotor transformation, such as in Ocular Following Response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-10-vss/">Different pooling of motion information for perceptual speed discrimination and behavioral speed estimation</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/vacher-14-ihp/">Dynamic Textures For Probing Motion Perception</a></h2>
    <div class="article-style">
      
      This work extends the MotionClouds dynamic texture model testing aspects of its parametrization with an application in psychophysics.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-07-a/">Dynamic inference for motion tracking</a></h2>
    <div class="article-style">
      
      When the visual information about an object's motion differs at the local level, the visuomotor system needs to integrate information across time to solve this ambiguity and converge to the final motion solution. For an oblique line moving ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-ciotat/">Dynamical contrast gain control mechanisms in a layer 2/3 model of the primary visual cortex</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-fab/">Dynamical contrast gain control mechanisms in a layer 2/3 model of the primary visual cortex</a></h2>
    <div class="article-style">
      
      Computations in a cortical column are characterized by the dynamical, event-based nature of neuronal signals and are structured by the layered and parallel structure of cortical areas. But they are also characterized by their efficiency in terms of ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-10-areadne/">Dynamical emergence of a neural solution for motion integration</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/voges-09-cosyne/">Dynamical state spaces of cortical networks representing various horizontal connectivities</a></h2>
    <div class="article-style">
      
      Most studies of cor tical network dynamics are either based on purely random wiring or neighborhood cou- plings, e.g., [Kumar, Schrader, Aer tsen, Rotter, 2008, Neural Computation 20, 1--43]. Neuronal connections in the cor tex, however, show a ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/voges-08/">Dynamics of cortical networks based on patchy connectivity patterns</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/voges-09-gns/">Dynamics of cortical networks including long-range patchy connections</a></h2>
    <div class="article-style">
      
      Most studies of cortical network dynamics are either based on purely random wiring or neighborhood couplings [1], focussing on a rather local scale. Neuronal connections in the cortex, however, show a more complex spatial pattern composed of local ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-05-a/">Dynamics of motion representation in short-latency ocular following: A two-pathways Bayesian model</a></h2>
    <div class="article-style">
      
      The integration of information is essential to measure the exact 2D motion of a surface from both local ambiguous 1D motion produced by elongated edges and local non-ambiguous 2D motion from features such as corners, end-points or texture elements. ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-11-sfn/">Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1</a></h2>
    <div class="article-style">
      
      Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/montagnini-16-ecvp/">Effects of motion predictability on anticipatory and visually-guided eye movements: a common prior for sensory processing and motor control?</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/boutin-ruffier-perrinet-17-neurofrance/">Efficient learning of sparse image representations using homeostatic regulation</a></h2>
    <div class="article-style">
      
      One core advantage of sparse representations is the efficient coding of complex signals using compact codes. For instance, it allows for the representation of any image as a combination of few elements drawn from a large dictionary of basis ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/boutin-ruffier-perrinet-17-spars/">Efficient learning of sparse image representations using homeostatic regulation</a></h2>
    <div class="article-style">
      
      One core advantage of sparse representations is the efficient coding of complex signals using compact codes. For instance, it allows for the representation of any image as a combination of few elements drawn from a large dictionary of basis ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/fischer-05/">Efficient representation of natural images using local cooperation</a></h2>
    <div class="article-style">
      
      Low-level perceptual computations may be understood in terms of efficient codes (Simoncelli and Olshausen, 2001, Annual Review of Neuroscience 24 1193-216). Following this argument, we explore models of representation for natural static images as a ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/danion-15-sfn/">Eye tracking a self-moved target with complex hand-target dynamics</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/boutin-franciosini-ruffier-perrinet-18-itwist/">From biological vision to unsupervised hierarchical sparse coding</a></h2>
    <div class="article-style">
      
      The formation of connections between neural cells is essentially emerging from an unsupervised learning process. During the development of primary visual cortex (V1) of mammals, for example, one may observe the emergence of cells selective to ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kremkow-09-gns/">Functional consequences of correlated excitation and inhibition on single neuron integration and signal propagation through synfire chains</a></h2>
    <div class="article-style">
      
      Neurons receive a large number of excitatory and inhibitory synaptic inputs whose temporal interplay determines their spiking behavior. On average, excitation (Gexc) and inhibition (Ginh) balance each other, such that spikes are elicited by ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/kremkow-08-neurocomp/">Functional properties of feed-forward inhibition</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/meso-13-vss/">How and why do image frequency properties influence perceived speed?</a></h2>
    <div class="article-style">
      
      Humans are able to interact successfully with moving objects in our dynamic world and the visual system effi ciently performs the motion computation that makes this possible. Object speed and direction are estimated following the integration of ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-09-vss/">Inferring monkey ocular following responses from V1 population dynamics using a probabilistic model of motion integration</a></h2>
    <div class="article-style">
      
      Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-fens/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-06-neurocomp/">Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework</a></h2>
    <div class="article-style">
      
      The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limi- tation of the visual motion analyzers (aperture prob- lem). Perceptual and oculomotor ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/dupeyroux-boutin-serres-perrinet-viollet-18/">M2APix: a bio-inspired auto-adaptive visual sensor for robust ground height estimation</a></h2>
    <div class="article-style">
      
      This paper presents for the first time the embedded stand-alone version of the bio-inspired M2APix (Michaelis-Menten auto-adaptive pixels) sensor as a ventral optic flow sensor to endow glider-type unmanned aerial vehicles with autonomous landing ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-12-coding/">Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.</a></h2>
    <div class="article-style">
      
      To measure speed and direction of moving objects, the cortical motion system pools information across different spatiotemporal channels. One yet unsolved question is to understand how the brain pools this information and whether this pooling is ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-12-vss/">Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.</a></h2>
    <div class="article-style">
      
      Under natural viewing conditions, small movements of the eyes prevent the maintenance of a steady direction of gaze. It is unclear how the spatiotemporal content of the fixated scene has an impact on the properties of miniatures, fixational eye ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/simoncini-13-vss/">Measuring speed of moving textures: Different pooling of motion information for human ocular following and perception.</a></h2>
    <div class="article-style">
      
      The visual system does not process information instantaneously, but rather integrates over time. Integration occurs both for stationary objects and moving objects, with very similar time constants (Burr, 1981). We measured, as a function of exposure ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/redondo-05/">Modeling of simple cells through a sparse overcomplete gabor wavelet representation based on local inhibition and facilitation</a></h2>
    <div class="article-style">
      
      We present a biologically plausible model of simple cortical cells as 1) a linear transform representing edges and 2) a non-linear iterative stage of inhibition and facilitation between neighboring coefficients. The linear transform is a complex ‚Ä¶
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/perrinet-08-a/">Modeling spatial integration in the ocular following response to center-surround stimulation using a probabilistic framework</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="/publication/damasse-16-ecvp/">Modeling the effect of dynamic contingencies on anticipatory eye movements</a></h2>
    <div class="article-style">
      
    </div>
  </div>
  

  
<nav>
  <ul class="pagination justify-content-center">
    
    
    <li class="page-item"><a class="page-link" href="/publication_types/1/page/2/">&raquo;</a></li>
    
  </ul>
</nav>


</div>
<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author&rsquo;s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>
Please note that multiple distribution, publication or commercial usage of copyrighted papers included in this website would require submission of a permission request addressed to the journal in which the paper appeared. &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.109caa4f51ff39522c6dfc25fb05b6e9.js"></script>

  </body>
</html>



